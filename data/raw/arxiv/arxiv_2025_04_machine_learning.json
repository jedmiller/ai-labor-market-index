{
  "query": "all:machine learning AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-05-03T02:36:51.514962",
  "target_period": "2025-04",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2505.00222v1",
      "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
      "published": "2025-04-30T23:55:44Z",
      "updated": "2025-04-30T23:55:44Z",
      "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.",
      "authors": [
        "Peter Yichen Chen",
        "Pingchuan Ma",
        "Niklas Hagemann",
        "John Romanishin",
        "Wei Wang",
        "Daniela Rus",
        "Wojciech Matusik"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "physics.comp-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00222v1",
        "http://arxiv.org/pdf/2505.00222v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21789v1",
      "title": "Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation",
      "published": "2025-04-30T16:48:00Z",
      "updated": "2025-04-30T16:48:00Z",
      "summary": "Magnetic Resonance Imaging (MRI) plays an important role in identifying\nclinically significant prostate cancer (csPCa), yet automated methods face\nchallenges such as data imbalance, variable tumor sizes, and a lack of\nannotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which\nincorporates anomaly maps derived from biparametric MRI sequences into a deep\nlearning-based segmentation framework to improve csPCa identification. We\nconduct a comparative analysis of anomaly detection methods and evaluate the\nintegration of anomaly maps into the segmentation pipeline. Anomaly maps,\ngenerated using Fixed-Point GAN reconstruction, highlight deviations from\nnormal prostate tissue, guiding the segmentation model to potential cancerous\nregions. We compare the performance by using the average score, computed as the\nmean of the AUROC and Average Precision (AP). On the external test set, adU-Net\nachieves the best average score of 0.618, outperforming the baseline nnU-Net\nmodel (0.605). The results demonstrate that incorporating anomaly detection\ninto segmentation improves generalization and performance, particularly with\nADC-based anomaly maps, offering a promising direction for automated csPCa\nidentification.",
      "authors": [
        "Alessia Hu",
        "Regina Beets-Tan",
        "Lishan Cai",
        "Eduardo Pooch"
      ],
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21789v1",
        "http://arxiv.org/pdf/2504.21789v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21464v1",
      "title": "VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep\n  Network for Diabetic Retinopathy Classification",
      "published": "2025-04-30T09:38:47Z",
      "updated": "2025-04-30T09:38:47Z",
      "summary": "Diabetic retinopathy is a severe eye condition caused by diabetes where the\nretinal blood vessels get damaged and can lead to vision loss and blindness if\nnot treated. Early and accurate detection is key to intervention and stopping\nthe disease progressing. For addressing this disease properly, this paper\npresents a comprehensive approach for automated diabetic retinopathy detection\nby proposing a new hybrid deep learning model called VR-FuseNet. Diabetic\nretinopathy is a major eye disease and leading cause of blindness especially\namong diabetic patients so accurate and efficient automated detection methods\nare required. To address the limitations of existing methods including dataset\nimbalance, diversity and generalization issues this paper presents a hybrid\ndataset created from five publicly available diabetic retinopathy datasets.\nEssential preprocessing techniques such as SMOTE for class balancing and CLAHE\nfor image enhancement are applied systematically to the dataset to improve the\nrobustness and generalizability of the dataset. The proposed VR-FuseNet model\ncombines the strengths of two state-of-the-art convolutional neural networks,\nVGG19 which captures fine-grained spatial features and ResNet50V2 which is\nknown for its deep hierarchical feature extraction. This fusion improves the\ndiagnostic performance and achieves an accuracy of 91.824%. The model\noutperforms individual architectures on all performance metrics demonstrating\nthe effectiveness of hybrid feature extraction in Diabetic Retinopathy\nclassification tasks. To make the proposed model more clinically useful and\ninterpretable this paper incorporates multiple XAI techniques. These techniques\ngenerate visual explanations that clearly indicate the retinal features\naffecting the model's prediction such as microaneurysms, hemorrhages and\nexudates so that clinicians can interpret and validate.",
      "authors": [
        "Shamim Rahim Refat",
        "Ziyan Shirin Raha",
        "Shuvashis Sarker",
        "Faika Fairuj Preotee",
        "MD. Musfikur Rahman",
        "Tashreef Muhammad",
        "Mohammad Shafiul Islam"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21464v1",
        "http://arxiv.org/pdf/2504.21464v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21254v1",
      "title": "ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph\n  Representation Learning",
      "published": "2025-04-30T01:44:27Z",
      "updated": "2025-04-30T01:44:27Z",
      "summary": "Effective and efficient graph representation learning is essential for\nenabling critical downstream tasks, such as node classification, link\nprediction, and subgraph search. However, existing graph neural network (GNN)\narchitectures often struggle to adapt to diverse and complex graph structures,\nlimiting their ability to provide robust and generalizable representations. To\naddress this challenge, we propose ABG-NAS, a novel framework for automated\ngraph neural network architecture search tailored for efficient graph\nrepresentation learning. ABG-NAS encompasses three key components: a\nComprehensive Architecture Search Space (CASS), an Adaptive Genetic\nOptimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASS\nsystematically explores diverse propagation (P) and transformation (T)\noperations, enabling the discovery of GNN architectures capable of capturing\nintricate graph characteristics. AGOS dynamically balances exploration and\nexploitation, ensuring search efficiency and preserving solution diversity.\nBGTM further optimizes hyperparameters periodically, enhancing the scalability\nand robustness of the resulting architectures. Empirical evaluations on\nbenchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate that\nABG-NAS consistently outperforms both manually designed GNNs and\nstate-of-the-art neural architecture search (NAS) methods. These results\nhighlight the potential of ABG-NAS to advance graph representation learning by\nproviding scalable and adaptive solutions for diverse graph structures. Our\ncode is publicly available at https://github.com/sserranw/ABG-NAS.",
      "authors": [
        "Sixuan Wang",
        "Jiao Yin",
        "Jinli Cao",
        "MingJian Tang",
        "Hua Wang",
        "Yanchun Zhang"
      ],
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21254v1",
        "http://arxiv.org/pdf/2504.21254v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21245v1",
      "title": "Database and deep-learning scalability of anharmonic phonon properties\n  by automated brute-force first-principles calculations",
      "published": "2025-04-30T00:54:32Z",
      "updated": "2025-04-30T00:54:32Z",
      "summary": "Understanding the anharmonic phonon properties of crystal compounds -- such\nas phonon lifetimes and thermal conductivities -- is essential for\ninvestigating and optimizing their thermal transport behaviors. These\nproperties also impact optical, electronic, and magnetic characteristics\nthrough interactions between phonons and other quasiparticles and fields. In\nthis study, we develop an automated first-principles workflow to calculate\nanharmonic phonon properties and build a comprehensive database encompassing\nmore than 6,000 inorganic compounds. Utilizing this dataset, we train a graph\nneural network model to predict thermal conductivity values and spectra from\nstructural parameters, demonstrating a scaling law in which prediction accuracy\nimproves with increasing training data size. High-throughput screening with the\nmodel enables the identification of materials exhibiting extreme thermal\nconductivities -- both high and low. The resulting database offers valuable\ninsights into the anharmonic behavior of phonons, thereby accelerating the\ndesign and development of advanced functional materials.",
      "authors": [
        "Masato Ohnishi",
        "Tianqi Deng",
        "Pol Torres",
        "Zhihao Xu",
        "Terumasa Tadano",
        "Haoming Zhang",
        "Wei Nong",
        "Masatoshi Hanai",
        "Zhiting Tian",
        "Ming Hu",
        "Xiulin Ruan",
        "Ryo Yoshida",
        "Toyotaro Suzumura",
        "Lucas Lindsay",
        "Alan J. H. McGaughey",
        "Tengfei Luo",
        "Kedar Hippalgaonkar",
        "Junichiro Shiomi"
      ],
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21245v1",
        "http://arxiv.org/pdf/2504.21245v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21211v1",
      "title": "A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in\n  Online Marketplaces",
      "published": "2025-04-29T22:34:42Z",
      "updated": "2025-04-29T22:34:42Z",
      "summary": "Wildlife trafficking remains a critical global issue, significantly impacting\nbiodiversity, ecological stability, and public health. Despite efforts to\ncombat this illicit trade, the rise of e-commerce platforms has made it easier\nto sell wildlife products, putting new pressure on wild populations of\nendangered and threatened species. The use of these platforms also opens a new\nopportunity: as criminals sell wildlife products online, they leave digital\ntraces of their activity that can provide insights into trafficking activities\nas well as how they can be disrupted. The challenge lies in finding these\ntraces. Online marketplaces publish ads for a plethora of products, and\nidentifying ads for wildlife-related products is like finding a needle in a\nhaystack. Learning classifiers can automate ad identification, but creating\nthem requires costly, time-consuming data labeling that hinders support for\ndiverse ads and research questions. This paper addresses a critical challenge\nin the data science pipeline for wildlife trafficking analytics: generating\nquality labeled data for classifiers that select relevant data. While large\nlanguage models (LLMs) can directly label advertisements, doing so at scale is\nprohibitively expensive. We propose a cost-effective strategy that leverages\nLLMs to generate pseudo labels for a small sample of the data and uses these\nlabels to create specialized classification models. Our novel method\nautomatically gathers diverse and representative samples to be labeled while\nminimizing the labeling costs. Our experimental evaluation shows that our\nclassifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We\npresent real use cases that demonstrate the effectiveness of our approach in\nenabling analyses of different aspects of wildlife trafficking.",
      "authors": [
        "Juliana Barbosa",
        "Ulhas Gondhali",
        "Gohar Petrossian",
        "Kinshuk Sharma",
        "Sunandan Chakraborty",
        "Jennifer Jacquet",
        "Juliana Freire"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3725256",
        "http://arxiv.org/abs/2504.21211v1",
        "http://arxiv.org/pdf/2504.21211v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21194v1",
      "title": "Geolocating Earth Imagery from ISS: Integrating Machine Learning with\n  Astronaut Photography for Enhanced Geographic Mapping",
      "published": "2025-04-29T22:00:02Z",
      "updated": "2025-04-29T22:00:02Z",
      "summary": "This paper presents a novel approach to geolocating images captured from the\nInternational Space Station (ISS) using advanced machine learning algorithms.\nDespite having precise ISS coordinates, the specific Earth locations depicted\nin astronaut-taken photographs often remain unidentified. Our research\naddresses this gap by employing three distinct image processing pipelines: a\nNeural Network based approach, a SIFT based method, and GPT-4 model. Each\npipeline is tailored to process high-resolution ISS imagery, identifying both\nnatural and man-made geographical features. Through extensive evaluation on a\ndiverse dataset of over 140 ISS images, our methods demonstrate significant\npromise in automated geolocation with varied levels of success. The NN approach\nshowed a high success rate in accurately matching geographical features, while\nthe SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided\nenriched geographical descriptions alongside location predictions. This\nresearch contributes to the fields of remote sensing and Earth observation by\nenhancing the accuracy and efficiency of geolocating space-based imagery,\nthereby aiding environmental monitoring and global mapping efforts.",
      "authors": [
        "Vedika Srivastava",
        "Hemant Kumar Singh",
        "Jaisal Singh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21194v1",
        "http://arxiv.org/pdf/2504.21194v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21190v1",
      "title": "TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse\n  Mixture-of-Experts",
      "published": "2025-04-29T21:46:43Z",
      "updated": "2025-04-29T21:46:43Z",
      "summary": "We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA\nMoE), a novel computational framework integrating Parameter-Efficient\nFine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in\nlarge model deployments. Unlike traditional MoE approaches, which face\nsubstantial computational overhead as expert counts grow, TT-LoRA MoE\ndecomposes training into two distinct, optimized stages. First, we\nindependently train lightweight, tensorized low-rank adapters (TT-LoRA\nexperts), each specialized for specific tasks. Subsequently, these expert\nadapters remain frozen, eliminating inter-task interference and catastrophic\nforgetting in multi-task setting. A sparse MoE router, trained separately,\ndynamically leverages base model representations to select exactly one\nspecialized adapter per input at inference time, automating expert selection\nwithout explicit task specification. Comprehensive experiments confirm our\narchitecture retains the memory efficiency of low-rank adapters, seamlessly\nscales to large expert pools, and achieves robust task-level optimization. This\nstructured decoupling significantly enhances computational efficiency and\nflexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion\nparameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling\npractical and scalable multi-task inference deployments.",
      "authors": [
        "Pradip Kunwar",
        "Minh N. Vu",
        "Maanak Gupta",
        "Mahmoud Abdelsalam",
        "Manish Bhattarai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21190v1",
        "http://arxiv.org/pdf/2504.21190v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21174v1",
      "title": "Efficient LLMs with AMP: Attention Heads and MLP Pruning",
      "published": "2025-04-29T20:50:08Z",
      "updated": "2025-04-29T20:50:08Z",
      "summary": "Deep learning drives a new wave in computing systems and triggers the\nautomation of increasingly complex problems. In particular, Large Language\nModels (LLMs) have significantly advanced cognitive tasks, often matching or\neven surpassing human-level performance. However, their extensive parameters\nresult in high computational costs and slow inference, posing challenges for\ndeployment in resource-limited settings. Among the strategies to overcome the\naforementioned challenges, pruning emerges as a successful mechanism since it\nreduces model size while maintaining predictive ability. In this paper, we\nintroduce AMP: Attention Heads and MLP Pruning, a novel structured pruning\nmethod that efficiently compresses LLMs by removing less critical structures\nwithin Multi-Head Attention (MHA) and Multilayer Perceptron (MLP). By\nprojecting the input data onto weights, AMP assesses structural importance and\novercomes the limitations of existing techniques, which often fall short in\nflexibility or efficiency. In particular, AMP surpasses the current\nstate-of-the-art on commonsense reasoning tasks by up to 1.49 percentage\npoints, achieving a 30% pruning ratio with minimal impact on zero-shot task\nperformance. Moreover, AMP also improves inference speeds, making it\nwell-suited for deployment in resource-constrained environments. We confirm the\nflexibility of AMP on different families of LLMs, including LLaMA and Phi.",
      "authors": [
        "Leandro Giusti Mugnaini",
        "Bruno Lopes Yamamoto",
        "Lucas Lauton de Alcantara",
        "Victor Zacarias",
        "Edson Bollis",
        "Lucas Pellicer",
        "Anna Helena Reali Costa",
        "Artur Jordao"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21174v1",
        "http://arxiv.org/pdf/2504.21174v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21166v1",
      "title": "Dance Style Recognition Using Laban Movement Analysis",
      "published": "2025-04-29T20:35:01Z",
      "updated": "2025-04-29T20:35:01Z",
      "summary": "The growing interest in automated movement analysis has presented new\nchallenges in recognition of complex human activities including dance. This\nstudy focuses on dance style recognition using features extracted using Laban\nMovement Analysis. Previous studies for dance style recognition often focus on\ncross-frame movement analysis, which limits the ability to capture temporal\ncontext and dynamic transitions between movements. This gap highlights the need\nfor a method that can add temporal context to LMA features. For this, we\nintroduce a novel pipeline which combines 3D pose estimation, 3D human mesh\nreconstruction, and floor aware body modeling to effectively extract LMA\nfeatures. To address the temporal limitation, we propose a sliding window\napproach that captures movement evolution across time in features. These\nfeatures are then used to train various machine learning methods for\nclassification, and their explainability explainable AI methods to evaluate the\ncontribution of each feature to classification performance. Our proposed method\nachieves a highest classification accuracy of 99.18\\% which shows that the\naddition of temporal context significantly improves dance style recognition\nperformance.",
      "authors": [
        "Muhammad Turab",
        "Philippe Colantoni",
        "Damien Muselet",
        "Alain Tremeau"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21166v1",
        "http://arxiv.org/pdf/2504.21166v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20993v1",
      "title": "GDP-GFCF Dynamics Across Global Economies: A Comparative Study of Panel\n  Regressions and Random Forest",
      "published": "2025-04-29T17:58:47Z",
      "updated": "2025-04-29T17:58:47Z",
      "summary": "This study examines the relationship between GDP growth and Gross Fixed\nCapital Formation (GFCF) across developed economies (G7, EU-15, OECD) and\nemerging markets (BRICS). We integrate Random Forest machine learning\n(non-linear regression) with traditional econometric models (linear regression)\nto better capture non-linear interactions in investment analysis. Our findings\nreveal that while GDP growth positively influences corporate investment, its\nimpact varies significantly by region. Developed economies show stronger\nGDP-GFCF linkages due to stable financial systems, while emerging markets\ndemonstrate weaker connections due to economic heterogeneity and structural\nconstraints. Random Forest models indicate that GDP growth's importance is\nlower than suggested by traditional econometrics, with lagged GFCF emerging as\nthe dominant predictor-confirming investment follows path-dependent patterns\nrather than short-term GDP fluctuations. Regional variations in investment\ndrivers are substantial: taxation significantly influences developed economies\nbut minimally affects BRICS, while unemployment strongly drives investment in\nBRICS but less so elsewhere. We introduce a parallelized p-value importance\nalgorithm for Random Forest that enhances computational efficiency while\nmaintaining statistical rigor through sequential testing methods (SPRT and\nSAPT). The research demonstrates that hybrid methodologies combining machine\nlearning with econometric techniques provide more nuanced understanding of\ninvestment dynamics, supporting region-specific policy design and improving\nforecasting accuracy.",
      "authors": [
        "Alina Landowska",
        "Robert A. K\u0142opotek",
        "Dariusz Filip",
        "Konrad Raczkowski"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20993v1",
        "http://arxiv.org/pdf/2504.20993v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20970v1",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep\n  Features",
      "published": "2025-04-29T17:39:16Z",
      "updated": "2025-04-29T17:39:16Z",
      "summary": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.",
      "authors": [
        "Mete Erdogan",
        "Sebnem Demirtas"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20970v1",
        "http://arxiv.org/pdf/2504.20970v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20965v1",
      "title": "AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM\n  Security",
      "published": "2025-04-29T17:36:05Z",
      "updated": "2025-04-29T17:36:05Z",
      "summary": "We introduce AegisLLM, a cooperative multi-agent defense against adversarial\nattacks and information leakage. In AegisLLM, a structured workflow of\nautonomous agents - orchestrator, deflector, responder, and evaluator -\ncollaborate to ensure safe and compliant LLM outputs, while self-improving over\ntime through prompt optimization. We show that scaling agentic reasoning system\nat test-time - both by incorporating additional agent roles and by leveraging\nautomated prompt optimization (such as DSPy)- substantially enhances robustness\nwithout compromising model utility. This test-time defense enables real-time\nadaptability to evolving attacks, without requiring model retraining.\nComprehensive evaluations across key threat scenarios, including unlearning and\njailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning\nbenchmark, AegisLLM achieves near-perfect unlearning with only 20 training\nexamples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve\n51% improvement compared to the base model on StrongReject, with false refusal\nrates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our\nresults highlight the advantages of adaptive, agentic reasoning over static\ndefenses, establishing AegisLLM as a strong runtime alternative to traditional\napproaches based on model modifications. Code is available at\nhttps://github.com/zikuicai/aegisllm",
      "authors": [
        "Zikui Cai",
        "Shayan Shabihi",
        "Bang An",
        "Zora Che",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Tom Goldstein",
        "Furong Huang"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20965v1",
        "http://arxiv.org/pdf/2504.20965v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20938v1",
      "title": "Towards Understanding the Nature of Attention with Low-Rank Sparse\n  Decomposition",
      "published": "2025-04-29T17:03:03Z",
      "updated": "2025-04-29T17:03:03Z",
      "summary": "We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.",
      "authors": [
        "Zhengfu He",
        "Junxuan Wang",
        "Rui Lin",
        "Xuyang Ge",
        "Wentao Shu",
        "Qiong Tang",
        "Junping Zhang",
        "Xipeng Qiu"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20938v1",
        "http://arxiv.org/pdf/2504.20938v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20906v1",
      "title": "GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In\n  Industrial Control Systems",
      "published": "2025-04-29T16:24:11Z",
      "updated": "2025-04-29T16:24:11Z",
      "summary": "The continuous monitoring of the interactions between cyber-physical\ncomponents of any industrial control system (ICS) is required to secure\nautomation of the system controls, and to guarantee plant processes are\nfail-safe and remain in an acceptably safe state. Safety is achieved by\nmanaging actuation (where electric signals are used to trigger physical\nmovement), dependent on corresponding sensor readings; used as ground truth in\ndecision making. Timely detection of anomalies (attacks, faults and\nunascertained states) in ICSs is crucial for the safe running of a plant, the\nsafety of its personnel, and for the safe provision of any services provided.\nWe propose an anomaly detection method that involves accurate linearization of\nthe non-linear forms arising from sensor-actuator(s) relationships, primarily\nbecause solving linear models is easier and well understood. Further, the time\ncomplexity of the anomaly detection scenario/problem at hand is lowered using\ndimensionality reduction of the actuator(s) in relationship with a sensor. We\naccomplish this by using a well-known water treatment testbed as a use case.\nOur experiments show millisecond time response to detect anomalies and provide\nexplainability; that are not simultaneously achieved by other state of the art\nAI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we\npin-point the sensor(s) and its actuation state for which anomaly was detected.",
      "authors": [
        "Sarad Venugopalan",
        "Sridhar Adepu"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20906v1",
        "http://arxiv.org/pdf/2504.20906v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20904v1",
      "title": "Dual Explanations via Subgraph Matching for Malware Detection",
      "published": "2025-04-29T16:20:28Z",
      "updated": "2025-04-29T16:20:28Z",
      "summary": "Interpretable malware detection is crucial for understanding harmful\nbehaviors and building trust in automated security systems. Traditional\nexplainable methods for Graph Neural Networks (GNNs) often highlight important\nregions within a graph but fail to associate them with known benign or\nmalicious behavioral patterns. This limitation reduces their utility in\nsecurity contexts, where alignment with verified prototypes is essential. In\nthis work, we introduce a novel dual prototype-driven explainable framework\nthat interprets GNN-based malware detection decisions. This dual explainable\nframework integrates a base explainer (a state-of-the-art explainer) with a\nnovel second-level explainer which is designed by subgraph matching technique,\ncalled SubMatch explainer. The proposed explainer assigns interpretable scores\nto nodes based on their association with matched subgraphs, offering a\nfine-grained distinction between benign and malicious regions. This\nprototype-guided scoring mechanism enables more interpretable, behavior-aligned\nexplanations. Experimental results demonstrate that our method preserves high\ndetection performance while significantly improving interpretability in malware\nanalysis.",
      "authors": [
        "Hossein Shokouhinejad",
        "Roozbeh Razavi-Far",
        "Griffin Higgins",
        "Ali A. Ghorbani"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20904v1",
        "http://arxiv.org/pdf/2504.20904v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21569v1",
      "title": "A Systematic Literature Review of Parameter-Efficient Fine-Tuning for\n  Large Code Models",
      "published": "2025-04-29T16:19:25Z",
      "updated": "2025-04-29T16:19:25Z",
      "summary": "The rise of Artificial Intelligence (AI)-and particularly Large Language\nModels (LLMs) for code-has reshaped Software Engineering (SE) by enabling the\nautomation of tasks such as code generation, bug detection, and repair.\nHowever, these models require significant computational resources for training\nand fine-tuning, posing challenges for real-world adoption in\nresource-constrained environments. To address this, the research community has\nincreasingly turned to Parameter-Efficient Fine-Tuning (PEFT)-a class of\ntechniques that enables the adaptation of large models by updating only a small\nsubset of parameters, rather than the entire model. In this Systematic\nLiterature Review (SLR), we examine the growing application of PEFT\ntechniques-across a wide range of software engineering tasks. We analyze how\nthese methods are used to optimize various deep learning (DL) architectures,\nfocusing on their impact on both performance and efficiency. Our study\nsynthesizes findings from 27 peer-reviewed papers, identifying patterns in\nconfiguration strategies and adaptation trade-offs. The outcome of this review\nis a comprehensive taxonomy that categorizes PEFT usage by task type,\ndistinguishing between generative (e.g., Code Summarization) and non-generative\n(e.g., Code Clone Detection) scenarios. Our findings aim to inform future\nresearch and guide the practical deployment of PEFT in sustainable, AI-powered\nsoftware development. Our artifacts are publicly available at\nhttps://github.com/alvi75/SLR-PEFT",
      "authors": [
        "Md Zahidul Haque",
        "Saima Afrin",
        "Antonio Mastropaolo"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21569v1",
        "http://arxiv.org/pdf/2504.21569v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21071v1",
      "title": "Automated Parking Trajectory Generation Using Deep Reinforcement\n  Learning",
      "published": "2025-04-29T15:25:34Z",
      "updated": "2025-04-29T15:25:34Z",
      "summary": "Autonomous parking is a key technology in modern autonomous driving systems,\nrequiring high precision, strong adaptability, and efficiency in complex\nenvironments. This paper proposes a Deep Reinforcement Learning (DRL) framework\nbased on the Soft Actor-Critic (SAC) algorithm to optimize autonomous parking\ntasks. SAC, an off-policy method with entropy regularization, is particularly\nwell-suited for continuous action spaces, enabling fine-grained vehicle\ncontrol. We model the parking task as a Markov Decision Process (MDP) and train\nan agent to maximize cumulative rewards while balancing exploration and\nexploitation through entropy maximization. The proposed system integrates\nmultiple sensor inputs into a high-dimensional state space and leverages SAC's\ndual critic networks and policy network to achieve stable learning. Simulation\nresults show that the SAC-based approach delivers high parking success rates,\nreduced maneuver times, and robust handling of dynamic obstacles, outperforming\ntraditional rule-based methods and other DRL algorithms. This study\ndemonstrates SAC's potential in autonomous parking and lays the foundation for\nreal-world applications.",
      "authors": [
        "Zheyu Zhang",
        "Yutong Luo",
        "Yongzhou Chen",
        "Haopeng Zhao",
        "Zhichao Ma",
        "Hao Liu"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21071v1",
        "http://arxiv.org/pdf/2504.21071v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20776v1",
      "title": "ECOSoundSet: a finely annotated dataset for the automated acoustic\n  identification of Orthoptera and Cicadidae in North, Central and temperate\n  Western Europe",
      "published": "2025-04-29T13:53:33Z",
      "updated": "2025-04-29T13:53:33Z",
      "summary": "Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.",
      "authors": [
        "David Funosas",
        "Elodie Massol",
        "Yves Bas",
        "Svenja Schmidt",
        "Dominik Arend",
        "Alexander Gebhard",
        "Luc Barbaro",
        "Sebastian K\u00f6nig",
        "Rafael Carbonell Font",
        "David Sannier",
        "Fernand Deroussen",
        "J\u00e9r\u00f4me Sueur",
        "Christian Roesti",
        "Tomi Trilar",
        "Wolfgang Forstmeier",
        "Lucas Roger",
        "Elo\u00efsa Matheu",
        "Piotr Guzik",
        "Julien Barataud",
        "Laurent Pelozuelo",
        "St\u00e9phane Puissant",
        "Sandra Mueller",
        "Bj\u00f6rn Schuller",
        "Jose M. Montoya",
        "Andreas Triantafyllopoulos",
        "Maxime Cauchoix"
      ],
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20776v1",
        "http://arxiv.org/pdf/2504.20776v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20726v1",
      "title": "Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization",
      "published": "2025-04-29T13:08:27Z",
      "updated": "2025-04-29T13:08:27Z",
      "summary": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.",
      "authors": [
        "Hattan Althebeiti",
        "Mohammed Alkinoon",
        "Manar Mohaisen",
        "Saeed Salem",
        "DaeHun Nyang",
        "David Mohaisen"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20726v1",
        "http://arxiv.org/pdf/2504.20726v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21062v1",
      "title": "A Hamiltonian Higher-Order Elasticity Framework for Dynamic\n  Diagnostics(2HOED)",
      "published": "2025-04-29T10:12:52Z",
      "updated": "2025-04-29T10:12:52Z",
      "summary": "Machine learning detects patterns, block chain guarantees trust and\nimmutability, and modern causal inference identifies directional linkages, yet\nnone alone exposes the full energetic anatomy of complex systems; the\nHamiltonian Higher Order Elasticity Dynamics(2HOED) framework bridges these\ngaps. Grounded in classical mechanics but extended to Economics order\nelasticity terms, 2HOED represents economic, social, and physical systems as\nenergy-based Hamiltonians whose position, velocity, acceleration, and jerk of\nelasticity jointly determine systemic power, Inertia, policy sensitivity, and\nmarginal responses. Because the formalism is scaling free and coordinate\nagnostic, it transfers seamlessly from financial markets to climate science,\nfrom supply chain logistics to epidemiology, thus any discipline in which\nadaptation and shocks coexist. By embedding standard econometric variables\ninside a Hamiltonian, 2HOED enriches conventional economic analysis with\nrigorous diagnostics of resilience, tipping points, and feedback loops,\nrevealing failure modes invisible to linear models. Wavelet spectra, phase\nspace attractors, and topological persistence diagrams derived from 2HOED\nexpose multistage policy leverage that machine learning detects only\nempirically and block chain secures only after the fact. For economists,\nphysicians and other scientists, the method opens a new causal energetic\nchannel linking biological or mechanical elasticity to macro level outcomes.\nPortable, interpretable, and computationally light, 2HOED turns data streams\ninto dynamical energy maps, empowering decision makers to anticipate crises,\ndesign adaptive policies, and engineer robust systems delivering the predictive\npunch of AI with the explanatory clarity of physics.",
      "authors": [
        "Ngueuleweu Tiwang Gildas"
      ],
      "categories": [
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21062v1",
        "http://arxiv.org/pdf/2504.21062v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20579v1",
      "title": "Representation Learning Preserving Ignorability and Covariate Matching\n  for Treatment Effects",
      "published": "2025-04-29T09:33:56Z",
      "updated": "2025-04-29T09:33:56Z",
      "summary": "Estimating treatment effects from observational data is challenging due to\ntwo main reasons: (a) hidden confounding, and (b) covariate mismatch (control\nand treatment groups not having identical distributions). Long lines of works\nexist that address only either of these issues. To address the former,\nconventional techniques that require detailed knowledge in the form of causal\ngraphs have been proposed. For the latter, covariate matching and importance\nweighting methods have been used. Recently, there has been progress in\ncombining testable independencies with partial side information for tackling\nhidden confounding. A common framework to address both hidden confounding and\nselection bias is missing. We propose neural architectures that aim to learn a\nrepresentation of pre-treatment covariates that is a valid adjustment and also\nsatisfies covariate matching constraints. We combine two different neural\narchitectures: one based on gradient matching across domains created by\nsubsampling a suitable anchor variable that assumes causal side information,\nfollowed by the other, a covariate matching transformation. We prove that\napproximately invariant representations yield approximate valid adjustment sets\nwhich would enable an interval around the true causal effect. In contrast to\nusual sensitivity analysis, where an unknown nuisance parameter is varied, we\nhave a testable approximation yielding a bound on the effect estimate. We also\noutperform various baselines with respect to ATE and PEHE errors on causal\nbenchmarks that include IHDP, Jobs, Cattaneo, and an image-based Crowd\nManagement dataset.",
      "authors": [
        "Praharsh Nanavati",
        "Ranjitha Prasad",
        "Karthikeyan Shanmugam"
      ],
      "categories": [
        "cs.LG",
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20579v1",
        "http://arxiv.org/pdf/2504.20579v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20501v1",
      "title": "SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image\n  Segmentation",
      "published": "2025-04-29T07:43:37Z",
      "updated": "2025-04-29T07:43:37Z",
      "summary": "One-shot medical image segmentation (MIS) is crucial for medical analysis due\nto the burden of medical experts on manual annotation. The recent emergence of\nthe segment anything model (SAM) has demonstrated remarkable adaptation in MIS\nbut cannot be directly applied to one-shot medical image segmentation (MIS) due\nto its reliance on labor-intensive user interactions and the high computational\ncost. To cope with these limitations, we propose a novel SAM-guided robust\nrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot\n3D MIS, which exploits the strong generalization capabilities of the SAM\nencoder to learn better feature representation. We devise a dual-stage\nknowledge distillation (DSKD) strategy to distill general knowledge between\nnatural and medical images from the foundation model to train a lightweight\nencoder, and then adopt a mutual exponential moving average (mutual-EMA) to\nupdate the weights of the general lightweight encoder and medical-specific\nencoder. Specifically, pseudo labels from the registration network are used to\nperform mutual supervision for such two encoders. Moreover, we introduce an\nauto-prompting (AP) segmentation decoder which adopts the mask generated from\nthe general lightweight model as a prompt to assist the medical-specific model\nin boosting the final segmentation performance. Extensive experiments conducted\non three public datasets, i.e., OASIS, CT-lung demonstrate that the proposed\nRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for both\nsegmentation and registration tasks. Especially, our lightweight encoder uses\nonly 3\\% of the parameters compared to the encoder of SAM-Base.",
      "authors": [
        "Jia Wang",
        "Yunan Mei",
        "Jiarui Liu",
        "Xin Fan"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20501v1",
        "http://arxiv.org/pdf/2504.20501v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20471v1",
      "title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams",
      "published": "2025-04-29T07:13:28Z",
      "updated": "2025-04-29T07:13:28Z",
      "summary": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.",
      "authors": [
        "Baining Chen",
        "Yiming Zhang",
        "Yuqiao Han",
        "Ruyue Zhang",
        "Ruihuan Du",
        "Zhishuo Zhou",
        "Zhengdan Zhu",
        "Xun Liu",
        "Jiecheng Guo"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20471v1",
        "http://arxiv.org/pdf/2504.20471v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20454v1",
      "title": "LymphAtlas- A Unified Multimodal Lymphoma Imaging Repository Delivering\n  AI-Enhanced Diagnostic Insight",
      "published": "2025-04-29T06:10:12Z",
      "updated": "2025-04-29T06:10:12Z",
      "summary": "This study integrates PET metabolic information with CT anatomical structures\nto establish a 3D multimodal segmentation dataset for lymphoma based on\nwhole-body FDG PET/CT examinations, which bridges the gap of the lack of\nstandardised multimodal segmentation datasets in the field of haematological\nmalignancies. We retrospectively collected 483 examination datasets acquired\nbetween March 2011 and May 2024, involving 220 patients (106 non-Hodgkin\nlymphoma, 42 Hodgkin lymphoma); all data underwent ethical review and were\nrigorously de-identified. Complete 3D structural information was preserved\nduring data acquisition, preprocessing and annotation, and a high-quality\ndataset was constructed based on the nnUNet format. By systematic technical\nvalidation and evaluation of the preprocessing process, annotation quality and\nautomatic segmentation algorithm, the deep learning model trained based on this\ndataset is verified to achieve accurate segmentation of lymphoma lesions in\nPET/CT images with high accuracy, good robustness and reproducibility, which\nproves the applicability and stability of this dataset in accurate segmentation\nand quantitative analysis. The deep fusion of PET/CT images achieved with this\ndataset not only significantly improves the accurate portrayal of the\nmorphology, location and metabolic features of tumour lesions, but also\nprovides solid data support for early diagnosis, clinical staging and\npersonalized treatment, and promotes the development of automated image\nsegmentation and precision medicine based on deep learning. The dataset and\nrelated resources are available at https://github.com/SuperD0122/LymphAtlas-.",
      "authors": [
        "Jiajun Ding",
        "Beiyao Zhu",
        "Xiaosheng Liu",
        "Lishen Zhang",
        "Zhao Liu"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20454v1",
        "http://arxiv.org/pdf/2504.20454v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20447v1",
      "title": "APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech",
      "published": "2025-04-29T05:45:09Z",
      "updated": "2025-04-29T05:45:09Z",
      "summary": "Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.",
      "authors": [
        "Zhicheng Lian",
        "Lizhi Wang",
        "Hua Huang"
      ],
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20447v1",
        "http://arxiv.org/pdf/2504.20447v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20401v1",
      "title": "Nonlinear Computation with Linear Optics via Source-Position Encoding",
      "published": "2025-04-29T03:55:05Z",
      "updated": "2025-04-29T03:55:05Z",
      "summary": "Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.",
      "authors": [
        "N. Richardson",
        "C. Bosch",
        "R. P. Adams"
      ],
      "categories": [
        "physics.optics",
        "cs.AR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20401v1",
        "http://arxiv.org/pdf/2504.20401v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20368v1",
      "title": "AKIBoards: A Structure-Following Multiagent System for Predicting Acute\n  Kidney Injury",
      "published": "2025-04-29T02:12:48Z",
      "updated": "2025-04-29T02:12:48Z",
      "summary": "Diagnostic reasoning entails a physician's local (mental) model based on an\nassumed or known shared perspective (global model) to explain patient\nobservations with evidence assigned towards a clinical assessment. But in\nseveral (complex) medical situations, multiple experts work together as a team\nto optimize health evaluation and decision-making by leveraging different\nperspectives. Such consensus-driven reasoning reflects individual knowledge\ncontributing toward a broader perspective on the patient. In this light, we\nintroduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework\nautomating the learning of these global models and their incorporation as prior\nbeliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof\nof concept with a prosocial MAS application for predicting acute kidney\ninjuries (AKIs). In this case, we found that incorporating a global structure\nenabled multiple agents to achieve better performance (average precision, AP)\nin predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT,\nAP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs.\nbaseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180)\nfor balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents\nwith higher recall scores reported lower confidence levels in the initial round\non true positive and false negative cases. But after explicit interactions,\ntheir confidence in their decisions increased (suggesting reinforced belief).\nIn contrast, the SF-FT agent with the lowest recall decreased its confidence in\ntrue positive and false negative cases (suggesting a new belief). This approach\nsuggests that learning and leveraging global structures in MAS is necessary\nprior to achieving competitive classification and diagnostic reasoning\nperformance.",
      "authors": [
        "David Gordon",
        "Panayiotis Petousis",
        "Susanne B. Nicholas",
        "Alex A. T. Bui"
      ],
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20368v1",
        "http://arxiv.org/pdf/2504.20368v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20323v1",
      "title": "Labeling Case Similarity based on Co-Citation of Legal Articles in\n  Judgment Documents with Empirical Dispute-Based Evaluation",
      "published": "2025-04-29T00:26:37Z",
      "updated": "2025-04-29T00:26:37Z",
      "summary": "This report addresses the challenge of limited labeled datasets for\ndeveloping legal recommender systems, particularly in specialized domains like\nlabor disputes. We propose a new approach leveraging the co-citation of legal\narticles within cases to establish similarity and enable algorithmic\nannotation. This method draws a parallel to the concept of case co-citation,\nutilizing cited precedents as indicators of shared legal issues. To evaluate\nthe labeled results, we employ a system that recommends similar cases based on\nplaintiffs' accusations, defendants' rebuttals, and points of disputes. The\nevaluation demonstrates that the recommender, with finetuned text embedding\nmodels and a reasonable BiLSTM module can recommend labor cases whose\nsimilarity was measured by the co-citation of the legal articles. This research\ncontributes to the development of automated annotation techniques for legal\ndocuments, particularly in areas with limited access to comprehensive legal\ndatabases.",
      "authors": [
        "Chao-Lin Liu",
        "Po-Hsien Wu",
        "Yi-Ting Yu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20323v1",
        "http://arxiv.org/pdf/2504.20323v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20266v1",
      "title": "A Virtual Cybersecurity Department for Securing Digital Twins in Water\n  Distribution Systems",
      "published": "2025-04-28T21:14:48Z",
      "updated": "2025-04-28T21:14:48Z",
      "summary": "Digital twins (DTs) help improve real-time monitoring and decision-making in\nwater distribution systems. However, their connectivity makes them easy targets\nfor cyberattacks such as scanning, denial-of-service (DoS), and unauthorized\naccess. Small and medium-sized enterprises (SMEs) that manage these systems\noften do not have enough budget or staff to build strong cybersecurity teams.\nTo solve this problem, we present a Virtual Cybersecurity Department (VCD), an\naffordable and automated framework designed for SMEs. The VCD uses open-source\ntools like Zabbix for real-time monitoring, Suricata for network intrusion\ndetection, Fail2Ban to block repeated login attempts, and simple firewall\nsettings. To improve threat detection, we also add a machine-learning-based IDS\ntrained on the OD-IDS2022 dataset using an improved ensemble model. This model\ndetects cyber threats such as brute-force attacks, remote code execution (RCE),\nand network flooding, with 92\\% accuracy and fewer false alarms. Our solution\ngives SMEs a practical and efficient way to secure water systems using low-cost\nand easy-to-manage tools.",
      "authors": [
        "Mohammadhossein Homaei",
        "Agustin Di Bartolo",
        "Oscar Mogollon-Gutierrez",
        "Fernando Broncano Morgado",
        "Pablo Garcia Rodriguez"
      ],
      "categories": [
        "cs.CR",
        "cs.LG",
        "cs.NI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20266v1",
        "http://arxiv.org/pdf/2504.20266v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20213v1",
      "title": "Can Large Language Models Learn Formal Logic? A Data-Driven Training and\n  Evaluation Framework",
      "published": "2025-04-28T19:25:29Z",
      "updated": "2025-04-28T19:25:29Z",
      "summary": "This paper investigates the logical reasoning capabilities of large language\nmodels (LLMs). For a precisely defined yet tractable formulation, we choose the\nconceptually simple but technically complex task of constructing proofs in\nBoolean logic. A trained LLM receives as input a set of assumptions and a goal,\nand produces as output a proof that formally derives the goal from the\nassumptions. Incorrect proofs are caught by an automated proof checker. A\ncritical obstacle for training is the scarcity of real-world proofs. We propose\nan efficient, randomized procedure for synthesizing valid proofs and introduce\nTemplate Transformation, a data augmentation technique that enhances the\nmodel's ability to handle complex logical expressions. The central evaluation\nquestion is whether an LLM has indeed learned to reason. We propose tests to\nmeasure the reasoning ability of a black-box LLM. By these measures,\nexperiments demonstrate strong reasoning capabilities for assertions with short\nproofs, which decline with proof complexity. Notably, template transformation\nimproves accuracy even for smaller models, suggesting its effectiveness across\nmodel scales.",
      "authors": [
        "Yuan Xia",
        "Akanksha Atrey",
        "Fadoua Khmaissia",
        "Kedar S. Namjoshi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20213v1",
        "http://arxiv.org/pdf/2504.20213v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20157v1",
      "title": "Toward Evaluative Thinking: Meta Policy Optimization with Evolving\n  Reward Models",
      "published": "2025-04-28T18:02:35Z",
      "updated": "2025-04-28T18:02:35Z",
      "summary": "Reward-based alignment methods for large language models (LLMs) face two key\nlimitations: vulnerability to reward hacking, where models exploit flaws in the\nreward signal; and reliance on brittle, labor-intensive prompt engineering when\nLLMs are used as reward models. We introduce Meta Policy Optimization (MPO), a\nframework that addresses these challenges by integrating a meta-reward model\nthat dynamically refines the reward model's prompt throughout training. In MPO,\nthe meta-reward model monitors the evolving training context and continuously\nadjusts the reward model's prompt to maintain high alignment, providing an\nadaptive reward signal that resists exploitation by the policy. This\nmeta-learning approach promotes a more stable policy optimization, and greatly\nreduces the need for manual reward prompt design. It yields performance on par\nwith or better than models guided by extensively hand-crafted reward prompts.\nFurthermore, we show that MPO maintains its effectiveness across diverse tasks,\nsuch as question answering and mathematical reasoning, without requiring\nspecialized reward designs. Beyond standard RLAIF, MPO's meta-learning\nformulation is readily extensible to higher-level alignment frameworks.\nOverall, this method addresses theoretical and practical challenges in\nreward-based RL alignment for LLMs, paving the way for more robust and\nadaptable alignment strategies. The code and models will be publicly shared.",
      "authors": [
        "Zae Myung Kim",
        "Chanwoo Park",
        "Vipul Raheja",
        "Dongyeop Kang"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20157v1",
        "http://arxiv.org/pdf/2504.20157v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19981v1",
      "title": "Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided\n  GFlowNets",
      "published": "2025-04-28T16:56:41Z",
      "updated": "2025-04-28T16:56:41Z",
      "summary": "Achieving both accuracy and diverse reasoning remains challenging for Large\nLanguage Models (LLMs) in complex domains like mathematics. A key bottleneck is\nevaluating intermediate reasoning steps to guide generation without costly\nhuman annotations. To address this, we first introduce a novel Process Reward\nModel (PRM) trained automatically using Monte Carlo Tree Search coupled with a\nsimilarity-based data augmentation technique, effectively capturing step-level\nreasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks\n(GFlowNets) to operate at the reasoning step level. Unlike traditional\nreinforcement learning focused on maximizing a single reward, GFlowNets\nnaturally sample diverse, high-quality solutions proportional to their rewards,\nas measured by our PRM. Empirical evaluation shows strong improvements in both\naccuracy and solution diversity on challenging mathematical benchmarks (e.g.,\n+2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective\ngeneralization to unseen datasets (+9.4% absolute on SAT MATH). Our work\ndemonstrates the potential of PRM-guided, step-level GFlowNets for developing\nmore robust and versatile mathematical reasoning in LLMs.",
      "authors": [
        "Adam Younsi",
        "Abdalgader Abubaker",
        "Mohamed El Amine Seddik",
        "Hakim Hacid",
        "Salem Lahlou"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19981v1",
        "http://arxiv.org/pdf/2504.19981v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19933v1",
      "title": "Automated decision-making for dynamic task assignment at scale",
      "published": "2025-04-28T16:08:35Z",
      "updated": "2025-04-28T16:08:35Z",
      "summary": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.",
      "authors": [
        "Riccardo Lo Bianco",
        "Willem van Jaarsveld",
        "Jeroen Middelhuis",
        "Luca Begnardi",
        "Remco Dijkman"
      ],
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19933v1",
        "http://arxiv.org/pdf/2504.19933v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19838v1",
      "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and\n  Prospects",
      "published": "2025-04-28T14:39:25Z",
      "updated": "2025-04-28T14:39:25Z",
      "summary": "With the rapid rise of large language models (LLMs), phone automation has\nundergone transformative changes. This paper systematically reviews LLM-driven\nphone GUI agents, highlighting their evolution from script-based automation to\nintelligent, adaptive systems. We first contextualize key challenges, (i)\nlimited generality, (ii) high maintenance overhead, and (iii) weak intent\ncomprehension, and show how LLMs address these issues through advanced language\nunderstanding, multimodal perception, and robust decision-making. We then\npropose a taxonomy covering fundamental agent frameworks (single-agent,\nmulti-agent, plan-then-act), modeling approaches (prompt engineering,\ntraining-based), and essential datasets and benchmarks. Furthermore, we detail\ntask-specific architectures, supervised fine-tuning, and reinforcement learning\nstrategies that bridge user intent and GUI operations. Finally, we discuss open\nchallenges such as dataset diversity, on-device deployment efficiency,\nuser-centric adaptation, and security concerns, offering forward-looking\ninsights into this rapidly evolving field. By providing a structured overview\nand identifying pressing research gaps, this paper serves as a definitive\nreference for researchers and practitioners seeking to harness LLMs in\ndesigning scalable, user-friendly phone GUI agents.",
      "authors": [
        "Guangyi Liu",
        "Pengxiang Zhao",
        "Liang Liu",
        "Yaxuan Guo",
        "Han Xiao",
        "Weifeng Lin",
        "Yuxiang Chai",
        "Yue Han",
        "Shuai Ren",
        "Hao Wang",
        "Xiaoyu Liang",
        "Wenhao Wang",
        "Tianze Wu",
        "Linghao Li",
        "Hao Wang",
        "Guanjing Xiong",
        "Yong Liu",
        "Hongsheng Li"
      ],
      "categories": [
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19838v1",
        "http://arxiv.org/pdf/2504.19838v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19835v1",
      "title": "Automated Generation of Precedence Graphs in Digital Value Chains for\n  Automotive Production",
      "published": "2025-04-28T14:37:06Z",
      "updated": "2025-04-28T14:37:06Z",
      "summary": "This study examines the digital value chain in automotive manufacturing,\nfocusing on the identification, software flashing, customization, and\ncommissioning of electronic control units in vehicle networks. A novel\nprecedence graph design is proposed to optimize this process chain using an\nautomated scheduling algorithm that employs mixed integer linear programming\ntechniques. The results show significant improvements in key metrics. The\nalgorithm reduces the number of production stations equipped with expensive\nhardware and software to execute digital value chain processes, while\nincreasing capacity utilization through efficient scheduling and reduced idle\ntime. Task parallelization is optimized, resulting in streamlined workflows and\nincreased throughput. Compared to the traditional method, the automated\napproach has reduced preparation time by 50% and reduced scheduling activities,\nas it now takes two minutes to create the precedence graph. The flexibility of\nthe algorithm's constraints allows for vehicle-specific configurations while\nmaintaining high responsiveness, eliminating backup stations and facilitating\nthe integration of new topologies. Automated scheduling significantly\noutperforms manual methods in efficiency, functionality, and adaptability.",
      "authors": [
        "Cornelius Hake",
        "Christian Friedrich"
      ],
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19835v1",
        "http://arxiv.org/pdf/2504.19835v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19831v1",
      "title": "Optimal real-time dynamic treatment regimes with application to oxytocin\n  use in preventing postpartum hemorrhage",
      "published": "2025-04-28T14:33:51Z",
      "updated": "2025-04-28T14:33:51Z",
      "summary": "Real-time dynamic treatment regimes (real-time DTRs) refers to decision rules\nthat personalize patient treatment in real-time based on treatment and\ncovariate histories. These rules are crucial for real-time clinical decision\nsupport systems and automated drug delivery systems for chronic diseases.\nAlthough considerable statistical and machine learning DTR methods have been\ndeveloped, they are designed for a small number of fixed decision points, and\nthus can not adapt to real-time cases. This paper proposes a new semiparametric\nBayesian method for estimating an optimal treatment regime in real-time, which\nallows for the existence of latent individual level variables. Specifically,\nrandom real-time DTRs are defined through interventional parameters, the\noptimal values of which are estimated by maximizing the posterior predictive\nutility. The proposed approach is compared with alternative methods using\nsimulated datasets, and applied to estimate the optimal real-time oxytocin\nadministration regime for preventing postpartum hemorrhage.",
      "authors": [
        "Haiyan Zhu",
        "Yingchun Zhou"
      ],
      "categories": [
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19831v1",
        "http://arxiv.org/pdf/2504.19831v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20126v1",
      "title": "Enhancing Cell Counting through MLOps: A Structured Approach for\n  Automated Cell Analysis",
      "published": "2025-04-28T13:53:50Z",
      "updated": "2025-04-28T13:53:50Z",
      "summary": "Machine Learning (ML) models offer significant potential for advancing cell\ncounting applications in neuroscience, medical research, pharmaceutical\ndevelopment, and environmental monitoring. However, implementing these models\neffectively requires robust operational frameworks. This paper introduces Cell\nCounting Machine Learning Operations (CC-MLOps), a comprehensive framework that\nstreamlines the integration of ML in cell counting workflows. CC-MLOps\nencompasses data access and preprocessing, model training, monitoring,\nexplainability features, and sustainability considerations. Through a practical\nuse case, we demonstrate how MLOps principles can enhance model reliability,\nreduce human error, and enable scalable Cell Counting solutions. This work\nprovides actionable guidance for researchers and laboratory professionals\nseeking to implement machine learning (ML)- powered cell counting systems.",
      "authors": [
        "Matteo Testi",
        "Luca Clissa",
        "Matteo Ballabio",
        "Salvatore Ricciardi",
        "Federico Baldo",
        "Emanuele Frontoni",
        "Sara Moccia",
        "Gennario Vessio"
      ],
      "categories": [
        "cs.SE",
        "cs.LG",
        "physics.app-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20126v1",
        "http://arxiv.org/pdf/2504.20126v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19734v1",
      "title": "LLM-Assisted Automated Deductive Coding of Dialogue Data: Leveraging\n  Dialogue-Specific Characteristics to Enhance Contextual Understanding",
      "published": "2025-04-28T12:31:38Z",
      "updated": "2025-04-28T12:31:38Z",
      "summary": "Dialogue data has been a key source for understanding learning processes,\noffering critical insights into how students engage in collaborative\ndiscussions and how these interactions shape their knowledge construction. The\nadvent of Large Language Models (LLMs) has introduced promising opportunities\nfor advancing qualitative research, particularly in the automated coding of\ndialogue data. However, the inherent contextual complexity of dialogue presents\nunique challenges for these models, especially in understanding and\ninterpreting complex contextual information. This study addresses these\nchallenges by developing a novel LLM-assisted automated coding approach for\ndialogue data. The novelty of our proposed framework is threefold: 1) We\npredict the code for an utterance based on dialogue-specific characteristics --\ncommunicative acts and communicative events -- using separate prompts following\nthe role prompts and chain-of-thoughts methods; 2) We engaged multiple LLMs\nincluding GPT-4-turbo, GPT-4o, DeepSeek in collaborative code prediction; 3) We\nleveraged the interrelation between events and acts to implement consistency\nchecking using GPT-4o. In particular, our contextual consistency checking\nprovided a substantial accuracy improvement. We also found the accuracy of act\npredictions was consistently higher than that of event predictions. This study\ncontributes a new methodological framework for enhancing the precision of\nautomated coding of dialogue data as well as offers a scalable solution for\naddressing the contextual challenges inherent in dialogue analysis.",
      "authors": [
        "Ying Na",
        "Shihui Feng"
      ],
      "categories": [
        "cs.CL",
        "cs.SI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19734v1",
        "http://arxiv.org/pdf/2504.19734v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19678v1",
      "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review",
      "published": "2025-04-28T11:08:22Z",
      "updated": "2025-04-28T11:08:22Z",
      "summary": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.",
      "authors": [
        "Mohamed Amine Ferrag",
        "Norbert Tihanyi",
        "Merouane Debbah"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19678v1",
        "http://arxiv.org/pdf/2504.19678v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19667v1",
      "title": "A Tripartite Perspective on GraphRAG",
      "published": "2025-04-28T10:43:35Z",
      "updated": "2025-04-28T10:43:35Z",
      "summary": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.",
      "authors": [
        "Michael Banf",
        "Johannes Kuhn"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19667v1",
        "http://arxiv.org/pdf/2504.19667v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19649v1",
      "title": "Intelligent4DSE: Optimizing High-Level Synthesis Design Space\n  Exploration with Graph Neural Networks and Large Language Models",
      "published": "2025-04-28T10:08:56Z",
      "updated": "2025-04-28T10:08:56Z",
      "summary": "High-level synthesis (HLS) design space exploration (DSE) is an optimization\nprocess in electronic design automation (EDA) that systematically explores\nhigh-level design configurations to achieve Pareto-optimal hardware\nimplementations balancing performance, area, and power (PPA). To optimize this\nprocess, HLS prediction tasks often employ message-passing neural networks\n(MPNNs), leveraging complex architectures to achieve high accuracy. These\npredictors serve as evaluators in the DSE process, effectively bypassing the\ntime-consuming estimations traditionally required by HLS tools. However,\nexisting models often prioritize structural complexity and minimization of\ntraining loss, overlooking task-specific characteristics. Additionally, while\nevolutionary algorithms are widely used in DSE, they typically require\nextensive domain-specific knowledge to design effective crossover and mutation\noperators. To address these limitations, we propose CoGNNs-LLMEA, a framework\nthat integrates a graph neural network with task-adaptive message passing and a\nlarge language model-enhanced evolutionary algorithm. As a predictive model,\nCoGNNs directly leverages intermediate representations generated from source\ncode after compiler front-end processing, enabling prediction of quality of\nresults (QoR) without invoking HLS tools. Due to its strong adaptability to\ntasks, CoGNNs can be tuned to predict post-HLS and post-implementation\noutcomes, effectively bridging the gap between high-level abstractions and\nphysical implementation characteristics. CoGNNs achieves state-of-the-art\nprediction accuracy in post-HLS QoR prediction, reducing mean prediction errors\nby 2.8$\\times$ for latency and 3.4$\\times$ for resource utilization compared to\nbaseline models.",
      "authors": [
        "Lei Xu",
        "Shanshan Wang",
        "Emmanuel Casseau",
        "Chenglong Xiao"
      ],
      "categories": [
        "cs.LG",
        "cs.AR"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19649v1",
        "http://arxiv.org/pdf/2504.19649v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19632v1",
      "title": "QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural\n  Networks for Fraud Detection and Loan Prediction",
      "published": "2025-04-28T09:47:28Z",
      "updated": "2025-04-28T09:47:28Z",
      "summary": "Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead.",
      "authors": [
        "Subham Das",
        "Ashtakala Meghanath",
        "Bikash K. Behera",
        "Shahid Mumtaz",
        "Saif Al-Kuwari",
        "Ahmed Farouk"
      ],
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19632v1",
        "http://arxiv.org/pdf/2504.19632v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19624v1",
      "title": "ARMOR: Adaptive Meshing with Reinforcement Optimization for Real-time 3D\n  Monitoring in Unexposed Scenes",
      "published": "2025-04-28T09:33:40Z",
      "updated": "2025-04-28T09:33:40Z",
      "summary": "Unexposed environments, such as lava tubes, mines, and tunnels, are among the\nmost complex yet strategically significant domains for scientific exploration\nand infrastructure development. Accurate and real-time 3D meshing of these\nenvironments is essential for applications including automated structural\nassessment, robotic-assisted inspection, and safety monitoring. Implicit neural\nSigned Distance Fields (SDFs) have shown promising capabilities in online\nmeshing; however, existing methods often suffer from large projection errors\nand rely on fixed reconstruction parameters, limiting their adaptability to\ncomplex and unstructured underground environments such as tunnels, caves, and\nlava tubes. To address these challenges, this paper proposes ARMOR, a\nscene-adaptive and reinforcement learning-based framework for real-time 3D\nmeshing in unexposed environments. The proposed method was validated across\nmore than 3,000 meters of underground environments, including engineered\ntunnels, natural caves, and lava tubes. Experimental results demonstrate that\nARMOR achieves superior performance in real-time mesh reconstruction, reducing\ngeometric error by 3.96\\% compared to state-of-the-art baselines, while\nmaintaining real-time efficiency. The method exhibits improved robustness,\naccuracy, and adaptability, indicating its potential for advanced 3D monitoring\nand mapping in challenging unexposed scenarios. The project page can be found\nat: https://yizhezhang0418.github.io/armor.github.io/",
      "authors": [
        "Yizhe Zhang",
        "Jianping Li",
        "Xin Zhao",
        "Fuxun Liang",
        "Zhen Dong",
        "Bisheng Yang"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19624v1",
        "http://arxiv.org/pdf/2504.19624v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20117v1",
      "title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification\n  of Research Methodologies",
      "published": "2025-04-28T07:18:45Z",
      "updated": "2025-04-28T07:18:45Z",
      "summary": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.",
      "authors": [
        "Shubham Gandhi",
        "Dhruv Shah",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Gautam Shroff"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20117v1",
        "http://arxiv.org/pdf/2504.20117v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20115v1",
      "title": "AutoP2C: An LLM-Based Agent Framework for Code Repository Generation\n  from Multimodal Content in Academic Papers",
      "published": "2025-04-28T05:47:37Z",
      "updated": "2025-04-28T05:47:37Z",
      "summary": "Machine Learning (ML) research is spread through academic papers featuring\nrich multimodal content, including text, diagrams, and tabular results.\nHowever, translating these multimodal elements into executable code remains a\nchallenging and time-consuming process that requires substantial ML expertise.\nWe introduce ``Paper-to-Code'' (P2C), a novel task that transforms the\nmultimodal content of scientific publications into fully executable code\nrepositories, which extends beyond the existing formulation of code generation\nthat merely converts textual descriptions into isolated code snippets. To\nautomate the P2C process, we propose AutoP2C, a multi-agent framework based on\nlarge language models that processes both textual and visual content from\nresearch papers to generate complete code repositories. Specifically, AutoP2C\ncontains four stages: (1) repository blueprint extraction from established\ncodebases, (2) multimodal content parsing that integrates information from\ntext, equations, and figures, (3) hierarchical task decomposition for\nstructured code generation, and (4) iterative feedback-driven debugging to\nensure functionality and performance. Evaluation on a benchmark of eight\nresearch papers demonstrates the effectiveness of AutoP2C, which can\nsuccessfully generate executable code repositories for all eight papers, while\nOpenAI-o1 or DeepSeek-R1 can only produce runnable code for one paper. The code\nis available at https://github.com/shoushouyu/Automated-Paper-to-Code.",
      "authors": [
        "Zijie Lin",
        "Yiqing Shen",
        "Qilin Cai",
        "He Sun",
        "Jinrui Zhou",
        "Mingjun Xiao"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20115v1",
        "http://arxiv.org/pdf/2504.20115v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19498v2",
      "title": "Motion Generation for Food Topping Challenge 2024: Serving Salmon Roe\n  Bowl and Picking Fried Chicken",
      "published": "2025-04-28T05:41:09Z",
      "updated": "2025-04-30T12:32:20Z",
      "summary": "Although robots have been introduced in many industries, food production\nrobots are yet to be widely employed because the food industry requires not\nonly delicate movements to handle food but also complex movements that adapt to\nthe environment. Force control is important for handling delicate objects such\nas food. In addition, achieving complex movements is possible by making robot\nmotions based on human teachings. Four-channel bilateral control is proposed,\nwhich enables the simultaneous teaching of position and force information.\nMoreover, methods have been developed to reproduce motions obtained through\nhuman teachings and generate adaptive motions using learning. We demonstrated\nthe effectiveness of these methods for food handling tasks in the Food Topping\nChallenge at the 2024 IEEE International Conference on Robotics and Automation\n(ICRA 2024). For the task of serving salmon roe on rice, we achieved the best\nperformance because of the high reproducibility and quick motion of the\nproposed method. Further, for the task of picking fried chicken, we\nsuccessfully picked the most pieces of fried chicken among all participating\nteams. This paper describes the implementation and performance of these\nmethods.",
      "authors": [
        "Koki Inami",
        "Masashi Konosu",
        "Koki Yamane",
        "Nozomu Masuya",
        "Yunhan Li",
        "Yu-Han Shu",
        "Hiroshi Sato",
        "Shinnosuke Homma",
        "Sho Sakaino"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19498v2",
        "http://arxiv.org/pdf/2504.19498v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19480v1",
      "title": "An Automated Reinforcement Learning Reward Design Framework with Large\n  Language Model for Cooperative Platoon Coordination",
      "published": "2025-04-28T04:41:15Z",
      "updated": "2025-04-28T04:41:15Z",
      "summary": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.",
      "authors": [
        "Dixiao Wei",
        "Peng Yi",
        "Jinlong Lei",
        "Yiguang Hong",
        "Yuchuan Du"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19480v1",
        "http://arxiv.org/pdf/2504.19480v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19443v1",
      "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal\n  Learning and Symmetry-Aware Loss Functions",
      "published": "2025-04-28T03:10:24Z",
      "updated": "2025-04-28T03:10:24Z",
      "summary": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.",
      "authors": [
        "Yejin Jeong",
        "Donghun Lee"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19443v1",
        "http://arxiv.org/pdf/2504.19443v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20113v1",
      "title": "Transforming Evidence Synthesis: A Systematic Review of the Evolution of\n  Automated Meta-Analysis in the Age of AI",
      "published": "2025-04-28T00:40:17Z",
      "updated": "2025-04-28T00:40:17Z",
      "summary": "Exponential growth in scientific literature has heightened the demand for\nefficient evidence-based synthesis, driving the rise of the field of Automated\nMeta-analysis (AMA) powered by natural language processing and machine\nlearning. This PRISMA systematic review introduces a structured framework for\nassessing the current state of AMA, based on screening 978 papers from 2006 to\n2024, and analyzing 54 studies across diverse domains. Findings reveal a\npredominant focus on automating data processing (57%), such as extraction and\nstatistical modeling, while only 17% address advanced synthesis stages. Just\none study (2%) explored preliminary full-process automation, highlighting a\ncritical gap that limits AMA's capacity for comprehensive synthesis. Despite\nrecent breakthroughs in large language models (LLMs) and advanced AI, their\nintegration into statistical modeling and higher-order synthesis, such as\nheterogeneity assessment and bias evaluation, remains underdeveloped. This has\nconstrained AMA's potential for fully autonomous meta-analysis. From our\ndataset spanning medical (67%) and non-medical (33%) applications, we found\nthat AMA has exhibited distinct implementation patterns and varying degrees of\neffectiveness in actually improving efficiency, scalability, and\nreproducibility. While automation has enhanced specific meta-analytic tasks,\nachieving seamless, end-to-end automation remains an open challenge. As AI\nsystems advance in reasoning and contextual understanding, addressing these\ngaps is now imperative. Future efforts must focus on bridging automation across\nall meta-analysis stages, refining interpretability, and ensuring\nmethodological robustness to fully realize AMA's potential for scalable,\ndomain-agnostic synthesis.",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20113v1",
        "http://arxiv.org/pdf/2504.20113v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}