{
  "query": "all:artificial intelligence AND (labor market OR employment OR jobs OR workforce OR automation)",
  "target_period": "2025-03",
  "date_collected": "2025-03-20T15:52:45.307330",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2503.15415v1",
      "title": "Automated Processing of eXplainable Artificial Intelligence Outputs in\n  Deep Learning Models for Fault Diagnostics of Large Infrastructures",
      "published": "2025-03-19T16:57:00Z",
      "updated": "2025-03-19T16:57:00Z",
      "summary": "Deep Learning (DL) models processing images to recognize the health state of\nlarge infrastructure components can exhibit biases and rely on non-causal\nshortcuts. eXplainable Artificial Intelligence (XAI) can address these issues\nbut manually analyzing explanations generated by XAI techniques is\ntime-consuming and prone to errors. This work proposes a novel framework that\ncombines post-hoc explanations with semi-supervised learning to automatically\nidentify anomalous explanations that deviate from those of correctly classified\nimages and may therefore indicate model abnormal behaviors. This significantly\nreduces the workload for maintenance decision-makers, who only need to manually\nreclassify images flagged as having anomalous explanations. The proposed\nframework is applied to drone-collected images of insulator shells for power\ngrid infrastructure monitoring, considering two different Convolutional Neural\nNetworks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly\nDetection. The average classification accuracy on two faulty classes is\nimproved by 8% and maintenance operators are required to manually reclassify\nonly 15% of the images. We compare the proposed framework with a\nstate-of-the-art approach based on the faithfulness metric: the experimental\nresults obtained demonstrate that the proposed framework consistently achieves\nF_1 scores larger than those of the faithfulness-based approach. Additionally,\nthe proposed framework successfully identifies correct classifications that\nresult from non-causal shortcuts, such as the presence of ID tags printed on\ninsulator shells.",
      "authors": [
        "Giovanni Floreale",
        "Piero Baraldi",
        "Enrico Zio",
        "Olga Fink"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15415v1",
        "http://arxiv.org/pdf/2503.15415v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15374v1",
      "title": "Real-world validation of a multimodal LLM-powered pipeline for\n  High-Accuracy Clinical Trial Patient Matching leveraging EHR data",
      "published": "2025-03-19T16:12:11Z",
      "updated": "2025-03-19T16:12:11Z",
      "summary": "Background: Patient recruitment in clinical trials is hindered by complex\neligibility criteria and labor-intensive chart reviews. Prior research using\ntext-only models have struggled to address this problem in a reliable and\nscalable way due to (1) limited reasoning capabilities, (2) information loss\nfrom converting visual records to text, and (3) lack of a generic EHR\nintegration to extract patient data.\n  Methods: We introduce a broadly applicable, integration-free, LLM-powered\npipeline that automates patient-trial matching using unprocessed documents\nextracted from EHRs. Our approach leverages (1) the new reasoning-LLM paradigm,\nenabling the assessment of even the most complex criteria, (2) visual\ncapabilities of latest LLMs to interpret medical records without lossy\nimage-to-text conversions, and (3) multimodal embeddings for efficient medical\nrecord search. The pipeline was validated on the n2c2 2018 cohort selection\ndataset (288 diabetic patients) and a real-world dataset composed of 485\npatients from 30 different sites matched against 36 diverse trials.\n  Results: On the n2c2 dataset, our method achieved a new state-of-the-art\ncriterion-level accuracy of 93\\%. In real-world trials, the pipeline yielded an\naccuracy of 87\\%, undermined by the difficulty to replicate human\ndecision-making when medical records lack sufficient information. Nevertheless,\nusers were able to review overall eligibility in under 9 minutes per patient on\naverage, representing an 80\\% improvement over traditional manual chart\nreviews.\n  Conclusion: This pipeline demonstrates robust performance in clinical trial\npatient matching without requiring custom integration with site systems or\ntrial-specific tailoring, thereby enabling scalable deployment across sites\nseeking to leverage AI for patient matching.",
      "authors": [
        "Anatole Callies",
        "Quentin Bodinier",
        "Philippe Ravaud",
        "Kourosh Davarpanah"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15374v1",
        "http://arxiv.org/pdf/2503.15374v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15248v1",
      "title": "Automated Non-Functional Requirements Generation in Software Engineering\n  with Large Language Models: A Comparative Study",
      "published": "2025-03-19T14:23:22Z",
      "updated": "2025-03-19T14:23:22Z",
      "summary": "Neglecting non-functional requirements (NFRs) early in software development\ncan lead to critical challenges. Despite their importance, NFRs are often\noverlooked or difficult to identify, impacting software quality. To support\nrequirements engineers in eliciting NFRs, we developed a framework that\nleverages Large Language Models (LLMs) to derive quality-driven NFRs from\nfunctional requirements (FRs). Using a custom prompting technique within a\nDeno-based pipeline, the system identifies relevant quality attributes for each\nfunctional requirement and generates corresponding NFRs, aiding systematic\nintegration. A crucial aspect is evaluating the quality and suitability of\nthese generated requirements. Can LLMs produce high-quality NFR suggestions?\nUsing 34 functional requirements - selected as a representative subset of 3,964\nFRs-the LLMs inferred applicable attributes based on the ISO/IEC 25010:2023\nstandard, generating 1,593 NFRs. A horizontal evaluation covered three\ndimensions: NFR validity, applicability of quality attributes, and\nclassification precision. Ten industry software quality evaluators, averaging\n13 years of experience, assessed a subset for relevance and quality. The\nevaluation showed strong alignment between LLM-generated NFRs and expert\nassessments, with median validity and applicability scores of 5.0 (means: 4.63\nand 4.59, respectively) on a 1-5 scale. In the classification task, 80.4% of\nLLM-assigned attributes matched expert choices, with 8.3% near misses and 11.3%\nmismatches. A comparative analysis of eight LLMs highlighted variations in\nperformance, with gemini-1.5-pro exhibiting the highest attribute accuracy,\nwhile llama-3.3-70B achieved higher validity and applicability scores. These\nfindings provide insights into the feasibility of using LLMs for automated NFR\ngeneration and lay the foundation for further exploration of AI-assisted\nrequirements engineering.",
      "authors": [
        "Jomar Thomas Almonte",
        "Santhosh Anitha Boominathan",
        "Nathalia Nascimento"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15248v1",
        "http://arxiv.org/pdf/2503.15248v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15234v1",
      "title": "CoE: Chain-of-Explanation via Automatic Visual Concept Circuit\n  Description and Polysemanticity Quantification",
      "published": "2025-03-19T14:13:02Z",
      "updated": "2025-03-19T14:13:02Z",
      "summary": "Explainability is a critical factor influencing the wide deployment of deep\nvision models (DVMs). Concept-based post-hoc explanation methods can provide\nboth global and local insights into model decisions. However, current methods\nin this field face challenges in that they are inflexible to automatically\nconstruct accurate and sufficient linguistic explanations for global concepts\nand local circuits. Particularly, the intrinsic polysemanticity in semantic\nVisual Concepts (VCs) impedes the interpretability of concepts and DVMs, which\nis underestimated severely. In this paper, we propose a Chain-of-Explanation\n(CoE) approach to address these issues. Specifically, CoE automates the\ndecoding and description of VCs to construct global concept explanation\ndatasets. Further, to alleviate the effect of polysemanticity on model\nexplainability, we design a concept polysemanticity disentanglement and\nfiltering mechanism to distinguish the most contextually relevant concept\natoms. Besides, a Concept Polysemanticity Entropy (CPE), as a measure of model\ninterpretability, is formulated to quantify the degree of concept uncertainty.\nThe modeling of deterministic concepts is upgraded to uncertain concept atom\ndistributions. Finally, CoE automatically enables linguistic local explanations\nof the decision-making process of DVMs by tracing the concept circuit. GPT-4o\nand human-based experiments demonstrate the effectiveness of CPE and the\nsuperiority of CoE, achieving an average absolute improvement of 36% in terms\nof explainability scores.",
      "authors": [
        "Wenlong Yu",
        "Qilong Wang",
        "Chuang Liu",
        "Dong Li",
        "Qinghua Hu"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15234v1",
        "http://arxiv.org/pdf/2503.15234v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15128v1",
      "title": "Increasing the Robustness of the Fine-tuned Multilingual\n  Machine-Generated Text Detectors",
      "published": "2025-03-19T11:42:33Z",
      "updated": "2025-03-19T11:42:33Z",
      "summary": "Since the proliferation of LLMs, there have been concerns about their misuse\nfor harmful content creation and spreading. Recent studies justify such fears,\nproviding evidence of LLM vulnerabilities and high potential of their misuse.\nHumans are no longer able to distinguish between high-quality machine-generated\nand authentic human-written texts. Therefore, it is crucial to develop\nautomated means to accurately detect machine-generated content. It would enable\nto identify such content in online information space, thus providing an\nadditional information about its credibility. This work addresses the problem\nby proposing a robust fine-tuning process of LLMs for the detection task,\nmaking the detectors more robust against obfuscation and more generalizable to\nout-of-distribution data.",
      "authors": [
        "Dominik Macko",
        "Robert Moro",
        "Ivan Srba"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15128v1",
        "http://arxiv.org/pdf/2503.15128v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15095v1",
      "title": "Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive\n  Control",
      "published": "2025-03-19T10:48:26Z",
      "updated": "2025-03-19T10:48:26Z",
      "summary": "We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic\nframework for uncertainty-aware prediction and decision-making in partially\nobservable stochastic systems by integrating diffusion-based time series\nforecasting models in Model Predictive Control algorithms. In our approach, a\ndiffusion-based time series forecasting model is used to probabilistically\nestimate the evolution of the system's stochastic components. These forecasts\nare then incorporated into MPC algorithms to estimate future trajectories and\noptimize action selection under the uncertainty of the future. We evaluate the\nframework on the task of energy arbitrage, where a Battery Energy Storage\nSystem participates in the day-ahead electricity market of the New York state.\nExperimental results indicate that our model-based approach with a\ndiffusion-based forecaster significantly outperforms both implementations with\nclassical forecasting methods and model-free reinforcement learning baselines.",
      "authors": [
        "Stelios Zarifis",
        "Ioannis Kordonis",
        "Petros Maragos"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2.6; I.5.1"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15095v1",
        "http://arxiv.org/pdf/2503.15095v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14933v1",
      "title": "A Language Vision Model Approach for Automated Tumor Contouring in\n  Radiation Oncology",
      "published": "2025-03-19T06:41:37Z",
      "updated": "2025-03-19T06:41:37Z",
      "summary": "Background: Lung cancer ranks as the leading cause of cancer-related\nmortality worldwide. The complexity of tumor delineation, crucial for radiation\ntherapy, requires expertise often unavailable in resource-limited settings.\nArtificial Intelligence(AI), particularly with advancements in deep learning\n(DL) and natural language processing (NLP), offers potential solutions yet is\nchallenged by high false positive rates. Purpose: The Oncology Contouring\nCopilot (OCC) system is developed to leverage oncologist expertise for precise\ntumor contouring using textual descriptions, aiming to increase the efficiency\nof oncological workflows by combining the strengths of AI with human oversight.\nMethods: Our OCC system initially identifies nodule candidates from CT scans.\nEmploying Language Vision Models (LVMs) like GPT-4V, OCC then effectively\nreduces false positives with clinical descriptive texts, merging textual and\nvisual data to automate tumor delineation, designed to elevate the quality of\noncology care by incorporating knowledge from experienced domain experts.\nResults: Deployments of the OCC system resulted in a significant reduction in\nthe false discovery rate by 35.0%, a 72.4% decrease in false positives per\nscan, and an F1-score of 0.652 across our dataset for unbiased evaluation.\nConclusions: OCC represents a significant advance in oncology care,\nparticularly through the use of the latest LVMs to improve contouring results\nby (1) streamlining oncology treatment workflows by optimizing tumor\ndelineation, reducing manual processes; (2) offering a scalable and intuitive\nframework to reduce false positives in radiotherapy planning using LVMs; (3)\nintroducing novel medical language vision prompt techniques to minimize LVMs\nhallucinations with ablation study, and (4) conducting a comparative analysis\nof LVMs, highlighting their potential in addressing medical language vision\nchallenges.",
      "authors": [
        "Yi Luo",
        "Hamed Hooshangnejad",
        "Xue Feng",
        "Gaofeng Huang",
        "Xiaojian Chen",
        "Rui Zhang",
        "Quan Chen",
        "Wil Ngwa",
        "Kai Ding"
      ],
      "categories": [
        "eess.IV",
        "cs.CV",
        "physics.med-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14933v1",
        "http://arxiv.org/pdf/2503.14933v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14899v1",
      "title": "Speed Optimization Algorithm based on Deterministic Markov Decision\n  Process for Automated Highway Merge",
      "published": "2025-03-19T04:57:03Z",
      "updated": "2025-03-19T04:57:03Z",
      "summary": "This study presents a robust optimization algorithm for automated highway\nmerge. The merging scenario is one of the challenging scenes in automated\ndriving, because it requires adjusting ego vehicle's speed to match other\nvehicles before reaching the end point. Then, we model the speed planning\nproblem as a deterministic Markov decision process. The proposed scheme is able\nto compute each state value of the process and reliably derive the optimal\nsequence of actions. In our approach, we adopt jerk as the action of the\nprocess to prevent a sudden change of acceleration. However, since this expands\nthe state space, we also consider ways to achieve a real-time operation. We\ncompared our scheme with a simple algorithm with the Intelligent Driver Model.\nWe not only evaluated the scheme in a simulation environment but also conduct a\nreal world testing.",
      "authors": [
        "Takeru Goto",
        "Kosuke Toda",
        "Takayasu Kumano"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14899v1",
        "http://arxiv.org/pdf/2503.14899v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14716v1",
      "title": "Construction Site Scaffolding Completeness Detection Based on Mask R-CNN\n  and Hough Transform",
      "published": "2025-03-18T20:27:22Z",
      "updated": "2025-03-18T20:27:22Z",
      "summary": "Construction site scaffolding is essential for many building projects, and\nensuring its safety is crucial to prevent accidents. The safety inspector must\ncheck the scaffolding's completeness and integrity, where most violations\noccur. The inspection process includes ensuring all the components are in the\nright place since workers often compromise safety for convenience and\ndisassemble parts such as cross braces. This paper proposes a deep\nlearning-based approach to detect the scaffolding and its cross braces using\ncomputer vision. A scaffold image dataset with annotated labels is used to\ntrain a convolutional neural network (CNN) model. With the proposed approach,\nwe can automatically detect the completeness of cross braces from images taken\nat construction sites, without the need for manual inspection, saving a\nsignificant amount of time and labor costs. This non-invasive and efficient\nsolution for detecting scaffolding completeness can help improve safety in\nconstruction sites.",
      "authors": [
        "Pei-Hsin Lin",
        "Jacob J. Lin",
        "Shang-Hsien Hsieh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14716v1",
        "http://arxiv.org/pdf/2503.14716v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14630v1",
      "title": "Assessing Large Language Models for Automated Feedback Generation in\n  Learning Programming Problem Solving",
      "published": "2025-03-18T18:31:36Z",
      "updated": "2025-03-18T18:31:36Z",
      "summary": "Providing effective feedback is important for student learning in programming\nproblem-solving. In this sense, Large Language Models (LLMs) have emerged as\npotential tools to automate feedback generation. However, their reliability and\nability to identify reasoning errors in student code remain not well\nunderstood. This study evaluates the performance of four LLMs (GPT-4o, GPT-4o\nmini, GPT-4-Turbo, and Gemini-1.5-pro) on a benchmark dataset of 45 student\nsolutions. We assessed the models' capacity to provide accurate and insightful\nfeedback, particularly in identifying reasoning mistakes. Our analysis reveals\nthat 63\\% of feedback hints were accurate and complete, while 37\\% contained\nmistakes, including incorrect line identification, flawed explanations, or\nhallucinated issues. These findings highlight the potential and limitations of\nLLMs in programming education and underscore the need for improvements to\nenhance reliability and minimize risks in educational applications.",
      "authors": [
        "Priscylla Silva",
        "Evandro Costa"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14630v1",
        "http://arxiv.org/pdf/2503.14630v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14499v1",
      "title": "Measuring AI Ability to Complete Long Tasks",
      "published": "2025-03-18T17:59:31Z",
      "updated": "2025-03-18T17:59:31Z",
      "summary": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark\nperformance remains unclear. To quantify the capabilities of AI systems in\nterms of human capabilities, we propose a new metric: 50%-task-completion time\nhorizon. This is the time humans typically take to complete tasks that AI\nmodels can complete with 50% success rate. We first timed humans with relevant\ndomain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter\ntasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet\nhave a 50% time horizon of around 50 minutes. Furthermore, frontier AI time\nhorizon has been doubling approximately every seven months since 2019, though\nthe trend may have accelerated in 2024. The increase in AI models' time\nhorizons seems to be primarily driven by greater reliability and ability to\nadapt to mistakes, combined with better logical reasoning and tool use\ncapabilities. We discuss the limitations of our results -- including their\ndegree of external validity -- and the implications of increased autonomy for\ndangerous capabilities. If these results generalize to real-world software\ntasks, extrapolation of this trend predicts that within 5 years, AI systems\nwill be capable of automating many software tasks that currently take humans a\nmonth.",
      "authors": [
        "Thomas Kwa",
        "Ben West",
        "Joel Becker",
        "Amy Deng",
        "Katharyn Garcia",
        "Max Hasin",
        "Sami Jawhar",
        "Megan Kinniment",
        "Nate Rush",
        "Sydney Von Arx",
        "Ryan Bloom",
        "Thomas Broadley",
        "Haoxing Du",
        "Brian Goodrich",
        "Nikola Jurkovic",
        "Luke Harold Miles",
        "Seraphina Nix",
        "Tao Lin",
        "Neev Parikh",
        "David Rein",
        "Lucas Jun Koba Sato",
        "Hjalmar Wijk",
        "Daniel M. Ziegler",
        "Elizabeth Barnes",
        "Lawrence Chan"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14499v1",
        "http://arxiv.org/pdf/2503.14499v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14434v1",
      "title": "LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as\n  Evolutionary Optimizers",
      "published": "2025-03-18T17:11:24Z",
      "updated": "2025-03-18T17:11:24Z",
      "summary": "Automated feature engineering plays a critical role in improving predictive\nmodel performance for tabular learning tasks. Traditional automated feature\nengineering methods are limited by their reliance on pre-defined\ntransformations within fixed, manually designed search spaces, often neglecting\ndomain knowledge. Recent advances using Large Language Models (LLMs) have\nenabled the integration of domain knowledge into the feature engineering\nprocess. However, existing LLM-based approaches use direct prompting or rely\nsolely on validation scores for feature selection, failing to leverage insights\nfrom prior feature discovery experiments or establish meaningful reasoning\nbetween feature generation and data-driven performance. To address these\nchallenges, we propose LLM-FE, a novel framework that combines evolutionary\nsearch with the domain knowledge and reasoning capabilities of LLMs to\nautomatically discover effective features for tabular learning tasks. LLM-FE\nformulates feature engineering as a program search problem, where LLMs propose\nnew feature transformation programs iteratively, and data-driven feedback\nguides the search process. Our results demonstrate that LLM-FE consistently\noutperforms state-of-the-art baselines, significantly enhancing the performance\nof tabular prediction models across diverse classification and regression\nbenchmarks.",
      "authors": [
        "Nikhil Abhyankar",
        "Parshin Shojaee",
        "Chandan K. Reddy"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14434v1",
        "http://arxiv.org/pdf/2503.14434v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14432v1",
      "title": "PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via\n  Tool Play",
      "published": "2025-03-18T17:09:57Z",
      "updated": "2025-03-18T17:09:57Z",
      "summary": "Large language models (LLMs) are increasingly integrated with specialized\nexternal tools, yet many tasks demand zero-shot tool usage with minimal or\nnoisy documentation. Existing solutions rely on manual rewriting or labeled\ndata for validation, making them inapplicable in true zero-shot settings. To\naddress these challenges, we propose PLAY2PROMPT, an automated framework that\nsystematically \"plays\" with each tool to explore its input-output behaviors.\nThrough this iterative trial-and-error process, PLAY2PROMPT refines tool\ndocumentation and generates usage examples without any labeled data. These\nexamples not only guide LLM inference but also serve as validation to further\nenhance tool utilization. Extensive experiments on real-world tasks demonstrate\nthat PLAY2PROMPT significantly improves zero-shot tool performance across both\nopen and closed models, offering a scalable and effective solution for\ndomain-specific tool integration.",
      "authors": [
        "Wei Fang",
        "Yang Zhang",
        "Kaizhi Qian",
        "James Glass",
        "Yada Zhu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14432v1",
        "http://arxiv.org/pdf/2503.14432v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14283v1",
      "title": "Techno-Feudalism and the Rise of AGI: A Future Without Economic Rights?",
      "published": "2025-03-18T14:21:17Z",
      "updated": "2025-03-18T14:21:17Z",
      "summary": "The rise of Artificial General Intelligence (AGI) marks an existential\nrupture in economic and political order, dissolving the historic boundaries\nbetween labor and capital. Unlike past technological advancements, AGI is both\na worker and an owner, producing economic value while concentrating power in\nthose who control its infrastructure. Left unchecked, this shift risks\nexacerbating inequality, eroding democratic agency, and entrenching\ntechno-feudalism. The classical Social Contract-rooted in human labor as the\nfoundation of economic participation-must be renegotiated to prevent mass\ndisenfranchisement. This paper calls for a redefined economic framework that\nensures AGI-driven prosperity is equitably distributed through mechanisms such\nas universal AI dividends, progressive taxation, and decentralized governance.\nThe time for intervention is now-before intelligence itself becomes the most\nexclusive form of capital.",
      "authors": [
        "Pascal Stiefenhofer"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14283v1",
        "http://arxiv.org/pdf/2503.14283v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14273v2",
      "title": "Manual Labelling Artificially Inflates Deep Learning-Based Segmentation\n  Performance on RGB Images of Closed Canopy: Validation Using TLS",
      "published": "2025-03-18T14:09:00Z",
      "updated": "2025-03-19T16:17:19Z",
      "summary": "Monitoring forest dynamics at an individual tree scale is essential for\naccurately assessing ecosystem responses to climate change, yet traditional\nmethods relying on field-based forest inventories are labor-intensive and\nlimited in spatial coverage. Advances in remote sensing using drone-acquired\nRGB imagery combined with deep learning models have promised precise individual\ntree crown (ITC) segmentation; however, existing methods are frequently\nvalidated against human-annotated images, lacking rigorous independent ground\ntruth. In this study, we generate high-fidelity validation labels from\nco-located Terrestrial Laser Scanning (TLS) data for drone imagery of mixed\nunmanaged boreal and Mediterranean forests. We evaluate the performance of two\nwidely used deep learning ITC segmentation models - DeepForest (RetinaNet) and\nDetectree2 (Mask R-CNN) - on these data, and compare to performance on further\nMediterranean forest data labelled manually. When validated against TLS-derived\nground truth from Mediterranean forests, model performance decreased\nsignificantly compared to assessment based on hand-labelled from an\necologically similar site (AP50: 0.094 vs. 0.670). Restricting evaluation to\nonly canopy trees shrank this gap considerably (Canopy AP50: 0.365), although\nperformance was still far lower than on similar hand-labelled data. Models also\nperformed poorly on boreal forest data (AP50: 0.142), although again increasing\nwhen evaluated on canopy trees only (Canopy AP50: 0.308). Both models showed\nvery poor localisation accuracy at stricter IoU thresholds, even when\nrestricted to canopy trees (Max AP75: 0.051). Similar results have been\nobserved in studies using aerial LiDAR data, suggesting fundamental limitations\nin aerial-based segmentation approaches in closed canopy forests.",
      "authors": [
        "Matthew J. Allen",
        "Harry J. F. Owen",
        "Stuart W. D. Grieve",
        "Emily R. Lines"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4; I.4.6; I.4.8; I.4.9; I.5; I.5.4"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14273v2",
        "http://arxiv.org/pdf/2503.14273v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14258v1",
      "title": "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal\n  System",
      "published": "2025-03-18T13:48:18Z",
      "updated": "2025-03-18T13:48:18Z",
      "summary": "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https://github.com/oneal2000/JuDGE.",
      "authors": [
        "Weihang Su",
        "Baoqing Yue",
        "Qingyao Ai",
        "Yiran Hu",
        "Jiaqi Li",
        "Changyue Wang",
        "Kaiyuan Zhang",
        "Yueyue Wu",
        "Yiqun Liu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14258v1",
        "http://arxiv.org/pdf/2503.14258v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14184v1",
      "title": "Variable Time-Step MPC for Agile Multi-Rotor UAV Interception of Dynamic\n  Targets",
      "published": "2025-03-18T11:59:24Z",
      "updated": "2025-03-18T11:59:24Z",
      "summary": "Agile trajectory planning can improve the efficiency of multi-rotor Uncrewed\nAerial Vehicles (UAVs) in scenarios with combined task-oriented and kinematic\ntrajectory planning, such as monitoring spatio-temporal phenomena or\nintercepting dynamic targets. Agile planning using existing non-linear model\npredictive control methods is limited by the number of planning steps as it\nbecomes increasingly computationally demanding. That reduces the prediction\nhorizon length, leading to a decrease in solution quality. Besides, the fixed\ntime-step length limits the utilization of the available UAV dynamics in the\ntarget neighborhood. In this paper, we propose to address these limitations by\nintroducing variable time steps and coupling them with the prediction horizon\nlength. A simplified point-mass motion primitive is used to leverage the\ndifferential flatness of quadrotor dynamics and the generation of feasible\ntrajectories in the flat output space. Based on the presented evaluation\nresults and experimentally validated deployment, the proposed method increases\nthe solution quality by enabling planning for long flight segments but allowing\ntightly sampled maneuvering.",
      "authors": [
        "Atharva Ghotavadekar",
        "Franti\u0161ek Nekov\u00e1\u0159",
        "Martin Saska",
        "Jan Faigl"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3518096",
        "http://arxiv.org/abs/2503.14184v1",
        "http://arxiv.org/pdf/2503.14184v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14138v1",
      "title": "Exploring Disparity-Accuracy Trade-offs in Face Recognition Systems: The\n  Role of Datasets, Architectures, and Loss Functions",
      "published": "2025-03-18T11:04:57Z",
      "updated": "2025-03-18T11:04:57Z",
      "summary": "Automated Face Recognition Systems (FRSs), developed using deep learning\nmodels, are deployed worldwide for identity verification and facial attribute\nanalysis. The performance of these models is determined by a complex\ninterdependence among the model architecture, optimization/loss function and\ndatasets. Although FRSs have surpassed human-level accuracy, they continue to\nbe disparate against certain demographics. Due to the ubiquity of applications,\nit is extremely important to understand the impact of the three components --\nmodel architecture, loss function and face image dataset on the\naccuracy-disparity trade-off to design better, unbiased platforms. In this\nwork, we perform an in-depth analysis of three FRSs for the task of gender\nprediction, with various architectural modifications resulting in ten\ndeep-learning models coupled with four loss functions and benchmark them on\nseven face datasets across 266 evaluation configurations. Our results show that\nall three components have an individual as well as a combined impact on both\naccuracy and disparity. We identify that datasets have an inherent property\nthat causes them to perform similarly across models, independent of the choice\nof loss functions. Moreover, the choice of dataset determines the model's\nperceived bias -- the same model reports bias in opposite directions for three\ngender-balanced datasets of ``in-the-wild'' face images of popular individuals.\nStudying the facial embeddings shows that the models are unable to generalize a\nuniform definition of what constitutes a ``female face'' as opposed to a ``male\nface'', due to dataset diversity. We provide recommendations to model\ndevelopers on using our study as a blueprint for model development and\nsubsequent deployment.",
      "authors": [
        "Siddharth D Jaiswal",
        "Sagnik Basu",
        "Sandipan Sikdar",
        "Animesh Mukherjee"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14138v1",
        "http://arxiv.org/pdf/2503.14138v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14130v1",
      "title": "Inference-Time Intervention in Large Language Models for Reliable\n  Requirement Verification",
      "published": "2025-03-18T10:49:36Z",
      "updated": "2025-03-18T10:49:36Z",
      "summary": "Steering the behavior of Large Language Models (LLMs) remains a challenge,\nparticularly in engineering applications where precision and reliability are\ncritical. While fine-tuning and prompting methods can modify model behavior,\nthey lack the dynamic and exact control necessary for engineering applications.\nInference-time intervention techniques provide a promising alternative,\nallowing targeted adjustments to LLM outputs. In this work, we demonstrate how\ninterventions enable fine-grained control for automating the usually\ntime-intensive requirement verification process in Model-Based Systems\nEngineering (MBSE). Using two early-stage Capella SysML models of space\nmissions with associated requirements, we apply the intervened LLMs to reason\nover a graph representation of the model to determine whether a requirement is\nfulfilled. Our method achieves robust and reliable outputs, significantly\nimproving over both a baseline model and a fine-tuning approach. By identifying\nand modifying as few as one to three specialised attention heads, we can\nsignificantly change the model's behavior. When combined with self-consistency,\nthis allows us to achieve perfect precision on our holdout test set.",
      "authors": [
        "Paul Darm",
        "James Xie",
        "Annalisa Riccardi"
      ],
      "categories": [
        "cs.AI",
        "cs.SE",
        "H.4.2; I.2.1; I.2.7"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14130v1",
        "http://arxiv.org/pdf/2503.14130v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14005v1",
      "title": "Flexible BiSel/NiO-based X-ray synapses bridging the functions of\n  detection and memory",
      "published": "2025-03-18T08:10:50Z",
      "updated": "2025-03-18T08:10:50Z",
      "summary": "Currently, the X-ray detectors are widely used in medical imaging, industrial\ninspection, aerospace, and other fields, as the market demand for\nhigh-efficiency, flexible, and low-power detectors is increased. Although the\ntraditional inorganic X-ray detection materials have achieved great success and\neffectiveness, they have their own limitations and let alone\nflexibility/bendability and memory function. In this study, we present the\ndesign of a BiSeI/NiO-based X-ray synaptic detector and its application in the\nsimulation of biological synaptic processes. Herein, the BiSeI, a quasi-1D\ninorganic semiconductor, stands out as an ideal choice for the X-ray detectors,\nespecially for flexible and portable devices due to its large atomic number,\nlarge photoelectric absorption coefficient, and mechanical plasticity.\nMeanwhile, the NiO-based materials provide the memory function required for the\nintelligent detection systems. Moreover, our devices offer notable advantages\nin terms of low power consumption, compared with traditional X-ray detectors.\nThe BiSeI/NiO detectors demonstrate advanced features with an ultrahigh\nsensitivity, an ultralow detection limit, and include the paired-pulse\nfacilitation (PPF) and the transition from short- to long-term memory,\nmaintaining the functionality on flexible substrates. This design represents a\nsignificant step toward the development of intelligent and flexible X-ray\ndetectors.",
      "authors": [
        "Qiao Wang",
        "Pengfei Li",
        "Yushou Song",
        "Jalu Li",
        "Haiying Xiao",
        "Yuqing Wang",
        "Guoliang Ma",
        "Hsu-Sheng Tsai",
        "Ping-An Hu"
      ],
      "categories": [
        "physics.ins-det",
        "cond-mat.mtrl-sci",
        "physics.optics"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14005v1",
        "http://arxiv.org/pdf/2503.14005v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14002v1",
      "title": "MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific\n  Generative Modeling",
      "published": "2025-03-18T08:09:24Z",
      "updated": "2025-03-18T08:09:24Z",
      "summary": "Generative models have recently made remarkable progress in the field of 3D\nobjects. However, their practical application in fields like engineering\nremains limited since they fail to deliver the accuracy, quality, and\ncontrollability needed for domain-specific tasks. Fine-tuning large generative\nmodels is a promising perspective for making these models available in these\nfields. Creating high-quality, domain-specific 3D datasets is crucial for\nfine-tuning large generative models, yet the data filtering and annotation\nprocess remains a significant bottleneck. We present MeshFleet, a filtered and\nannotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive\npublicly available collection of 3D objects. Our approach proposes a pipeline\nfor automated data filtering based on a quality classifier. This classifier is\ntrained on a manually labeled subset of Objaverse, incorporating DINOv2 and\nSigLIP embeddings, refined through caption-based analysis and uncertainty\nestimation. We demonstrate the efficacy of our filtering method through a\ncomparative analysis against caption and image aesthetic score-based techniques\nand fine-tuning experiments with SV3D, highlighting the importance of targeted\ndata selection for domain-specific 3D generative modeling.",
      "authors": [
        "Damian Boborzi",
        "Phillip Mueller",
        "Jonas Emrich",
        "Dominik Schmid",
        "Sebastian Mueller",
        "Lars Mikelsons"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14002v1",
        "http://arxiv.org/pdf/2503.14002v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13923v1",
      "title": "ConSCompF: Consistency-focused Similarity Comparison Framework for\n  Generative Large Language Models",
      "published": "2025-03-18T05:38:04Z",
      "updated": "2025-03-18T05:38:04Z",
      "summary": "Large language models (LLMs) have been one of the most important discoveries\nin machine learning in recent years. LLM-based artificial intelligence (AI)\nassistants, such as ChatGPT, have consistently attracted the attention from\nresearchers, investors, and the general public, driving the rapid growth of\nthis industry. With the frequent introduction of new LLMs to the market, it\nbecomes increasingly difficult to differentiate between them, creating a demand\nfor new LLM comparison methods.\n  In this research, the Consistency-focused Similarity Comparison Framework\n(ConSCompF) for generative large language models is proposed. It compares texts\ngenerated by two LLMs and produces a similarity score, indicating the overall\ndegree of similarity between their responses. The main advantage of this\nframework is that it can operate on a small number of unlabeled data, such as\nchatbot instruction prompts, and does not require LLM developers to disclose\nany information about their product.\n  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying\nsimilarities between multiple LLMs are conducted. Additionally, these\nexperiments examine the correlation between the similarity scores generated by\nConSCompF and the differences in the outputs produced by other benchmarking\ntechniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison\nexperiments is conducted to evaluate the performance of ConSCompF in a few-shot\nLLM comparison scenario.\n  The proposed framework can be used for calculating similarity matrices of\nmultiple LLMs, which can be effectively visualized using principal component\nanalysis (PCA). The ConSCompF output may provide useful insights into data that\nmight have been used during LLM training and help detect possible investment\nfraud attempts.",
      "authors": [
        "Alexey Karev",
        "Dong Xu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1613/jair.1.17028",
        "http://arxiv.org/abs/2503.13923v1",
        "http://arxiv.org/pdf/2503.13923v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13882v1",
      "title": "MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented\n  Generation for Embodied AI Environments",
      "published": "2025-03-18T04:27:02Z",
      "updated": "2025-03-18T04:27:02Z",
      "summary": "While human cognition inherently retrieves information from diverse and\nspecialized knowledge sources during decision-making processes, current\nRetrieval-Augmented Generation (RAG) systems typically operate through\nsingle-source knowledge retrieval, leading to a cognitive-algorithmic\ndiscrepancy. To bridge this gap, we introduce MoK-RAG, a novel multi-source RAG\nframework that implements a mixture of knowledge paths enhanced retrieval\nmechanism through functional partitioning of a large language model (LLM)\ncorpus into distinct sections, enabling retrieval from multiple specialized\nknowledge paths. Applied to the generation of 3D simulated environments, our\nproposed MoK-RAG3D enhances this paradigm by partitioning 3D assets into\ndistinct sections and organizing them based on a hierarchical knowledge tree\nstructure. Different from previous methods that only use manual evaluation, we\npioneered the introduction of automated evaluation methods for 3D scenes. Both\nautomatic and human evaluations in our experiments demonstrate that MoK-RAG3D\ncan assist Embodied AI agents in generating diverse scenes.",
      "authors": [
        "Zhengsheng Guo",
        "Linwei Zheng",
        "Xinyang Chen",
        "Xuefeng Bai",
        "Kehai Chen",
        "Min Zhang"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13882v1",
        "http://arxiv.org/pdf/2503.13882v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13879v1",
      "title": "Bridging Social Psychology and LLM Reasoning: Conflict-Aware Meta-Review\n  Generation via Cognitive Alignment",
      "published": "2025-03-18T04:13:11Z",
      "updated": "2025-03-18T04:13:11Z",
      "summary": "The rapid growth of scholarly submissions has overwhelmed traditional peer\nreview systems, driving the need for intelligent automation to preserve\nscientific rigor. While large language models (LLMs) show promise in automating\nmanuscript critiques, their ability to synthesize high-stakes meta-reviews,\nwhich require conflict-aware reasoning and consensus derivation, remains\nunderdeveloped. Existing methods fail to effectively handle conflicting\nviewpoints within differing opinions, and often introduce additional cognitive\nbiases, such as anchoring effects and conformity bias.To overcome these\nlimitations, we propose the Cognitive Alignment Framework (CAF), a dual-process\narchitecture that transforms LLMs into adaptive scientific arbitrators. By\noperationalizing Kahneman's dual-process theory, CAF introduces a three-step\ncognitive pipeline: review initialization, incremental integration, and\ncognitive alignment.Empirical validation shows that CAF outperforms existing\nLLM-based methods, with sentiment consistency gains reaching up to 19.47\\% and\ncontent consistency improving by as much as 12.95\\%.",
      "authors": [
        "Wei Chen",
        "Han Ding",
        "Meng Yuan",
        "Zhao Zhang",
        "Deqing Wang",
        "Fuzhen Zhuang"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13879v1",
        "http://arxiv.org/pdf/2503.13879v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14557v1",
      "title": "Generating Causal Explanations of Vehicular Agent Behavioural\n  Interactions with Learnt Reward Profiles",
      "published": "2025-03-18T01:53:59Z",
      "updated": "2025-03-18T01:53:59Z",
      "summary": "Transparency and explainability are important features that responsible\nautonomous vehicles should possess, particularly when interacting with humans,\nand causal reasoning offers a strong basis to provide these qualities. However,\neven if one assumes agents act to maximise some concept of reward, it is\ndifficult to make accurate causal inferences of agent planning without\ncapturing what is of importance to the agent. Thus our work aims to learn a\nweighting of reward metrics for agents such that explanations for agent\ninteractions can be causally inferred. We validate our approach quantitatively\nand qualitatively across three real-world driving datasets, demonstrating a\nfunctional improvement over previous methods and competitive performance across\nevaluation metrics.",
      "authors": [
        "Rhys Howard",
        "Nick Hawes",
        "Lars Kunze"
      ],
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "I.2.0; I.2.6; I.2.9; I.2.11; I.6.0"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14557v1",
        "http://arxiv.org/pdf/2503.14557v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13817v1",
      "title": "VARP: Reinforcement Learning from Vision-Language Model Feedback with\n  Agent Regularized Preferences",
      "published": "2025-03-18T01:51:27Z",
      "updated": "2025-03-18T01:51:27Z",
      "summary": "Designing reward functions for continuous-control robotics often leads to\nsubtle misalignments or reward hacking, especially in complex tasks.\nPreference-based RL mitigates some of these pitfalls by learning rewards from\ncomparative feedback rather than hand-crafted signals, yet scaling human\nannotations remains challenging. Recent work uses Vision-Language Models (VLMs)\nto automate preference labeling, but a single final-state image generally fails\nto capture the agent's full motion. In this paper, we present a two-part\nsolution that both improves feedback accuracy and better aligns reward learning\nwith the agent's policy. First, we overlay trajectory sketches on final\nobservations to reveal the path taken, allowing VLMs to provide more reliable\npreferences-improving preference accuracy by approximately 15-20% in metaworld\ntasks. Second, we regularize reward learning by incorporating the agent's\nperformance, ensuring that the reward model is optimized based on data\ngenerated by the current policy; this addition boosts episode returns by 20-30%\nin locomotion tasks. Empirical studies on metaworld demonstrate that our method\nachieves, for instance, around 70-80% success rate in all tasks, compared to\nbelow 50% for standard approaches. These results underscore the efficacy of\ncombining richer visual representations with agent-aware reward regularization.",
      "authors": [
        "Anukriti Singh",
        "Amisha Bhaskar",
        "Peihong Yu",
        "Souradip Chakraborty",
        "Ruthwik Dasyam",
        "Amrit Bedi",
        "Pratap Tokekar"
      ],
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13817v1",
        "http://arxiv.org/pdf/2503.13817v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13813v1",
      "title": "Automatic MILP Model Construction for Multi-Robot Task Allocation and\n  Scheduling Based on Large Language Models",
      "published": "2025-03-18T01:45:19Z",
      "updated": "2025-03-18T01:45:19Z",
      "summary": "With the accelerated development of Industry 4.0, intelligent manufacturing\nsystems increasingly require efficient task allocation and scheduling in\nmulti-robot systems. However, existing methods rely on domain expertise and\nface challenges in adapting to dynamic production constraints. Additionally,\nenterprises have high privacy requirements for production scheduling data,\nwhich prevents the use of cloud-based large language models (LLMs) for solution\ndevelopment. To address these challenges, there is an urgent need for an\nautomated modeling solution that meets data privacy requirements. This study\nproposes a knowledge-augmented mixed integer linear programming (MILP)\nautomated formulation framework, integrating local LLMs with domain-specific\nknowledge bases to generate executable code from natural language descriptions\nautomatically. The framework employs a knowledge-guided\nDeepSeek-R1-Distill-Qwen-32B model to extract complex spatiotemporal\nconstraints (82% average accuracy) and leverages a supervised fine-tuned\nQwen2.5-Coder-7B-Instruct model for efficient MILP code generation (90% average\naccuracy). Experimental results demonstrate that the framework successfully\nachieves automatic modeling in the aircraft skin manufacturing case while\nensuring data privacy and computational efficiency. This research provides a\nlow-barrier and highly reliable technical path for modeling in complex\nindustrial scenarios.",
      "authors": [
        "Mingming Peng",
        "Zhendong Chen",
        "Jie Yang",
        "Jin Huang",
        "Zhengqi Shi",
        "Qihao Liu",
        "Xinyu Li",
        "Liang Gao"
      ],
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13813v1",
        "http://arxiv.org/pdf/2503.13813v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13806v1",
      "title": "Organ-aware Multi-scale Medical Image Segmentation Using Text Prompt\n  Engineering",
      "published": "2025-03-18T01:35:34Z",
      "updated": "2025-03-18T01:35:34Z",
      "summary": "Accurate segmentation is essential for effective treatment planning and\ndisease monitoring. Existing medical image segmentation methods predominantly\nrely on uni-modal visual inputs, such as images or videos, requiring\nlabor-intensive manual annotations. Additionally, medical imaging techniques\ncapture multiple intertwined organs within a single scan, further complicating\nsegmentation accuracy. To address these challenges, MedSAM, a large-scale\nmedical segmentation model based on the Segment Anything Model (SAM), was\ndeveloped to enhance segmentation accuracy by integrating image features with\nuser-provided prompts. While MedSAM has demonstrated strong performance across\nvarious medical segmentation tasks, it primarily relies on geometric prompts\n(e.g., points and bounding boxes) and lacks support for text-based prompts,\nwhich could help specify subtle or ambiguous anatomical structures. To overcome\nthese limitations, we propose the Organ-aware Multi-scale Text-guided Medical\nImage Segmentation Model (OMT-SAM) for multi-organ segmentation. Our approach\nintroduces CLIP encoders as a novel image-text prompt encoder, operating with\nthe geometric prompt encoder to provide informative contextual guidance. We\npair descriptive textual prompts with corresponding images, processing them\nthrough pre-trained CLIP encoders and a cross-attention mechanism to generate\nfused image-text embeddings. Additionally, we extract multi-scale visual\nfeatures from MedSAM, capturing fine-grained anatomical details at different\nlevels of granularity. We evaluate OMT-SAM on the FLARE 2021 dataset,\nbenchmarking its performance against existing segmentation methods. Empirical\nresults demonstrate that OMT-SAM achieves a mean Dice Similarity Coefficient of\n0.937, outperforming MedSAM (0.893) and other segmentation models, highlighting\nits superior capability in handling complex medical image segmentation tasks.",
      "authors": [
        "Wenjie Zhang",
        "Ziyang Zhang",
        "Mengnan He",
        "Jiancheng Ye"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13806v1",
        "http://arxiv.org/pdf/2503.13806v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13799v1",
      "title": "SMILE: a Scale-aware Multiple Instance Learning Method for Multicenter\n  STAS Lung Cancer Histopathology Diagnosis",
      "published": "2025-03-18T01:09:52Z",
      "updated": "2025-03-18T01:09:52Z",
      "summary": "Spread through air spaces (STAS) represents a newly identified aggressive\npattern in lung cancer, which is known to be associated with adverse prognostic\nfactors and complex pathological features. Pathologists currently rely on time\nconsuming manual assessments, which are highly subjective and prone to\nvariation. This highlights the urgent need for automated and precise diag\nnostic solutions. 2,970 lung cancer tissue slides are comprised from multiple\ncenters, re-diagnosed them, and constructed and publicly released three lung\ncancer STAS datasets: STAS CSU (hospital), STAS TCGA, and STAS CPTAC. All STAS\ndatasets provide corresponding pathological feature diagnoses and related\nclinical data. To address the bias, sparse and heterogeneous nature of STAS, we\npropose an scale-aware multiple instance learning(SMILE) method for STAS\ndiagnosis of lung cancer. By introducing a scale-adaptive attention mechanism,\nthe SMILE can adaptively adjust high attention instances, reducing\nover-reliance on local regions and promoting consistent detection of STAS\nlesions. Extensive experiments show that SMILE achieved competitive diagnostic\nresults on STAS CSU, diagnosing 251 and 319 STAS samples in CPTAC\nandTCGA,respectively, surpassing clinical average AUC. The 11 open baseline\nresults are the first to be established for STAS research, laying the\nfoundation for the future expansion, interpretability, and clinical integration\nof computational pathology technologies. The datasets and code are available at\nhttps://anonymous.4open.science/r/IJCAI25-1DA1.",
      "authors": [
        "Liangrui Pan",
        "Xiaoyu Li",
        "Yutao Dou",
        "Qiya Song",
        "Jiadi Luo",
        "Qingchun Liang",
        "Shaoliang Peng"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13799v1",
        "http://arxiv.org/pdf/2503.13799v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13778v1",
      "title": "Using 3D reconstruction from image motion to predict total leaf area in\n  dwarf tomato plants",
      "published": "2025-03-17T23:51:19Z",
      "updated": "2025-03-17T23:51:19Z",
      "summary": "Accurate estimation of total leaf area (TLA) is crucial for evaluating plant\ngrowth, photosynthetic activity, and transpiration. However, it remains\nchallenging for bushy plants like dwarf tomatoes due to their complex canopies.\nTraditional methods are often labor-intensive, damaging to plants, or limited\nin capturing canopy complexity. This study evaluated a non-destructive method\ncombining sequential 3D reconstructions from RGB images and machine learning to\nestimate TLA for three dwarf tomato cultivars: Mohamed, Hahms Gelbe Topftomate,\nand Red Robin -- grown under controlled greenhouse conditions. Two experiments\n(spring-summer and autumn-winter) included 73 plants, yielding 418 TLA\nmeasurements via an \"onion\" approach. High-resolution videos were recorded, and\n500 frames per plant were used for 3D reconstruction. Point clouds were\nprocessed using four algorithms (Alpha Shape, Marching Cubes, Poisson's, Ball\nPivoting), and meshes were evaluated with seven regression models:\nMultivariable Linear Regression, Lasso Regression, Ridge Regression, Elastic\nNet Regression, Random Forest, Extreme Gradient Boosting, and Multilayer\nPerceptron. The Alpha Shape reconstruction ($\\alpha = 3$) with Extreme Gradient\nBoosting achieved the best performance ($R^2 = 0.80$, $MAE = 489 cm^2$).\nCross-experiment validation showed robust results ($R^2 = 0.56$, $MAE = 579\ncm^2$). Feature importance analysis identified height, width, and surface area\nas key predictors. This scalable, automated TLA estimation method is suited for\nurban farming and precision agriculture, offering applications in automated\npruning, resource efficiency, and sustainable food production. The approach\ndemonstrated robustness across variable environmental conditions and canopy\nstructures.",
      "authors": [
        "Dmitrii Usenko",
        "David Helman",
        "Chen Giladi"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13778v1",
        "http://arxiv.org/pdf/2503.13778v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13708v1",
      "title": "A Circular Construction Product Ontology for End-of-Life Decision-Making",
      "published": "2025-03-17T20:28:08Z",
      "updated": "2025-03-17T20:28:08Z",
      "summary": "Efficient management of end-of-life (EoL) products is critical for advancing\ncircularity in supply chains, particularly within the construction industry\nwhere EoL strategies are hindered by heterogenous lifecycle data and data\nsilos. Current tools like Environmental Product Declarations (EPDs) and Digital\nProduct Passports (DPPs) are limited by their dependency on seamless data\nintegration and interoperability which remain significant challenges. To\naddress these, we present the Circular Construction Product Ontology (CCPO), an\napplied framework designed to overcome semantic and data heterogeneity\nchallenges in EoL decision-making for construction products. CCPO standardises\nvocabulary and facilitates data integration across supply chain stakeholders\nenabling lifecycle assessments (LCA) and robust decision-making. By aggregating\ndisparate data into a unified product provenance, CCPO enables automated EoL\nrecommendations through customisable SWRL rules aligned with European standards\nand stakeholder-specific circularity SLAs, demonstrating its scalability and\nintegration capabilities. The adopted circular product scenario depicts CCPO's\napplication while competency question evaluations show its superior performance\nin generating accurate EoL suggestions highlighting its potential to greatly\nimprove decision-making in circular supply chains and its applicability in\nreal-world construction environments.",
      "authors": [
        "Kwabena Adu-Duodu",
        "Stanly Wilson",
        "Yinhao Li",
        "Aanuoluwapo Oladimeji",
        "Talea Huraysi",
        "Masoud Barati",
        "Charith Perera",
        "Ellis Solaiman",
        "Omer Rana",
        "Rajiv Ranjan",
        "Tejal Shah"
      ],
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13708v1",
        "http://arxiv.org/pdf/2503.13708v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14550v1",
      "title": "Novel AI-Based Quantification of Breast Arterial Calcification to\n  Predict Cardiovascular Risk",
      "published": "2025-03-17T19:38:17Z",
      "updated": "2025-03-17T19:38:17Z",
      "summary": "Women are underdiagnosed and undertreated for cardiovascular disease.\nAutomatic quantification of breast arterial calcification on screening\nmammography can identify women at risk for cardiovascular disease and enable\nearlier treatment and management of disease. In this retrospective study of\n116,135 women from two healthcare systems, a transformer-based neural network\nquantified BAC severity (no BAC, mild, moderate, and severe) on screening\nmammograms. Outcomes included major adverse cardiovascular events (MACE) and\nall-cause mortality. BAC severity was independently associated with MACE after\nadjusting for cardiovascular risk factors, with increasing hazard ratios from\nmild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22)\nacross datasets (all p<0.001). This association remained significant across all\nage groups, with even mild BAC indicating increased risk in women under 50. BAC\nremained an independent predictor when analyzed alongside ASCVD risk scores,\nshowing significant associations with myocardial infarction, stroke, heart\nfailure, and mortality (all p<0.005). Automated BAC quantification enables\nopportunistic cardiovascular risk assessment during routine mammography without\nadditional radiation or cost. This approach provides value beyond traditional\nrisk factors, particularly in younger women, offering potential for early CVD\nrisk stratification in the millions of women undergoing annual mammography.",
      "authors": [
        "Theodorus Dapamede",
        "Aisha Urooj",
        "Vedant Joshi",
        "Gabrielle Gershon",
        "Frank Li",
        "Mohammadreza Chavoshi",
        "Beatrice Brown-Mulry",
        "Rohan Satya Isaac",
        "Aawez Mansuri",
        "Chad Robichaux",
        "Chadi Ayoub",
        "Reza Arsanjani",
        "Laurence Sperling",
        "Judy Gichoya",
        "Marly van Assen",
        "Charles W. ONeill",
        "Imon Banerjee",
        "Hari Trivedi"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14550v1",
        "http://arxiv.org/pdf/2503.14550v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13660v1",
      "title": "INPROVF: Leveraging Large Language Models to Repair High-level Robot\n  Controllers from Assumption Violations",
      "published": "2025-03-17T19:08:36Z",
      "updated": "2025-03-17T19:08:36Z",
      "summary": "This paper presents INPROVF, an automatic framework that combines large\nlanguage models (LLMs) and formal methods to speed up the repair process of\nhigh-level robot controllers. Previous approaches based solely on formal\nmethods are computationally expensive and cannot scale to large state spaces.\nIn contrast, INPROVF uses LLMs to generate repair candidates, and formal\nmethods to verify their correctness. To improve the quality of these\ncandidates, our framework first translates the symbolic representations of the\nenvironment and controllers into natural language descriptions. If a candidate\nfails the verification, INPROVF provides feedback on potential unsafe behaviors\nor unsatisfied tasks, and iteratively prompts LLMs to generate improved\nsolutions. We demonstrate the effectiveness of INPROVF through 12 violations\nwith various workspaces, tasks, and state space sizes.",
      "authors": [
        "Qian Meng",
        "Jin Peng Zhou",
        "Kilian Q. Weinberger",
        "Hadas Kress-Gazit"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13660v1",
        "http://arxiv.org/pdf/2503.13660v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13441v1",
      "title": "Humanoid Policy ~ Human Policy",
      "published": "2025-03-17T17:59:09Z",
      "updated": "2025-03-17T17:59:09Z",
      "summary": "Training manipulation policies for humanoid robots with diverse data enhances\ntheir robustness and generalization across tasks and platforms. However,\nlearning solely from robot demonstrations is labor-intensive, requiring\nexpensive tele-operated data collection which is difficult to scale. This paper\ninvestigates a more scalable data source, egocentric human demonstrations, to\nserve as cross-embodiment training data for robot learning. We mitigate the\nembodiment gap between humanoids and humans from both the data and modeling\nperspectives. We collect an egocentric task-oriented dataset (PH2D) that is\ndirectly aligned with humanoid manipulation demonstrations. We then train a\nhuman-humanoid behavior policy, which we term Human Action Transformer (HAT).\nThe state-action space of HAT is unified for both humans and humanoid robots\nand can be differentiably retargeted to robot actions. Co-trained with\nsmaller-scale robot data, HAT directly models humanoid robots and humans as\ndifferent embodiments without additional supervision. We show that human data\nimproves both generalization and robustness of HAT with significantly better\ndata collection efficiency. Code and data: https://human-as-robot.github.io/",
      "authors": [
        "Ri-Zhao Qiu",
        "Shiqi Yang",
        "Xuxin Cheng",
        "Chaitanya Chawla",
        "Jialong Li",
        "Tairan He",
        "Ge Yan",
        "Lars Paulsen",
        "Ge Yang",
        "Sha Yi",
        "Guanya Shi",
        "Xiaolong Wang"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13441v1",
        "http://arxiv.org/pdf/2503.13441v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13413v3",
      "title": "DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization\n  Framework from a Deep-Learning Perspective",
      "published": "2025-03-17T17:42:51Z",
      "updated": "2025-03-19T14:18:01Z",
      "summary": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, largely driven by well-designed prompts. However, crafting and selecting\nsuch prompts often requires considerable human effort, significantly limiting\nits scalability. To mitigate this, recent studies have explored automated\nprompt optimization as a promising solution. Despite these efforts, existing\nmethods still face critical challenges in robustness, efficiency, and\ngeneralization. To systematically address these challenges, we first conduct an\nempirical analysis to identify the limitations of current reflection-based\nprompt optimization paradigm. Building on these insights, we propose 7\ninnovative approaches inspired by traditional deep learning paradigms for\nprompt optimization (DLPO), seamlessly integrating these concepts into\ntext-based gradient optimization. Through these advancements, we progressively\ntackle the aforementioned challenges and validate our methods through extensive\nexperimentation. We hope our study not only provides valuable guidance for\nfuture research but also offers a comprehensive understanding of the challenges\nand potential solutions in prompt optimization. Our code is available at\nhttps://github.com/sfasfaffa/DLPO.",
      "authors": [
        "Dengyun Peng",
        "Yuhang Zhou",
        "Qiguang Chen",
        "Jinhao Liu",
        "Jingjing Chen",
        "Libo Qin"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13413v3",
        "http://arxiv.org/pdf/2503.13413v3"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13580v1",
      "title": "LLM Test Generation via Iterative Hybrid Program Analysis",
      "published": "2025-03-17T16:10:38Z",
      "updated": "2025-03-17T16:10:38Z",
      "summary": "Automating unit test generation remains a significant challenge, particularly\nfor complex methods in real-world projects. While Large Language Models (LLMs)\nhave made strides in code generation, they struggle to achieve high branch\ncoverage due to their limited ability to reason about intricate control flow\nstructures. To address this limitation, we introduce Panta, a technique that\nemulates the iterative process human developers follow when analyzing code and\nconstructing test cases. Panta integrates static control flow analysis and\ndynamic code coverage analysis to systematically guide LLMs in identifying\nuncovered execution paths and generating better test cases. By incorporating an\niterative feedback-driven mechanism, our technique continuously refines test\ngeneration based on static and dynamic path coverage insights, ensuring more\ncomprehensive and effective testing. Our empirical evaluation, conducted on\nclasses with high cyclomatic complexity from open-source projects, demonstrates\nthat Panta achieves 26% higher line coverage and 23% higher branch coverage\ncompared to the state-of-the-art.",
      "authors": [
        "Sijia Gu",
        "Noor Nashid",
        "Ali Mesbah"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13580v1",
        "http://arxiv.org/pdf/2503.13580v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13579v1",
      "title": "ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative\n  Prior",
      "published": "2025-03-17T15:59:02Z",
      "updated": "2025-03-17T15:59:02Z",
      "summary": "Despite the growing accessibility of skeletal motion data, integrating it for\nanimating character meshes remains challenging due to diverse configurations of\nboth skeletons and meshes. Specifically, the body scale and bone lengths of the\nskeleton should be adjusted in accordance with the size and proportions of the\nmesh, ensuring that all joints are accurately positioned within the character\nmesh. Furthermore, defining skinning weights is complicated by variations in\nskeletal configurations, such as the number of joints and their hierarchy, as\nwell as differences in mesh configurations, including their connectivity and\nshapes. While existing approaches have made efforts to automate this process,\nthey hardly address the variations in both skeletal and mesh configurations. In\nthis paper, we present a novel method for the automatic rigging and skinning of\ncharacter meshes using skeletal motion data, accommodating arbitrary\nconfigurations of both meshes and skeletons. The proposed method predicts the\noptimal skeleton aligned with the size and proportion of the mesh as well as\ndefines skinning weights for various mesh-skeleton configurations, without\nrequiring explicit supervision tailored to each of them. By incorporating\nDiffusion 3D Features (Diff3F) as semantic descriptors of character meshes, our\nmethod achieves robust generalization across different configurations. To\nassess the performance of our method in comparison to existing approaches, we\nconducted comprehensive evaluations encompassing both quantitative and\nqualitative analyses, specifically examining the predicted skeletons, skinning\nweights, and deformation quality.",
      "authors": [
        "Seokhyeon Hong",
        "Soojin Choi",
        "Chaelin Kim",
        "Sihun Cha",
        "Junyong Noh"
      ],
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13579v1",
        "http://arxiv.org/pdf/2503.13579v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13578v1",
      "title": "Convolutional neural network for early detection of lameness and\n  irregularity in horses using an IMU sensor",
      "published": "2025-03-17T15:05:01Z",
      "updated": "2025-03-17T15:05:01Z",
      "summary": "Lameness and gait irregularities are significant concerns in equine health\nmanagement, affecting performance, welfare, and economic value. Traditional\nobservational methods rely on subjective expert assessments, which can lead to\ninconsistencies in detecting subtle or early-stage lameness. While AI-based\napproaches have emerged, many require multiple sensors, force plates, or video\nsystems, making them costly and impractical for field deployment. In this\napplied research study, we present a stride-level classification system that\nutilizes a single inertial measurement unit (IMU) and a one-dimensional\nconvolutional neural network (1D CNN) to objectively differentiate between\nsound and lame horses, with a primary focus on the trot gait. The proposed\nsystem was tested under real-world conditions, achieving a 90% session-level\naccuracy with no false positives, demonstrating its robustness for practical\napplications. By employing a single, non-intrusive, and readily available\nsensor, our approach significantly reduces the complexity and cost of hardware\nrequirements while maintaining high classification performance. These results\nhighlight the potential of our CNN-based method as a field-tested, scalable\nsolution for automated lameness detection. By enabling early diagnosis, this\nsystem offers a valuable tool for preventing minor gait irregularities from\ndeveloping into severe conditions, ultimately contributing to improved equine\nwelfare and performance in veterinary and equestrian practice.",
      "authors": [
        "Beno\u00eet Savoini",
        "Jonathan Bertolaccini",
        "St\u00e9phane Montavon",
        "Michel Deriaz"
      ],
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13578v1",
        "http://arxiv.org/pdf/2503.13578v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14541v1",
      "title": "Regulating Ai In Financial Services: Legal Frameworks And Compliance\n  Challenges",
      "published": "2025-03-17T14:29:09Z",
      "updated": "2025-03-17T14:29:09Z",
      "summary": "This article examines the evolving landscape of artificial intelligence (AI)\nregulation in financial services, detailing the legal frameworks and compliance\nchallenges posed by rapid technological adoption. By reviewing current\nlegislation, industry guidelines, and real-world use cases, it highlights how\nAI-driven processes, from fraud detection to algorithmic trading, offer\nefficiency gains yet introduce significant risks, including algorithmic bias,\ndata privacy breaches, and lack of transparency in automated decision-making.\nThe study compares regulatory approaches across major jurisdictions such as the\nEuropean Union, United States, and United Kingdom, identifying both universal\nconcerns, like the need for explainability and robust data protection, and\nregion-specific compliance requirements that impact the implementation of\nhigh-risk AI applications. Additionally, it underscores emerging areas of\nfocus, such as liability for AI-driven errors, systemic risks posed by\ninterlinked AI systems, and the ethical considerations of technology-driven\nfinancial exclusion. The findings reveal gaps in existing rules and emphasize\nthe necessity for adaptive, technology-neutral policies capable of fostering\ninnovation while safeguarding consumer rights and market integrity. The article\nconcludes by proposing a principled regulatory model that balances flexibility\nwith enforceable standards, advocating closer collaboration between\npolicymakers, financial institutions, and AI developers to ensure a secure,\nfair, and forward-looking framework for AI in finance.",
      "authors": [
        "Shahmar Mirishli"
      ],
      "categories": [
        "cs.CY",
        "q-fin.GN"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14541v1",
        "http://arxiv.org/pdf/2503.14541v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14538v1",
      "title": "Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal\n  Approach Combining Imaging and Clinical Data",
      "published": "2025-03-17T14:08:35Z",
      "updated": "2025-03-17T14:08:35Z",
      "summary": "Background: This study introduces a Vision-Language Model (VLM) leveraging\nSIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB)\nscreening. By integrating chest X-ray images and clinical notes, the model aims\nto enhance diagnostic accuracy and efficiency, particularly in resource-limited\nsettings.\n  Methods: The VLM combines visual data from chest X-rays with clinical context\nto generate detailed, context-aware diagnostic reports. The architecture\nemploys SIGLIP for visual encoding and Gemma-3b for decoding, ensuring\neffective representation of acute TB-specific pathologies and clinical\ninsights.\n  Results: Key acute TB pathologies, including consolidation, cavities, and\nnodules, were detected with high precision (97percent) and recall (96percent).\nThe model demonstrated strong spatial localization capabilities and robustness\nin distinguishing TB-positive cases, making it a reliable tool for acute TB\ndiagnosis.\n  Conclusion: The multimodal capability of the VLM reduces reliance on\nradiologists, providing a scalable solution for acute TB screening. Future work\nwill focus on improving the detection of subtle pathologies and addressing\ndataset biases to enhance its generalizability and application in diverse\nglobal healthcare settings.",
      "authors": [
        "Ananya Ganapthy",
        "Praveen Shastry",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Varshinipriya M",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 68T45, 92C55, 92C50, 68U10"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14538v1",
        "http://arxiv.org/pdf/2503.14538v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13171v1",
      "title": "HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of\n  Imitation Learning",
      "published": "2025-03-17T13:49:43Z",
      "updated": "2025-03-17T13:49:43Z",
      "summary": "The acquisition of large-scale and diverse demonstration data are essential\nfor improving robotic imitation learning generalization. However, generating\nsuch data for complex manipulations is challenging in real-world settings. We\nintroduce HybridGen, an automated framework that integrates Vision-Language\nModel (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first,\nVLM to parse expert demonstrations, decomposing tasks into expert-dependent\n(object-centric pose transformations for precise control) and plannable\nsegments (synthesizing diverse trajectories via path planning); second, pose\ntransformations substantially expand the first-stage data. Crucially, HybridGen\ngenerates a large volume of training data without requiring specific data\nformats, making it broadly applicable to a wide range of imitation learning\nalgorithms, a characteristic which we also demonstrate empirically across\nmultiple algorithms. Evaluations across seven tasks and their variants\ndemonstrate that agents trained with HybridGen achieve substantial performance\nand generalization gains, averaging a 5% improvement over state-of-the-art\nmethods. Notably, in the most challenging task variants, HybridGen achieves\nsignificant improvement, reaching a 59.7% average success rate, significantly\noutperforming Mimicgen's 49.5%. These results demonstrating its effectiveness\nand practicality.",
      "authors": [
        "Wensheng Wang",
        "Ning Tan"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13171v1",
        "http://arxiv.org/pdf/2503.13171v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14536v1",
      "title": "Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models:\n  A Multi modal Framework for Precision Analysis",
      "published": "2025-03-17T13:49:29Z",
      "updated": "2025-03-17T13:49:29Z",
      "summary": "Background This study proposes a Vision-Language Model (VLM) leveraging the\nSIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic\ntuberculosis (TB) screening. By integrating chest X-ray images with clinical\ndata, the model addresses the challenges of manual interpretation, improving\ndiagnostic consistency and accessibility, particularly in resource-constrained\nsettings.\n  Methods The VLM architecture combines a Vision Transformer (ViT) for visual\nencoding and a transformer-based text encoder to process clinical context, such\nas patient histories and treatment records. Cross-modal attention mechanisms\nalign radiographic features with textual information, while the Gemma-3b\ndecoder generates comprehensive diagnostic reports. The model was pre-trained\non 5 million paired medical images and texts and fine-tuned using 100,000\nchronic TB-specific chest X-rays.\n  Results The model demonstrated high precision (94 percent) and recall (94\npercent) for detecting key chronic TB pathologies, including fibrosis,\ncalcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores\nexceeded 0.93, and Intersection over Union (IoU) values were above 0.91,\nvalidating its effectiveness in detecting and localizing TB-related\nabnormalities.\n  Conclusion The VLM offers a robust and scalable solution for automated\nchronic TB diagnosis, integrating radiographic and clinical data to deliver\nactionable and context-aware insights. Future work will address subtle\npathologies and dataset biases to enhance the model's generalizability,\nensuring equitable performance across diverse populations and healthcare\nsettings.",
      "authors": [
        "Praveen Shastry",
        "Sowmya Chowdary Muthulur",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam",
        "Revathi Ezhumalai",
        "Abitha Marimuthu"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 92C55, 68U10, 92C50, 60G35"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14536v1",
        "http://arxiv.org/pdf/2503.14536v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13081v1",
      "title": "A Framework to Assess Multilingual Vulnerabilities of LLMs",
      "published": "2025-03-17T11:39:44Z",
      "updated": "2025-03-17T11:39:44Z",
      "summary": "Large Language Models (LLMs) are acquiring a wider range of capabilities,\nincluding understanding and responding in multiple languages. While they\nundergo safety training to prevent them from answering illegal questions,\nimbalances in training data and human evaluation resources can make these\nmodels more susceptible to attacks in low-resource languages (LRL). This paper\nproposes a framework to automatically assess the multilingual vulnerabilities\nof commonly used LLMs. Using our framework, we evaluated six LLMs across eight\nlanguages representing varying levels of resource availability. We validated\nthe assessments generated by our automated framework through human evaluation\nin two languages, demonstrating that the framework's results align with human\njudgments in most cases. Our findings reveal vulnerabilities in LRL; however,\nthese may pose minimal risk as they often stem from the model's poor\nperformance, resulting in incoherent responses.",
      "authors": [
        "Likai Tang",
        "Niruth Bogahawatta",
        "Yasod Ginige",
        "Jiarui Xu",
        "Shixuan Sun",
        "Surangika Ranathunga",
        "Suranga Seneviratne"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13081v1",
        "http://arxiv.org/pdf/2503.13081v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13031v1",
      "title": "Halving transcription time: A fast, user-friendly and GDPR-compliant\n  workflow to create AI-assisted transcripts for content analysis",
      "published": "2025-03-17T10:33:39Z",
      "updated": "2025-03-17T10:33:39Z",
      "summary": "In qualitative research, data transcription is often labor-intensive and\ntime-consuming. To expedite this process, a workflow utilizing artificial\nintelligence (AI) was developed. This workflow not only enhances transcription\nspeed but also addresses the issue of AI-generated transcripts often lacking\ncompatibility with standard content analysis software. Within this workflow,\nautomatic speech recognition is employed to create initial transcripts from\naudio recordings, which are then formatted to be compatible with content\nanalysis software such as ATLAS.ti or MAXQDA. Empirical data from a study of 12\ninterviews suggests that this workflow can reduce transcription time by up to\n46.2%. Furthermore, by using widely used standard software, this process is\nsuitable for both students and researchers while also being adaptable to a\nvariety of learning, teaching, and research environments. It is also\nparticularly beneficial for non-native speakers. In addition, the workflow is\nGDPR-compliant and facilitates local, offline transcript generation, which is\ncrucial when dealing with sensitive data.",
      "authors": [
        "Jakob Sponholz",
        "Andreas Weilinghoff",
        "Juliane Schopf"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13031v1",
        "http://arxiv.org/pdf/2503.13031v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12989v1",
      "title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation\n  Classification Using Large Language Models",
      "published": "2025-03-17T09:44:50Z",
      "updated": "2025-03-17T09:44:50Z",
      "summary": "Automatically annotating job data with standardized occupations from\ntaxonomies, known as occupation classification, is crucial for labor market\nanalysis. However, this task is often hindered by data scarcity and the\nchallenges of manual annotations. While large language models (LLMs) hold\npromise due to their extensive world knowledge and in-context learning\ncapabilities, their effectiveness depends on their knowledge of occupational\ntaxonomies, which remains unclear. In this study, we assess the ability of LLMs\nto generate precise taxonomic entities from taxonomy, highlighting their\nlimitations. To address these challenges, we propose a multi-stage framework\nconsisting of inference, retrieval, and reranking stages, which integrates\ntaxonomy-guided reasoning examples to enhance performance by aligning outputs\nwith taxonomic knowledge. Evaluations on a large-scale dataset show significant\nimprovements in classification accuracy. Furthermore, we demonstrate the\nframework's adaptability for multi-label skill classification. Our results\nindicate that the framework outperforms existing LLM-based methods, offering a\npractical and scalable solution for occupation classification and related tasks\nacross LLMs.",
      "authors": [
        "Palakorn Achananuparp",
        "Ee-Peng Lim"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12989v1",
        "http://arxiv.org/pdf/2503.12989v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12797v2",
      "title": "DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs\n  for Knowledge-Intensive Visual Grounding",
      "published": "2025-03-17T04:06:34Z",
      "updated": "2025-03-18T05:06:22Z",
      "summary": "Human experts excel at fine-grained visual discrimination by leveraging\ndomain knowledge to refine perceptual features, a capability that remains\nunderdeveloped in current Multimodal Large Language Models (MLLMs). Despite\npossessing vast expert-level knowledge, MLLMs struggle to integrate reasoning\ninto visual perception, often generating direct responses without deeper\nanalysis. To bridge this gap, we introduce knowledge-intensive visual grounding\n(KVG), a novel visual grounding task that requires both fine-grained perception\nand domain-specific knowledge integration. To address the challenges of KVG, we\npropose DeepPerception, an MLLM enhanced with cognitive visual perception\ncapabilities. Our approach consists of (1) an automated data synthesis pipeline\nthat generates high-quality, knowledge-aligned training samples, and (2) a\ntwo-stage training framework combining supervised fine-tuning for cognitive\nreasoning scaffolding and reinforcement learning to optimize\nperception-cognition synergy. To benchmark performance, we introduce KVG-Bench\na comprehensive dataset spanning 10 domains with 1.3K manually curated test\ncases. Experimental results demonstrate that DeepPerception significantly\noutperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on\nKVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over\nbaseline approaches. Our findings highlight the importance of integrating\ncognitive processes into MLLMs for human-like visual perception and open new\ndirections for multimodal reasoning research. The data, codes, and models are\nreleased at https://github.com/thunlp/DeepPerception.",
      "authors": [
        "Xinyu Ma",
        "Ziyang Ding",
        "Zhicong Luo",
        "Chi Chen",
        "Zonghao Guo",
        "Derek F. Wong",
        "Xiaoyi Feng",
        "Maosong Sun"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12797v2",
        "http://arxiv.org/pdf/2503.12797v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12667v1",
      "title": "Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility",
      "published": "2025-03-16T21:55:17Z",
      "updated": "2025-03-16T21:55:17Z",
      "summary": "Despite advances in language modelling, distributional methods that build\nsemantic representations from co-occurrences fail to discriminate between\nplausible and implausible events. In this work, we investigate how plausibility\nprediction can be improved by injecting latent knowledge prompted from large\nlanguage models using parameter-efficient fine-tuning. We train 12 task\nadapters to learn various physical properties and association measures and\nperform adapter fusion to compose latent semantic knowledge from each task on\ntop of pre-trained AlBERT embeddings. We automate auxiliary task data\ngeneration, which enables us to scale our approach and fine-tune our learned\nrepresentations across two plausibility datasets. Our code is available at\nhttps://github.com/Jacob-Chmura/plausibility-vaccine.",
      "authors": [
        "Jacob Chmura",
        "Jonah Dauvet",
        "Sebastian Sabry"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12667v1",
        "http://arxiv.org/pdf/2503.12667v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12626v1",
      "title": "Automated Planning for Optimal Data Pipeline Instantiation",
      "published": "2025-03-16T19:43:12Z",
      "updated": "2025-03-16T19:43:12Z",
      "summary": "Data pipeline frameworks provide abstractions for implementing sequences of\ndata-intensive transformation operators, automating the deployment and\nexecution of such transformations in a cluster. Deploying a data pipeline,\nhowever, requires computing resources to be allocated in a data center, ideally\nminimizing the overhead for communicating data and executing operators in the\npipeline while considering each operator's execution requirements. In this\npaper, we model the problem of optimal data pipeline deployment as planning\nwith action costs, where we propose heuristics aiming to minimize total\nexecution time. Experimental results indicate that the heuristics can\noutperform the baseline deployment and that a heuristic based on connections\noutperforms other strategies.",
      "authors": [
        "Leonardo Rosa Amado",
        "Adriano Vogel",
        "Dalvan Griebler",
        "Gabriel Paludo Licks",
        "Eric Simon",
        "Felipe Meneguzzi"
      ],
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12626v1",
        "http://arxiv.org/pdf/2503.12626v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12499v1",
      "title": "Facilitating Automated Online Consensus Building through Parallel\n  Thinking",
      "published": "2025-03-16T13:32:35Z",
      "updated": "2025-03-16T13:32:35Z",
      "summary": "Consensus building is inherently challenging due to the diverse opinions held\nby stakeholders. Effective facilitation is crucial to support the consensus\nbuilding process and enable efficient group decision making. However, the\neffectiveness of facilitation is often constrained by human factors such as\nlimited experience and scalability. In this research, we propose a Parallel\nThinking-based Facilitation Agent (PTFA) that facilitates online, text-based\nconsensus building processes. The PTFA automatically collects textual posts and\nleverages large language models (LLMs) to perform all of the six distinct roles\nof the well-established Six Thinking Hats technique in parallel thinking. To\nillustrate the potential of PTFA, a pilot study was carried out and PTFA's\nability in idea generation, emotional probing, and deeper analysis of ideas was\ndemonstrated. Furthermore, a comprehensive dataset that contains not only the\nconversational content among the participants but also between the participants\nand the agent is constructed for future study.",
      "authors": [
        "Wen Gu",
        "Zhaoxing Li",
        "Jan Buermann",
        "Jim Dilkes",
        "Dimitris Michailidis",
        "Shinobu Hasegawa",
        "Vahid Yazdanpanah",
        "Sebastian Stein"
      ],
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12499v1",
        "http://arxiv.org/pdf/2503.12499v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12435v1",
      "title": "XAI-Driven Client Selection for Federated Learning in Scalable 6G\n  Network Slicing",
      "published": "2025-03-16T10:14:25Z",
      "updated": "2025-03-16T10:14:25Z",
      "summary": "In recent years, network slicing has embraced artificial intelligence (AI)\nmodels to manage the growing complexity of communication networks. In such a\nsituation, AI-driven zero-touch network automation should present a high degree\nof flexibility and viability, especially when deployed in live production\nnetworks. However, centralized controllers suffer from high data communication\noverhead due to the vast amount of user data, and most network slices are\nreluctant to share private data. In federated learning systems, selecting\ntrustworthy clients to participate in training is critical for ensuring system\nperformance and reliability. The present paper proposes a new approach to\nclient selection by leveraging an XAI method to guarantee scalable and fast\noperation of federated learning based analytic engines that implement\nslice-level resource provisioning at the RAN-Edge in a non-IID scenario.\nAttributions from XAI are used to guide the selection of devices participating\nin training. This approach enhances network trustworthiness for users and\naddresses the black-box nature of neural network models. The simulations\nconducted outperformed the standard approach in terms of both convergence time\nand computational cost, while also demonstrating high scalability.",
      "authors": [
        "Martino Chiarani",
        "Swastika Roy",
        "Christos Verikoukis",
        "Fabrizio Granelli"
      ],
      "categories": [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12435v1",
        "http://arxiv.org/pdf/2503.12435v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12339v1",
      "title": "Augmented Adversarial Trigger Learning",
      "published": "2025-03-16T03:20:52Z",
      "updated": "2025-03-16T03:20:52Z",
      "summary": "Gradient optimization-based adversarial attack methods automate the learning\nof adversarial triggers to generate jailbreak prompts or leak system prompts.\nIn this work, we take a closer look at the optimization objective of\nadversarial trigger learning and propose ATLA: Adversarial Trigger Learning\nwith Augmented objectives. ATLA improves the negative log-likelihood loss used\nby previous studies into a weighted loss formulation that encourages the\nlearned adversarial triggers to optimize more towards response format tokens.\nThis enables ATLA to learn an adversarial trigger from just one query-response\npair and the learned trigger generalizes well to other similar queries. We\nfurther design a variation to augment trigger optimization with an auxiliary\nloss that suppresses evasive responses. We showcase how to use ATLA to learn\nadversarial suffixes jailbreaking LLMs and to extract hidden system prompts.\nEmpirically we demonstrate that ATLA consistently outperforms current\nstate-of-the-art techniques, achieving nearly 100% success in attacking while\nrequiring 80% fewer queries. ATLA learned jailbreak suffixes demonstrate high\ngeneralization to unseen queries and transfer well to new LLMs.",
      "authors": [
        "Zhe Wang",
        "Yanjun Qi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12339v1",
        "http://arxiv.org/pdf/2503.12339v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12326v1",
      "title": "Leveraging Vision Capabilities of Multimodal LLMs for Automated Data\n  Extraction from Plots",
      "published": "2025-03-16T02:41:43Z",
      "updated": "2025-03-16T02:41:43Z",
      "summary": "Automated data extraction from research texts has been steadily improving,\nwith the emergence of large language models (LLMs) accelerating progress even\nfurther. Extracting data from plots in research papers, however, has been such\na complex task that it has predominantly been confined to manual data\nextraction. We show that current multimodal large language models, with proper\ninstructions and engineered workflows, are capable of accurately extracting\ndata from plots. This capability is inherent to the pretrained models and can\nbe achieved with a chain-of-thought sequence of zero-shot engineered prompts we\ncall PlotExtract, without the need to fine-tune. We demonstrate PlotExtract\nhere and assess its performance on synthetic and published plots. We consider\nonly plots with two axes in this analysis. For plots identified as extractable,\nPlotExtract finds points with over 90% precision (and around 90% recall) and\nerrors in x and y position of around 5% or lower. These results prove that\nmultimodal LLMs are a viable path for high-throughput data extraction for plots\nand in many circumstances can replace the current manual methods of data\nextraction.",
      "authors": [
        "Maciej P. Polak",
        "Dane Morgan"
      ],
      "categories": [
        "cs.CV",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12326v1",
        "http://arxiv.org/pdf/2503.12326v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12143v1",
      "title": "Language Models for Automated Classification of Brain MRI Reports and\n  Growth Chart Generation",
      "published": "2025-03-15T13:59:44Z",
      "updated": "2025-03-15T13:59:44Z",
      "summary": "Clinically acquired brain MRIs and radiology reports are valuable but\nunderutilized resources due to the challenges of manual analysis and data\nheterogeneity. We developed fine-tuned language models (LMs) to classify brain\nMRI reports as normal (reports with limited pathology) or abnormal, fine-tuning\nBERT, BioBERT, ClinicalBERT, and RadBERT on 44,661 reports. We also explored\nthe reasoning capabilities of a leading LM, Gemini 1.5-Pro, for normal report\ncategorization. Automated image processing and modeling generated brain growth\ncharts from LM-classified normal scans, comparing them to human-derived charts.\nFine-tuned LMs achieved high classification performance (F1-Score >97%), with\nunbalanced training mitigating class imbalance. Performance was robust on\nout-of-distribution data, with full text outperforming summary (impression)\nsections. Gemini 1.5-Pro showed a promising categorization performance,\nespecially with clinical inference. LM-derived brain growth charts were nearly\nidentical to human-annotated charts (r = 0.99, p < 2.2e-16). Our LMs offer\nscalable analysis of radiology reports, enabling automated classification of\nbrain MRIs in large datasets. One application is automated generation of brain\ngrowth charts for benchmarking quantitative image features. Further research is\nneeded to address data heterogeneity and optimize LM reasoning.",
      "authors": [
        "Maryam Daniali",
        "Shivaram Karandikar",
        "Dabriel Zimmerman",
        "J. Eric Schmitt",
        "Matthew J. Buczek",
        "Benjamin Jung",
        "Laura Mercedes",
        "Jakob Seidlitz",
        "Vanessa Troiani",
        "Lena Dorfschmidt",
        "Eren Kafadar",
        "Remo Williams",
        "Susan Sotardi",
        "Arastoo Vosough",
        "Scott Haag",
        "Jenna M. Schabdach",
        "Aaron Alexander-Bloch"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12143v1",
        "http://arxiv.org/pdf/2503.12143v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12085v1",
      "title": "Automating the loop in traffic incident management on highway",
      "published": "2025-03-15T11:22:13Z",
      "updated": "2025-03-15T11:22:13Z",
      "summary": "Effective traffic incident management is essential for ensuring safety,\nminimizing congestion, and reducing response times in emergency situations.\nTraditional highway incident management relies heavily on radio room operators,\nwho must make rapid, informed decisions in high-stakes environments. This paper\nproposes an innovative solution to support and enhance these decisions by\nintegrating Large Language Models (LLMs) into a decision-support system for\ntraffic incident management. We introduce two approaches: (1) an LLM +\nOptimization hybrid that leverages both the flexibility of natural language\ninteraction and the robustness of optimization techniques, and (2) a Full LLM\napproach that autonomously generates decisions using only LLM capabilities. We\ntested our solutions using historical event data from Autostrade per l'Italia.\nExperimental results indicate that while both approaches show promise, the LLM\n+ Optimization solution demonstrates superior reliability, making it\nparticularly suited to critical applications where consistency and accuracy are\nparamount. This research highlights the potential for LLMs to transform highway\nincident management by enabling accessible, data-driven decision-making\nsupport.",
      "authors": [
        "Matteo Cercola",
        "Nicola Gatti",
        "Pedro Huertas Leyva",
        "Benedetto Carambia",
        "Simone Formentin"
      ],
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12085v1",
        "http://arxiv.org/pdf/2503.12085v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12053v1",
      "title": "Ferret: An Efficient Online Continual Learning Framework under Varying\n  Memory Constraints",
      "published": "2025-03-15T08:58:38Z",
      "updated": "2025-03-15T08:58:38Z",
      "summary": "In the realm of high-frequency data streams, achieving real-time learning\nwithin varying memory constraints is paramount. This paper presents Ferret, a\ncomprehensive framework designed to enhance online accuracy of Online Continual\nLearning (OCL) algorithms while dynamically adapting to varying memory budgets.\nFerret employs a fine-grained pipeline parallelism strategy combined with an\niterative gradient compensation algorithm, ensuring seamless handling of\nhigh-frequency data with minimal latency, and effectively counteracting the\nchallenge of stale gradients in parallel training. To adapt to varying memory\nbudgets, its automated model partitioning and pipeline planning optimizes\nperformance regardless of memory limitations. Extensive experiments across 20\nbenchmarks and 5 integrated OCL algorithms show Ferret's remarkable efficiency,\nachieving up to 3.7$\\times$ lower memory overhead to reach the same online\naccuracy compared to competing methods. Furthermore, Ferret consistently\noutperforms these methods across diverse memory budgets, underscoring its\nsuperior adaptability. These findings position Ferret as a premier solution for\nefficient and adaptive OCL framework in real-time environments.",
      "authors": [
        "Yuhao Zhou",
        "Yuxin Tian",
        "Jindi Lv",
        "Mingjia Shi",
        "Yuanxi Li",
        "Qing Ye",
        "Shuhao Zhang",
        "Jiancheng Lv"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12053v1",
        "http://arxiv.org/pdf/2503.12053v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12043v1",
      "title": "An LLM-Integrated Framework for Completion, Management, and Tracing of\n  STPA",
      "published": "2025-03-15T08:31:13Z",
      "updated": "2025-03-15T08:31:13Z",
      "summary": "In many safety-critical engineering domains, hazard analysis techniques are\nan essential part of requirement elicitation. Of the methods proposed for this\ntask, STPA (System-Theoretic Process Analysis) represents a relatively recent\ndevelopment in the field. The completion, management, and traceability of this\nhazard analysis technique present a time-consuming challenge to the\nrequirements and safety engineers involved. In this paper, we introduce a free,\nopen-source software framework to build STPA models with several automated\nworkflows powered by large language models (LLMs). In past works, LLMs have\nbeen successfully integrated into a myriad of workflows across various fields.\nHere, we demonstrate that LLMs can be used to complete tasks associated with\nSTPA with a high degree of accuracy, saving the time and effort of the human\nengineers involved. We experimentally validate our method on real-world STPA\nmodels built by requirement engineers and researchers. The source code of our\nsoftware framework is available at the following link:\nhttps://github.com/blueskysolarracing/stpa.",
      "authors": [
        "Ali Raeisdanaei",
        "Juho Kim",
        "Michael Liao",
        "Sparsh Kochhar"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12043v1",
        "http://arxiv.org/pdf/2503.12043v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11989v1",
      "title": "Applications of Large Language Model Reasoning in Feature Generation",
      "published": "2025-03-15T04:18:01Z",
      "updated": "2025-03-15T04:18:01Z",
      "summary": "Large Language Models (LLMs) have revolutionized natural language processing\nthrough their state of art reasoning capabilities. This paper explores the\nconvergence of LLM reasoning techniques and feature generation for machine\nlearning tasks. We examine four key reasoning approaches: Chain of Thought,\nTree of Thoughts, Retrieval-Augmented Generation, and Thought Space\nExploration. Our analysis reveals how these approaches can be used to identify\neffective feature generation rules without having to manually specify search\nspaces. The paper categorizes LLM-based feature generation methods across\nvarious domains including finance, healthcare, and text analytics. LLMs can\nextract key information from clinical notes and radiology reports in\nhealthcare, by enabling more efficient data utilization. In finance, LLMs\nfacilitate text generation, summarization, and entity extraction from complex\ndocuments. We analyze evaluation methodologies for assessing feature quality\nand downstream performance, with particular attention to OCTree's decision tree\nreasoning approach that provides language-based feedback for iterative\nimprovements. Current challenges include hallucination, computational\nefficiency, and domain adaptation. As of March 2025, emerging approaches\ninclude inference-time compute scaling, reinforcement learning, and supervised\nfine-tuning with model distillation. Future directions point toward multimodal\nfeature generation, self-improving systems, and neuro-symbolic approaches. This\npaper provides a detailed overview of an emerging field that promises to\nautomate and enhance feature engineering through language model reasoning.",
      "authors": [
        "Dharani Chandra"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11989v1",
        "http://arxiv.org/pdf/2503.11989v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11933v1",
      "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN",
      "published": "2025-03-15T00:48:50Z",
      "updated": "2025-03-15T00:48:50Z",
      "summary": "With the advent of 6G, Open Radio Access Network (O-RAN) architectures are\nevolving to support intelligent, adaptive, and automated network orchestration.\nThis paper proposes a novel Edge AI and Network Service Orchestration framework\nthat leverages Large Language Model (LLM) agents deployed as O-RAN rApps. The\nproposed LLM-agent-powered system enables interactive and intuitive\norchestration by translating the user's use case description into deployable AI\nservices and corresponding network configurations. The LLM agent automates\nmultiple tasks, including AI model selection from repositories (e.g., Hugging\nFace), service deployment, network adaptation, and real-time monitoring via\nxApps. We implement a prototype using open-source O-RAN projects\n(OpenAirInterface and FlexRIC) to demonstrate the feasibility and functionality\nof our framework. Our demonstration showcases the end-to-end flow of AI service\norchestration, from user interaction to network adaptation, ensuring Quality of\nService (QoS) compliance. This work highlights the potential of integrating\nLLM-driven automation into 6G O-RAN ecosystems, paving the way for more\naccessible and efficient edge AI ecosystems.",
      "authors": [
        "Yun Tang",
        "Udhaya Chandhar Srinivasan",
        "Benjamin James Scott",
        "Obumneme Umealor",
        "Dennis Kevogo",
        "Weisi Guo"
      ],
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11933v1",
        "http://arxiv.org/pdf/2503.11933v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11901v1",
      "title": "Characterizing GPU Resilience and Impact on AI/HPC Systems",
      "published": "2025-03-14T22:14:18Z",
      "updated": "2025-03-14T22:14:18Z",
      "summary": "In this study, we characterize GPU failures in Delta, the current large-scale\nAI system with over 600 petaflops of peak compute throughput. The system\ncomprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA\nA40, A100, and H100 GPUs. The study uses two and a half years of data on GPU\nerrors. We evaluate the resilience of GPU hardware components to determine the\nvulnerability of different GPU components to failure and their impact on the\nGPU and node availability. We measure the key propagation paths in GPU\nhardware, GPU interconnect (NVLink), and GPU memory. Finally, we evaluate the\nimpact of the observed GPU errors on user jobs. Our key findings are: (i)\nContrary to common beliefs, GPU memory is over 30x more reliable than GPU\nhardware in terms of MTBE (mean time between errors). (ii) The newly introduced\nGSP (GPU System Processor) is the most vulnerable GPU hardware component. (iii)\nNVLink errors did not always lead to user job failure, and we attribute it to\nthe underlying error detection and retry mechanisms employed. (iv) We show\nmultiple examples of hardware errors originating from one of the key GPU\nhardware components, leading to application failure. (v) We project the impact\nof GPU node availability on larger scales with emulation and find that\nsignificant overprovisioning between 5-20% would be necessary to handle GPU\nfailures. If GPU availability were improved to 99.9%, the overprovisioning\nwould be reduced by 4x.",
      "authors": [
        "Shengkun Cui",
        "Archit Patke",
        "Ziheng Chen",
        "Aditya Ranjan",
        "Hung Nguyen",
        "Phuong Cao",
        "Saurabh Jha",
        "Brett Bode",
        "Gregory Bauer",
        "Chandra Narayanaswami",
        "Daby Sow",
        "Catello Di Martino",
        "Zbigniew T. Kalbarczyk",
        "Ravishankar K. Iyer"
      ],
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11901v1",
        "http://arxiv.org/pdf/2503.11901v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13522v1",
      "title": "Advanced Deep Learning Methods for Protein Structure Prediction and\n  Design",
      "published": "2025-03-14T21:28:29Z",
      "updated": "2025-03-14T21:28:29Z",
      "summary": "After AlphaFold won the Nobel Prize, protein prediction with deep learning\nonce again became a hot topic. We comprehensively explore advanced deep\nlearning methods applied to protein structure prediction and design. It begins\nby examining recent innovations in prediction architectures, with detailed\ndiscussions on improvements such as diffusion based frameworks and novel\npairwise attention modules. The text analyses key components including\nstructure generation, evaluation metrics, multiple sequence alignment\nprocessing, and network architecture, thereby illustrating the current state of\nthe art in computational protein modelling. Subsequent chapters focus on\npractical applications, presenting case studies that range from individual\nprotein predictions to complex biomolecular interactions. Strategies for\nenhancing prediction accuracy and integrating deep learning techniques with\nexperimental validation are thoroughly explored. The later sections review the\nindustry landscape of protein design, highlighting the transformative role of\nartificial intelligence in biotechnology and discussing emerging market trends\nand future challenges. Supplementary appendices provide essential resources\nsuch as databases and open source tools, making this volume a valuable\nreference for researchers and students.",
      "authors": [
        "Weikun Wu",
        "Tianyang Wang",
        "Yichao Zhang",
        "Ningyuan Deng",
        "Xinyuan Song",
        "Ziqian Bi",
        "Zheyu Yao",
        "Keyu Chen",
        "Ming Li",
        "Qian Niu",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Ming Liu",
        "Li Zhang",
        "Xuanhe Pan",
        "Jinlang Wang",
        "Pohsun Feng",
        "Yizhu Wen",
        "Lawrence KQ Yan",
        "Hongming Tseng",
        "Yan Zhong",
        "Yunze Wang",
        "Ziyuan Qin",
        "Bowen Jing",
        "Junjie Yang",
        "Jun Zhou",
        "Chia Xin Liang",
        "Junhao Song"
      ],
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13522v1",
        "http://arxiv.org/pdf/2503.13522v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11836v1",
      "title": "Transfer Learning for Automated Feedback Generation on Small Datasets",
      "published": "2025-03-14T19:57:54Z",
      "updated": "2025-03-14T19:57:54Z",
      "summary": "Feedback is a very important part the learning process. However, it is\nchallenging to make this feedback both timely and accurate when relying on\nhuman markers. This is the challenge that Automated Feedback Generation\nattempts to address. In this paper, a technique to train such a system on a\nvery small dataset with very long sequences is presented. Both of these\nattributes make this a very challenging task, however, by using a three stage\ntransfer learning pipeline state-of-the-art results can be achieved with\nqualitatively accurate but unhuman sounding results. The use of both Automated\nEssay Scoring and Automated Feedback Generation systems in the real world is\nalso discussed.",
      "authors": [
        "Oscar Morris"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11836v1",
        "http://arxiv.org/pdf/2503.11836v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11807v1",
      "title": "Mitigating Bad Ground Truth in Supervised Machine Learning based Crop\n  Classification: A Multi-Level Framework with Sentinel-2 Images",
      "published": "2025-03-14T18:50:30Z",
      "updated": "2025-03-14T18:50:30Z",
      "summary": "In agricultural management, precise Ground Truth (GT) data is crucial for\naccurate Machine Learning (ML) based crop classification. Yet, issues like crop\nmislabeling and incorrect land identification are common. We propose a\nmulti-level GT cleaning framework while utilizing multi-temporal Sentinel-2\ndata to address these issues. Specifically, this framework utilizes generating\nembeddings for farmland, clustering similar crop profiles, and identification\nof outliers indicating GT errors. We validated clusters with False Colour\nComposite (FCC) checks and used distance-based metrics to scale and automate\nthis verification process. The importance of cleaning the GT data became\napparent when the models were trained on the clean and unclean data. For\ninstance, when we trained a Random Forest model with the clean GT data, we\nachieved upto 70\\% absolute percentage points higher for the F1 score metric.\nThis approach advances crop classification methodologies, with potential for\napplications towards improving loan underwriting and agricultural\ndecision-making.",
      "authors": [
        "Sanayya A",
        "Amoolya Shetty",
        "Abhijeet Sharma",
        "Venkatesh Ravichandran",
        "Masthan Wali Gosuvarapalli",
        "Sarthak Jain",
        "Priyamvada Nanjundiah",
        "Ujjal Kr Dutta",
        "Divya Sharma"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11807v1",
        "http://arxiv.org/pdf/2503.11807v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11387v1",
      "title": "Hierarchical Information-Guided Spatio-Temporal Mamba for Stock Time\n  Series Forecasting",
      "published": "2025-03-14T13:30:38Z",
      "updated": "2025-03-14T13:30:38Z",
      "summary": "Mamba has demonstrated excellent performance in various time series\nforecasting tasks due to its superior selection mechanism. Nevertheless,\nconventional Mamba-based models encounter significant challenges in accurately\npredicting stock time series, as they fail to adequately capture both the\noverarching market dynamics and the intricate interdependencies among\nindividual stocks. To overcome these constraints, we introduce the Hierarchical\nInformation-Guided Spatio-Temporal Mamba (HIGSTM) framework. HIGSTM introduces\nIndex-Guided Frequency Filtering Decomposition to extract commonality and\nspecificity from time series. The model architecture features a meticulously\ndesigned hierarchical framework that systematically captures both temporal\ndynamic patterns and global static relationships within the stock market.\nFurthermore, we propose an Information-Guided Mamba that integrates macro\ninformations into the sequence selection process, thereby facilitating more\nmarket-conscious decision-making. Comprehensive experimental evaluations\nconducted on the CSI500, CSI800 and CSI1000 datasets demonstrate that HIGSTM\nachieves state-of-the-art performance.",
      "authors": [
        "Wenbo Yan",
        "Shurui Wang",
        "Ying Tan"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11387v1",
        "http://arxiv.org/pdf/2503.11387v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11733v1",
      "title": "LLM Agents for Education: Advances and Applications",
      "published": "2025-03-14T11:53:44Z",
      "updated": "2025-03-14T11:53:44Z",
      "summary": "Large Language Model (LLM) agents have demonstrated remarkable capabilities\nin automating tasks and driving innovation across diverse educational\napplications. In this survey, we provide a systematic review of\nstate-of-the-art research on LLM agents in education, categorizing them into\ntwo broad classes: (1) \\emph{Pedagogical Agents}, which focus on automating\ncomplex pedagogical tasks to support both teachers and students; and (2)\n\\emph{Domain-Specific Educational Agents}, which are tailored for specialized\nfields such as science education, language learning, and professional\ndevelopment. We comprehensively examine the technological advancements\nunderlying these LLM agents, including key datasets, benchmarks, and\nalgorithmic frameworks that drive their effectiveness. Furthermore, we discuss\ncritical challenges such as privacy, bias and fairness concerns, hallucination\nmitigation, and integration with existing educational ecosystems. This survey\naims to provide a comprehensive technological overview of LLM agents for\neducation, fostering further research and collaboration to enhance their impact\nfor the greater good of learners and educators alike.",
      "authors": [
        "Zhendong Chu",
        "Shen Wang",
        "Jian Xie",
        "Tinghui Zhu",
        "Yibo Yan",
        "Jinheng Ye",
        "Aoxiao Zhong",
        "Xuming Hu",
        "Jing Liang",
        "Philip S. Yu",
        "Qingsong Wen"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11733v1",
        "http://arxiv.org/pdf/2503.11733v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11281v3",
      "title": "AI and Deep Learning for Automated Segmentation and Quantitative\n  Measurement of Spinal Structures in MRI",
      "published": "2025-03-14T10:39:52Z",
      "updated": "2025-03-19T06:18:20Z",
      "summary": "Background: Accurate spinal structure measurement is crucial for assessing\nspine health and diagnosing conditions like spondylosis, disc herniation, and\nstenosis. Manual methods for measuring intervertebral disc height and spinal\ncanal diameter are subjective and time-consuming. Automated solutions are\nneeded to improve accuracy, efficiency, and reproducibility in clinical\npractice.\n  Purpose: This study develops an autonomous AI system for segmenting and\nmeasuring key spinal structures in MRI scans, focusing on intervertebral disc\nheight and spinal canal anteroposterior (AP) diameter in the cervical, lumbar,\nand thoracic regions. The goal is to reduce clinician workload, enhance\ndiagnostic consistency, and improve assessments.\n  Methods: The AI model leverages deep learning architectures, including UNet,\nnnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated\nagainst expert annotations. Performance was evaluated using Dice coefficients\nand segmentation accuracy.\n  Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for\ncervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely\nmeasured spinal parameters like disc height and canal diameter, demonstrating\nrobustness and clinical applicability.\n  Conclusion: The AI system effectively automates MRI-based spinal\nmeasurements, improving accuracy and reducing clinician workload. Its\nconsistent performance across spinal regions supports clinical decision-making,\nparticularly in high-demand settings, enhancing spinal assessments and patient\noutcomes.",
      "authors": [
        "Praveen Shastry",
        "Bhawana Sonawane",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Raghotham Sripadraj",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Kaviya SP",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "92C55, 68T07, 68U10, 62P10, 65D18"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11281v3",
        "http://arxiv.org/pdf/2503.11281v3"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11181v1",
      "title": "Multi-Stage Generative Upscaler: Reconstructing Football Broadcast\n  Images via Diffusion Models",
      "published": "2025-03-14T08:28:30Z",
      "updated": "2025-03-14T08:28:30Z",
      "summary": "The reconstruction of low-resolution football broadcast images presents a\nsignificant challenge in sports broadcasting, where detailed visuals are\nessential for analysis and audience engagement. This study introduces a\nmulti-stage generative upscaling framework leveraging Diffusion Models to\nenhance degraded images, transforming inputs as small as $64 \\times 64$ pixels\ninto high-fidelity $1024 \\times 1024$ outputs. By integrating an image-to-image\npipeline, ControlNet conditioning, and LoRA fine-tuning, our approach surpasses\ntraditional upscaling methods in restoring intricate textures and\ndomain-specific elements such as player details and jersey logos. The custom\nLoRA is trained on a custom football dataset, ensuring adaptability to sports\nbroadcast needs. Experimental results demonstrate substantial improvements over\nconventional models, with ControlNet refining fine details and LoRA enhancing\ntask-specific elements. These findings highlight the potential of\ndiffusion-based image reconstruction in sports media, paving the way for future\napplications in automated video enhancement and real-time sports analytics.",
      "authors": [
        "Luca Martini",
        "Daniele Zolezzi",
        "Saverio Iacono",
        "Gianni Viardo Vercelli"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11181v1",
        "http://arxiv.org/pdf/2503.11181v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11081v1",
      "title": "MoMa-Kitchen: A 100K+ Benchmark for Affordance-Grounded Last-Mile\n  Navigation in Mobile Manipulation",
      "published": "2025-03-14T04:47:38Z",
      "updated": "2025-03-14T04:47:38Z",
      "summary": "In mobile manipulation, navigation and manipulation are often treated as\nseparate problems, resulting in a significant gap between merely approaching an\nobject and engaging with it effectively. Many navigation approaches primarily\ndefine success by proximity to the target, often overlooking the necessity for\noptimal positioning that facilitates subsequent manipulation. To address this,\nwe introduce MoMa-Kitchen, a benchmark dataset comprising over 100k samples\nthat provide training data for models to learn optimal final navigation\npositions for seamless transition to manipulation. Our dataset includes\naffordance-grounded floor labels collected from diverse kitchen environments,\nin which robotic mobile manipulators of different models attempt to grasp\ntarget objects amidst clutter. Using a fully automated pipeline, we simulate\ndiverse real-world scenarios and generate affordance labels for optimal\nmanipulation positions. Visual data are collected from RGB-D inputs captured by\na first-person view camera mounted on the robotic arm, ensuring consistency in\nviewpoint during data collection. We also develop a lightweight baseline model,\nNavAff, for navigation affordance grounding that demonstrates promising\nperformance on the MoMa-Kitchen benchmark. Our approach enables models to learn\naffordance-based final positioning that accommodates different arm types and\nplatform heights, thereby paving the way for more robust and generalizable\nintegration of navigation and manipulation in embodied AI. Project page:\n\\href{https://momakitchen.github.io/}{https://momakitchen.github.io/}.",
      "authors": [
        "Pingrui Zhang",
        "Xianqiang Gao",
        "Yuhan Wu",
        "Kehui Liu",
        "Dong Wang",
        "Zhigang Wang",
        "Bin Zhao",
        "Yan Ding",
        "Xuelong Li"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11081v1",
        "http://arxiv.org/pdf/2503.11081v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11069v1",
      "title": "API Agents vs. GUI Agents: Divergence and Convergence",
      "published": "2025-03-14T04:26:21Z",
      "updated": "2025-03-14T04:26:21Z",
      "summary": "Large language models (LLMs) have evolved beyond simple text generation to\npower software agents that directly translate natural language commands into\ntangible actions. While API-based LLM agents initially rose to prominence for\ntheir robust automation capabilities and seamless integration with programmatic\nendpoints, recent progress in multimodal LLM research has enabled GUI-based LLM\nagents that interact with graphical user interfaces in a human-like manner.\nAlthough these two paradigms share the goal of enabling LLM-driven task\nautomation, they diverge significantly in architectural complexity, development\nworkflows, and user interaction models.\n  This paper presents the first comprehensive comparative study of API-based\nand GUI-based LLM agents, systematically analyzing their divergence and\npotential convergence. We examine key dimensions and highlight scenarios in\nwhich hybrid approaches can harness their complementary strengths. By proposing\nclear decision criteria and illustrating practical use cases, we aim to guide\npractitioners and researchers in selecting, combining, or transitioning between\nthese paradigms. Ultimately, we indicate that continuing innovations in\nLLM-based automation are poised to blur the lines between API- and GUI-driven\nagents, paving the way for more flexible, adaptive solutions in a wide range of\nreal-world applications.",
      "authors": [
        "Chaoyun Zhang",
        "Shilin He",
        "Liqun Li",
        "Si Qin",
        "Yu Kang",
        "Qingwei Lin",
        "Dongmei Zhang"
      ],
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11069v1",
        "http://arxiv.org/pdf/2503.11069v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11065v1",
      "title": "Low-cost Real-world Implementation of the Swing-up Pendulum for Deep\n  Reinforcement Learning Experiments",
      "published": "2025-03-14T04:18:36Z",
      "updated": "2025-03-14T04:18:36Z",
      "summary": "Deep reinforcement learning (DRL) has had success in virtual and simulated\ndomains, but due to key differences between simulated and real-world\nenvironments, DRL-trained policies have had limited success in real-world\napplications. To assist researchers to bridge the \\textit{sim-to-real gap}, in\nthis paper, we describe a low-cost physical inverted pendulum apparatus and\nsoftware environment for exploring sim-to-real DRL methods. In particular, the\ndesign of our apparatus enables detailed examination of the delays that arise\nin physical systems when sensing, communicating, learning, inferring and\nactuating. Moreover, we wish to improve access to educational systems, so our\napparatus uses readily available materials and parts to reduce cost and\nlogistical barriers. Our design shows how commercial, off-the-shelf electronics\nand electromechanical and sensor systems, combined with common metal\nextrusions, dowel and 3D printed couplings provide a pathway for affordable\nphysical DRL apparatus. The physical apparatus is complemented with a simulated\nenvironment implemented using a high-fidelity physics engine and OpenAI Gym\ninterface.",
      "authors": [
        "Peter B\u00f6hm",
        "Pauline Pounds",
        "Archie C. Chapman"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11065v1",
        "http://arxiv.org/pdf/2503.11065v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11059v1",
      "title": "Training Directional Locomotion for Quadrupedal Low-Cost Robotic Systems\n  via Deep Reinforcement Learning",
      "published": "2025-03-14T03:53:01Z",
      "updated": "2025-03-14T03:53:01Z",
      "summary": "In this work we present Deep Reinforcement Learning (DRL) training of\ndirectional locomotion for low-cost quadrupedal robots in the real world. In\nparticular, we exploit randomization of heading that the robot must follow to\nfoster exploration of action-state transitions most useful for learning both\nforward locomotion as well as course adjustments. Changing the heading in\nepisode resets to current yaw plus a random value drawn from a normal\ndistribution yields policies able to follow complex trajectories involving\nfrequent turns in both directions as well as long straight-line stretches. By\nrepeatedly changing the heading, this method keeps the robot moving within the\ntraining platform and thus reduces human involvement and need for manual resets\nduring the training. Real world experiments on a custom-built, low-cost\nquadruped demonstrate the efficacy of our method with the robot successfully\nnavigating all validation tests. When trained with other approaches, the robot\nonly succeeds in forward locomotion test and fails when turning is required.",
      "authors": [
        "Peter B\u00f6hm",
        "Archie C. Chapman",
        "Pauline Pounds"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11059v1",
        "http://arxiv.org/pdf/2503.11059v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11046v1",
      "title": "Measuring Similarity in Causal Graphs: A Framework for Semantic and\n  Structural Analysis",
      "published": "2025-03-14T03:29:26Z",
      "updated": "2025-03-14T03:29:26Z",
      "summary": "Causal graphs are commonly used to understand and model complex systems.\nResearchers often construct these graphs from different perspectives, leading\nto significant variations for the same problem. Comparing causal graphs is,\ntherefore, essential for evaluating assumptions, integrating insights, and\nresolving disagreements. The rise of AI tools has further amplified this need,\nas they are increasingly used to generate hypothesized causal graphs by\nsynthesizing information from various sources such as prior research and\ncommunity inputs, providing the potential for automating and scaling causal\nmodeling for complex systems. Similar to humans, these tools also produce\ninconsistent results across platforms, versions, and iterations. Despite its\nimportance, research on causal graph comparison remains scarce. Existing\nmethods often focus solely on structural similarities, assuming identical\nvariable names, and fail to capture nuanced semantic relationships, which is\nessential for causal graph comparison. We address these gaps by investigating\nmethods for comparing causal graphs from both semantic and structural\nperspectives. First, we reviewed over 40 existing metrics and, based on\npredefined criteria, selected nine for evaluation from two threads of machine\nlearning: four semantic similarity metrics and five learning graph kernels. We\ndiscuss the usability of these metrics in simple examples to illustrate their\nstrengths and limitations. We then generated a synthetic dataset of 2,000\ncausal graphs using generative AI based on a reference diagram. Our findings\nreveal that each metric captures a different aspect of similarity, highlighting\nthe need to use multiple metrics.",
      "authors": [
        "Ning-Yuan Georgia Liu",
        "Flower Yang",
        "Mohammad S. Jalali"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 68R10, 62H30",
        "I.2.6; G.2.2; I.5.4; H.2.8"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11046v1",
        "http://arxiv.org/pdf/2503.11046v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11011v1",
      "title": "Power-Aware Scheduling for Multi-Center HPC Electricity Cost\n  Optimization",
      "published": "2025-03-14T02:13:34Z",
      "updated": "2025-03-14T02:13:34Z",
      "summary": "This paper introduces TARDIS (Temporal Allocation for Resource Distribution\nusing Intelligent Scheduling), a novel power-aware job scheduler for\nHigh-Performance Computing (HPC) systems that minimizes electricity costs\nthrough both temporal and spatial optimization. Our approach addresses the\ngrowing concerns of energy consumption in HPC centers, where electricity\nexpenses constitute a substantial portion of operational costs and have a\nsignificant financial impact. TARDIS employs a Graph Neural Network (GNN) to\naccurately predict individual job power consumption, then uses these\npredictions to strategically schedule jobs across multiple HPC facilities based\non time-varying electricity prices. The system integrates both temporal\nscheduling, shifting power-intensive workloads to off-peak hours, and spatial\nscheduling, distributing jobs across geographically dispersed centers with\ndifferent pricing schemes. We evaluate TARDIS using trace-based simulations\nfrom real HPC workloads, demonstrating cost reductions of up to 18% in temporal\noptimization scenarios and 10 to 20% in multi-site environments compared to\nstate-of-the-art scheduling approaches, while maintaining comparable system\nperformance and job throughput. Our comprehensive evaluation shows that TARDIS\neffectively addresses limitations in existing power-aware scheduling approaches\nby combining accurate power prediction with holistic spatial-temporal\noptimization, providing a scalable solution for sustainable and cost-efficient\nHPC operations.",
      "authors": [
        "Abrar Hossain",
        "Abubeker Abdurahman",
        "Mohammad A. Islam",
        "Kishwar Ahmed"
      ],
      "categories": [
        "cs.DC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11011v1",
        "http://arxiv.org/pdf/2503.11011v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10937v1",
      "title": "ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with\n  Multi-Modal Large Language Models and General Vision Models",
      "published": "2025-03-13T22:53:24Z",
      "updated": "2025-03-13T22:53:24Z",
      "summary": "Face Recognition Systems (FRS) are increasingly vulnerable to face-morphing\nattacks, prompting the development of Morphing Attack Detection (MAD)\nalgorithms. However, a key challenge in MAD lies in its limited\ngeneralizability to unseen data and its lack of explainability-critical for\npractical application environments such as enrolment stations and automated\nborder control systems. Recognizing that most existing MAD algorithms rely on\nsupervised learning paradigms, this work explores a novel approach to MAD using\nzero-shot learning leveraged on Large Language Models (LLMs). We propose two\ntypes of zero-shot MAD algorithms: one leveraging general vision models and the\nother utilizing multimodal LLMs. For general vision models, we address the MAD\ntask by computing the mean support embedding of an independent support set\nwithout using morphed images. For the LLM-based approach, we employ the\nstate-of-the-art GPT-4 Turbo API with carefully crafted prompts. To evaluate\nthe feasibility of zero-shot MAD and the effectiveness of the proposed methods,\nwe constructed a print-scan morph dataset featuring various unseen morphing\nalgorithms, simulating challenging real-world application scenarios.\nExperimental results demonstrated notable detection accuracy, validating the\napplicability of zero-shot learning for MAD tasks. Additionally, our\ninvestigation into LLM-based MAD revealed that multimodal LLMs, such as\nChatGPT, exhibit remarkable generalizability to untrained MAD tasks.\nFurthermore, they possess a unique ability to provide explanations and\nguidance, which can enhance transparency and usability for end-users in\npractical applications.",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10937v1",
        "http://arxiv.org/pdf/2503.10937v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10918v1",
      "title": "Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for\n  Deep Learning Clusters",
      "published": "2025-03-13T22:13:20Z",
      "updated": "2025-03-13T22:13:20Z",
      "summary": "Scheduling deep learning (DL) models to train on powerful clusters with\naccelerators like GPUs and TPUs, presently falls short, either lacking\nfine-grained heterogeneity awareness or leaving resources substantially\nunder-utilized. To fill this gap, we propose a novel design of a task-level\nheterogeneity-aware scheduler, {\\em Hadar}, based on an optimization framework\nthat can boost resource utilization. {\\em Hadar} leverages the performance\ntraits of DL jobs on a heterogeneous DL cluster, characterizes the task-level\nperformance heterogeneity in the optimization problem, and makes scheduling\ndecisions across both spatial and temporal dimensions. %with the objective to\nreduce the average job completion time of DL jobs. It involves the primal-dual\nframework employing a dual subroutine, to solve the optimization problem and\nguide the scheduling design. Our trace-driven simulation with representative DL\nmodel training workloads demonstrates that {\\em Hadar} accelerates the total\ntime duration by 1.20$\\times$ when compared with its state-of-the-art\nheterogeneity-aware counterpart, Gavel. Further, our {\\em Hadar} scheduler is\nenhanced to {\\em HadarE} by forking each job into multiple copies to let a job\ntrain concurrently on heterogeneous GPUs resided on separate available nodes\n(i.e., machines or servers) for resource utilization enhancement. {\\em HadarE}\nis evaluated extensively on physical DL clusters for comparison with {\\em\nHadar} and Gavel. With substantial enhancement in cluster resource utilization\n(by 1.45$\\times$), {\\em HadarE} exhibits considerable speed-ups in DL model\ntraining, reducing the total time duration by 50\\% (or 80\\%) on an Amazon's AWS\n(or our lab) cluster, while producing trained DL models with consistently\nbetter inference quality than those trained by \\textit{Hadar}.",
      "authors": [
        "Abeda Sultana",
        "Nabin Pakka",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; F.1.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10918v1",
        "http://arxiv.org/pdf/2503.10918v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10894v1",
      "title": "HyperDAS: Towards Automating Mechanistic Interpretability with\n  Hypernetworks",
      "published": "2025-03-13T21:25:38Z",
      "updated": "2025-03-13T21:25:38Z",
      "summary": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.",
      "authors": [
        "Jiuding Sun",
        "Jing Huang",
        "Sidharth Baskaran",
        "Karel D'Oosterlinck",
        "Christopher Potts",
        "Michael Sklar",
        "Atticus Geiger"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10894v1",
        "http://arxiv.org/pdf/2503.10894v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10886v1",
      "title": "Taxonomic Reasoning for Rare Arthropods: Combining Dense Image\n  Captioning and RAG for Interpretable Classification",
      "published": "2025-03-13T21:18:10Z",
      "updated": "2025-03-13T21:18:10Z",
      "summary": "In the context of pressing climate change challenges and the significant\nbiodiversity loss among arthropods, automated taxonomic classification from\norganismal images is a subject of intense research. However, traditional AI\npipelines based on deep neural visual architectures such as CNNs or ViTs face\nlimitations such as degraded performance on the long-tail of classes and the\ninability to reason about their predictions. We integrate image captioning and\nretrieval-augmented generation (RAG) with large language models (LLMs) to\nenhance biodiversity monitoring, showing particular promise for characterizing\nrare and unknown arthropod species. While a naive Vision-Language Model (VLM)\nexcels in classifying images of common species, the RAG model enables\nclassification of rarer taxa by matching explicit textual descriptions of\ntaxonomic features to contextual biodiversity text data from external sources.\nThe RAG model shows promise in reducing overconfidence and enhancing accuracy\nrelative to naive LLMs, suggesting its viability in capturing the nuances of\ntaxonomic hierarchy, particularly at the challenging family and genus levels.\nOur findings highlight the potential for modern vision-language AI pipelines to\nsupport biodiversity conservation initiatives, emphasizing the role of\ncomprehensive data curation and collaboration with citizen science platforms to\nimprove species identification, unknown species characterization and ultimately\ninform conservation strategies.",
      "authors": [
        "Nathaniel Lesperance",
        "Sujeevan Ratnasingham",
        "Graham W. Taylor"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "q-bio.PE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10886v1",
        "http://arxiv.org/pdf/2503.10886v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10857v1",
      "title": "Towards Understanding Graphical Perception in Large Multimodal Models",
      "published": "2025-03-13T20:13:39Z",
      "updated": "2025-03-13T20:13:39Z",
      "summary": "Despite the promising results of large multimodal models (LMMs) in complex\nvision-language tasks that require knowledge, reasoning, and perception\nabilities together, we surprisingly found that these models struggle with\nsimple tasks on infographics that require perception only. As existing\nbenchmarks primarily focus on end tasks that require various abilities, they\nprovide limited, fine-grained insights into the limitations of the models'\nperception abilities. To address this gap, we leverage the theory of graphical\nperception, an approach used to study how humans decode visual information\nencoded on charts and graphs, to develop an evaluation framework for analyzing\ngaps in LMMs' perception abilities in charts. With automated task generation\nand response evaluation designs, our framework enables comprehensive and\ncontrolled testing of LMMs' graphical perception across diverse chart types,\nvisual elements, and task types. We apply our framework to evaluate and\ndiagnose the perception capabilities of state-of-the-art LMMs at three\ngranularity levels (chart, visual element, and pixel). Our findings underscore\nseveral critical limitations of current state-of-the-art LMMs, including\nGPT-4o: their inability to (1) generalize across chart types, (2) understand\nfundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities\nof LMMs. The evaluation framework and labeled data are publicly available at\nhttps://github.com/microsoft/lmm-graphical-perception.",
      "authors": [
        "Kai Zhang",
        "Jianwei Yang",
        "Jeevana Priya Inala",
        "Chandan Singh",
        "Jianfeng Gao",
        "Yu Su",
        "Chenglong Wang"
      ],
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10857v1",
        "http://arxiv.org/pdf/2503.10857v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10533v1",
      "title": "The Impact of Item-Writing Flaws on Difficulty and Discrimination in\n  Item Response Theory",
      "published": "2025-03-13T16:47:07Z",
      "updated": "2025-03-13T16:47:07Z",
      "summary": "High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.",
      "authors": [
        "Robin Schmucker",
        "Steven Moore"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10533v1",
        "http://arxiv.org/pdf/2503.10533v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10520v1",
      "title": "CountPath: Automating Fragment Counting in Digital Pathology",
      "published": "2025-03-13T16:29:16Z",
      "updated": "2025-03-13T16:29:16Z",
      "summary": "Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.",
      "authors": [
        "Ana Beatriz Vieira",
        "Maria Valente",
        "Diana Montezuma",
        "Tom\u00e9 Albuquerque",
        "Liliana Ribeiro",
        "Domingos Oliveira",
        "Jo\u00e3o Monteiro",
        "Sofia Gon\u00e7alves",
        "Isabel M. Pinto",
        "Jaime S. Cardoso",
        "Arlindo L. Oliveira"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2; I.4"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10520v1",
        "http://arxiv.org/pdf/2503.10520v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10737v1",
      "title": "Commenting Higher-level Code Unit: Full Code, Reduced Code, or\n  Hierarchical Code Summarization",
      "published": "2025-03-13T16:15:06Z",
      "updated": "2025-03-13T16:15:06Z",
      "summary": "Commenting code is a crucial activity in software development, as it aids in\nfacilitating future maintenance and updates. To enhance the efficiency of\nwriting comments and reduce developers' workload, researchers has proposed\nvarious automated code summarization (ACS) techniques to automatically generate\ncomments/summaries for given code units. However, these ACS techniques\nprimarily focus on generating summaries for code units at the method level.\nThere is a significant lack of research on summarizing higher-level code units,\nsuch as file-level and module-level code units, despite the fact that summaries\nof these higher-level code units are highly useful for quickly gaining a\nmacro-level understanding of software components and architecture. To fill this\ngap, in this paper, we conduct a systematic study on how to use LLMs for\ncommenting higher-level code units, including file level and module level.\nThese higher-level units are significantly larger than method-level ones, which\nposes challenges in handling long code inputs within LLM constraints and\nmaintaining efficiency. To address these issues, we explore various\nsummarization strategies for ACS of higher-level code units, which can be\ndivided into three types: full code summarization, reduced code summarization,\nand hierarchical code summarization. The experimental results suggest that for\nsummarizing file-level code units, using the full code is the most effective\napproach, with reduced code serving as a cost-efficient alternative. However,\nfor summarizing module-level code units, hierarchical code summarization\nbecomes the most promising strategy. In addition, inspired by the research on\nmethod-level ACS, we also investigate using the LLM as an evaluator to evaluate\nthe quality of summaries of higher-level code units. The experimental results\ndemonstrate that the LLM's evaluation results strongly correlate with human\nevaluations.",
      "authors": [
        "Weisong Sun",
        "Yiran Zhang",
        "Jie Zhu",
        "Zhihui Wang",
        "Chunrong Fang",
        "Yonglong Zhang",
        "Yebo Feng",
        "Jiangping Huang",
        "Xingya Wang",
        "Zhi Jin",
        "Yang Liu"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "68-04",
        "D.2.3; I.2.7"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10737v1",
        "http://arxiv.org/pdf/2503.10737v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10371v1",
      "title": "A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted\n  Features-based Deep Learning Networks for Facial Palsy Detection",
      "published": "2025-03-13T13:48:35Z",
      "updated": "2025-03-13T13:48:35Z",
      "summary": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).",
      "authors": [
        "Heng Yim Nicole Oo",
        "Min Hun Lee",
        "Jeong Hoon Lim"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10371v1",
        "http://arxiv.org/pdf/2503.10371v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10331v1",
      "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting\n  Conditions",
      "published": "2025-03-13T13:07:51Z",
      "updated": "2025-03-13T13:07:51Z",
      "summary": "Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.",
      "authors": [
        "Maxim Popov",
        "Regina Kurkova",
        "Mikhail Iumanov",
        "Jaafar Mahmoud",
        "Sergey Kolyubin"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10331v1",
        "http://arxiv.org/pdf/2503.10331v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10727v1",
      "title": "Word-level Annotation of GDPR Transparency Compliance in Privacy\n  Policies using Large Language Models",
      "published": "2025-03-13T11:41:25Z",
      "updated": "2025-03-13T11:41:25Z",
      "summary": "Ensuring transparency of data practices related to personal information is a\nfundamental requirement under the General Data Protection Regulation (GDPR),\nparticularly as mandated by Articles 13 and 14. However, assessing compliance\nat scale remains a challenge due to the complexity and variability of privacy\npolicy language. Manual audits are resource-intensive and inconsistent, while\nexisting automated approaches lack the granularity needed to capture nuanced\ntransparency disclosures.\n  In this paper, we introduce a large language model (LLM)-based framework for\nword-level GDPR transparency compliance annotation. Our approach comprises a\ntwo-stage annotation pipeline that combines initial LLM-based annotation with a\nself-correction mechanism for iterative refinement. This annotation pipeline\nenables the systematic identification and fine-grained annotation of\ntransparency-related content in privacy policies, aligning with 21 GDPR-derived\ntransparency requirements. To enable large-scale analysis, we compile a dataset\nof 703,791 English-language policies, from which we generate a sample of 200\nmanually annotated privacy policies.\n  To evaluate our approach, we introduce a two-tiered methodology assessing\nboth label- and span-level annotation performance. We conduct a comparative\nanalysis of eight high-profile LLMs, providing insights into their\neffectiveness in identifying GDPR transparency disclosures. Our findings\ncontribute to advancing the automation of GDPR compliance assessments and\nprovide valuable resources for future research in privacy policy analysis.",
      "authors": [
        "Thomas Cory",
        "Wolf Rieder",
        "Julia Kr\u00e4mer",
        "Philip Raschke",
        "Patrick Herbke",
        "Axel K\u00fcpper"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10727v1",
        "http://arxiv.org/pdf/2503.10727v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10723v1",
      "title": "RankPO: Preference Optimization for Job-Talent Matching",
      "published": "2025-03-13T10:14:37Z",
      "updated": "2025-03-13T10:14:37Z",
      "summary": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.",
      "authors": [
        "Yafei Zhang",
        "Murray Wang",
        "Yu Wang",
        "Xiaohui Wang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10723v1",
        "http://arxiv.org/pdf/2503.10723v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10721v1",
      "title": "From Understanding to Excelling: Template-Free Algorithm Design through\n  Structural-Functional Co-Evolution",
      "published": "2025-03-13T08:26:18Z",
      "updated": "2025-03-13T08:26:18Z",
      "summary": "Large language models (LLMs) have greatly accelerated the automation of\nalgorithm generation and optimization. However, current methods such as EoH and\nFunSearch mainly rely on predefined templates and expert-specified functions\nthat focus solely on the local evolution of key functionalities. Consequently,\nthey fail to fully leverage the synergistic benefits of the overall\narchitecture and the potential of global optimization. In this paper, we\nintroduce an end-to-end algorithm generation and optimization framework based\non LLMs. Our approach utilizes the deep semantic understanding of LLMs to\nconvert natural language requirements or human-authored papers into code\nsolutions, and employs a two-dimensional co-evolution strategy to optimize both\nfunctional and structural aspects. This closed-loop process spans problem\nanalysis, code generation, and global optimization, automatically identifying\nkey algorithm modules for multi-level joint optimization and continually\nenhancing performance and design innovation. Extensive experiments demonstrate\nthat our method outperforms traditional local optimization approaches in both\nperformance and innovation, while also exhibiting strong adaptability to\nunknown environments and breakthrough potential in structural design. By\nbuilding on human research, our framework generates and optimizes novel\nalgorithms that surpass those designed by human experts, broadening the\napplicability of LLMs for algorithm design and providing a novel solution\npathway for automated algorithm development.",
      "authors": [
        "Zhe Zhao",
        "Haibin Wen",
        "Pengkun Wang",
        "Ye Wei",
        "Zaixi Zhang",
        "Xi Lin",
        "Fei Liu",
        "Bo An",
        "Hui Xiong",
        "Yang Wang",
        "Qingfu Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "68W20, 68T20",
        "I.2.7"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10721v1",
        "http://arxiv.org/pdf/2503.10721v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10717v1",
      "title": "Deep Learning-Based Automated Workflow for Accurate Segmentation and\n  Measurement of Abdominal Organs in CT Scans",
      "published": "2025-03-13T06:50:44Z",
      "updated": "2025-03-13T06:50:44Z",
      "summary": "Background: Automated analysis of CT scans for abdominal organ measurement is\ncrucial for improving diagnostic efficiency and reducing inter-observer\nvariability. Manual segmentation and measurement of organs such as the kidneys,\nliver, spleen, and prostate are time-consuming and subject to inconsistency,\nunderscoring the need for automated approaches.\n  Purpose: The purpose of this study is to develop and validate an automated\nworkflow for the segmentation and measurement of abdominal organs in CT scans\nusing advanced deep learning models, in order to improve accuracy, reliability,\nand efficiency in clinical evaluations.\n  Methods: The proposed workflow combines nnU-Net, U-Net++ for organ\nsegmentation, followed by a 3D RCNN model for measuring organ volumes and\ndimensions. The models were trained and evaluated on CT datasets with metrics\nsuch as precision, recall, and Mean Squared Error (MSE) to assess performance.\nSegmentation quality was verified for its adaptability to variations in patient\nanatomy and scanner settings.\n  Results: The developed workflow achieved high precision and recall values,\nexceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were\nlow, indicating a high level of consistency between predicted and ground truth\nmeasurements. The segmentation and measurement pipeline demonstrated robust\nperformance, providing accurate delineation and quantification of the kidneys,\nliver, spleen, and prostate.\n  Conclusion: The proposed approach offers an automated, efficient, and\nreliable solution for abdominal organ measurement in CT scans. By significantly\nreducing manual intervention, this workflow enhances measurement accuracy and\nconsistency, with potential for widespread clinical implementation. Future work\nwill focus on expanding the approach to other organs and addressing complex\npathological cases.",
      "authors": [
        "Praveen Shastry",
        "Ashok Sharma",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T99"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10717v1",
        "http://arxiv.org/pdf/2503.10717v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10040v1",
      "title": "Rapid analysis of point-contact Andreev reflection spectra via machine\n  learning with adaptive data augmentation",
      "published": "2025-03-13T04:45:38Z",
      "updated": "2025-03-13T04:45:38Z",
      "summary": "Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.",
      "authors": [
        "Dongik Lee",
        "Valentin Stanev",
        "Xiaohang Zhang",
        "Mijeong Kang",
        "Ichiro Takeuchi",
        "Seunghun Lee"
      ],
      "categories": [
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10040v1",
        "http://arxiv.org/pdf/2503.10040v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10009v1",
      "title": "OR-LLM-Agent: Automating Modeling and Solving of Operations Research\n  Optimization Problem with Reasoning Large Language Model",
      "published": "2025-03-13T03:40:50Z",
      "updated": "2025-03-13T03:40:50Z",
      "summary": "Operations Research (OR) has been widely applied in various fields such as\nresource allocation, production planning, and supply chain management. However,\naddressing real-world OR problems requires OR experts to perform mathematical\nmodeling and programmers to develop solution algorithms. This traditional\nmethod, heavily reliant on experts, is costly and has long development cycles,\nseverely limiting the widespread adoption of OR techniques. Few have considered\nusing Artificial Intelligence (AI) to replace professionals to achieve fully\nautomated solutions for OR problems. We propose OR-LLM-Agent, the first AI\nagent that enables end-to-end automation for solving real-world OR problems.\nOR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of\nLarge Language Models (LLMs) to translate natural language problem descriptions\ninto formal mathematical models and automatically generate Gurobi solver code.\nIn OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair\nwithin a sandbox environment, facilitating the derivation of the final\nsolution. Due to the lack of dedicated benchmark datasets for evaluating the\nautomated solving of OR problems, we construct a benchmark dataset comprising\n83 real-world OR problems described in natural language. We conduct comparative\nexperiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,\nDeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the\nhighest pass rate of 100% and the highest solution accuracy of 85%,\ndemonstrating the feasibility of automated OR problem-solving. Data and code\nhave been publicly available at https://github.com/bwz96sco/or_llm_agent.",
      "authors": [
        "Bowen Zhang",
        "Pengcheng Luo"
      ],
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10009v1",
        "http://arxiv.org/pdf/2503.10009v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09988v1",
      "title": "Label Unbalance in High-frequency Trading",
      "published": "2025-03-13T02:55:06Z",
      "updated": "2025-03-13T02:55:06Z",
      "summary": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
      "authors": [
        "Zijian Zhao",
        "Xuming Chen",
        "Jiayu Wen",
        "Mingwen Liu",
        "Xiaoteng Ma"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09988v1",
        "http://arxiv.org/pdf/2503.09988v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09901v1",
      "title": "AI Rivalry as a Craft: How Resisting and Embracing Generative AI Reshape\n  Writing Professions",
      "published": "2025-03-12T23:43:57Z",
      "updated": "2025-03-12T23:43:57Z",
      "summary": "Generative AI (GAI) technologies are disrupting professional writing,\nchallenging traditional practices. Recent studies explore GAI adoption\nexperiences of creative practitioners, but we know little about how these\nexperiences evolve into established practices and how GAI resistance alters\nthese practices. To address this gap, we conducted 25 semi-structured\ninterviews with writing professionals who adopted and/or resisted GAI. Using\nthe theoretical lens of Job Crafting, we identify four strategies professionals\nemploy to reshape their roles. Writing professionals employed GAI resisting\nstrategies to maximize human potential, reinforce professional identity, carve\nout a professional niche, and preserve credibility within their networks. In\ncontrast, GAI-enabled strategies allowed writers who embraced GAI to enhance\ndesirable workflows, minimize mundane tasks, and engage in new AI-managerial\nlabor. These strategies amplified their collaborations with GAI while reducing\ntheir reliance on other people. We conclude by discussing implications of GAI\npractices on writers' identity and practices as well as crafting theory.",
      "authors": [
        "Rama Adithya Varanasi",
        "Batia Mishan Wiesenfeld",
        "Oded Nov"
      ],
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3706598.3714035",
        "http://arxiv.org/abs/2503.09901v1",
        "http://arxiv.org/pdf/2503.09901v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11711v1",
      "title": "Privacy-Preserved Automated Scoring using Federated Learning for\n  Educational Research",
      "published": "2025-03-12T19:06:25Z",
      "updated": "2025-03-12T19:06:25Z",
      "summary": "Data privacy remains a critical concern in educational research,\nnecessitating Institutional Review Board (IRB) certification and stringent data\nhandling protocols to ensure compliance with ethical standards. Traditional\napproaches rely on anonymization and controlled data-sharing mechanisms to\nfacilitate research while mitigating privacy risks. However, these methods\nstill involve direct access to raw student data, posing potential\nvulnerabilities and being time-consuming. This study proposes a federated\nlearning (FL) framework for automatic scoring in educational assessments,\neliminating the need to share raw data. Our approach leverages client-side\nmodel training, where student responses are processed locally on edge devices,\nand only optimized model parameters are shared with a central aggregation\nserver. To effectively aggregate heterogeneous model updates, we introduce an\nadaptive weighted averaging strategy, which dynamically adjusts weight\ncontributions based on client-specific learning characteristics. This method\nensures robust model convergence while preserving privacy. We evaluate our\nframework using assessment data from nine middle schools, comparing the\naccuracy of federated learning-based scoring models with traditionally trained\ncentralized models. A statistical significance test (paired t-test, $t(8) =\n2.29, p = 0.051$) confirms that the accuracy difference between the two\napproaches is not statistically significant, demonstrating that federated\nlearning achieves comparable performance while safeguarding student data.\nFurthermore, our method significantly reduces data collection, processing, and\ndeployment overhead, accelerating the adoption of AI-driven educational\nassessments in a privacy-compliant manner.",
      "authors": [
        "Ehsan Latif",
        "Xiaoming Zhai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11711v1",
        "http://arxiv.org/pdf/2503.11711v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11710v1",
      "title": "ConjointNet: Enhancing Conjoint Analysis for Preference Prediction with\n  Representation Learning",
      "published": "2025-03-12T19:01:59Z",
      "updated": "2025-03-12T19:01:59Z",
      "summary": "Understanding consumer preferences is essential to product design and\npredicting market response to these new products. Choice-based conjoint\nanalysis is widely used to model user preferences using their choices in\nsurveys. However, traditional conjoint estimation techniques assume simple\nlinear models. This assumption may lead to limited predictability and\ninaccurate estimation of product attribute contributions, especially on data\nthat has underlying non-linear relationships. In this work, we employ\nrepresentation learning to efficiently alleviate this issue. We propose\nConjointNet, which is composed of two novel neural architectures, to predict\nuser preferences. We demonstrate that the proposed ConjointNet models\noutperform traditional conjoint estimate techniques on two preference datasets\nby over 5%, and offer insights into non-linear feature interactions.",
      "authors": [
        "Yanxia Zhang",
        "Francine Chen",
        "Shabnam Hakimi",
        "Totte Harinen",
        "Alex Filipowicz",
        "Yan-Ying Chen",
        "Rumen Iliev",
        "Nikos Arechiga",
        "Kalani Murakami",
        "Kent Lyons",
        "Charlene Wu",
        "Matt Klenk"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11710v1",
        "http://arxiv.org/pdf/2503.11710v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09730v1",
      "title": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem\n  Proving",
      "published": "2025-03-12T18:20:47Z",
      "updated": "2025-03-12T18:20:47Z",
      "summary": "The most promising recent methods for AI reasoning require applying variants\nof reinforcement learning (RL) either on rolled out trajectories from the\nmodel, even for the step-wise rewards, or large quantities of human annotated\ntrajectory data. The reliance on the rolled-out trajectory renders the compute\ncost and time prohibitively high. In particular, the correctness of a reasoning\ntrajectory can typically only be judged at its completion, leading to sparse\nrewards in RL or requiring expensive synthetic data generation in expert\niteration-like methods. In this work, we focus on the Automatic Theorem Proving\n(ATP) task and propose a novel verifier-in-the-loop design, which unlike\nexisting approaches that leverage feedback on the entire reasoning trajectory,\nemploys an automated verifier to give intermediate feedback at each step of the\nreasoning process. Using Lean as the verifier, we empirically show that the\nstep-by-step local verification produces a global improvement in the model's\nreasoning accuracy and efficiency.",
      "authors": [
        "Sara Rajaee",
        "Kumar Pratik",
        "Gabriele Cesa",
        "Arash Behboodi"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09730v1",
        "http://arxiv.org/pdf/2503.09730v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09586v1",
      "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial\n  Intelligence-based Copilot",
      "published": "2025-03-12T17:54:18Z",
      "updated": "2025-03-12T17:54:18Z",
      "summary": "We present Auspex - a threat modeling system built using a specialized\ncollection of generative artificial intelligence-based methods that capture\nthreat modeling tradecraft. This new approach, called tradecraft prompting,\ncenters on encoding the on-the-ground knowledge of threat modelers within the\nprompts that drive a generative AI-based threat modeling system. Auspex employs\ntradecraft prompts in two processing stages. The first stage centers on\ningesting and processing system architecture information using prompts that\nencode threat modeling tradecraft knowledge pertaining to system decomposition\nand description. The second stage centers on chaining the resulting system\nanalysis through a collection of prompts that encode tradecraft knowledge on\nthreat identification, classification, and mitigation. The two-stage process\nyields a threat matrix for a system that specifies threat scenarios, threat\ntypes, information security categorizations and potential mitigations. Auspex\nproduces formalized threat model output in minutes, relative to the weeks or\nmonths a manual process takes. More broadly, the focus on bespoke tradecraft\nprompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a\nlightweight, flexible, modular, and extensible foundational system capable of\naddressing the complexity, resource, and standardization limitations of both\nexisting manual and automated threat modeling processes. In this connection, we\nestablish the baseline value of Auspex to threat modelers through an evaluation\nprocedure based on feedback collected from cybersecurity subject matter experts\nmeasuring the quality and utility of threat models generated by Auspex on real\nbanking systems. We conclude with a discussion of system performance and plans\nfor enhancements to Auspex.",
      "authors": [
        "Andrew Crossman",
        "Andrew R. Plummer",
        "Chandra Sekharudu",
        "Deepak Warrier",
        "Mohammad Yekrangian"
      ],
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09586v1",
        "http://arxiv.org/pdf/2503.09586v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09669v1",
      "title": "Silent Branding Attack: Trigger-free Data Poisoning Attack on\n  Text-to-Image Diffusion Models",
      "published": "2025-03-12T17:21:57Z",
      "updated": "2025-03-12T17:21:57Z",
      "summary": "Text-to-image diffusion models have achieved remarkable success in generating\nhigh-quality contents from text prompts. However, their reliance on publicly\navailable data and the growing trend of data sharing for fine-tuning make these\nmodels particularly vulnerable to data poisoning attacks. In this work, we\nintroduce the Silent Branding Attack, a novel data poisoning method that\nmanipulates text-to-image diffusion models to generate images containing\nspecific brand logos or symbols without any text triggers. We find that when\ncertain visual patterns are repeatedly in the training data, the model learns\nto reproduce them naturally in its outputs, even without prompt mentions.\nLeveraging this, we develop an automated data poisoning algorithm that\nunobtrusively injects logos into original images, ensuring they blend naturally\nand remain undetected. Models trained on this poisoned dataset generate images\ncontaining logos without degrading image quality or text alignment. We\nexperimentally validate our silent branding attack across two realistic\nsettings on large-scale high-quality image datasets and style personalization\ndatasets, achieving high success rates even without a specific text trigger.\nHuman evaluation and quantitative metrics including logo detection show that\nour method can stealthily embed logos.",
      "authors": [
        "Sangwon Jang",
        "June Suk Choi",
        "Jaehyeong Jo",
        "Kimin Lee",
        "Sung Ju Hwang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09669v1",
        "http://arxiv.org/pdf/2503.09669v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09499v1",
      "title": "MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging\n  Questions",
      "published": "2025-03-12T16:03:03Z",
      "updated": "2025-03-12T16:03:03Z",
      "summary": "Large vision-language models (VLMs) face challenges in achieving robust,\ntransferable reasoning abilities due to reliance on labor-intensive manual\ninstruction datasets or computationally expensive self-supervised methods. To\naddress these issues, we introduce MindGYM, a framework that enhances VLMs\nthrough synthetic self-challenging questions, consisting of three stages: (1)\nSeed Single-Hop Question Synthesis, generating cognitive questions across\ntextual (e.g., logical deduction) and multimodal contexts (e.g., diagram-based\nqueries) spanning eight semantic areas like ethical analysis; (2) Challenging\nMulti-Hop Question Synthesis, combining seed questions via diverse principles\nlike bridging, visual-textual alignment, to create multi-step problems\ndemanding deeper reasoning; and (3) Thinking-Induced Curriculum Fine-Tuning, a\nstructured pipeline that progressively trains the model from scaffolded\nreasoning to standalone inference. By leveraging the model's self-synthesis\ncapability, MindGYM achieves high data efficiency (e.g., +16% gains on\nMathVision-Mini with only 400 samples), computational efficiency (reducing both\ntraining and inference costs), and robust generalization across tasks.\nExtensive evaluations on seven benchmarks demonstrate superior performance over\nstrong baselines, with notable improvements (+15.77% win rates) in reasoning\ndepth and breadth validated via GPT-based scoring. MindGYM underscores the\nviability of self-challenging for refining VLM capabilities while minimizing\nhuman intervention and resource demands. Code and data are released to advance\nmultimodal reasoning research.",
      "authors": [
        "Zhe Xu",
        "Daoyuan Chen",
        "Zhenqing Ling",
        "Yaliang Li",
        "Ying Shen"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09499v1",
        "http://arxiv.org/pdf/2503.09499v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09433v1",
      "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards\n  CWE Detection",
      "published": "2025-03-12T14:30:05Z",
      "updated": "2025-03-12T14:30:05Z",
      "summary": "Identifying vulnerabilities in source code is crucial, especially in critical\nsoftware components. Existing methods such as static analysis, dynamic\nanalysis, formal verification, and recently Large Language Models are widely\nused to detect security flaws. This paper introduces CASTLE (CWE Automated\nSecurity Testing and Low-Level Evaluation), a benchmarking framework for\nevaluating the vulnerability detection capabilities of different methods. We\nassess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using\na hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs.\nWe propose the CASTLE Score, a novel evaluation metric to ensure fair\ncomparison. Our results reveal key differences: ESBMC (a formal verification\ntool) minimizes false positives but struggles with vulnerabilities beyond model\nchecking, such as weak cryptography or SQL injection. Static analyzers suffer\nfrom high false positives, increasing manual validation efforts for developers.\nLLMs perform exceptionally well in the CASTLE dataset when identifying\nvulnerabilities in small code snippets. However, their accuracy declines, and\nhallucinations increase as the code size grows. These results suggest that LLMs\ncould play a pivotal role in future security solutions, particularly within\ncode completion frameworks, where they can provide real-time guidance to\nprevent vulnerabilities. The dataset is accessible at\nhttps://github.com/CASTLE-Benchmark.",
      "authors": [
        "Richard A. Dubniczky",
        "Krisztofer Zolt\u00e1n Horv\u00e1t",
        "Tam\u00e1s Bisztray",
        "Mohamed Amine Ferrag",
        "Lucas C. Cordeiro",
        "Norbert Tihanyi"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09433v1",
        "http://arxiv.org/pdf/2503.09433v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09409v1",
      "title": "AI-based Framework for Robust Model-Based Connector Mating in Robotic\n  Wire Harness Installation",
      "published": "2025-03-12T13:59:26Z",
      "updated": "2025-03-12T13:59:26Z",
      "summary": "Despite the widespread adoption of industrial robots in automotive assembly,\nwire harness installation remains a largely manual process, as it requires\nprecise and flexible manipulation. To address this challenge, we design a novel\nAI-based framework that automates cable connector mating by integrating force\ncontrol with deep visuotactile learning. Our system optimizes\nsearch-and-insertion strategies using first-order optimization over a\nmultimodal transformer architecture trained on visual, tactile, and\nproprioceptive data. Additionally, we design a novel automated data collection\nand optimization pipeline that minimizes the need for machine learning\nexpertise. The framework optimizes robot programs that run natively on standard\nindustrial controllers, permitting human experts to audit and certify them.\nExperimental validations on a center console assembly task demonstrate\nsignificant improvements in cycle times and robustness compared to conventional\nrobot programming approaches. Videos are available under\nhttps://claudius-kienle.github.io/AppMuTT.",
      "authors": [
        "Claudius Kienle",
        "Benjamin Alt",
        "Finn Schneider",
        "Tobias Pertlwieser",
        "Rainer J\u00e4kel",
        "Rania Rayyes"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "68T40",
        "I.2; J.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09409v1",
        "http://arxiv.org/pdf/2503.09409v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09347v1",
      "title": "Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts",
      "published": "2025-03-12T12:49:02Z",
      "updated": "2025-03-12T12:49:02Z",
      "summary": "Large Language Models (LLMs) are increasingly employed as automated\nevaluators to assess the safety of generated content, yet their reliability in\nthis role remains uncertain. This study evaluates a diverse set of 11 LLM judge\nmodels across critical safety domains, examining three key aspects:\nself-consistency in repeated judging tasks, alignment with human judgments, and\nsusceptibility to input artifacts such as apologetic or verbose phrasing. Our\nfindings reveal that biases in LLM judges can significantly distort the final\nverdict on which content source is safer, undermining the validity of\ncomparative evaluations. Notably, apologetic language artifacts alone can skew\nevaluator preferences by up to 98\\%. Contrary to expectations, larger models do\nnot consistently exhibit greater robustness, while smaller models sometimes\nshow higher resistance to specific artifacts. To mitigate LLM evaluator\nrobustness issues, we investigate jury-based evaluations aggregating decisions\nfrom multiple models. Although this approach both improves robustness and\nenhances alignment to human judgements, artifact sensitivity persists even with\nthe best jury configurations. These results highlight the urgent need for\ndiversified, artifact-resistant methodologies to ensure reliable safety\nassessments.",
      "authors": [
        "Hongyu Chen",
        "Seraphina Goldfarb-Tarrant"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09347v1",
        "http://arxiv.org/pdf/2503.09347v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09334v1",
      "title": "CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs\n  Using Cyber Security Data",
      "published": "2025-03-12T12:29:27Z",
      "updated": "2025-03-12T12:29:27Z",
      "summary": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. To address these challenges, we developed CyberLLMInstruct, a\ndataset of 54,928 instruction-response pairs spanning cyber security tasks such\nas malware analysis, phishing simulations, and zero-day vulnerabilities. The\ndataset was constructed through a multi-stage process. This involved sourcing\ndata from multiple resources, filtering and structuring it into\ninstruction-response pairs, and aligning it with real-world scenarios to\nenhance its applicability. Seven open-source LLMs were chosen to test the\nusefulness of CyberLLMInstruct: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama\n3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. In our primary example, we\nrigorously assess the safety of fine-tuned models using the OWASP top 10\nframework, finding that fine-tuning reduces safety resilience across all tested\nLLMs and every adversarial attack (e.g., the security score of Llama 3.1 8B\nagainst prompt injection drops from 0.95 to 0.15). In our second example, we\nshow that these same fine-tuned models can also achieve up to 92.50 percent\naccuracy on the CyberMetric benchmark. These findings highlight a trade-off\nbetween performance and safety, showing the importance of adversarial testing\nand further research into fine-tuning methodologies that can mitigate safety\nrisks while still improving performance across diverse datasets and domains.\nAll scripts required to reproduce the dataset, along with examples and relevant\nresources for replicating our results, will be made available upon the paper's\nacceptance.",
      "authors": [
        "Adel ElZemity",
        "Budi Arief",
        "Shujun Li"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09334v1",
        "http://arxiv.org/pdf/2503.09334v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11704v1",
      "title": "Unlimited Practice Opportunities: Automated Generation of Comprehensive,\n  Personalized Programming Tasks",
      "published": "2025-03-12T10:35:25Z",
      "updated": "2025-03-12T10:35:25Z",
      "summary": "Generative artificial intelligence (GenAI) offers new possibilities for\ngenerating personalized programming exercises, addressing the need for\nindividual practice. However, the task quality along with the student\nperspective on such generated tasks remains largely unexplored. Therefore, this\npaper introduces and evaluates a new feature of the so-called Tutor Kai for\ngenerating comprehensive programming tasks, including problem descriptions,\ncode skeletons, unit tests, and model solutions. The presented system allows\nstudents to freely choose programming concepts and contextual themes for their\ntasks. To evaluate the system, we conducted a two-phase mixed-methods study\ncomprising (1) an expert rating of 200 automatically generated programming\ntasks w.r.t. task quality, and (2) a study with 26 computer science students\nwho solved and rated the personalized programming tasks. Results show that\nexperts classified 89.5% of the generated tasks as functional and 92.5% as\nsolvable. However, the system's rate for implementing all requested programming\nconcepts decreased from 94% for single-concept tasks to 40% for tasks\naddressing three concepts. The student evaluation further revealed high\nsatisfaction with the personalization. Students also reported perceived\nbenefits for learning. The results imply that the new feature has the potential\nto offer students individual tasks aligned with their context and need for\nexercise. Tool developers, educators, and, above all, students can benefit from\nthese insights and the system itself.",
      "authors": [
        "Sven Jacobs",
        "Henning Peters",
        "Steffen Jaschke",
        "Natalie Kiesler"
      ],
      "categories": [
        "cs.SE",
        "cs.CY",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11704v1",
        "http://arxiv.org/pdf/2503.11704v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09217v1",
      "title": "Evaluating the Generalizability of LLMs in Automated Program Repair",
      "published": "2025-03-12T10:03:58Z",
      "updated": "2025-03-12T10:03:58Z",
      "summary": "LLM-based automated program repair methods have attracted significant\nattention for their state-of-the-art performance. However, they were primarily\nevaluated on a few well known datasets like Defects4J, raising questions about\ntheir effectiveness on new datasets. In this study, we evaluate 11\ntop-performing LLMs on DEFECTS4J-TRANS, a new dataset derived from transforming\nDefects4J while maintaining the original semantics. Results from experiments on\nboth Defects4J and DEFECTS4J-TRANS show that all studied LLMs have limited\ngeneralizability in APR tasks, with the average number of correct and plausible\npatches decreasing by 49.48% and 42.90%, respectively, on DEFECTS4J-TRANS.\nFurther investigation into incorporating additional repair-relevant information\nin repair prompts reveals that, although this information significantly\nenhances the LLMs' capabilities (increasing the number of correct and plausible\npatches by up to 136.67% and 121.82%, respectively), performance still falls\nshort of their original results. This indicates that prompt engineering alone\nis insufficient to substantially enhance LLMs' repair capabilities. Based on\nour study, we also offer several recommendations for future research.",
      "authors": [
        "Fengjie Li",
        "Jiajun Jiang",
        "Jiajun Sun",
        "Hongyu Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09217v1",
        "http://arxiv.org/pdf/2503.09217v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10700v1",
      "title": "TA-V2A: Textually Assisted Video-to-Audio Generation",
      "published": "2025-03-12T06:43:24Z",
      "updated": "2025-03-12T06:43:24Z",
      "summary": "As artificial intelligence-generated content (AIGC) continues to evolve,\nvideo-to-audio (V2A) generation has emerged as a key area with promising\napplications in multimedia editing, augmented reality, and automated content\ncreation. While Transformer and Diffusion models have advanced audio\ngeneration, a significant challenge persists in extracting precise semantic\ninformation from videos, as current models often lose sequential context by\nrelying solely on frame-based features. To address this, we present TA-V2A, a\nmethod that integrates language, audio, and video features to improve semantic\nrepresentation in latent space. By incorporating large language models for\nenhanced video comprehension, our approach leverages text guidance to enrich\nsemantic expression. Our diffusion model-based system utilizes automated text\nmodulation to enhance inference quality and efficiency, providing personalized\ncontrol through text-guided interfaces. This integration enhances semantic\nexpression while ensuring temporal alignment, leading to more accurate and\ncoherent video-to-audio generation.",
      "authors": [
        "Yuhuan You",
        "Xihong Wu",
        "Tianshu Qu"
      ],
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10700v1",
        "http://arxiv.org/pdf/2503.10700v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09068v1",
      "title": "Probing Network Decisions: Capturing Uncertainties and Unveiling\n  Vulnerabilities Without Label Information",
      "published": "2025-03-12T05:05:58Z",
      "updated": "2025-03-12T05:05:58Z",
      "summary": "To improve trust and transparency, it is crucial to be able to interpret the\ndecisions of Deep Neural classifiers (DNNs). Instance-level examinations, such\nas attribution techniques, are commonly employed to interpret the model\ndecisions. However, when interpreting misclassified decisions, human\nintervention may be required. Analyzing the attribu tions across each class\nwithin one instance can be particularly labor intensive and influenced by the\nbias of the human interpreter. In this paper, we present a novel framework to\nuncover the weakness of the classifier via counterfactual examples. A prober is\nintroduced to learn the correctness of the classifier's decision in terms of\nbinary code-hit or miss. It enables the creation of the counterfactual example\nconcerning the prober's decision. We test the performance of our prober's\nmisclassification detection and verify its effectiveness on the image\nclassification benchmark datasets. Furthermore, by generating counterfactuals\nthat penetrate the prober, we demonstrate that our framework effectively\nidentifies vulnerabilities in the target classifier without relying on label\ninformation on the MNIST dataset.",
      "authors": [
        "Youngju Joung",
        "Sehyun Lee",
        "Jaesik Choi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://dx.doi.org/10.1007/978-981-97-8702-9_21",
        "http://arxiv.org/abs/2503.09068v1",
        "http://arxiv.org/pdf/2503.09068v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09002v1",
      "title": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers",
      "published": "2025-03-12T02:30:19Z",
      "updated": "2025-03-12T02:30:19Z",
      "summary": "Static analysis is a powerful technique for bug detection in critical systems\nlike operating system kernels. However, designing and implementing static\nanalyzers is challenging, time-consuming, and typically limited to predefined\nbug patterns. While large language models (LLMs) have shown promise for static\nanalysis, directly applying them to scan large codebases remains impractical\ndue to computational constraints and contextual limitations.\n  We present KNighter, the first approach that unlocks practical LLM-based\nstatic analysis by automatically synthesizing static analyzers from historical\nbug patterns. Rather than using LLMs to directly analyze massive codebases, our\nkey insight is leveraging LLMs to generate specialized static analyzers guided\nby historical patch knowledge. KNighter implements this vision through a\nmulti-stage synthesis pipeline that validates checker correctness against\noriginal patches and employs an automated refinement process to iteratively\nreduce false positives. Our evaluation on the Linux kernel demonstrates that\nKNighter generates high-precision checkers capable of detecting diverse bug\npatterns overlooked by existing human-written analyzers. To date,\nKNighter-synthesized checkers have discovered 70 new bugs/vulnerabilities in\nthe Linux kernel, with 56 confirmed and 41 already fixed. 11 of these findings\nhave been assigned CVE numbers. This work establishes an entirely new paradigm\nfor scalable, reliable, and traceable LLM-based static analysis for real-world\nsystems via checker synthesis.",
      "authors": [
        "Chenyuan Yang",
        "Zijie Zhao",
        "Zichen Xie",
        "Haoyu Li",
        "Lingming Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.OS"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09002v1",
        "http://arxiv.org/pdf/2503.09002v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08994v1",
      "title": "DistJoin: A Decoupled Join Cardinality Estimator based on Adaptive\n  Neural Predicate Modulation",
      "published": "2025-03-12T02:07:08Z",
      "updated": "2025-03-12T02:07:08Z",
      "summary": "Research on learned cardinality estimation has achieved significant progress\nin recent years. However, existing methods still face distinct challenges that\nhinder their practical deployment in production environments. We conceptualize\nthese challenges as the \"Trilemma of Cardinality Estimation\", where learned\ncardinality estimation methods struggle to balance generality, accuracy, and\nupdatability. To address these challenges, we introduce DistJoin, a join\ncardinality estimator based on efficient distribution prediction using\nmulti-autoregressive models. Our contributions are threefold: (1) We propose a\nmethod for estimating both equi and non-equi join cardinality by leveraging the\nconditional probability distributions of individual tables in a decoupled\nmanner. (2) To meet the requirements of efficient training and inference for\nDistJoin, we develop Adaptive Neural Predicate Modulation (ANPM), a\nhigh-throughput conditional probability distribution estimation model. (3) We\nformally analyze the variance of existing similar methods and demonstrate that\nsuch approaches suffer from variance accumulation issues. To mitigate this\nproblem, DistJoin employs a selectivity-based approach rather than a\ncount-based approach to infer join cardinality, effectively reducing variance.\nIn summary, DistJoin not only represents the first data-driven method to\neffectively support both equi and non-equi joins but also demonstrates superior\naccuracy while enabling fast and flexible updates. We evaluate DistJoin on\nJOB-light and JOB-light-ranges, extending the evaluation to non-equi join\nconditions. The results demonstrate that our approach achieves the highest\naccuracy, robustness to data updates, generality, and comparable update and\ninference speed relative to existing methods.",
      "authors": [
        "Kaixin Zhang",
        "Hongzhi Wang",
        "Ziqi Li",
        "Yabin Lu",
        "Yingze Li",
        "Yu Yan",
        "Yiming Guan"
      ],
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08994v1",
        "http://arxiv.org/pdf/2503.08994v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08990v1",
      "title": "JBFuzz: Jailbreaking LLMs Efficiently and Effectively Using Fuzzing",
      "published": "2025-03-12T01:52:17Z",
      "updated": "2025-03-12T01:52:17Z",
      "summary": "Large language models (LLMs) have shown great promise as language\nunderstanding and decision making tools, and they have permeated various\naspects of our everyday life. However, their widespread availability also comes\nwith novel risks, such as generating harmful, unethical, or offensive content,\nvia an attack called jailbreaking. Despite extensive efforts from LLM\ndevelopers to align LLMs using human feedback, they are still susceptible to\njailbreak attacks. To tackle this issue, researchers often employ red-teaming\nto understand and investigate jailbreak prompts. However, existing red-teaming\napproaches lack effectiveness, scalability, or both. To address these issues,\nwe propose JBFuzz, a novel effective, automated, and scalable red-teaming\ntechnique for jailbreaking LLMs.\n  JBFuzz is inspired by the success of fuzzing for detecting\nbugs/vulnerabilities in software. We overcome three challenges related to\neffectiveness and scalability by devising novel seed prompts, a lightweight\nmutation engine, and a lightweight and accurate evaluator for guiding the\nfuzzer. Assimilating all three solutions results in a potent fuzzer that only\nrequires black-box access to the target LLM. We perform extensive experimental\nevaluation of JBFuzz using nine popular and widely-used LLMs. We find that\nJBFuzz successfully jailbreaks all LLMs for various harmful/unethical\nquestions, with an average attack success rate of 99%. We also find that JBFuzz\nis extremely efficient as it jailbreaks a given LLM for a given question in 60\nseconds on average. Our work highlights the susceptibility of the\nstate-of-the-art LLMs to jailbreak attacks even after safety alignment, and\nserves as a valuable red-teaming tool for LLM developers.",
      "authors": [
        "Vasudev Gohil"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08990v1",
        "http://arxiv.org/pdf/2503.08990v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09637v1",
      "title": "Complementarity, Augmentation, or Substitutivity? The Impact of\n  Generative Artificial Intelligence on the U.S. Federal Workforce",
      "published": "2025-03-12T01:19:52Z",
      "updated": "2025-03-12T01:19:52Z",
      "summary": "This study investigates the near-future impacts of generative artificial\nintelligence (AI) technologies on occupational competencies across the U.S.\nfederal workforce. We develop a multi-stage Retrieval-Augmented Generation\nsystem to leverage large language models for predictive AI modeling that\nprojects shifts in required competencies and to identify vulnerable occupations\non a knowledge-by-skill-by-ability basis across the federal government\nworkforce. This study highlights policy recommendations essential for workforce\nplanning in the era of AI. We integrate several sources of detailed data on\noccupational requirements across the federal government from both centralized\nand decentralized human resource sources, including from the U.S. Office of\nPersonnel Management (OPM) and various federal agencies. While our preliminary\nfindings suggest some significant shifts in required competencies and potential\nvulnerability of certain roles to AI-driven changes, we provide nuanced\ninsights that support arguments against abrupt or generic approaches to\nstrategic human capital planning around the development of generative AI. The\nstudy aims to inform strategic workforce planning and policy development within\nfederal agencies and demonstrates how this approach can be replicated across\nother large employment institutions and labor markets.",
      "authors": [
        "William G. Resh",
        "Yi Ming",
        "Xinyao Xia",
        "Michael Overton",
        "Gul Nisa G\u00fcrb\u00fcz",
        "Brandon De Breuhl"
      ],
      "categories": [
        "cs.CY",
        "econ.GN",
        "q-fin.EC",
        "I.2.7; I.2.11; I.2.1; I.2.3; I.7"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09637v1",
        "http://arxiv.org/pdf/2503.09637v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08936v1",
      "title": "Simulator Ensembles for Trustworthy Autonomous Driving Testing",
      "published": "2025-03-11T22:34:14Z",
      "updated": "2025-03-11T22:34:14Z",
      "summary": "Scenario-based testing with driving simulators is extensively used to\nidentify failing conditions of automated driving assistance systems (ADAS) and\nreduce the amount of in-field road testing. However, existing studies have\nshown that repeated test execution in the same as well as in distinct\nsimulators can yield different outcomes, which can be attributed to sources of\nflakiness or different implementations of the physics, among other factors. In\nthis paper, we present MultiSim, a novel approach to multi-simulation ADAS\ntesting based on a search-based testing approach that leverages an ensemble of\nsimulators to identify failure-inducing, simulator-agnostic test scenarios.\nDuring the search, each scenario is evaluated jointly on multiple simulators.\nScenarios that produce consistent results across simulators are prioritized for\nfurther exploration, while those that fail on only a subset of simulators are\ngiven less priority, as they may reflect simulator-specific issues rather than\ngeneralizable failures. Our case study, which involves testing a deep neural\nnetwork-based ADAS on different pairs of three widely used simulators,\ndemonstrates that MultiSim outperforms single-simulator testing by achieving on\naverage a higher rate of simulator-agnostic failures by 51%. Compared to a\nstate-of-the-art multi-simulator approach that combines the outcome of\nindependent test generation campaigns obtained in different simulators,\nMultiSim identifies 54% more simulator-agnostic failing tests while showing a\ncomparable validity rate. An enhancement of MultiSim that leverages surrogate\nmodels to predict simulator disagreements and bypass executions does not only\nincrease the average number of valid failures but also improves efficiency in\nfinding the first valid failure.",
      "authors": [
        "Lev Sorokin",
        "Matteo Biagiola",
        "Andrea Stocco"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08936v1",
        "http://arxiv.org/pdf/2503.08936v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08823v1",
      "title": "ResBench: Benchmarking LLM-Generated FPGA Designs with Resource\n  Awareness",
      "published": "2025-03-11T18:54:17Z",
      "updated": "2025-03-11T18:54:17Z",
      "summary": "Field-Programmable Gate Arrays (FPGAs) are widely used in modern hardware\ndesign, yet writing Hardware Description Language (HDL) code for FPGA\nimplementation remains labor-intensive and complex. Large Language Models\n(LLMs) have emerged as a promising tool for automating HDL generation, but\nexisting benchmarks for LLM HDL code generation primarily evaluate functional\ncorrectness while overlooking the critical aspect of hardware resource\nefficiency. Moreover, current benchmarks lack diversity, failing to capture the\nbroad range of real-world FPGA applications. To address these gaps, we\nintroduce ResBench, the first resource-oriented benchmark explicitly designed\nto differentiate between resource-optimized and inefficient LLM-generated HDL.\nResBench consists of 56 problems across 12 categories, covering applications\nfrom finite state machines to financial computing. Our evaluation framework\nsystematically integrates FPGA resource constraints, with a primary focus on\nLookup Table (LUT) usage, enabling a realistic assessment of hardware\nefficiency. Experimental results reveal substantial differences in resource\nutilization across LLMs, demonstrating ResBench's effectiveness in\ndistinguishing models based on their ability to generate resource-optimized\nFPGA designs.",
      "authors": [
        "Ce Guo",
        "Tong Zhao"
      ],
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.LG",
        "I.2.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08823v1",
        "http://arxiv.org/pdf/2503.08823v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08669v1",
      "title": "AgentOrca: A Dual-System Framework to Evaluate Language Agents on\n  Operational Routine and Constraint Adherence",
      "published": "2025-03-11T17:53:02Z",
      "updated": "2025-03-11T17:53:02Z",
      "summary": "As language agents progressively automate critical tasks across domains,\ntheir ability to operate within operational constraints and safety protocols\nbecomes essential. While extensive research has demonstrated these agents'\neffectiveness in downstream task completion, their reliability in following\noperational procedures and constraints remains largely unexplored. To this end,\nwe present AgentOrca, a dual-system framework for evaluating language agents'\ncompliance with operational constraints and routines. Our framework encodes\naction constraints and routines through both natural language prompts for\nagents and corresponding executable code serving as ground truth for automated\nverification. Through an automated pipeline of test case generation and\nevaluation across five real-world domains, we quantitatively assess current\nlanguage agents' adherence to operational constraints. Our findings reveal\nnotable performance gaps among state-of-the-art models, with large reasoning\nmodels like o1 demonstrating superior compliance while others show\nsignificantly lower performance, particularly when encountering complex\nconstraints or user persuasion attempts.",
      "authors": [
        "Zekun Li",
        "Shinda Huang",
        "Jiangtian Wang",
        "Nathan Zhang",
        "Antonis Antoniades",
        "Wenyue Hua",
        "Kaijie Zhu",
        "Sirui Zeng",
        "William Yang Wang",
        "Xifeng Yan"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08669v1",
        "http://arxiv.org/pdf/2503.08669v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08609v1",
      "title": "Vision Transformer for Intracranial Hemorrhage Classification in CT\n  Scans Using an Entropy-Aware Fuzzy Integral Strategy for Adaptive Scan-Level\n  Decision Fusion",
      "published": "2025-03-11T16:47:32Z",
      "updated": "2025-03-11T16:47:32Z",
      "summary": "Intracranial hemorrhage (ICH) is a critical medical emergency caused by the\nrupture of cerebral blood vessels, leading to internal bleeding within the\nskull. Accurate and timely classification of hemorrhage subtypes is essential\nfor effective clinical decision-making. To address this challenge, we propose\nan advanced pyramid vision transformer (PVT)-based model, leveraging its\nhierarchical attention mechanisms to capture both local and global spatial\ndependencies in brain CT scans. Instead of processing all extracted features\nindiscriminately, A SHAP-based feature selection method is employed to identify\nthe most discriminative components, which are then used as a latent feature\nspace to train a boosting neural network, reducing computational complexity. We\nintroduce an entropy-aware aggregation strategy along with a fuzzy integral\noperator to fuse information across multiple CT slices, ensuring a more\ncomprehensive and reliable scan-level diagnosis by accounting for inter-slice\ndependencies. Experimental results show that our PVT-based framework\nsignificantly outperforms state-of-the-art deep learning architectures in terms\nof classification accuracy, precision, and robustness. By combining SHAP-driven\nfeature selection, transformer-based modeling, and an entropy-aware fuzzy\nintegral operator for decision fusion, our method offers a scalable and\ncomputationally efficient AI-driven solution for automated ICH subtype\nclassification.",
      "authors": [
        "Mehdi Hosseini Chagahi",
        "Niloufar Delfan",
        "Behzad Moshiri",
        "Md. Jalil Piran",
        "Jaber Hatam Parikhan"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08609v1",
        "http://arxiv.org/pdf/2503.08609v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08533v1",
      "title": "ESPnet-SDS: Unified Toolkit and Demo for Spoken Dialogue Systems",
      "published": "2025-03-11T15:24:02Z",
      "updated": "2025-03-11T15:24:02Z",
      "summary": "Advancements in audio foundation models (FMs) have fueled interest in\nend-to-end (E2E) spoken dialogue systems, but different web interfaces for each\nsystem makes it challenging to compare and contrast them effectively. Motivated\nby this, we introduce an open-source, user-friendly toolkit designed to build\nunified web interfaces for various cascaded and E2E spoken dialogue systems.\nOur demo further provides users with the option to get on-the-fly automated\nevaluation metrics such as (1) latency, (2) ability to understand user input,\n(3) coherence, diversity, and relevance of system response, and (4)\nintelligibility and audio quality of system output. Using the evaluation\nmetrics, we compare various cascaded and E2E spoken dialogue systems with a\nhuman-human conversation dataset as a proxy. Our analysis demonstrates that the\ntoolkit allows researchers to effortlessly compare and contrast different\ntechnologies, providing valuable insights such as current E2E systems having\npoorer audio quality and less diverse responses. An example demo produced using\nour toolkit is publicly available here:\nhttps://huggingface.co/spaces/Siddhant/Voice_Assistant_Demo.",
      "authors": [
        "Siddhant Arora",
        "Yifan Peng",
        "Jiatong Shi",
        "Jinchuan Tian",
        "William Chen",
        "Shikhar Bharadwaj",
        "Hayato Futami",
        "Yosuke Kashiwagi",
        "Emiru Tsunoo",
        "Shuichiro Shimizu",
        "Vaibhav Srivastav",
        "Shinji Watanabe"
      ],
      "categories": [
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08533v1",
        "http://arxiv.org/pdf/2503.08533v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08525v1",
      "title": "GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based\n  VLM Agent Training",
      "published": "2025-03-11T15:17:02Z",
      "updated": "2025-03-11T15:17:02Z",
      "summary": "Reinforcement learning with verifiable outcome rewards (RLVR) has effectively\nscaled up chain-of-thought (CoT) reasoning in large language models (LLMs).\nYet, its efficacy in training vision-language model (VLM) agents for\ngoal-directed action reasoning in visual environments is less established. This\nwork investigates this problem through extensive experiments on complex card\ngames, such as 24 points, and embodied tasks from ALFWorld. We find that when\nrewards are based solely on action outcomes, RL fails to incentivize CoT\nreasoning in VLMs, instead leading to a phenomenon we termed thought collapse,\ncharacterized by a rapid loss of diversity in the agent's thoughts,\nstate-irrelevant and incomplete reasoning, and subsequent invalid actions,\nresulting in negative rewards. To counteract thought collapse, we highlight the\nnecessity of process guidance and propose an automated corrector that evaluates\nand refines the agent's reasoning at each RL step. This simple and scalable GTR\n(Guided Thought Reinforcement) framework trains reasoning and action\nsimultaneously without the need for dense, per-step human labeling. Our\nexperiments demonstrate that GTR significantly enhances the performance and\ngeneralization of the LLaVA-7b model across various visual environments,\nachieving 3-5 times higher task success rates compared to SoTA models with\nnotably smaller model sizes.",
      "authors": [
        "Tong Wei",
        "Yijun Yang",
        "Junliang Xing",
        "Yuanchun Shi",
        "Zongqing Lu",
        "Deheng Ye"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08525v1",
        "http://arxiv.org/pdf/2503.08525v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08437v1",
      "title": "ICPR 2024 Competition on Rider Intention Prediction",
      "published": "2025-03-11T13:50:37Z",
      "updated": "2025-03-11T13:50:37Z",
      "summary": "The recent surge in the vehicle market has led to an alarming increase in\nroad accidents. This underscores the critical importance of enhancing road\nsafety measures, particularly for vulnerable road users like motorcyclists.\nHence, we introduce the rider intention prediction (RIP) competition that aims\nto address challenges in rider safety by proactively predicting maneuvers\nbefore they occur, thereby strengthening rider safety. This capability enables\nthe riders to react to the potential incorrect maneuvers flagged by advanced\ndriver assistance systems (ADAS). We collect a new dataset, namely, rider\naction anticipation dataset (RAAD) for the competition consisting of two tasks:\nsingle-view RIP and multi-view RIP. The dataset incorporates a spectrum of\ntraffic conditions and challenging navigational maneuvers on roads with varying\nlighting conditions. For the competition, we received seventy-five\nregistrations and five team submissions for inference of which we compared the\nmethods of the top three performing teams on both the RIP tasks: one\nstate-space model (Mamba2) and two learning-based approaches (SVM and\nCNN-LSTM). The results indicate that the state-space model outperformed the\nother methods across the entire dataset, providing a balanced performance\nacross maneuver classes. The SVM-based RIP method showed the second-best\nperformance when using random sampling and SMOTE. However, the CNN-LSTM method\nunderperformed, primarily due to class imbalance issues, particularly\nstruggling with minority classes. This paper details the proposed RAAD dataset\nand provides a summary of the submissions for the RIP 2024 competition.",
      "authors": [
        "Shankar Gangisetty",
        "Abdul Wasi",
        "Shyam Nandan Rai",
        "C. V. Jawahar",
        "Sajay Raj",
        "Manish Prajapati",
        "Ayesha Choudhary",
        "Aaryadev Chandra",
        "Dev Chandan",
        "Shireen Chand",
        "Suvaditya Mukherjee"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "links": [
        "http://dx.doi.org/10.1007/978-3-031-80139-6_3",
        "http://arxiv.org/abs/2503.08437v1",
        "http://arxiv.org/pdf/2503.08437v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08416v1",
      "title": "A Distributed Clustering Algorithm based on Coalition Game for\n  Intelligent Vehicles",
      "published": "2025-03-11T13:27:44Z",
      "updated": "2025-03-11T13:27:44Z",
      "summary": "In the context of Vehicular ad-hoc networks (VANETs), the hierarchical\nmanagement of intelligent vehicles, based on clustering methods, represents a\nwell-established solution for effectively addressing scalability and\nreliability issues. The previous studies have primarily focused on centralized\nclustering problems with a single objective. However, this paper investigates\nthe distributed clustering problem that simultaneously optimizes two\nobjectives: the cooperative capacity and management overhead of cluster\nformation, under dynamic network conditions. Specifically, the clustering\nproblem is formulated within a coalition formation game framework to achieve\nboth low computational complexity and automated decision-making in cluster\nformation. Additionally, we propose a distributed clustering algorithm (DCA)\nthat incorporates three innovative operations for forming/breaking coalition,\nfacilitating collaborative decision-making among individual intelligent\nvehicles. The convergence of the DCA is proven to result in a Nash stable\npartition, and extensive simulations demonstrate its superior performance\ncompared to existing state-of-the-art approaches for coalition formation.",
      "authors": [
        "Weiyi Yang",
        "Xiaolu Liu",
        "Lei He",
        "Yonghao Du",
        "Yingwu Chen"
      ],
      "categories": [
        "cs.GT"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08416v1",
        "http://arxiv.org/pdf/2503.08416v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08750v1",
      "title": "Exposing Product Bias in LLM Investment Recommendation",
      "published": "2025-03-11T13:10:00Z",
      "updated": "2025-03-11T13:10:00Z",
      "summary": "Large language models (LLMs), as a new generation of recommendation engines,\npossess powerful summarization and data analysis capabilities, surpassing\ntraditional recommendation systems in both scope and performance. One promising\napplication is investment recommendation. In this paper, we reveal a novel\nproduct bias in LLM investment recommendation, where LLMs exhibit systematic\npreferences for specific products. Such preferences can subtly influence user\ninvestment decisions, potentially leading to inflated valuations of products\nand financial bubbles, posing risks to both individual investors and market\nstability. To comprehensively study the product bias, we develop an automated\npipeline to create a dataset of 567,000 samples across five asset classes\n(stocks, mutual funds, cryptocurrencies, savings, and portfolios). With this\ndataset, we present the bf first study on product bias in LLM investment\nrecommendations. Our findings reveal that LLMs exhibit clear product\npreferences, such as certain stocks (e.g., `AAPL' from Apple and `MSFT' from\nMicrosoft). Notably, this bias persists even after applying debiasing\ntechniques. We urge AI researchers to take heed of the product bias in LLM\ninvestment recommendations and its implications, ensuring fairness and security\nin the digital space and market.",
      "authors": [
        "Yuhan Zhi",
        "Xiaoyu Zhang",
        "Longtian Wang",
        "Shumin Jiang",
        "Shiqing Ma",
        "Xiaohong Guan",
        "Chao Shen"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08750v1",
        "http://arxiv.org/pdf/2503.08750v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08747v1",
      "title": "IA generativa aplicada a la detecci\u00f3n del c\u00e1ncer a trav\u00e9s de\n  Resonancia Magn\u00e9tica",
      "published": "2025-03-11T10:34:47Z",
      "updated": "2025-03-11T10:34:47Z",
      "summary": "Cognitive delegation to artificial intelligence (AI) systems is transforming\nscientific research by enabling the automation of analytical processes and the\ndiscovery of new patterns in large datasets. This study examines the ability of\nAI to complement and expand knowledge in the analysis of breast cancer using\ndynamic contrast-enhanced magnetic resonance imaging (DCE-MRI). Building on a\nprevious study, we assess the extent to which AI can generate novel approaches\nand successfully solve them. For this purpose, AI models, specifically\nChatGPT-4o, were used for data preprocessing, hypothesis generation, and the\napplication of clustering techniques, predictive modeling, and correlation\nnetwork analysis. The results obtained were compared with manually computed\noutcomes, revealing limitations in process transparency and the accuracy of\ncertain calculations. However, as AI reduces errors and improves reasoning\ncapabilities, an important question arises regarding the future of scientific\nresearch: could automation replace the human role in science? This study seeks\nto open the debate on the methodological and ethical implications of a science\ndominated by artificial intelligence.",
      "authors": [
        "Virginia del Campo",
        "Iker Malaina"
      ],
      "categories": [
        "q-bio.QM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08747v1",
        "http://arxiv.org/pdf/2503.08747v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08228v1",
      "title": "Investigating Execution-Aware Language Models for Code Optimization",
      "published": "2025-03-11T09:46:07Z",
      "updated": "2025-03-11T09:46:07Z",
      "summary": "Code optimization is the process of enhancing code efficiency, while\npreserving its intended functionality. This process often requires a deep\nunderstanding of the code execution behavior at run-time to identify and\naddress inefficiencies effectively. Recent studies have shown that language\nmodels can play a significant role in automating code optimization. However,\nthese models may have insufficient knowledge of how code execute at run-time.\nTo address this limitation, researchers have developed strategies that\nintegrate code execution information into language models. These strategies\nhave shown promise, enhancing the effectiveness of language models in various\nsoftware engineering tasks. However, despite the close relationship between\ncode execution behavior and efficiency, the specific impact of these strategies\non code optimization remains largely unexplored. This study investigates how\nincorporating code execution information into language models affects their\nability to optimize code. Specifically, we apply three different training\nstrategies to incorporate four code execution aspects -- line executions, line\ncoverage, branch coverage, and variable states -- into CodeT5+, a well-known\nlanguage model for code. Our results indicate that execution-aware models\nprovide limited benefits compared to the standard CodeT5+ model in optimizing\ncode.",
      "authors": [
        "Federico Di Menna",
        "Luca Traini",
        "Gabriele Bavota",
        "Vittorio Cortellessa"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PF"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08228v1",
        "http://arxiv.org/pdf/2503.08228v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08741v2",
      "title": "Oasis: One Image is All You Need for Multimodal Instruction Data\n  Synthesis",
      "published": "2025-03-11T08:25:40Z",
      "updated": "2025-03-13T06:15:32Z",
      "summary": "The success of multi-modal large language models (MLLMs) has been largely\nattributed to the large-scale training data. However, the training data of many\nMLLMs is unavailable due to privacy concerns. The expensive and labor-intensive\nprocess of collecting multi-modal data further exacerbates the problem. Is it\npossible to synthesize multi-modal training data automatically without\ncompromising diversity and quality? In this paper, we propose a new method,\nOasis, to synthesize high-quality multi-modal data with only images. Oasis\nbreaks through traditional methods by prompting only images to the MLLMs, thus\nextending the data diversity by a large margin. Our method features a delicate\nquality control method which ensures the data quality. We collected over 500k\ndata and conducted incremental experiments on LLaVA-NeXT. Extensive experiments\ndemonstrate that our method can significantly improve the performance of MLLMs.\nThe image-based synthesis also allows us to focus on the specific-domain\nability of MLLMs. Code and data will be publicly available.",
      "authors": [
        "Letian Zhang",
        "Quan Cui",
        "Bingchen Zhao",
        "Cheng Yang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08741v2",
        "http://arxiv.org/pdf/2503.08741v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08074v1",
      "title": "Hedonic Adaptation in the Age of AI: A Perspective on Diminishing\n  Satisfaction Returns in Technology Adoption",
      "published": "2025-03-11T06:08:36Z",
      "updated": "2025-03-11T06:08:36Z",
      "summary": "The fast paced progress of artificial intelligence (AI) through scaling laws\nconnecting rising computational power with improving performance has created\ntremendous technological breakthroughs. These breakthroughs do not translate to\ncorresponding user satisfaction improvements, resulting in a general mismatch.\nThis research suggests that hedonic adaptation the psychological process by\nwhich people revert to a baseline state of happiness after drastic change\nprovides a suitable model for understanding this phenomenon. We argue that user\nsatisfaction with AI follows a logarithmic path, thus creating a longterm\n\"satisfaction gap\" as people rapidly get used to new capabilities as\nexpectations. This process occurs through discrete stages: initial excitement,\ndeclining returns, stabilization, and sporadic resurgence, depending on\nadaptation rate and capability introduction. These processes have far reaching\nimplications for AI research, user experience design, marketing, and ethics,\nsuggesting a paradigm shift from sole technical scaling to methods that sustain\nperceived value in the midst of human adaptation. This perspective reframes AI\ndevelopment, necessitating practices that align technological progress with\npeople's subjective experience.",
      "authors": [
        "Venkat Ram Reddy Ganuthula",
        "Krishna Kumar Balaraman",
        "Nimish Vohra"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08074v1",
        "http://arxiv.org/pdf/2503.08074v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07993v1",
      "title": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics",
      "published": "2025-03-11T02:50:45Z",
      "updated": "2025-03-11T02:50:45Z",
      "summary": "Disconnected data silos within enterprises obstruct the extraction of\nactionable insights, diminishing efficiency in areas such as product\ndevelopment, client engagement, meeting preparation, and analytics-driven\ndecision-making. This paper introduces a framework that uses large language\nmodels (LLMs) to unify various data sources into a comprehensive,\nactivity-centric knowledge graph. The framework automates tasks such as entity\nextraction, relationship inference, and semantic enrichment, enabling advanced\nquerying, reasoning, and analytics across data types like emails, calendars,\nchats, documents, and logs. Designed for enterprise flexibility, it supports\napplications such as contextual search, task prioritization, expertise\ndiscovery, personalized recommendations, and advanced analytics to identify\ntrends and actionable insights. Experimental results demonstrate its success in\nthe discovery of expertise, task management, and data-driven decision making.\nBy integrating LLMs with knowledge graphs, this solution bridges disconnected\nsystems and delivers intelligent analytics-powered enterprise tools.",
      "authors": [
        "Rajeev Kumar",
        "Kumar Ishan",
        "Harishankar Kumar",
        "Abhinandan Singla"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07993v1",
        "http://arxiv.org/pdf/2503.07993v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07963v2",
      "title": "Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal\n  Manipulation using Tight Convex Relaxations",
      "published": "2025-03-11T01:40:23Z",
      "updated": "2025-03-12T01:43:20Z",
      "summary": "Designing trajectories for manipulation through contact is challenging as it\nrequires reasoning of object \\& robot trajectories as well as complex contact\nsequences simultaneously. In this paper, we present a novel framework for\nsimultaneously designing trajectories of robots, objects, and contacts\nefficiently for contact-rich manipulation. We propose a hierarchical\noptimization framework where Mixed-Integer Linear Program (MILP) selects\noptimal contacts between robot \\& object using approximate dynamical\nconstraints, and then a NonLinear Program (NLP) optimizes trajectory of the\nrobot(s) and object considering full nonlinear constraints. We present a convex\nrelaxation of bilinear constraints using binary encoding technique such that\nMILP can provide tighter solutions with better computational complexity. The\nproposed framework is evaluated on various manipulation tasks where it can\nreason about complex multi-contact interactions while providing computational\nadvantages. We also demonstrate our framework in hardware experiments using a\nbimanual robot system. The video summarizing this paper and hardware\nexperiments is found https://youtu.be/s2S1Eg5RsRE?si=chPkftz_a3NAHxLq",
      "authors": [
        "Yuki Shirai",
        "Arvind Raghunathan",
        "Devesh K. Jha"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07963v2",
        "http://arxiv.org/pdf/2503.07963v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.08729v1",
      "title": "Preserving Product Fidelity in Large Scale Image Recontextualization\n  with Diffusion Models",
      "published": "2025-03-11T01:24:39Z",
      "updated": "2025-03-11T01:24:39Z",
      "summary": "We present a framework for high-fidelity product image recontextualization\nusing text-to-image diffusion models and a novel data augmentation pipeline.\nThis pipeline leverages image-to-video diffusion, in/outpainting & negatives to\ncreate synthetic training data, addressing limitations of real-world data\ncollection for this task. Our method improves the quality and diversity of\ngenerated images by disentangling product representations and enhancing the\nmodel's understanding of product characteristics. Evaluation on the ABO dataset\nand a private product dataset, using automated metrics and human assessment,\ndemonstrates the effectiveness of our framework in generating realistic and\ncompelling product visualizations, with implications for applications such as\ne-commerce and virtual product showcasing.",
      "authors": [
        "Ishaan Malhi",
        "Praneet Dutta",
        "Ellie Talius",
        "Sally Ma",
        "Brendan Driscoll",
        "Krista Holden",
        "Garima Pruthi",
        "Arunachalam Narayanaswamy"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.08729v1",
        "http://arxiv.org/pdf/2503.08729v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10674v1",
      "title": "Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index\n  Finetuning Dataset for Mapping GRI and ESRS",
      "published": "2025-03-10T18:07:33Z",
      "updated": "2025-03-10T18:07:33Z",
      "summary": "Climate change has intensified the need for transparency and accountability\nin organizational practices, making Environmental, Social, and Governance (ESG)\nreporting increasingly crucial. Frameworks like the Global Reporting Initiative\n(GRI) and the new European Sustainability Reporting Standards (ESRS) aim to\nstandardize ESG reporting, yet generating comprehensive reports remains\nchallenging due to the considerable length of ESG documents and variability in\ncompany reporting styles. To facilitate ESG report automation,\nRetrieval-Augmented Generation (RAG) systems can be employed, but their\ndevelopment is hindered by a lack of labeled data suitable for training\nretrieval models. In this paper, we leverage an underutilized source of weak\nsupervision -- the disclosure content index found in past ESG reports -- to\ncreate a comprehensive dataset, ESG-CID, for both GRI and ESRS standards. By\nextracting mappings between specific disclosure requirements and corresponding\nreport sections, and refining them using a Large Language Model as a judge, we\ngenerate a robust training and evaluation set. We benchmark popular embedding\nmodels on this dataset and show that fine-tuning BERT-based models can\noutperform commercial embeddings and leading public models, even under temporal\ndata splits for cross-report style transfer from GRI to ESRS",
      "authors": [
        "Shafiuddin Rehan Ahmed",
        "Ankit Parag Shah",
        "Quan Hung Tran",
        "Vivek Khetan",
        "Sukryool Kang",
        "Ankit Mehta",
        "Yujia Bao",
        "Wei Wei"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10674v1",
        "http://arxiv.org/pdf/2503.10674v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07701v1",
      "title": "Automated Benchmark Generation for Repository-Level Coding Tasks",
      "published": "2025-03-10T17:42:49Z",
      "updated": "2025-03-10T17:42:49Z",
      "summary": "Code Agent development is an extremely active research area, where a reliable\nperformance metric is critical for tracking progress and guiding new\ndevelopments. This demand is underscored by the meteoric rise in popularity of\nSWE-Bench. This benchmark challenges code agents to generate patches addressing\nGitHub issues given the full repository as context. The correctness of\ngenerated patches is then evaluated by executing a human-written test suite\nextracted from the repository after the issue's resolution. However,\nconstructing benchmarks like SWE-Bench requires substantial manual effort to\nset up historically accurate execution environments for testing. Crucially,\nthis severely limits the number of considered repositories, e.g., just 12 for\nSWE-Bench. Considering so few repositories, selected for their popularity runs\nthe risk of leading to a distributional mismatch, i.e., the measured\nperformance may not be representative of real-world scenarios potentially\nmisguiding development efforts. In this work, we address this challenge and\nintroduce SetUpAgent, a fully automated system capable of historically accurate\ndependency setup, test execution, and result parsing. Using SetUpAgent, we\ngenerate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench\nencompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing\non applications rather than libraries. Comparing these datasets to SWE-Bench\nwith respect to their characteristics and code agent performance, we find\nsignificant distributional differences, including lower issue description\nquality and detail level, higher fix complexity, and most importantly up to 40%\nlower agent success rates.",
      "authors": [
        "Konstantinos Vergopoulos",
        "Mark Niklas M\u00fcller",
        "Martin Vechev"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07701v1",
        "http://arxiv.org/pdf/2503.07701v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07545v1",
      "title": "Queueing, Predictions, and LLMs: Challenges and Open Problems",
      "published": "2025-03-10T17:12:47Z",
      "updated": "2025-03-10T17:12:47Z",
      "summary": "Queueing systems present many opportunities for applying machine-learning\npredictions, such as estimated service times, to improve system performance.\nThis integration raises numerous open questions about how predictions can be\neffectively leveraged to improve scheduling decisions. Recent studies explore\nqueues with predicted service times, typically aiming to minimize job time in\nthe system. We review these works, highlight the effectiveness of predictions,\nand present open questions on queue performance. We then move to consider an\nimportant practical example of using predictions in scheduling, namely Large\nLanguage Model (LLM) systems, which presents novel scheduling challenges and\nhighlights the potential for predictions to improve performance. In particular,\nwe consider LLMs performing inference. Inference requests (jobs) in LLM systems\nare inherently complex; they have variable inference times, dynamic memory\nfootprints that are constrained by key-value (KV) store memory limitations, and\nmultiple possible preemption approaches that affect performance differently. We\nprovide background on the important aspects of scheduling in LLM systems, and\nintroduce new models and open problems that arise from them. We argue that\nthere are significant opportunities for applying insights and analysis from\nqueueing theory to scheduling in LLM systems.",
      "authors": [
        "Michael Mitzenmacher",
        "Rana Shahout"
      ],
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07545v1",
        "http://arxiv.org/pdf/2503.07545v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07429v1",
      "title": "From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector\n  Graphics",
      "published": "2025-03-10T15:13:38Z",
      "updated": "2025-03-10T15:13:38Z",
      "summary": "Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences.",
      "authors": [
        "Jaewook Lee",
        "Jeongah Lee",
        "Wanyong Feng",
        "Andrew Lan"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07429v1",
        "http://arxiv.org/pdf/2503.07429v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07341v1",
      "title": "The Economics of p(doom): Scenarios of Existential Risk and Economic\n  Growth in the Age of Transformative AI",
      "published": "2025-03-10T13:53:39Z",
      "updated": "2025-03-10T13:53:39Z",
      "summary": "Recent advances in artificial intelligence (AI) have led to a diverse set of\npredictions about its long-term impact on humanity. A central focus is the\npotential emergence of transformative AI (TAI), eventually capable of\noutperforming humans in all economically valuable tasks and fully automating\nlabor. Discussed scenarios range from human extinction after a misaligned TAI\ntakes over (\"AI doom\") to unprecedented economic growth and abundance\n(\"post-scarcity\"). However, the probabilities and implications of these\nscenarios remain highly uncertain. Here, we organize the various scenarios and\nevaluate their associated existential risks and economic outcomes in terms of\naggregate welfare. Our analysis shows that even low-probability catastrophic\noutcomes justify large investments in AI safety and alignment research. We find\nthat the optimizing representative individual would rationally allocate\nsubstantial resources to mitigate extinction risk; in some cases, she would\nprefer not to develop TAI at all. This result highlights that current global\nefforts in AI safety and alignment research are vastly insufficient relative to\nthe scale and urgency of existential risks posed by TAI. Our findings therefore\nunderscore the need for stronger safeguards to balance the potential economic\nbenefits of TAI with the prevention of irreversible harm. Addressing these\nrisks is crucial for steering technological progress toward sustainable human\nprosperity.",
      "authors": [
        "Jakub Growiec",
        "Klaus Prettner"
      ],
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07341v1",
        "http://arxiv.org/pdf/2503.07341v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07317v1",
      "title": "Self-Corrective Task Planning by Inverse Prompting with Large Language\n  Models",
      "published": "2025-03-10T13:35:51Z",
      "updated": "2025-03-10T13:35:51Z",
      "summary": "In robot task planning, large language models (LLMs) have shown significant\npromise in generating complex and long-horizon action sequences. However, it is\nobserved that LLMs often produce responses that sound plausible but are not\naccurate. To address these problems, existing methods typically employ\npredefined error sets or external knowledge sources, requiring human efforts\nand computation resources. Recently, self-correction approaches have emerged,\nwhere LLM generates and refines plans, identifying errors by itself. Despite\ntheir effectiveness, they are more prone to failures in correction due to\ninsufficient reasoning. In this paper, we introduce InversePrompt, a novel\nself-corrective task planning approach that leverages inverse prompting to\nenhance interpretability. Our method incorporates reasoning steps to provide\nclear, interpretable feedback. It generates inverse actions corresponding to\nthe initially generated actions and verifies whether these inverse actions can\nrestore the system to its original state, explicitly validating the logical\ncoherence of the generated plans. The results on benchmark datasets show an\naverage 16.3% higher success rate over existing LLM-based task planning\nmethods. Our approach offers clearer justifications for feedback in real-world\nenvironments, resulting in more successful task completion than existing\nself-correction approaches across various scenarios.",
      "authors": [
        "Jiho Lee",
        "Hayun Lee",
        "Jonghyeon Kim",
        "Kyungjae Lee",
        "Eunwoo Kim"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07317v1",
        "http://arxiv.org/pdf/2503.07317v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07248v1",
      "title": "AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in\n  Gastrointestinal Cancer Management",
      "published": "2025-03-10T12:32:44Z",
      "updated": "2025-03-10T12:32:44Z",
      "summary": "The incidence of gastrointestinal cancers remains significantly high,\nparticularly in China, emphasizing the importance of accurate prognostic\nassessments and effective treatment strategies. Research shows a strong\ncorrelation between abdominal muscle and fat tissue composition and patient\noutcomes. However, existing manual methods for analyzing abdominal tissue\ncomposition are time-consuming and costly, limiting clinical research\nscalability. To address these challenges, we developed an AI-driven tool for\nautomated analysis of abdominal CT scans to effectively identify and segment\nmuscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view\nlocalization model and a high-precision 2D nnUNet-based segmentation model,\ndemonstrating a localization accuracy of 90% and a Dice Score Coefficient of\n0.967 for segmentation. Furthermore, it features an interactive interface that\nallows clinicians to refine the segmentation results, ensuring high-quality\noutcomes effectively. Our tool offers a standardized method for effectively\nextracting critical abdominal tissues, potentially enhancing the management and\ntreatment for gastrointestinal cancers. The code is available at\nhttps://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git}{https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git.",
      "authors": [
        "Xinyu Nan",
        "Meng He",
        "Zifan Chen",
        "Bin Dong",
        "Lei Tang",
        "Li Zhang"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07248v1",
        "http://arxiv.org/pdf/2503.07248v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07222v1",
      "title": "XMutant: XAI-based Fuzzing for Deep Learning Systems",
      "published": "2025-03-10T12:05:49Z",
      "updated": "2025-03-10T12:05:49Z",
      "summary": "Semantic-based test generators are widely used to produce failure-inducing\ninputs for Deep Learning (DL) systems. They typically generate challenging test\ninputs by applying random perturbations to input semantic concepts until a\nfailure is found or a timeout is reached. However, such randomness may hinder\nthem from efficiently achieving their goal. This paper proposes XMutant, a\ntechnique that leverages explainable artificial intelligence (XAI) techniques\nto generate challenging test inputs. XMutant uses the local explanation of the\ninput to inform the fuzz testing process and effectively guide it toward\nfailures of the DL system under test. We evaluated different configurations of\nXMutant in triggering failures for different DL systems both for model-level\n(sentiment analysis, digit recognition) and system-level testing (advanced\ndriving assistance). Our studies showed that XMutant enables more effective and\nefficient test generation by focusing on the most impactful parts of the input.\nXMutant generates up to 125% more failure-inducing inputs compared to an\nexisting baseline, up to 7X faster. We also assessed the validity of these\ninputs, maintaining a validation rate above 89%, according to automated and\nhuman validators.",
      "authors": [
        "Xingcheng Chen",
        "Matteo Biagiola",
        "Vincenzo Riccio",
        "Marcelo d'Amorim",
        "Andrea Stocco"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07222v1",
        "http://arxiv.org/pdf/2503.07222v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13489v2",
      "title": "AI-driven control of bioelectric signalling for real-time topological\n  reorganization of cells",
      "published": "2025-03-10T11:30:32Z",
      "updated": "2025-03-19T14:56:52Z",
      "summary": "Understanding and manipulating bioelectric signaling could present a new wave\nof progress in developmental biology, regenerative medicine, and synthetic\nbiology. Bioelectric signals, defined as voltage gradients across cell\nmembranes caused by ionic movements, play a role in regulating crucial\nprocesses including cellular differentiation, proliferation, apoptosis, and\ntissue morphogenesis. Recent studies demonstrate the ability to modulate these\nsignals to achieve controlled tissue regeneration and morphological outcomes in\norganisms such as planaria and frogs. However, significant knowledge gaps\nremain, particularly in predicting and controlling the spatial and temporal\ndynamics of membrane potentials (V_mem), understanding their regulatory roles\nin tissue and organ development, and exploring their therapeutic potential in\ndiseases. In this work we propose an experiment using Deep Reinforcement\nLearning (DRL) framework together with lab automation techniques for real-time\nmanipulation of bioelectric signals to guide tissue regeneration and\nmorphogenesis. The proposed framework should interact continuously with\nbiological systems, adapting strategies based on direct biological feedback.\nCombining DRL with real-time measurement techniques -- such as optogenetics,\nvoltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could\nprovide a comprehensive platform for precise bioelectric control, leading to\nimproved understanding of bioelectric mechanisms in morphogenesis, quantitative\nbioelectric models, identification of minimal experimental setups, and\nadvancements in bioelectric modulation techniques relevant to regenerative\nmedicine and cancer therapy. Ultimately, this research aims to utilize\nbioelectric signaling to develop new biomedical and bioengineering\napplications.",
      "authors": [
        "Gon\u00e7alo Hora de Carvalho"
      ],
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "physics.bio-ph",
        "q-bio.CB",
        "q-bio.QM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13489v2",
        "http://arxiv.org/pdf/2503.13489v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07172v1",
      "title": "Lawful and Accountable Personal Data Processing with GDPR-based Access\n  and Usage Control in Distributed Systems",
      "published": "2025-03-10T10:49:34Z",
      "updated": "2025-03-10T10:49:34Z",
      "summary": "Compliance with the GDPR privacy regulation places a significant burden on\norganisations regarding the handling of personal data. The perceived efforts\nand risks of complying with the GDPR further increase when data processing\nactivities span across organisational boundaries, as is the case in both\nsmall-scale data sharing settings and in large-scale international data spaces.\n  This paper addresses these concerns by proposing a case-generic method for\nautomated normative reasoning that establishes legal arguments for the\nlawfulness of data processing activities. The arguments are established on the\nbasis of case-specific legal qualifications made by privacy experts, bringing\nthe human in the loop. The obtained expert system promotes transparency and\naccountability, remains adaptable to extended or altered interpretations of the\nGDPR, and integrates into novel or existing distributed data processing\nsystems.\n  This result is achieved by defining a formal ontology and semantics for\nautomated normative reasoning based on an analysis of the purpose-limitation\nprinciple of the GDPR. The ontology and semantics are implemented in eFLINT, a\ndomain-specific language for specifying and reasoning with norms. The XACML\narchitecture standard, applicable to both access and usage control, is\nextended, demonstrating how GDPR-based normative reasoning can integrate into\n(existing, distributed) systems for data processing. The resulting system is\ndesigned and critically assessed in reference to requirements extracted from\nthe GPDR.",
      "authors": [
        "L. Thomas van Binsbergen",
        "Marten C. Steketee",
        "Milen G. Kebede",
        "Heleen L. Janssen",
        "Tom M. van Engers"
      ],
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07172v1",
        "http://arxiv.org/pdf/2503.07172v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07158v4",
      "title": "Generative AI in Transportation Planning: A Survey",
      "published": "2025-03-10T10:33:31Z",
      "updated": "2025-03-18T05:03:23Z",
      "summary": "The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.",
      "authors": [
        "Longchao Da",
        "Tiejin Chen",
        "Zhuoheng Li",
        "Shreyas Bachiraju",
        "Huaiyuan Yao",
        "Li Li",
        "Yushun Dong",
        "Xiyang Hu",
        "Zhengzhong Tu",
        "Dongjie Wang",
        "Yue Zhao",
        " Xuanyu",
        " Zhou",
        "Ram Pendyala",
        "Benjamin Stabler",
        "Yezhou Yang",
        "Xuesong Zhou",
        "Hua Wei"
      ],
      "categories": [
        "cs.AI",
        "68T99, 90B06",
        "I.2.6; I.2.8; I.6.3; J.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07158v4",
        "http://arxiv.org/pdf/2503.07158v4"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07086v1",
      "title": "Data Insights as Data: Quick Overview and Exploration of Automated Data\n  Insights",
      "published": "2025-03-10T09:09:14Z",
      "updated": "2025-03-10T09:09:14Z",
      "summary": "Automated data insight mining and visualization have been widely used in\nvarious business intelligence applications (e.g., market analysis and product\npromotion). However, automated insight mining techniques often output the same\nmining results to different analysts without considering their personal\npreferences, while interactive insight discovery requires significant manual\neffort. This paper fills the gap by integrating automated insight mining with\ninteractive data visualization and striking a proper balance between them to\nfacilitate insight discovery and exploration. Specifically, we regard data\ninsights as a special type of data and further present InsightMap, a novel\nvisualization approach that uses the map metaphor to provide a quick overview\nand in-depth exploration of different data insights, where a metric is proposed\nto measure the similarity between different insights. The effectiveness and\nusability of InsightMap are demonstrated through extensive case studies and\nin-depth user interviews.",
      "authors": [
        "Shangxuan Wu",
        "Wendi Luan",
        "Yong Wang",
        "Dan Zeng",
        "Qiaomu Shen",
        "Bo Tang"
      ],
      "categories": [
        "cs.HC"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3706599.3719702",
        "http://arxiv.org/abs/2503.07086v1",
        "http://arxiv.org/pdf/2503.07086v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07044v1",
      "title": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data\n  Science",
      "published": "2025-03-10T08:32:33Z",
      "updated": "2025-03-10T08:32:33Z",
      "summary": "Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.",
      "authors": [
        "Ziming You",
        "Yumiao Zhang",
        "Dexuan Xu",
        "Yiwei Lou",
        "Yandong Yan",
        "Wei Wang",
        "Huaming Zhang",
        "Yu Huang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07044v1",
        "http://arxiv.org/pdf/2503.07044v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07032v1",
      "title": "Multimodal Human-AI Synergy for Medical Imaging Quality Control: A\n  Hybrid Intelligence Framework with Adaptive Dataset Curation and Closed-Loop\n  Evaluation",
      "published": "2025-03-10T08:16:18Z",
      "updated": "2025-03-10T08:16:18Z",
      "summary": "Medical imaging quality control (QC) is essential for accurate diagnosis, yet\ntraditional QC methods remain labor-intensive and subjective. To address this\nchallenge, in this study, we establish a standardized dataset and evaluation\nframework for medical imaging QC, systematically assessing large language\nmodels (LLMs) in image quality assessment and report standardization.\nSpecifically, we first constructed and anonymized a dataset of 161 chest X-ray\n(CXR) radiographs and 219 CT reports for evaluation. Then, multiple LLMs,\nincluding Gemini 2.0-Flash, GPT-4o, and DeepSeek-R1, were evaluated based on\nrecall, precision, and F1 score to detect technical errors and inconsistencies.\nExperimental results show that Gemini 2.0-Flash achieved a Macro F1 score of 90\nin CXR tasks, demonstrating strong generalization but limited fine-grained\nperformance. DeepSeek-R1 excelled in CT report auditing with a 62.23\\% recall\nrate, outperforming other models. However, its distilled variants performed\npoorly, while InternLM2.5-7B-chat exhibited the highest additional discovery\nrate, indicating broader but less precise error detection. These findings\nhighlight the potential of LLMs in medical imaging QC, with DeepSeek-R1 and\nGemini 2.0-Flash demonstrating superior performance.",
      "authors": [
        "Zhi Qin",
        "Qianhui Gui",
        "Mouxiao Bian",
        "Rui Wang",
        "Hong Ge",
        "Dandan Yao",
        "Ziying Sun",
        "Yuan Zhao",
        "Yu Zhang",
        "Hui Shi",
        "Dongdong Wang",
        "Chenxin Song",
        "Shenghong Ju",
        "Lihao Liu",
        "Junjun He",
        "Jie Xu",
        "Yuan-Cheng Wang"
      ],
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07032v1",
        "http://arxiv.org/pdf/2503.07032v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07025v1",
      "title": "Weak Supervision for Improved Precision in Search Systems",
      "published": "2025-03-10T08:06:30Z",
      "updated": "2025-03-10T08:06:30Z",
      "summary": "Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.",
      "authors": [
        "Sriram Vasudevan"
      ],
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07025v1",
        "http://arxiv.org/pdf/2503.07025v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.07676v1",
      "title": "The Janus Face of Innovation: Global Disparities and Divergent Options",
      "published": "2025-03-10T06:33:07Z",
      "updated": "2025-03-10T06:33:07Z",
      "summary": "This article examines how unequal access to AI innovation creates systemic\nchallenges for developing countries. Differential access to AI innovation\nresults from the acute competition between domestic and global actors. While\ndeveloping nations contribute significantly to AI development through data\nannotation labor, they face limited access to advanced AI technologies and are\nincreasingly caught between divergent regulatory approaches from democratic and\nauthoritarian tendencies. This brief paper analyzes how more affordable AI\nengagement and Western countries' development cooperation present developing\nnations with a complex choice between accessibility and governance standards. I\nargue this challenge entails new institutional mechanisms for technology\ntransfer and regulatory cooperation, while carefully balancing universal\nstandards with local needs. In turn, good practices could help developing\ncountries close the deepening gap of global technological divides, while\nensuring responsible AI development in developing countries.",
      "authors": [
        "Nihat Mugurtay"
      ],
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.07676v1",
        "http://arxiv.org/pdf/2503.07676v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06791v1",
      "title": "AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in\n  the Misty Social Robot",
      "published": "2025-03-09T22:07:46Z",
      "updated": "2025-03-09T22:07:46Z",
      "summary": "The social robot's open API allows users to customize open-domain\ninteractions. However, it remains inaccessible to those without programming\nexperience. In this work, we introduce AutoMisty, the first multi-agent\ncollaboration framework powered by large language models (LLMs), to enable the\nseamless generation of executable Misty robot code from natural language\ninstructions. AutoMisty incorporates four specialized agent modules to manage\ntask decomposition, assignment, problem-solving, and result synthesis. Each\nagent incorporates a two-layer optimization mechanism, with self-reflection for\niterative refinement and human-in-the-loop for better alignment with user\npreferences. AutoMisty ensures a transparent reasoning process, allowing users\nto iteratively refine tasks through natural language feedback for precise\nexecution. To evaluate AutoMisty's effectiveness, we designed a benchmark task\nset spanning four levels of complexity and conducted experiments in a real\nMisty robot environment. Extensive evaluations demonstrate that AutoMisty not\nonly consistently generates high-quality code but also enables precise code\ncontrol, significantly outperforming direct reasoning with ChatGPT-4o and\nChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly\nreleased through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html",
      "authors": [
        "Xiao Wang",
        "Lu Dong",
        "Sahana Rangasrinivasan",
        "Ifeoma Nwogu",
        "Srirangaraj Setlur",
        "Venugopal Govindaraju"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06791v1",
        "http://arxiv.org/pdf/2503.06791v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06778v1",
      "title": "Large Language Models Are Effective Human Annotation Assistants, But Not\n  Good Independent Annotators",
      "published": "2025-03-09T21:14:14Z",
      "updated": "2025-03-09T21:14:14Z",
      "summary": "Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.",
      "authors": [
        "Feng Gu",
        "Zongxia Li",
        "Carlos Rafael Colon",
        "Benjamin Evans",
        "Ishani Mondal",
        "Jordan Lee Boyd-Graber"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06778v1",
        "http://arxiv.org/pdf/2503.06778v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06771v1",
      "title": "Task-Oriented Connectivity for Networked Robotics with Generative AI and\n  Semantic Communications",
      "published": "2025-03-09T20:56:04Z",
      "updated": "2025-03-09T20:56:04Z",
      "summary": "The convergence of robotics, advanced communication networks, and artificial\nintelligence (AI) holds the promise of transforming industries through fully\nautomated and intelligent operations. In this work, we introduce a novel\nco-working framework for robots that unifies goal-oriented semantic\ncommunication (SemCom) with a Generative AI (GenAI)-agent under a\nsemantic-aware network. SemCom prioritizes the exchange of meaningful\ninformation among robots and the network, thereby reducing overhead and\nlatency. Meanwhile, the GenAI-agent leverages generative AI models to interpret\nhigh-level task instructions, allocate resources, and adapt to dynamic changes\nin both network and robotic environments. This agent-driven paradigm ushers in\na new level of autonomy and intelligence, enabling complex tasks of networked\nrobots to be conducted with minimal human intervention. We validate our\napproach through a multi-robot anomaly detection use-case simulation, where\nrobots detect, compress, and transmit relevant information for classification.\nSimulation results confirm that SemCom significantly reduces data traffic while\npreserving critical semantic details, and the GenAI-agent ensures task\ncoordination and network adaptation. This synergy provides a robust, efficient,\nand scalable solution for modern industrial environments.",
      "authors": [
        "Peizheng Li",
        "Adnan Aijaz"
      ],
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.NI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06771v1",
        "http://arxiv.org/pdf/2503.06771v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06664v1",
      "title": "Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets",
      "published": "2025-03-09T15:29:46Z",
      "updated": "2025-03-09T15:29:46Z",
      "summary": "High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases.",
      "authors": [
        "Tommaso Bendinelli",
        "Artur Dox",
        "Christian Holz"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06664v1",
        "http://arxiv.org/pdf/2503.06664v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06648v1",
      "title": "Enhancing NLP Robustness and Generalization through LLM-Generated\n  Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial\n  Training",
      "published": "2025-03-09T14:52:53Z",
      "updated": "2025-03-09T14:52:53Z",
      "summary": "Standard NLP benchmarks often fail to capture vulnerabilities stemming from\ndataset artifacts and spurious correlations. Contrast sets address this gap by\nchallenging models near decision boundaries but are traditionally\nlabor-intensive to create and limited in diversity. This study leverages large\nlanguage models to automate the generation of diverse contrast sets. Using the\nSNLI dataset, we created a 3,000-example contrast set to evaluate and improve\nmodel robustness. Fine-tuning on these contrast sets enhanced performance on\nsystematically perturbed examples, maintained standard test accuracy, and\nmodestly improved generalization to novel perturbations. This automated\napproach offers a scalable solution for evaluating and improving NLP models,\naddressing systematic generalization challenges, and advancing robustness in\nreal-world applications.",
      "authors": [
        "Hender Lin"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06648v1",
        "http://arxiv.org/pdf/2503.06648v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06553v1",
      "title": "ProJudge: A Multi-Modal Multi-Discipline Benchmark and\n  Instruction-Tuning Dataset for MLLM-based Process Judges",
      "published": "2025-03-09T10:55:51Z",
      "updated": "2025-03-09T10:55:51Z",
      "summary": "As multi-modal large language models (MLLMs) frequently exhibit errors when\nsolving scientific problems, evaluating the validity of their reasoning\nprocesses is critical for ensuring reliability and uncovering fine-grained\nmodel weaknesses. Since human evaluation is laborious and costly, prompting\nMLLMs as automated process judges has become a common practice. However, the\nreliability of these model-based judges remains uncertain. To address this, we\nintroduce ProJudgeBench, the first comprehensive benchmark specifically\ndesigned for evaluating abilities of MLLM-based process judges. ProJudgeBench\ncomprises 2,400 test cases and 50,118 step-level labels, spanning four\nscientific disciplines with diverse difficulty levels and multi-modal content.\nIn ProJudgeBench, each step is meticulously annotated by human experts for\ncorrectness, error type, and explanation, enabling a systematic evaluation of\njudges' capabilities to detect, classify and diagnose errors. Evaluation on\nProJudgeBench reveals a significant performance gap between open-source and\nproprietary models. To bridge this gap, we further propose ProJudge-173k, a\nlarge-scale instruction-tuning dataset, and a Dynamic Dual-Phase fine-tuning\nstrategy that encourages models to explicitly reason through problem-solving\nbefore assessing solutions. Both contributions significantly enhance the\nprocess evaluation capabilities of open-source models. All the resources will\nbe released to foster future research of reliable multi-modal process\nevaluation.",
      "authors": [
        "Jiaxin Ai",
        "Pengfei Zhou",
        "Zhaopan Xu",
        "Ming Li",
        "Fanrui Zhang",
        "Zizhen Li",
        "Jianwen Sun",
        "Yukang Feng",
        "Baojin Huang",
        "Zhongyuan Wang",
        "Kaipeng Zhang"
      ],
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06553v1",
        "http://arxiv.org/pdf/2503.06553v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06525v1",
      "title": "From Motion Signals to Insights: A Unified Framework for Student\n  Behavior Analysis and Feedback in Physical Education Classes",
      "published": "2025-03-09T09:04:36Z",
      "updated": "2025-03-09T09:04:36Z",
      "summary": "Analyzing student behavior in educational scenarios is crucial for enhancing\nteaching quality and student engagement. Existing AI-based models often rely on\nclassroom video footage to identify and analyze student behavior. While these\nvideo-based methods can partially capture and analyze student actions, they\nstruggle to accurately track each student's actions in physical education\nclasses, which take place in outdoor, open spaces with diverse activities, and\nare challenging to generalize to the specialized technical movements involved\nin these settings. Furthermore, current methods typically lack the ability to\nintegrate specialized pedagogical knowledge, limiting their ability to provide\nin-depth insights into student behavior and offer feedback for optimizing\ninstructional design. To address these limitations, we propose a unified\nend-to-end framework that leverages human activity recognition technologies\nbased on motion signals, combined with advanced large language models, to\nconduct more detailed analyses and feedback of student behavior in physical\neducation classes. Our framework begins with the teacher's instructional\ndesigns and the motion signals from students during physical education\nsessions, ultimately generating automated reports with teaching insights and\nsuggestions for improving both learning and class instructions. This solution\nprovides a motion signal-based approach for analyzing student behavior and\noptimizing instructional design tailored to physical education classes.\nExperimental results demonstrate that our framework can accurately identify\nstudent behaviors and produce meaningful pedagogical insights.",
      "authors": [
        "Xian Gao",
        "Jiacheng Ruan",
        "Jingsheng Gao",
        "Mingye Xie",
        "Zongyun Zhang",
        "Ting Liu",
        "Yuzhuo Fu"
      ],
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06525v1",
        "http://arxiv.org/pdf/2503.06525v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06497v1",
      "title": "Evaluation of Safety Cognition Capability in Vision-Language Models for\n  Autonomous Driving",
      "published": "2025-03-09T07:53:19Z",
      "updated": "2025-03-09T07:53:19Z",
      "summary": "Assessing the safety of vision-language models (VLMs) in autonomous driving\nis particularly important; however, existing work mainly focuses on traditional\nbenchmark evaluations. As interactive components within autonomous driving\nsystems, VLMs must maintain strong safety cognition during interactions. From\nthis perspective, we propose a novel evaluation method: Safety Cognitive\nDriving Benchmark (SCD-Bench) . To address the large-scale annotation challenge\nfor SCD-Bench, we develop the Autonomous Driving Image-Text Annotation System\n(ADA) . Additionally, to ensure data quality in SCD-Bench, our dataset\nundergoes manual refinement by experts with professional knowledge in\nautonomous driving. We further develop an automated evaluation method based on\nlarge language models (LLMs). To verify its effectiveness, we compare its\nevaluation results with those of expert human evaluations, achieving a\nconsistency rate of 99.74%. Preliminary experimental results indicate that\nexisting open-source models still lack sufficient safety cognition, showing a\nsignificant gap compared to GPT-4o. Notably, lightweight models (1B-4B)\ndemonstrate minimal safety cognition. However, since lightweight models are\ncrucial for autonomous driving systems, this presents a significant challenge\nfor integrating VLMs into the field.",
      "authors": [
        "Enming Zhang",
        "Peizhe Gong",
        "Xingyuan Dai",
        "Yisheng Lv",
        "Qinghai Miao"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06497v1",
        "http://arxiv.org/pdf/2503.06497v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06479v1",
      "title": "ExKG-LLM: Leveraging Large Language Models for Automated Expansion of\n  Cognitive Neuroscience Knowledge Graphs",
      "published": "2025-03-09T06:32:56Z",
      "updated": "2025-03-09T06:32:56Z",
      "summary": "The paper introduces ExKG-LLM, a framework designed to automate the expansion\nof cognitive neuroscience knowledge graphs (CNKG) using large language models\n(LLMs). It addresses limitations in existing tools by enhancing accuracy,\ncompleteness, and usefulness in CNKG. The framework leverages a large dataset\nof scientific papers and clinical reports, applying state-of-the-art LLMs to\nextract, optimize, and integrate new entities and relationships. Evaluation\nmetrics include precision, recall, and graph density. Results show significant\nimprovements: precision (0.80, +6.67%), recall (0.81, +15.71%), F1 score\n(0.805, +11.81%), and increased edge nodes (21.13% and 31.92%). Graph density\nslightly decreased, reflecting a broader but more fragmented structure.\nEngagement rates rose by 20%, while CNKG diameter increased to 15, indicating a\nmore distributed structure. Time complexity improved to O(n log n), but space\ncomplexity rose to O(n2), indicating higher memory usage. ExKG-LLM demonstrates\npotential for enhancing knowledge generation, semantic search, and clinical\ndecision-making in cognitive neuroscience, adaptable to broader scientific\nfields.",
      "authors": [
        "Ali Sarabadani",
        "Kheirolah Rahsepar Fard",
        "Hamid Dalvand"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06479v1",
        "http://arxiv.org/pdf/2503.06479v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.06420v1",
      "title": "Explaining Control Policies through Predicate Decision Diagrams",
      "published": "2025-03-09T03:31:48Z",
      "updated": "2025-03-09T03:31:48Z",
      "summary": "Safety-critical controllers of complex systems are hard to construct\nmanually. Automated approaches such as controller synthesis or learning provide\na tempting alternative but usually lack explainability. To this end, learning\ndecision trees (DTs) have been prevalently used towards an interpretable model\nof the generated controllers. However, DTs do not exploit shared\ndecision-making, a key concept exploited in binary decision diagrams (BDDs) to\nreduce their size and thus improve explainability. In this work, we introduce\npredicate decision diagrams (PDDs) that extend BDDs with predicates and thus\nunite the advantages of DTs and BDDs for controller representation. We\nestablish a synthesis pipeline for efficient construction of PDDs from DTs\nrepresenting controllers, exploiting reduction techniques for BDDs also for\nPDDs.",
      "authors": [
        "Debraj Chakraborty",
        "Clemens Dubslaff",
        "Sudeep Kanav",
        "Jan Kretinsky",
        "Christoph Weinhuber"
      ],
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.06420v1",
        "http://arxiv.org/pdf/2503.06420v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}