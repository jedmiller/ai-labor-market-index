{
  "query": "all:machine learning AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-03-21T23:00:33.723295",
  "target_period": "2024-04",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2406.08739v1",
      "title": "At the edge of a generative cultural precipice",
      "published": "2024-04-30T23:26:24Z",
      "updated": "2024-04-30T23:26:24Z",
      "summary": "Since NFTs and large generative models (such as DALLE2 and Stable Diffusion)\nhave been publicly available, artists have seen their jobs threatened and\nstolen. While artists depend on sharing their art on online platforms such as\nDeviantart, Pixiv, and Artstation, many slowed down sharing their work or\ndownright removed their past work therein, especially if these platforms fail\nto provide certain guarantees regarding the copyright of their uploaded work.\nText-to-image (T2I) generative models are trained using human-produced content\nto better guide the style and themes they can produce. Still, if the trend\ncontinues where data found online is generated by a machine instead of a human,\nthis will have vast repercussions in culture. Inspired by recent work in\ngenerative models, we wish to tell a cautionary tale and ask what will happen\nto the visual arts if generative models continue on the path to be (eventually)\ntrained solely on generated content.",
      "authors": [
        "Diego Porres",
        "Alex Gomez-Villa"
      ],
      "categories": [
        "cs.CY",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2406.08739v1",
        "http://arxiv.org/pdf/2406.08739v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.07896v2",
      "title": "Almanac Copilot: Towards Autonomous Electronic Health Record Navigation",
      "published": "2024-04-30T22:55:27Z",
      "updated": "2024-05-14T20:25:23Z",
      "summary": "Clinicians spend large amounts of time on clinical documentation, and\ninefficiencies impact quality of care and increase clinician burnout. Despite\nthe promise of electronic medical records (EMR), the transition from\npaper-based records has been negatively associated with clinician wellness, in\npart due to poor user experience, increased burden of documentation, and alert\nfatigue. In this study, we present Almanac Copilot, an autonomous agent capable\nof assisting clinicians with EMR-specific tasks such as information retrieval\nand order placement. On EHR-QA, a synthetic evaluation dataset of 300 common\nEHR queries based on real patient data, Almanac Copilot obtains a successful\ntask completion rate of 74% (n = 221 tasks) with a mean score of 2.45 over 3\n(95% CI:2.34-2.56). By automating routine tasks and streamlining the\ndocumentation process, our findings highlight the significant potential of\nautonomous agents to mitigate the cognitive load imposed on clinicians by\ncurrent EMR systems.",
      "authors": [
        "Cyril Zakka",
        "Joseph Cho",
        "Gracia Fahed",
        "Rohan Shad",
        "Michael Moor",
        "Robyn Fong",
        "Dhamanpreet Kaur",
        "Vishnu Ravi",
        "Oliver Aalami",
        "Roxana Daneshjou",
        "Akshay Chaudhari",
        "William Hiesinger"
      ],
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.07896v2",
        "http://arxiv.org/pdf/2405.07896v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.00232v1",
      "title": "Constraining the giant radio galaxy population with machine learning and\n  Bayesian inference",
      "published": "2024-04-30T22:47:07Z",
      "updated": "2024-04-30T22:47:07Z",
      "summary": "Large-scale sky surveys at low frequencies, like the LOFAR Two-metre Sky\nSurvey (LoTSS), allow for the detection and characterisation of unprecedented\nnumbers of giant radio galaxies (GRGs, or 'giants'). In this work, by\nautomating the creation of radio--optical catalogues, we aim to significantly\nexpand the census of known giants. We then combine this sample with a forward\nmodel to constrain GRG properties of cosmological interest. In particular, we\nautomate radio source component association through machine learning and\noptical host identification for resolved radio sources. We create a\nradio--optical catalogue for the full LoTSS Data Release 2 (DR2) and select all\npossible giants. We combine our candidates with an existing catalogue of LoTSS\nDR2 crowd-sourced GRG candidates and visually confirm or reject them. To infer\nintrinsic GRG properties from GRG observations, we develop further a\npopulation-based forward model that takes into account selection effects and\nconstrain its parameters using Bayesian inference. We confirm 5,647 previously\nunknown giants from the crowd-sourced catalogue and 2,597 previously unknown\ngiants from the ML-driven catalogue. Our confirmations and discoveries bring\nthe total number of known giants to at least 11,585. We predict a comoving GRG\nnumber density $n_\\mathrm{GRG} = 13 \\pm 10\\ (100\\ \\mathrm{Mpc})^{-3}$, close to\na recent estimate of the number density of luminous non-giant radio galaxies.\nWe derive a current-day GRG lobe volume-filling fraction $V_\\mathrm{GRG-CW}(z =\n0) = 1.4 \\pm 1.1 \\cdot 10^{-5}$ in clusters and filaments of the Cosmic Web.\nOur analysis suggests that giants are more common than previously thought.\nMoreover, tentative results imply that it is possible that magnetic fields once\ncontained in giants pervade a significant ($\\gtrsim 10\\%$) fraction of today's\nCosmic Web.",
      "authors": [
        "Rafa\u00ebl I. J. Mostert",
        "Martijn S. S. L. Oei",
        "B. Barkus",
        "Lara Alegre",
        "Martin J. Hardcastle",
        "Kenneth J. Duncan",
        "Huub J. A. R\u00f6ttgering",
        "Reinout J. van Weeren",
        "Maya Horton"
      ],
      "categories": [
        "astro-ph.GA",
        "astro-ph.CO",
        "astro-ph.HE"
      ],
      "links": [
        "http://dx.doi.org/10.1051/0004-6361/202348897",
        "http://arxiv.org/abs/2405.00232v1",
        "http://arxiv.org/pdf/2405.00232v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.00166v1",
      "title": "Discovering intrinsic multi-compartment pharmacometric models using\n  Physics Informed Neural Networks",
      "published": "2024-04-30T19:31:31Z",
      "updated": "2024-04-30T19:31:31Z",
      "summary": "Pharmacometric models are pivotal across drug discovery and development,\nplaying a decisive role in determining the progression of candidate molecules.\nHowever, the derivation of mathematical equations governing the system is a\nlabor-intensive trial-and-error process, often constrained by tight timelines.\nIn this study, we introduce PKINNs, a novel purely data-driven\npharmacokinetic-informed neural network model. PKINNs efficiently discovers and\nmodels intrinsic multi-compartment-based pharmacometric structures, reliably\nforecasting their derivatives. The resulting models are both interpretable and\nexplainable through Symbolic Regression methods. Our computational framework\ndemonstrates the potential for closed-form model discovery in pharmacometric\napplications, addressing the labor-intensive nature of traditional model\nderivation. With the increasing availability of large datasets, this framework\nholds the potential to significantly enhance model-informed drug discovery.",
      "authors": [
        "Imran Nasim",
        "Adam Nasim"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "links": [
        "http://arxiv.org/abs/2405.00166v1",
        "http://arxiv.org/pdf/2405.00166v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2407.01555v1",
      "title": "Unveiling Patterns in European Airbnb Prices: A Comprehensive Analytical\n  Study Using Machine Learning Techniques",
      "published": "2024-04-30T17:11:30Z",
      "updated": "2024-04-30T17:11:30Z",
      "summary": "In the burgeoning market of short-term rentals, understanding pricing\ndynamics is crucial for a range of stake-holders. This study delves into the\nfactors influencing Airbnb pricing in major European cities, employing a\ncomprehensive dataset sourced from Kaggle. We utilize advanced regression\ntechniques, including linear, polynomial, and random forest models, to analyze\na diverse array of determinants, such as location characteristics, property\ntypes, and host-related factors. Our findings reveal nuanced insights into the\nvariables most significantly impacting pricing, highlighting the varying roles\nof geographical, structural, and host-specific attributes. This research not\nonly sheds light on the complex pricing landscape of Airbnb accommodations in\nEurope but also offers valuable implications for hosts seeking to optimize\npricing strategies and for travelers aiming to understand pricing trends.\nFurthermore, the study contributes to the broader discourse on pricing\nmechanisms in the shared economy, suggesting avenues for future research in\nthis rapidly evolving sector.",
      "authors": [
        "Trinath Sai Subhash Reddy Pittala",
        "Uma Maheswara R Meleti",
        "Hemanth Vasireddy"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2407.01555v1",
        "http://arxiv.org/pdf/2407.01555v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19713v2",
      "title": "Automated Generation of High-Quality Medical Simulation Scenarios\n  Through Integration of Semi-Structured Data and Large Language Models",
      "published": "2024-04-30T17:06:11Z",
      "updated": "2024-05-06T17:58:48Z",
      "summary": "This study introduces a transformative framework for medical education by\nintegrating semi-structured data with Large Language Models (LLMs), primarily\nOpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios.\nTraditionally, developing these scenarios was a time-intensive process with\nlimited flexibility to meet diverse educational needs. The proposed approach\nutilizes AI to efficiently generate detailed, clinically relevant scenarios\nthat are tailored to specific educational objectives. This innovation has\nsignificantly reduced the time and resources required for scenario development,\nallowing for a broader variety of simulations. Preliminary feedback from\neducators and learners has shown enhanced engagement and improved knowledge\nacquisition, confirming the effectiveness of this AI-enhanced methodology in\nsimulation-based learning. The integration of structured data with LLMs not\nonly streamlines the creation process but also offers a scalable, dynamic\nsolution that could revolutionize medical training, highlighting the critical\nrole of AI in advancing educational outcomes and patient care standards.",
      "authors": [
        "Scott Sumpter"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19713v2",
        "http://arxiv.org/pdf/2404.19713v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19656v1",
      "title": "Towards Scenario- and Capability-Driven Dataset Development and\n  Evaluation: An Approach in the Context of Mapless Automated Driving",
      "published": "2024-04-30T15:52:49Z",
      "updated": "2024-04-30T15:52:49Z",
      "summary": "The foundational role of datasets in defining the capabilities of deep\nlearning models has led to their rapid proliferation. At the same time,\npublished research focusing on the process of dataset development for\nenvironment perception in automated driving has been scarce, thereby reducing\nthe applicability of openly available datasets and impeding the development of\neffective environment perception systems. Sensor-based, mapless automated\ndriving is one of the contexts where this limitation is evident. While\nleveraging real-time sensor data, instead of pre-defined HD maps promises\nenhanced adaptability and safety by effectively navigating unexpected\nenvironmental changes, it also increases the demands on the scope and\ncomplexity of the information provided by the perception system.\n  To address these challenges, we propose a scenario- and capability-based\napproach to dataset development. Grounded in the principles of ISO 21448\n(safety of the intended functionality, SOTIF), extended by ISO/TR 4804, our\napproach facilitates the structured derivation of dataset requirements. This\nnot only aids in the development of meaningful new datasets but also enables\nthe effective comparison of existing ones. Applying this methodology to a broad\nrange of existing lane detection datasets, we identify significant limitations\nin current datasets, particularly in terms of real-world applicability, a lack\nof labeling of critical features, and an absence of comprehensive information\nfor complex driving maneuvers.",
      "authors": [
        "Felix Gr\u00fcn",
        "Marcus Nolte",
        "Markus Maurer"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19656v1",
        "http://arxiv.org/pdf/2404.19656v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19403v1",
      "title": "Transformer-Enhanced Motion Planner: Attention-Guided Sampling for\n  State-Specific Decision Making",
      "published": "2024-04-30T09:48:11Z",
      "updated": "2024-04-30T09:48:11Z",
      "summary": "Sampling-based motion planning (SBMP) algorithms are renowned for their\nrobust global search capabilities. However, the inherent randomness in their\nsampling mechanisms often result in inconsistent path quality and limited\nsearch efficiency. In response to these challenges, this work proposes a novel\ndeep learning-based motion planning framework, named Transformer-Enhanced\nMotion Planner (TEMP), which synergizes an Environmental Information Semantic\nEncoder (EISE) with a Motion Planning Transformer (MPT). EISE converts\nenvironmental data into semantic environmental information (SEI), providing MPT\nwith an enriched environmental comprehension. MPT leverages an attention\nmechanism to dynamically recalibrate its focus on SEI, task objectives, and\nhistorical planning data, refining the sampling node generation. To demonstrate\nthe capabilities of TEMP, we train our model using a dataset comprised of\nplanning results produced by the RRT*. EISE and MPT are collaboratively\ntrained, enabling EISE to autonomously learn and extract patterns from\nenvironmental data, thereby forming semantic representations that MPT could\nmore effectively interpret and utilize for motion planning. Subsequently, we\nconducted a systematic evaluation of TEMP's efficacy across diverse task\ndimensions, which demonstrates that TEMP achieves exceptional performance\nmetrics and a heightened degree of generalizability compared to\nstate-of-the-art SBMPs.",
      "authors": [
        "Lei Zhuang",
        "Jingdong Zhao",
        "Yuntao Li",
        "Zichun Xu",
        "Liangliang Zhao",
        "Hong Liu"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3450305",
        "http://arxiv.org/abs/2404.19403v1",
        "http://arxiv.org/pdf/2404.19403v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19230v1",
      "title": "Deep Lead Optimization: Leveraging Generative AI for Structural\n  Modification",
      "published": "2024-04-30T03:17:42Z",
      "updated": "2024-04-30T03:17:42Z",
      "summary": "The idea of using deep-learning-based molecular generation to accelerate\ndiscovery of drug candidates has attracted extraordinary attention, and many\ndeep generative models have been developed for automated drug design, termed\nmolecular generation. In general, molecular generation encompasses two main\nstrategies: de novo design, which generates novel molecular structures from\nscratch, and lead optimization, which refines existing molecules into drug\ncandidates. Among them, lead optimization plays an important role in real-world\ndrug design. For example, it can enable the development of me-better drugs that\nare chemically distinct yet more effective than the original drugs. It can also\nfacilitate fragment-based drug design, transforming virtual-screened small\nligands with low affinity into first-in-class medicines. Despite its\nimportance, automated lead optimization remains underexplored compared to the\nwell-established de novo generative models, due to its reliance on complex\nbiological and chemical knowledge. To bridge this gap, we conduct a systematic\nreview of traditional computational methods for lead optimization, organizing\nthese strategies into four principal sub-tasks with defined inputs and outputs.\nThis review delves into the basic concepts, goals, conventional CADD\ntechniques, and recent advancements in AIDD. Additionally, we introduce a\nunified perspective based on constrained subgraph generation to harmonize the\nmethodologies of de novo design and lead optimization. Through this lens, de\nnovo design can incorporate strategies from lead optimization to address the\nchallenge of generating hard-to-synthesize molecules; inversely, lead\noptimization can benefit from the innovations in de novo design by approaching\nit as a task of generating molecules conditioned on certain substructures.",
      "authors": [
        "Odin Zhang",
        "Haitao Lin",
        "Hui Zhang",
        "Huifeng Zhao",
        "Yufei Huang",
        "Yuansheng Huang",
        "Dejun Jiang",
        "Chang-yu Hsieh",
        "Peichen Pan",
        "Tingjun Hou"
      ],
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19230v1",
        "http://arxiv.org/pdf/2404.19230v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19226v1",
      "title": "A Survey of Deep Learning Based Software Refactoring",
      "published": "2024-04-30T03:07:11Z",
      "updated": "2024-04-30T03:07:11Z",
      "summary": "Refactoring is one of the most important activities in software engineering\nwhich is used to improve the quality of a software system. With the advancement\nof deep learning techniques, researchers are attempting to apply deep learning\ntechniques to software refactoring. Consequently, dozens of deep learning-based\nrefactoring approaches have been proposed. However, there is a lack of\ncomprehensive reviews on such works as well as a taxonomy for deep\nlearning-based refactoring. To this end, in this paper, we present a survey on\ndeep learning-based software refactoring. We classify related works into five\ncategories according to the major tasks they cover. Among these categories, we\nfurther present key aspects (i.e., code smell types, refactoring types,\ntraining strategies, and evaluation) to give insight into the details of the\ntechnologies that have supported refactoring through deep learning. The\nclassification indicates that there is an imbalance in the adoption of deep\nlearning techniques for the process of refactoring. Most of the deep learning\ntechniques have been used for the detection of code smells and the\nrecommendation of refactoring solutions as found in 56.25\\% and 33.33\\% of the\nliterature respectively. In contrast, only 6.25\\% and 4.17\\% were towards the\nend-to-end code transformation as refactoring and the mining of refactorings,\nrespectively. Notably, we found no literature representation for the quality\nassurance for refactoring. We also observe that most of the deep learning\ntechniques have been used to support refactoring processes occurring at the\nmethod level whereas classes and variables attracted minimal attention.\nFinally, we discuss the challenges and limitations associated with the\nemployment of deep learning-based refactorings and present some potential\nresearch opportunities for future work.",
      "authors": [
        "Bridget Nyirongo",
        "Yanjie Jiang",
        "He Jiang",
        "Hui Liu"
      ],
      "categories": [
        "cs.SE",
        "D.2.3"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19226v1",
        "http://arxiv.org/pdf/2404.19226v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19083v1",
      "title": "Longitudinal Mammogram Risk Prediction",
      "published": "2024-04-29T19:52:09Z",
      "updated": "2024-04-29T19:52:09Z",
      "summary": "Breast cancer is one of the leading causes of mortality among women\nworldwide. Early detection and risk assessment play a crucial role in improving\nsurvival rates. Therefore, annual or biennial mammograms are often recommended\nfor screening in high-risk groups. Mammograms are typically interpreted by\nexpert radiologists based on the Breast Imaging Reporting and Data System\n(BI-RADS), which provides a uniform way to describe findings and categorizes\nthem to indicate the level of concern for breast cancer. Recently, machine\nlearning (ML) and computational approaches have been developed to automate and\nimprove the interpretation of mammograms. However, both BI-RADS and the\nML-based methods focus on the analysis of data from the present and sometimes\nthe most recent prior visit. While it is clear that temporal changes in image\nfeatures of the longitudinal scans should carry value for quantifying breast\ncancer risk, no prior work has conducted a systematic study of this. In this\npaper, we extend a state-of-the-art ML model to ingest an arbitrary number of\nlongitudinal mammograms and predict future breast cancer risk. On a large-scale\ndataset, we demonstrate that our model, LoMaR, achieves state-of-the-art\nperformance when presented with only the present mammogram. Furthermore, we use\nLoMaR to characterize the predictive value of prior visits. Our results show\nthat longer histories (e.g., up to four prior annual mammograms) can\nsignificantly boost the accuracy of predicting future breast cancer risk,\nparticularly beyond the short-term. Our code and model weights are available at\nhttps://github.com/batuhankmkaraman/LoMaR.",
      "authors": [
        "Batuhan K. Karaman",
        "Katerina Dodelzon",
        "Gozde B. Akar",
        "Mert R. Sabuncu"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19083v1",
        "http://arxiv.org/pdf/2404.19083v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19066v1",
      "title": "Revolutionizing Traffic Sign Recognition: Unveiling the Potential of\n  Vision Transformers",
      "published": "2024-04-29T19:18:52Z",
      "updated": "2024-04-29T19:18:52Z",
      "summary": "This research introduces an innovative method for Traffic Sign Recognition\n(TSR) by leveraging deep learning techniques, with a particular emphasis on\nVision Transformers. TSR holds a vital role in advancing driver assistance\nsystems and autonomous vehicles. Traditional TSR approaches, reliant on manual\nfeature extraction, have proven to be labor-intensive and costly. Moreover,\nmethods based on shape and color have inherent limitations, including\nsusceptibility to various factors and changes in lighting conditions. This\nstudy explores three variants of Vision Transformers (PVT, TNT, LNL) and six\nconvolutional neural networks (AlexNet, ResNet, VGG16, MobileNet, EfficientNet,\nGoogleNet) as baseline models. To address the shortcomings of traditional\nmethods, a novel pyramid EATFormer backbone is proposed, amalgamating\nEvolutionary Algorithms (EAs) with the Transformer architecture. The introduced\nEA-based Transformer block captures multi-scale, interactive, and individual\ninformation through its components: Feed-Forward Network, Global and Local\nInteraction, and Multi-Scale Region Aggregation modules. Furthermore, a\nModulated Deformable MSA module is introduced to dynamically model irregular\nlocations. Experimental evaluations on the GTSRB and BelgiumTS datasets\ndemonstrate the efficacy of the proposed approach in enhancing both prediction\nspeed and accuracy. This study concludes that Vision Transformers hold\nsignificant promise in traffic sign classification and contributes a fresh\nalgorithmic framework for TSR. These findings set the stage for the development\nof precise and dependable TSR algorithms, benefiting driver assistance systems\nand autonomous vehicles.",
      "authors": [
        "Susano Mingwin",
        "Yulong Shisu",
        "Yongshuai Wanwag",
        "Sunshin Huing"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19066v1",
        "http://arxiv.org/pdf/2404.19066v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19043v1",
      "title": "Improving Interpretability of Deep Active Learning for Flood Inundation\n  Mapping Through Class Ambiguity Indices Using Multi-spectral Satellite\n  Imagery",
      "published": "2024-04-29T18:33:17Z",
      "updated": "2024-04-29T18:33:17Z",
      "summary": "Flood inundation mapping is a critical task for responding to the increasing\nrisk of flooding linked to global warming. Significant advancements of deep\nlearning in recent years have triggered its extensive applications, including\nflood inundation mapping. To cope with the time-consuming and labor-intensive\ndata labeling process in supervised learning, deep active learning strategies\nare one of the feasible approaches. However, there remains limited exploration\ninto the interpretability of how deep active learning strategies operate, with\na specific focus on flood inundation mapping in the field of remote sensing. In\nthis study, we introduce a novel framework of Interpretable Deep Active\nLearning for Flood inundation Mapping (IDAL-FIM), specifically in terms of\nclass ambiguity of multi-spectral satellite images. In the experiments, we\nutilize Sen1Floods11 dataset, and adopt U-Net with MC-dropout. In addition, we\nemploy five acquisition functions, which are the random, K-means, BALD,\nentropy, and margin acquisition functions. Based on the experimental results,\nwe demonstrate that two proposed class ambiguity indices are effective\nvariables to interpret the deep active learning by establishing statistically\nsignificant correlation with the predictive uncertainty of the deep learning\nmodel at the tile level. Then, we illustrate the behaviors of deep active\nlearning through visualizing two-dimensional density plots and providing\ninterpretations regarding the operation of deep active learning, in flood\ninundation mapping.",
      "authors": [
        "Hyunho Lee",
        "Wenwen Li"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://dx.doi.org/10.1016/j.rse.2024.114213",
        "http://arxiv.org/abs/2404.19043v1",
        "http://arxiv.org/pdf/2404.19043v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18992v2",
      "title": "Unifying Simulation and Inference with Normalizing Flows",
      "published": "2024-04-29T18:00:00Z",
      "updated": "2024-05-09T21:41:49Z",
      "summary": "There have been many applications of deep neural networks to detector\ncalibrations and a growing number of studies that propose deep generative\nmodels as automated fast detector simulators. We show that these two tasks can\nbe unified by using maximum likelihood estimation (MLE) from conditional\ngenerative models for energy regression. Unlike direct regression techniques,\nthe MLE approach is prior-independent and non-Gaussian resolutions can be\ndetermined from the shape of the likelihood near the maximum. Using an\nATLAS-like calorimeter simulation, we demonstrate this concept in the context\nof calorimeter energy calibration.",
      "authors": [
        "Haoxing Du",
        "Claudius Krause",
        "Vinicius Mikuni",
        "Benjamin Nachman",
        "Ian Pang",
        "David Shih"
      ],
      "categories": [
        "hep-ph",
        "hep-ex",
        "physics.data-an",
        "physics.ins-det",
        "stat.ML"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18992v2",
        "http://arxiv.org/pdf/2404.18992v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18926v1",
      "title": "Point Cloud Models Improve Visual Robustness in Robotic Learners",
      "published": "2024-04-29T17:59:11Z",
      "updated": "2024-04-29T17:59:11Z",
      "summary": "Visual control policies can encounter significant performance degradation\nwhen visual conditions like lighting or camera position differ from those seen\nduring training -- often exhibiting sharp declines in capability even for minor\ndifferences. In this work, we examine robustness to a suite of these types of\nvisual changes for RGB-D and point cloud based visual control policies. To\nperform these experiments on both model-free and model-based reinforcement\nlearners, we introduce a novel Point Cloud World Model (PCWM) and point cloud\nbased control policies. Our experiments show that policies that explicitly\nencode point clouds are significantly more robust than their RGB-D\ncounterparts. Further, we find our proposed PCWM significantly outperforms\nprior works in terms of sample efficiency during training. Taken together,\nthese results suggest reasoning about the 3D scene through point clouds can\nimprove performance, reduce learning time, and increase robustness for robotic\nlearners. Project Webpage: https://pvskand.github.io/projects/PCWM",
      "authors": [
        "Skand Peri",
        "Iain Lee",
        "Chanho Kim",
        "Li Fuxin",
        "Tucker Hermans",
        "Stefan Lee"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18926v1",
        "http://arxiv.org/pdf/2404.18926v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18851v1",
      "title": "A Comprehensive Rubric for Annotating Pathological Speech",
      "published": "2024-04-29T16:44:27Z",
      "updated": "2024-04-29T16:44:27Z",
      "summary": "Rubrics are a commonly used tool for labeling voice corpora in speech quality\nassessment, although their application in the context of pathological speech\nremains relatively limited. In this study, we introduce a comprehensive rubric\nbased on various dimensions of speech quality, including phonetics, fluency,\nand prosody. The objective is to establish standardized criteria for\nidentifying errors within the speech of individuals with Down syndrome, thereby\nenabling the development of automated assessment systems. To achieve this\nobjective, we utilized the Prautocal corpus. To assess the quality of\nannotations using our rubric, two experiments were conducted, focusing on\nphonetics and fluency. For phonetic evaluation, we employed the Goodness of\nPronunciation (GoP) metric, utilizing automatic segmentation systems and\ncorrelating the results with evaluations conducted by a specialized speech\ntherapist. While the obtained correlation values were not notably high, a\npositive trend was observed. In terms of fluency assessment, deep learning\nmodels like wav2vec were used to extract audio features, and we employed an SVM\nclassifier trained on a corpus focused on identifying fluency issues to\ncategorize Prautocal corpus samples. The outcomes highlight the complexities of\nevaluating such phenomena, with variability depending on the specific type of\ndisfluency detected.",
      "authors": [
        "Mario Corrales-Astorgano",
        "David Escudero-Mancebo",
        "Lourdes Aguilar",
        "Valle Flores-Lucas",
        "Valent\u00edn Carde\u00f1oso-Payo",
        "Carlos Vivaracho-Pascual",
        "C\u00e9sar Gonz\u00e1lez-Ferreras"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18851v1",
        "http://arxiv.org/pdf/2404.18851v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18790v1",
      "title": "3D Mapping of Glacier Moulins: Challenges and lessons learned",
      "published": "2024-04-29T15:23:16Z",
      "updated": "2024-04-29T15:23:16Z",
      "summary": "In this paper, we present a field report of the mapping of the Athabasca\nGlacier, using a custom-made lidar-inertial mapping platform. With the\nincreasing autonomy of robotics, a wider spectrum of applications emerges.\nAmong these, the surveying of environmental areas presents arduous and\nhazardous challenges for human operators. Leveraging automated platforms for\ndata collection holds the promise of unlocking new applications and a deeper\ncomprehension of the environment. Over the course of a week-long deployment, we\ncollected glacier data using a tailor-made measurement platform and reflected\non the inherent challenges associated with such experiments. We focus on the\ninsights gained and the forthcoming challenges that robotics must surmount to\neffectively map these terrains.",
      "authors": [
        "William Dubois",
        "Mat\u011bj Boxan",
        "Johann Laconte",
        "Fran\u00e7ois Pomerleau"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18790v1",
        "http://arxiv.org/pdf/2404.18790v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18977v1",
      "title": "Computational Job Market Analysis with Natural Language Processing",
      "published": "2024-04-29T14:52:38Z",
      "updated": "2024-04-29T14:52:38Z",
      "summary": "[Abridged Abstract]\n  Recent technological advances underscore labor market dynamics, yielding\nsignificant consequences for employment prospects and increasing job vacancy\ndata across platforms and languages. Aggregating such data holds potential for\nvaluable insights into labor market demands, new skills emergence, and\nfacilitating job matching for various stakeholders. However, despite prevalent\ninsights in the private sector, transparent language technology systems and\ndata for this domain are lacking. This thesis investigates Natural Language\nProcessing (NLP) technology for extracting relevant information from job\ndescriptions, identifying challenges including scarcity of training data, lack\nof standardized annotation guidelines, and shortage of effective extraction\nmethods from job ads. We frame the problem, obtaining annotated data, and\nintroducing extraction methodologies. Our contributions include job description\ndatasets, a de-identification dataset, and a novel active learning algorithm\nfor efficient model training. We propose skill extraction using weak\nsupervision, a taxonomy-aware pre-training methodology adapting multilingual\nlanguage models to the job market domain, and a retrieval-augmented model\nleveraging multiple skill extraction datasets to enhance overall performance.\nFinally, we ground extracted information within a designated taxonomy.",
      "authors": [
        "Mike Zhang"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18977v1",
        "http://arxiv.org/pdf/2404.18977v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18731v3",
      "title": "Real Time Multi Organ Classification on Computed Tomography Images",
      "published": "2024-04-29T14:17:52Z",
      "updated": "2025-01-09T22:10:14Z",
      "summary": "Organ segmentation is a fundamental task in medical imaging since it is\nuseful for many clinical automation pipelines. However, some tasks do not\nrequire full segmentation. Instead, a classifier can identify the selected\norgan without segmenting the entire volume. In this study, we demonstrate a\nclassifier based method to obtain organ labels in real time by using a large\ncontext size with a sparse data sampling strategy. Although our method operates\nas an independent classifier at query locations, it can generate full\nsegmentations by querying grid locations at any resolution, offering faster\nperformance than segmentation algorithms. We compared our method with existing\nsegmentation techniques, demonstrating its superior runtime potential for\npractical applications in medical imaging.",
      "authors": [
        "Halid Ziya Yerebakan",
        "Yoshihisa Shinagawa",
        "Gerardo Hermosillo Valadez"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18731v3",
        "http://arxiv.org/pdf/2404.18731v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18973v1",
      "title": "The Convergence of AI and Synthetic Biology: The Looming Deluge",
      "published": "2024-04-29T14:17:06Z",
      "updated": "2024-04-29T14:17:06Z",
      "summary": "The convergence of artificial intelligence (AI) and synthetic biology is\nrapidly accelerating the pace of biological discovery and engineering. AI\ntechniques, such as large language models and biological design tools, are\nenabling the automated design, build, test, and learning cycles for engineered\nbiological systems. This convergence promises to democratize synthetic biology\nand unlock novel applications across domains from medicine to environmental\nsustainability. However, it also poses significant risks around reliability,\ndual use, and governance. The opacity of AI models, the deskilling of\nworkforces, and the outdated nature of current regulatory frameworks present\nchallenges in ensuring responsible development. Urgent attention is needed to\nupdate governance structures, integrate human oversight into increasingly\nautomated workflows, and foster a culture of responsibility among the growing\ncommunity of bioengineers. Only by proactively addressing these issues can we\nrealize the transformative potential of AI-driven synthetic biology while\nmitigating its risks.",
      "authors": [
        "Cindy Vindman",
        "Benjamin Trump",
        "Christopher Cummings",
        "Madison Smith",
        "Alexander J. Titus",
        "Ken Oye",
        "Valentina Prado",
        "Eyup Turmus",
        "Igor Linkov"
      ],
      "categories": [
        "q-bio.OT"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18973v1",
        "http://arxiv.org/pdf/2404.18973v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18681v1",
      "title": "LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs",
      "published": "2024-04-29T13:24:23Z",
      "updated": "2024-04-29T13:24:23Z",
      "summary": "Machine learning's influence is expanding rapidly, now integral to\ndecision-making processes from corporate strategy to the advancements in\nIndustry 4.0. The efficacy of Artificial Intelligence broadly hinges on the\ncaliber of data used during its training phase; optimal performance is tied to\nexceptional data quality. Data cleaning tools, particularly those that exploit\nfunctional dependencies within ontological frameworks or context models, are\ninstrumental in augmenting data quality. Nevertheless, crafting these context\nmodels is a demanding task, both in terms of resources and expertise, often\nnecessitating specialized knowledge from domain experts.\n  In light of these challenges, this paper introduces an innovative approach,\ncalled LLMClean, for the automated generation of context models, utilizing\nLarge Language Models to analyze and understand various datasets. LLMClean\nencompasses a sequence of actions, starting with categorizing the dataset,\nextracting or mapping relevant models, and ultimately synthesizing the context\nmodel. To demonstrate its potential, we have developed and tested a prototype\nthat applies our approach to three distinct datasets from the Internet of\nThings, healthcare, and Industry 4.0 sectors. The results of our evaluation\nindicate that our automated approach can achieve data cleaning efficacy\ncomparable with that of context models crafted by human experts.",
      "authors": [
        "Fabian Biester",
        "Mohamed Abdelaal",
        "Daniel Del Gaudio"
      ],
      "categories": [
        "cs.DB"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18681v1",
        "http://arxiv.org/pdf/2404.18681v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18663v1",
      "title": "Terrain characterisation for online adaptability of automated sonar\n  processing: Lessons learnt from operationally applying ATR to sidescan sonar\n  in MCM applications",
      "published": "2024-04-29T12:48:42Z",
      "updated": "2024-04-29T12:48:42Z",
      "summary": "The performance of Automated Recognition (ATR) algorithms on side-scan sonar\nimagery has shown to degrade rapidly when deployed on non benign environments.\nComplex seafloors and acoustic artefacts constitute distractors in the form of\nstrong textural patterns, creating false detections or preventing detections of\ntrue objects. This paper presents two online seafloor characterisation\ntechniques to improve explainability during Autonomous Underwater Vehicles\n(AUVs) missions. Importantly and as opposed to previous work in the domain,\nthese techniques are not based on a model and require limited input from human\noperators, making it suitable for real-time onboard processing. Both techniques\nrely on an unsupervised machine learning approach to extract terrain features\nwhich relate to the human understanding of terrain complexity. The first\ntechnnique provides a quantitative, application-driven terrain characterisation\nmetric based on the performance of an ATR algorithm. The second method provides\na way to incorporate subject matter expertise and enables contextualisation and\nexplainability in support for scenario-dependent subjective terrain\ncharacterisation. The terrain complexity matches the expectation of seasoned\nusers making this tool desirable and trustworthy in comparison to traditional\nunsupervised approaches. We finally detail an application of these techniques\nto repair a Mine Countermeasures (MCM) mission carried with SeeByte autonomy\nframework Neptune.",
      "authors": [
        "Thomas Guerneve",
        "Stephanos Loizou",
        "Andrea Munafo",
        "Pierre-Yves Mignotte"
      ],
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18663v1",
        "http://arxiv.org/pdf/2404.18663v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18573v2",
      "title": "Predicting Safety Misbehaviours in Autonomous Driving Systems using\n  Uncertainty Quantification",
      "published": "2024-04-29T10:28:28Z",
      "updated": "2025-02-13T11:09:19Z",
      "summary": "The automated real-time recognition of unexpected situations plays a crucial\nrole in the safety of autonomous vehicles, especially in unsupported and\nunpredictable scenarios. This paper evaluates different Bayesian uncertainty\nquantification methods from the deep learning domain for the anticipatory\ntesting of safety-critical misbehaviours during system-level simulation-based\ntesting. Specifically, we compute uncertainty scores as the vehicle executes,\nfollowing the intuition that high uncertainty scores are indicative of\nunsupported runtime conditions that can be used to distinguish safe from\nfailure-inducing driving behaviors. In our study, we conducted an evaluation of\nthe effectiveness and computational overhead associated with two Bayesian\nuncertainty quantification methods, namely MC- Dropout and Deep Ensembles, for\nmisbehaviour avoidance. Overall, for three benchmarks from the Udacity\nsimulator comprising both out-of-distribution and unsafe conditions introduced\nvia mutation testing, both methods successfully detected a high number of\nout-of-bounds episodes providing early warnings several seconds in advance,\noutperforming two state-of-the-art misbehaviour prediction methods based on\nautoencoders and attention maps in terms of effectiveness and efficiency.\nNotably, Deep Ensembles detected most misbehaviours without any false alarms\nand did so even when employing a relatively small number of models, making them\ncomputationally feasible for real-time detection. Our findings suggest that\nincorporating uncertainty quantification methods is a viable approach for\nbuilding fail-safe mechanisms in deep neural network-based autonomous vehicles.",
      "authors": [
        "Ruben Grewal",
        "Paolo Tonella",
        "Andrea Stocco"
      ],
      "categories": [
        "cs.LG",
        "cs.RO",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18573v2",
        "http://arxiv.org/pdf/2404.18573v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18470v2",
      "title": "ECC Analyzer: Extract Trading Signal from Earnings Conference Calls\n  using Large Language Model for Stock Performance Prediction",
      "published": "2024-04-29T07:11:39Z",
      "updated": "2024-08-29T23:13:56Z",
      "summary": "In the realm of financial analytics, leveraging unstructured data, such as\nearnings conference calls (ECCs), to forecast stock volatility is a critical\nchallenge that has attracted both academics and investors. While previous\nstudies have used multimodal deep learning-based models to obtain a general\nview of ECCs for volatility predicting, they often fail to capture detailed,\ncomplex information. Our research introduces a novel framework: \\textbf{ECC\nAnalyzer}, which utilizes large language models (LLMs) to extract richer, more\npredictive content from ECCs to aid the model's prediction performance. We use\nthe pre-trained large models to extract textual and audio features from ECCs\nand implement a hierarchical information extraction strategy to extract more\nfine-grained information. This strategy first extracts paragraph-level general\ninformation by summarizing the text and then extracts fine-grained focus\nsentences using Retrieval-Augmented Generation (RAG). These features are then\nfused through multimodal feature fusion to perform volatility prediction.\nExperimental results demonstrate that our model outperforms traditional\nanalytical benchmarks, confirming the effectiveness of advanced LLM techniques\nin financial analysis.",
      "authors": [
        "Yupeng Cao",
        "Zhi Chen",
        "Qingyun Pei",
        "Nathan Jinseok Lee",
        "K. P. Subbalakshmi",
        "Papa Momar Ndiaye"
      ],
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "q-fin.RM",
        "q-fin.TR"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18470v2",
        "http://arxiv.org/pdf/2404.18470v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18963v1",
      "title": "RE-GrievanceAssist: Enhancing Customer Experience through ML-Powered\n  Complaint Management",
      "published": "2024-04-29T07:03:23Z",
      "updated": "2024-04-29T07:03:23Z",
      "summary": "In recent years, digital platform companies have faced increasing challenges\nin managing customer complaints, driven by widespread consumer adoption. This\npaper introduces an end-to-end pipeline, named RE-GrievanceAssist, designed\nspecifically for real estate customer complaint management. The pipeline\nconsists of three key components: i) response/no-response ML model using TF-IDF\nvectorization and XGBoost classifier ; ii) user type classifier using fasttext\nclassifier; iii) issue/sub-issue classifier using TF-IDF vectorization and\nXGBoost classifier. Finally, it has been deployed as a batch job in Databricks,\nresulting in a remarkable 40% reduction in overall manual effort with monthly\ncost reduction of Rs 1,50,000 since August 2023.",
      "authors": [
        "Venkatesh C",
        "Harshit Oberoi",
        "Anurag Kumar Pandey",
        "Anil Goyal",
        "Nikhil Sikka"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18963v1",
        "http://arxiv.org/pdf/2404.18963v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18462v1",
      "title": "Self-supervised contrastive learning of radio data for source detection,\n  classification and peculiar object discovery",
      "published": "2024-04-29T06:46:25Z",
      "updated": "2024-04-29T06:46:25Z",
      "summary": "New advancements in radio data post-processing are underway within the SKA\nprecursor community, aiming to facilitate the extraction of scientific results\nfrom survey images through a semi-automated approach. Several of these\ndevelopments leverage deep learning (DL) methodologies for diverse tasks,\nincluding source detection, object or morphology classification, and anomaly\ndetection. Despite substantial progress, the full potential of these methods\noften remains untapped due to challenges associated with training large\nsupervised models, particularly in the presence of small and class-unbalanced\nlabelled datasets. Self-supervised learning has recently established itself as\na powerful methodology to deal with some of the aforementioned challenges, by\ndirectly learning a lower-dimensional representation from large samples of\nunlabelled data. The resulting model and data representation can then be used\nfor data inspection and various downstream tasks if a small subset of labelled\ndata is available. In this work, we explored contrastive learning methods to\nlearn suitable radio data representation from unlabelled images taken from the\nASKAP EMU and SARAO MeerKAT GPS surveys. We evaluated trained models and the\nobtained data representation over smaller labelled datasets, also taken from\ndifferent radio surveys, in selected analysis tasks: source detection and\nclassification, and search for objects with peculiar morphology. For all\nexplored downstream tasks, we reported and discussed the benefits brought by\nself-supervised foundational models built on radio data.",
      "authors": [
        "S. Riggi",
        "T. Cecconello",
        "S. Palazzo",
        "A. M. Hopkins",
        "N. Gupta",
        "C. Bordiu",
        "A. Ingallinera",
        "C. Buemi",
        "F. Bufano",
        "F. Cavallaro",
        "M. D. Filipovi\u0107",
        "P. Leto",
        "S. Loru",
        "A. C. Ruggeri",
        "C. Trigilio",
        "G. Umana",
        "F. Vitello"
      ],
      "categories": [
        "astro-ph.IM"
      ],
      "links": [
        "http://dx.doi.org/10.1017/pasa.2024.84",
        "http://arxiv.org/abs/2404.18462v1",
        "http://arxiv.org/pdf/2404.18462v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18392v1",
      "title": "Dflow, a Python framework for constructing cloud-native AI-for-Science\n  workflows",
      "published": "2024-04-29T03:11:13Z",
      "updated": "2024-04-29T03:11:13Z",
      "summary": "In the AI-for-science era, scientific computing scenarios such as concurrent\nlearning and high-throughput computing demand a new generation of\ninfrastructure that supports scalable computing resources and automated\nworkflow management on both cloud and high-performance supercomputers. Here we\nintroduce Dflow, an open-source Python toolkit designed for scientists to\nconstruct workflows with simple programming interfaces. It enables complex\nprocess control and task scheduling across a distributed, heterogeneous\ninfrastructure, leveraging containers and Kubernetes for flexibility. Dflow is\nhighly observable and can scale to thousands of concurrent nodes per workflow,\nenhancing the efficiency of complex scientific computing tasks. The basic unit\nin Dflow, known as an Operation (OP), is reusable and independent of the\nunderlying infrastructure or context. Dozens of workflow projects have been\ndeveloped based on Dflow, spanning a wide range of projects. We anticipate that\nthe reusability of Dflow and its components will encourage more scientists to\npublish their workflows and OP components. These components, in turn, can be\nadapted and reused in various contexts, fostering greater collaboration and\ninnovation in the scientific community.",
      "authors": [
        "Xinzijian Liu",
        "Yanbo Han",
        "Zhuoyuan Li",
        "Jiahao Fan",
        "Chengqian Zhang",
        "Jinzhe Zeng",
        "Yifan Shan",
        "Yannan Yuan",
        "Wei-Hong Xu",
        "Yun-Pei Liu",
        "Yuzhi Zhang",
        "Tongqi Wen",
        "Darrin M. York",
        "Zhicheng Zhong",
        "Hang Zheng",
        "Jun Cheng",
        "Linfeng Zhang",
        "Han Wang"
      ],
      "categories": [
        "cs.DC"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18392v1",
        "http://arxiv.org/pdf/2404.18392v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18326v1",
      "title": "SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement\n  Learning Policies",
      "published": "2024-04-28T21:47:34Z",
      "updated": "2024-04-28T21:47:34Z",
      "summary": "While Deep Reinforcement Learning (DRL) has emerged as a promising solution\nfor intricate control tasks, the lack of explainability of the learned policies\nimpedes its uptake in safety-critical applications, such as automated driving\nsystems (ADS). Counterfactual (CF) explanations have recently gained prominence\nfor their ability to interpret black-box Deep Learning (DL) models. CF examples\nare associated with minimal changes in the input, resulting in a complementary\noutput by the DL model. Finding such alternations, particularly for\nhigh-dimensional visual inputs, poses significant challenges. Besides, the\ntemporal dependency introduced by the reliance of the DRL agent action on a\nhistory of past state observations further complicates the generation of CF\nexamples. To address these challenges, we propose using a saliency map to\nidentify the most influential input pixels across the sequence of past observed\nstates by the agent. Then, we feed this map to a deep generative model,\nenabling the generation of plausible CFs with constrained modifications centred\non the salient regions. We evaluate the effectiveness of our framework in\ndiverse domains, including ADS, Atari Pong, Pacman and space-invaders games,\nusing traditional performance metrics such as validity, proximity and sparsity.\nExperimental results demonstrate that this framework generates more informative\nand plausible CFs than the state-of-the-art for a wide range of environments\nand DRL agents. In order to foster research in this area, we have made our\ndatasets and codes publicly available at\nhttps://github.com/Amir-Samadi/SAFE-RL.",
      "authors": [
        "Amir Samadi",
        "Konstantinos Koufos",
        "Kurt Debattista",
        "Mehrdad Dianati"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18326v1",
        "http://arxiv.org/pdf/2404.18326v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18293v1",
      "title": "Quantum-enhanced learning with a controllable bosonic variational sensor\n  network",
      "published": "2024-04-28T19:41:40Z",
      "updated": "2024-04-28T19:41:40Z",
      "summary": "The emergence of quantum sensor networks has presented opportunities for\nenhancing complex sensing tasks, while simultaneously introducing significant\nchallenges in designing and analyzing quantum sensing protocols due to the\nintricate nature of entanglement and physical processes. Supervised learning\nassisted by an entangled sensor network (SLAEN) [Phys. Rev. X 9, 041023 (2019)]\nrepresents a promising paradigm for automating sensor-network design through\nvariational quantum machine learning. However, the original SLAEN, constrained\nby the Gaussian nature of quantum circuits, is limited to learning linearly\nseparable data. Leveraging the universal quantum control available in\ncavity-QED experiments, we propose a generalized SLAEN capable of handling\nnonlinear data classification tasks. We establish a theoretical framework for\nphysical-layer data classification to underpin our approach. Through training\nquantum probes and measurements, we uncover a threshold phenomenon in\nclassification error across various tasks -- when the energy of probes exceeds\na certain threshold, the error drastically diminishes to zero, providing a\nsignificant improvement over the Gaussian SLAEN. Despite the non-Gaussian\nnature of the problem, we offer analytical insights into determining the\nthreshold and residual error in the presence of noise. Our findings carry\nimplications for radio-frequency photonic sensors and microwave dark matter\nhaloscopes.",
      "authors": [
        "Pengcheng Liao",
        "Bingzhi Zhang",
        "Quntao Zhuang"
      ],
      "categories": [
        "quant-ph"
      ],
      "links": [
        "http://dx.doi.org/10.1088/2058-9565/ad752d",
        "http://arxiv.org/abs/2404.18293v1",
        "http://arxiv.org/pdf/2404.18293v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18212v3",
      "title": "Paint by Inpaint: Learning to Add Image Objects by Removing Them First",
      "published": "2024-04-28T15:07:53Z",
      "updated": "2025-03-20T06:59:54Z",
      "summary": "Image editing has advanced significantly with the introduction of\ntext-conditioned diffusion models. Despite this progress, seamlessly adding\nobjects to images based on textual instructions without requiring user-provided\ninput masks remains a challenge. We address this by leveraging the insight that\nremoving objects (Inpaint) is significantly simpler than its inverse process of\nadding them (Paint), attributed to inpainting models that benefit from\nsegmentation mask guidance. Capitalizing on this realization, by implementing\nan automated and extensive pipeline, we curate a filtered large-scale image\ndataset containing pairs of images and their corresponding object-removed\nversions. Using these pairs, we train a diffusion model to inverse the\ninpainting process, effectively adding objects into images. Unlike other\nediting datasets, ours features natural target images instead of synthetic ones\nwhile ensuring source-target consistency by construction. Additionally, we\nutilize a large Vision-Language Model to provide detailed descriptions of the\nremoved objects and a Large Language Model to convert these descriptions into\ndiverse, natural-language instructions. Our quantitative and qualitative\nresults show that the trained model surpasses existing models in both object\naddition and general editing tasks. Visit our project page for the released\ndataset and trained models at https://rotsteinnoam.github.io/Paint-by-Inpaint.",
      "authors": [
        "Navve Wasserman",
        "Noam Rotstein",
        "Roy Ganz",
        "Ron Kimmel"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18212v3",
        "http://arxiv.org/pdf/2404.18212v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18207v1",
      "title": "Testing for Asymmetric Information in Insurance with Deep Learning",
      "published": "2024-04-28T14:59:46Z",
      "updated": "2024-04-28T14:59:46Z",
      "summary": "The positive correlation test for asymmetric information developed by\nChiappori and Salanie (2000) has been applied in many insurance markets. Most\nof the literature focuses on the special case of constant correlation; it also\nrelies on restrictive parametric specifications for the choice of coverage and\nthe occurrence of claims. We relax these restrictions by estimating conditional\ncovariances and correlations using deep learning methods. We test the positive\ncorrelation property by using the intersection test of Chernozhukov, Lee, and\nRosen (2013) and the \"sorted groups\" test of Chernozhukov, Demirer, Duflo, and\nFernandez-Val (2023). Our results confirm earlier findings that the correlation\nbetween risk and coverage is small. Random forests and gradient boosting trees\nproduce similar results to neural networks.",
      "authors": [
        "Serguei Maliar",
        "Bernard Salanie"
      ],
      "categories": [
        "econ.EM"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18207v1",
        "http://arxiv.org/pdf/2404.18207v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18184v1",
      "title": "Application and practice of AI technology in quantitative investment",
      "published": "2024-04-28T13:37:45Z",
      "updated": "2024-04-28T13:37:45Z",
      "summary": "With the continuous development of artificial intelligence technology, using\nmachine learning technology to predict market trends may no longer be out of\nreach. In recent years, artificial intelligence has become a research hotspot\nin the academic circle,and it has been widely used in image recognition,\nnatural language processing and other fields, and also has a huge impact on the\nfield of quantitative investment. As an investment method to obtain stable\nreturns through data analysis, model construction and program trading,\nquantitative investment is deeply loved by financial institutions and\ninvestors. At the same time, as an important application field of quantitative\ninvestment, the quantitative investment strategy based on artificial\nintelligence technology arises at the historic moment.How to apply artificial\nintelligence to quantitative investment, so as to better achieve profit and\nrisk control, has also become the focus and difficulty of the research. From a\nglobal perspective, inflation in the US and the Federal Reserve are the\nconcerns of investors, which to some extent affects the direction of global\nassets, including the Chinese stock market. This paper studies the application\nof AI technology, quantitative investment, and AI technology in quantitative\ninvestment, aiming to provide investors with auxiliary decision-making, reduce\nthe difficulty of investment analysis, and help them to obtain higher returns.",
      "authors": [
        "Shuochen Bi",
        "Wenqing Bao",
        "Jue Xiao",
        "Jiangshan Wang",
        "Tingting Deng"
      ],
      "categories": [
        "q-fin.PM"
      ],
      "links": [
        "http://dx.doi.org/10.23977/infse.2024.050217",
        "http://arxiv.org/abs/2404.18184v1",
        "http://arxiv.org/pdf/2404.18184v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18134v2",
      "title": "Learning Fairer Representations with FairVIC",
      "published": "2024-04-28T10:10:21Z",
      "updated": "2025-02-03T12:49:14Z",
      "summary": "Mitigating bias in automated decision-making systems, particularly in deep\nlearning models, is a critical challenge due to nuanced definitions of\nfairness, dataset-specific biases, and the inherent trade-off between fairness\nand accuracy. To address these issues, we introduce FairVIC, an innovative\napproach that enhances fairness in neural networks by integrating variance,\ninvariance, and covariance terms into the loss function during training. Unlike\nmethods that rely on predefined fairness criteria, FairVIC abstracts fairness\nconcepts to minimise dependency on protected characteristics. We evaluate\nFairVIC against comparable bias mitigation techniques on benchmark datasets,\nconsidering both group and individual fairness, and conduct an ablation study\non the accuracy-fairness trade-off. FairVIC demonstrates significant\nimprovements ($\\approx70\\%$) in fairness across all tested metrics without\ncompromising accuracy, thus offering a robust, generalisable solution for fair\ndeep learning across diverse tasks and datasets.",
      "authors": [
        "Charmaine Barker",
        "Daniel Bethell",
        "Dimitar Kazakov"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ML"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18134v2",
        "http://arxiv.org/pdf/2404.18134v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18043v2",
      "title": "Utilizing Large Language Models for Information Extraction from Real\n  Estate Transactions",
      "published": "2024-04-28T01:38:38Z",
      "updated": "2024-12-22T20:31:15Z",
      "summary": "Real estate sales contracts contain crucial information for property\ntransactions, but manual data extraction can be time-consuming and error-prone.\nThis paper explores the application of large language models, specifically\ntransformer-based architectures, for automated information extraction from real\nestate contracts. We discuss challenges, techniques, and future directions in\nleveraging these models to improve efficiency and accuracy in real estate\ncontract analysis. We generated synthetic contracts using the real-world\ntransaction dataset, thereby fine-tuning the large-language model and achieving\nsignificant metrics improvements and qualitative improvements in information\nretrieval and reasoning tasks.",
      "authors": [
        "Yu Zhao",
        "Haoxiang Gao"
      ],
      "categories": [
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18043v2",
        "http://arxiv.org/pdf/2404.18043v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18038v1",
      "title": "Multi-Stage Watermarking for Quantum Circuits",
      "published": "2024-04-28T00:52:38Z",
      "updated": "2024-04-28T00:52:38Z",
      "summary": "Quantum computing represents a burgeoning computational paradigm that\nsignificantly advances the resolution of contemporary intricate problems across\nvarious domains, including cryptography, chemistry, and machine learning.\nQuantum circuits tailored to address specific problems have emerged as critical\nintellectual properties (IPs) for quantum computing companies, attributing to\nthe escalating commercial value of quantum computing. Consequently, designing\nwatermarking schemes for quantum circuits becomes imperative to thwart\nmalicious entities from producing unauthorized circuit replicas and unlawfully\ndisseminating them within the market.\n  Unfortunately, the prevailing watermarking technique reliant on unitary\nmatrix decomposition markedly inflates the number of 2-qubit gates and circuit\ndepth, thereby compromising the fidelity of watermarked circuits when embedding\ndetectable signatures into the corresponding unitary matrices. In this paper,\nwe propose an innovative multi-stage watermarking scheme for quantum circuits,\nintroducing additional constraints across various synthesis stages to validate\nthe ownership of IPs. Compared to the state-of-the-art watermarking technique,\nour multi-stage watermarking approach demonstrates, on average, a reduction in\nthe number of 2-qubit gates by 16\\% and circuit depth by 6\\%, alongside an\nincrease in the fidelity of watermarked circuits by 8\\%, while achieving a\n79.4\\% lower probabilistic proof of authorship.",
      "authors": [
        "Min Yang",
        "Xiaolong Guo",
        "Lei Jiang"
      ],
      "categories": [
        "quant-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18038v1",
        "http://arxiv.org/pdf/2404.18038v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18017v1",
      "title": "Application of Deep Learning for Factor Timing in Asset Management",
      "published": "2024-04-27T21:57:17Z",
      "updated": "2024-04-27T21:57:17Z",
      "summary": "The paper examines the performance of regression models (OLS linear\nregression, Ridge regression, Random Forest, and Fully-connected Neural\nNetwork) on the prediction of CMA (Conservative Minus Aggressive) factor\npremium and the performance of factor timing investment with them.\nOut-of-sample R-squared shows that more flexible models have better performance\nin explaining the variance in factor premium of the unseen period, and the back\ntesting affirms that the factor timing based on more flexible models tends to\nover perform the ones with linear models. However, for flexible models like\nneural networks, the optimal weights based on their prediction tend to be\nunstable, which can lead to high transaction costs and market impacts. We\nverify that tilting down the rebalance frequency according to the historical\noptimal rebalancing scheme can help reduce the transaction costs.",
      "authors": [
        "Prabhu Prasad Panda",
        "Maysam Khodayari Gharanchaei",
        "Xilin Chen",
        "Haoshu Lyu"
      ],
      "categories": [
        "q-fin.PM",
        "cs.LG",
        "q-fin.CP"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18017v1",
        "http://arxiv.org/pdf/2404.18017v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.18952v1",
      "title": "CUE-Net: Violence Detection Video Analytics with Spatial Cropping,\n  Enhanced UniformerV2 and Modified Efficient Additive Attention",
      "published": "2024-04-27T20:09:40Z",
      "updated": "2024-04-27T20:09:40Z",
      "summary": "In this paper we introduce CUE-Net, a novel architecture designed for\nautomated violence detection in video surveillance. As surveillance systems\nbecome more prevalent due to technological advances and decreasing costs, the\nchallenge of efficiently monitoring vast amounts of video data has intensified.\nCUE-Net addresses this challenge by combining spatial Cropping with an enhanced\nversion of the UniformerV2 architecture, integrating convolutional and\nself-attention mechanisms alongside a novel Modified Efficient Additive\nAttention mechanism (which reduces the quadratic time complexity of\nself-attention) to effectively and efficiently identify violent activities.\nThis approach aims to overcome traditional challenges such as capturing distant\nor partially obscured subjects within video frames. By focusing on both local\nand global spatiotemporal features, CUE-Net achieves state-of-the-art\nperformance on the RWF-2000 and RLVS datasets, surpassing existing methods.",
      "authors": [
        "Damith Chamalke Senadeera",
        "Xiaoyun Yang",
        "Dimitrios Kollias",
        "Gregory Slabaugh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.18952v1",
        "http://arxiv.org/pdf/2404.18952v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17985v1",
      "title": "Detection of Conspiracy Theories Beyond Keyword Bias in German-Language\n  Telegram Using Large Language Models",
      "published": "2024-04-27T19:17:31Z",
      "updated": "2024-04-27T19:17:31Z",
      "summary": "The automated detection of conspiracy theories online typically relies on\nsupervised learning. However, creating respective training data requires\nexpertise, time and mental resilience, given the often harmful content.\nMoreover, available datasets are predominantly in English and often\nkeyword-based, introducing a token-level bias into the models. Our work\naddresses the task of detecting conspiracy theories in German Telegram\nmessages. We compare the performance of supervised fine-tuning approaches using\nBERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4\nwhich require little or no additional training data. We use a dataset of\n$\\sim\\!\\! 4,000$ messages collected during the COVID-19 pandemic, without the\nuse of keyword filters.\n  Our findings demonstrate that both approaches can be leveraged effectively:\nFor supervised fine-tuning, we report an F1 score of $\\sim\\!\\! 0.8$ for the\npositive class, making our model comparable to recent models trained on\nkeyword-focused English corpora. We demonstrate our model's adaptability to\nintra-domain temporal shifts, achieving F1 scores of $\\sim\\!\\! 0.7$. Among\nprompting variants, the best model is GPT-4, achieving an F1 score of $\\sim\\!\\!\n0.8$ for the positive class in a zero-shot setting and equipped with a custom\nconspiracy theory definition.",
      "authors": [
        "Milena Pustet",
        "Elisabeth Steffen",
        "Helena Mihaljevi\u0107"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI",
        "I.2.7"
      ],
      "links": [
        "http://dx.doi.org/10.18653/v1/2024.woah-1.2",
        "http://arxiv.org/abs/2404.17985v1",
        "http://arxiv.org/pdf/2404.17985v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17975v1",
      "title": "Automating Customer Needs Analysis: A Comparative Study of Large\n  Language Models in the Travel Industry",
      "published": "2024-04-27T18:28:10Z",
      "updated": "2024-04-27T18:28:10Z",
      "summary": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large\nLanguage Models (LLMs) have emerged as powerful tools for many tasks, such as\nextracting valuable insights from vast amounts of textual data. In this study,\nwe conduct a comparative analysis of LLMs for the extraction of travel customer\nneeds from TripAdvisor posts. Leveraging a diverse range of models, including\nboth open-source and proprietary ones such as GPT-4 and Gemini, we aim to\nelucidate their strengths and weaknesses in this specialized domain. Through an\nevaluation process involving metrics such as BERTScore, ROUGE, and BLEU, we\nassess the performance of each model in accurately identifying and summarizing\ncustomer needs. Our findings highlight the efficacy of opensource LLMs,\nparticularly Mistral 7B, in achieving comparable performance to larger closed\nmodels while offering affordability and customization benefits. Additionally,\nwe underscore the importance of considering factors such as model size,\nresource requirements, and performance metrics when selecting the most suitable\nLLM for customer needs analysis tasks. Overall, this study contributes valuable\ninsights for businesses seeking to leverage advanced NLP techniques to enhance\ncustomer experience and drive operational efficiency in the travel industry.",
      "authors": [
        "Simone Barandoni",
        "Filippo Chiarello",
        "Lorenzo Cascone",
        "Emiliano Marrale",
        "Salvatore Puccio"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17975v1",
        "http://arxiv.org/pdf/2404.17975v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17960v1",
      "title": "PhishGuard: A Convolutional Neural Network Based Model for Detecting\n  Phishing URLs with Explainability Analysis",
      "published": "2024-04-27T17:13:49Z",
      "updated": "2024-04-27T17:13:49Z",
      "summary": "Cybersecurity is one of the global issues because of the extensive dependence\non cyber systems of individuals, industries, and organizations. Among the cyber\nattacks, phishing is increasing tremendously and affecting the global economy.\nTherefore, this phenomenon highlights the vital need for enhancing user\nawareness and robust support at both individual and organizational levels.\nPhishing URL identification is the best way to address the problem. Various\nmachine learning and deep learning methods have been proposed to automate the\ndetection of phishing URLs. However, these approaches often need more\nconvincing accuracy and rely on datasets consisting of limited samples.\nFurthermore, these black box intelligent models decision to detect suspicious\nURLs needs proper explanation to understand the features affecting the output.\nTo address the issues, we propose a 1D Convolutional Neural Network (CNN) and\ntrained the model with extensive features and a substantial amount of data. The\nproposed model outperforms existing works by attaining an accuracy of 99.85%.\nAdditionally, our explainability analysis highlights certain features that\nsignificantly contribute to identifying the phishing URL.",
      "authors": [
        "Md Robiul Islam",
        "Md Mahamodul Islam",
        "Mst. Suraiya Afrin",
        "Anika Antara",
        "Nujhat Tabassum",
        "Al Amin"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17960v1",
        "http://arxiv.org/pdf/2404.17960v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17912v2",
      "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision\n  Language Models",
      "published": "2024-04-27T13:46:23Z",
      "updated": "2024-07-18T16:03:18Z",
      "summary": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large\nLanguage Models (MLLMs) can automate the creation of accurate and coherent\nradiological reports. Existing methods often hallucinate details in text-based\nreports that don't accurately reflect the image content. To mitigate this, we\nintroduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort\nGENeraTion using Vision Language Models), which improves the R2Gen task by\nintegrating a self-refining mechanism into the MLLM framework. We employ a\nunique self-supervised loss that leverages similarity between pooled image\nrepresentations and the contextual representations of the generated\nradiological text, alongside the standard Causal Language Modeling objective,\nto refine image-text representations. This allows the model to scrutinize and\nalign the generated text through dynamic interaction between a given image and\nthe generated text, therefore reducing hallucination and continuously enhancing\nnuanced report generation. SERPENT-VLM outperforms existing baselines such as\nLLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and\nRadiology Objects in COntext (ROCO) datasets, and also proves to be robust\nagainst noisy images. A qualitative case study emphasizes the significant\nadvancements towards more sophisticated MLLM frameworks for R2Gen, opening\npaths for further research into self-supervised refinement in the medical\nimaging domain.",
      "authors": [
        "Manav Nitin Kapadnis",
        "Sohan Patnaik",
        "Abhilash Nandy",
        "Sourjyadip Ray",
        "Pawan Goyal",
        "Debdoot Sheet"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17912v2",
        "http://arxiv.org/pdf/2404.17912v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17896v1",
      "title": "How the Training Procedure Impacts the Performance of Deep\n  Learning-based Vulnerability Patching",
      "published": "2024-04-27T13:08:42Z",
      "updated": "2024-04-27T13:08:42Z",
      "summary": "Generative deep learning (DL) models have been successfully adopted for\nvulnerability patching. However, such models require the availability of a\nlarge dataset of patches to learn from. To overcome this issue, researchers\nhave proposed to start from models pre-trained with general knowledge, either\non the programming language or on similar tasks such as bug fixing. Despite the\nefforts in the area of automated vulnerability patching, there is a lack of\nsystematic studies on how these different training procedures impact the\nperformance of DL models for such a task. This paper provides a manyfold\ncontribution to bridge this gap, by (i) comparing existing solutions of\nself-supervised and supervised pre-training for vulnerability patching; and\n(ii) for the first time, experimenting with different kinds of prompt-tuning\nfor this task. The study required to train/test 23 DL models. We found that a\nsupervised pre-training focused on bug-fixing, while expensive in terms of data\ncollection, substantially improves DL-based vulnerability patching. When\napplying prompt-tuning on top of this supervised pre-trained model, there is no\nsignificant gain in performance. Instead, prompt-tuning is an effective and\ncheap solution to substantially boost the performance of self-supervised\npre-trained models, i.e., those not relying on the bug-fixing pre-training.",
      "authors": [
        "Antonio Mastropaolo",
        "Vittoria Nardone",
        "Gabriele Bavota",
        "Massimiliano Di Penta"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17896v1",
        "http://arxiv.org/pdf/2404.17896v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17839v1",
      "title": "Improving Smart Contract Security with Contrastive Learning-based\n  Vulnerability Detection",
      "published": "2024-04-27T09:13:25Z",
      "updated": "2024-04-27T09:13:25Z",
      "summary": "Currently, smart contract vulnerabilities (SCVs) have emerged as a major\nfactor threatening the transaction security of blockchain. Existing\nstate-of-the-art methods rely on deep learning to mitigate this threat. They\ntreat each input contract as an independent entity and feed it into a deep\nlearning model to learn vulnerability patterns by fitting vulnerability labels.\nIt is a pity that they disregard the correlation between contracts, failing to\nconsider the commonalities between contracts of the same type and the\ndifferences among contracts of different types. As a result, the performance of\nthese methods falls short of the desired level.\n  To tackle this problem, we propose a novel Contrastive Learning Enhanced\nAutomated Recognition Approach for Smart Contract Vulnerabilities, named Clear.\nIn particular, Clear employs a contrastive learning (CL) model to capture the\nfine-grained correlation information among contracts and generates correlation\nlabels based on the relationships between contracts to guide the training\nprocess of the CL model. Finally, it combines the correlation and the semantic\ninformation of the contract to detect SCVs. Through an empirical evaluation of\na large-scale real-world dataset of over 40K smart contracts and compare 13\nstate-of-the-art baseline methods. We show that Clear achieves (1) optimal\nperformance over all baseline methods; (2) 9.73%-39.99% higher F1-score than\nexisting deep learning methods.",
      "authors": [
        "Yizhou Chen",
        "Zeyu Sun",
        "Zhihao Gong",
        "Dan Hao"
      ],
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17839v1",
        "http://arxiv.org/pdf/2404.17839v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17815v1",
      "title": "Learning-based Hierarchical Control: Emulating the Central Nervous\n  System for Bio-Inspired Legged Robot Locomotion",
      "published": "2024-04-27T07:47:55Z",
      "updated": "2024-04-27T07:47:55Z",
      "summary": "Animals possess a remarkable ability to navigate challenging terrains,\nachieved through the interplay of various pathways between the brain, central\npattern generators (CPGs) in the spinal cord, and musculoskeletal system.\nTraditional bioinspired control frameworks often rely on a singular control\npolicy that models both higher (supraspinal) and spinal cord functions. In this\nwork, we build upon our previous research by introducing two distinct neural\nnetworks: one tasked with modulating the frequency and amplitude of CPGs to\ngenerate the basic locomotor rhythm (referred to as the spinal policy, SCP),\nand the other responsible for receiving environmental perception data and\ndirectly modulating the rhythmic output from the SCP to execute precise\nmovements on challenging terrains (referred to as the descending modulation\npolicy). This division of labor more closely mimics the hierarchical locomotor\ncontrol systems observed in legged animals, thereby enhancing the robot's\nability to navigate various uneven surfaces, including steps, high obstacles,\nand terrains with gaps. Additionally, we investigate the impact of sensorimotor\ndelays within our framework, validating several biological assumptions about\nanimal locomotion systems. Specifically, we demonstrate that spinal circuits\nplay a crucial role in generating the basic locomotor rhythm, while descending\npathways are essential for enabling appropriate gait modifications to\naccommodate uneven terrain. Notably, our findings also reveal that the\nmulti-layered control inherent in animals exhibits remarkable robustness\nagainst time delays. Through these investigations, this paper contributes to a\ndeeper understanding of the fundamental principles of interplay between spinal\nand supraspinal mechanisms in biological locomotion. It also supports the\ndevelopment of locomotion controllers in parallel to biological structures\nwhich are ...",
      "authors": [
        "Ge Sun",
        "Milad Shafiee",
        "Peizhuo Li",
        "Guillaume Bellegarda",
        "Auke Ijspeert",
        "Guillaume Sartoretti"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17815v1",
        "http://arxiv.org/pdf/2404.17815v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.19641v1",
      "title": "Fast and label-free 3D virtual H&E histology via active\n  modulation-assisted dynamic full-field OCT",
      "published": "2024-04-27T03:22:10Z",
      "updated": "2024-04-27T03:22:10Z",
      "summary": "Pathological features are the gold standard for tumor diagnosis, guiding\ntreatment and prognosis. However, standard histopathological process is\nlabor-intensive and time-consuming, while frozen sections have lower accuracy.\nDynamic full-field optical coherence tomography (D-FFOCT) offers rapid\nhistologic information by measuring the subcellular dynamics of fresh,\nunprocessed tissues. However, D-FFOCT images suffer from abrupt shifts in hue\nand brightness, which is confusing for pathologists and diminish their\ninterpretability and reliability. Here, we present active phase\nmodulation-assisted D-FFOCT (APMD-FFOCT) to improve the imaging stability and\nenhance the contrast of static tissues. This enables us to further employ an\nunsupervised deep learning to convert APMD-FFOCT images into virtual\nhematoxylin and eosin (H&E) stained images for the first time.\nThree-dimensional (3D) virtual H&E-stained images have been obtained at a\nscanning rate of 1 frame per second, as demonstrated in cancer diagnosis for\nhuman central nervous system and breast. The results prove that this new method\nwill play a unique and important role in intraoperative histology.",
      "authors": [
        "Zichen Yin",
        "Bin He",
        "Yuzhe Ying",
        "Shuwei Zhang",
        "Panqi Yang",
        "Zhengyu Chen",
        "Zhangwei Hu",
        "Yejiong Shi",
        "Ruizhi Xue",
        "Chengming Wang",
        "Shu Wang",
        "Guihuai Wang",
        "Ping Xue"
      ],
      "categories": [
        "physics.med-ph",
        "physics.bio-ph",
        "physics.optics"
      ],
      "links": [
        "http://arxiv.org/abs/2404.19641v1",
        "http://arxiv.org/pdf/2404.19641v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17683v1",
      "title": "Energy Storage Arbitrage in Two-settlement Markets: A Transformer-Based\n  Approach",
      "published": "2024-04-26T20:25:05Z",
      "updated": "2024-04-26T20:25:05Z",
      "summary": "This paper presents an integrated model for bidding energy storage in\nday-ahead and real-time markets to maximize profits. We show that in integrated\ntwo-stage bidding, the real-time bids are independent of day-ahead settlements,\nwhile the day-ahead bids should be based on predicted real-time prices. We\nutilize a transformer-based model for real-time price prediction, which\ncaptures complex dynamical patterns of real-time prices, and use the result for\nday-ahead bidding design. For real-time bidding, we utilize a long short-term\nmemory-dynamic programming hybrid real-time bidding model. We train and test\nour model with historical data from New York State, and our results showed that\nthe integrated system achieved promising results of almost a 20\\% increase in\nprofit compared to only bidding in real-time markets, and at the same time\nreducing the risk in terms of the number of days with negative profits.",
      "authors": [
        "Saud Alghumayjan",
        "Jiajun Han",
        "Ningkun Zheng",
        "Ming Yi",
        "Bolun Xu"
      ],
      "categories": [
        "math.OC",
        "cs.GT",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17683v1",
        "http://arxiv.org/pdf/2404.17683v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17673v1",
      "title": "Learning Manipulation Tasks in Dynamic and Shared 3D Spaces",
      "published": "2024-04-26T19:40:19Z",
      "updated": "2024-04-26T19:40:19Z",
      "summary": "Automating the segregation process is a need for every sector experiencing a\nhigh volume of materials handling, repetitive and exhaustive operations, in\naddition to risky exposures. Learning automated pick-and-place operations can\nbe efficiently done by introducing collaborative autonomous systems (e.g.\nmanipulators) in the workplace and among human operators. In this paper, we\npropose a deep reinforcement learning strategy to learn the place task of\nmulti-categorical items from a shared workspace between dual-manipulators and\nto multi-goal destinations, assuming the pick has been already completed. The\nlearning strategy leverages first a stochastic actor-critic framework to train\nan agent's policy network, and second, a dynamic 3D Gym environment where both\nstatic and dynamic obstacles (e.g. human factors and robot mate) constitute the\nstate space of a Markov decision process. Learning is conducted in a Gazebo\nsimulator and experiments show an increase in cumulative reward function for\nthe agent further away from human factors. Future investigations will be\nconducted to enhance the task performance for both agents simultaneously.",
      "authors": [
        "Hariharan Arunachalam",
        "Marc Hanheide",
        "Sariah Mghames"
      ],
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17673v1",
        "http://arxiv.org/pdf/2404.17673v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17546v1",
      "title": "Probabilistic Inference in Language Models via Twisted Sequential Monte\n  Carlo",
      "published": "2024-04-26T17:18:32Z",
      "updated": "2024-04-26T17:18:32Z",
      "summary": "Numerous capability and safety techniques of Large Language Models (LLMs),\nincluding RLHF, automated red-teaming, prompt engineering, and infilling, can\nbe cast as sampling from an unnormalized target distribution defined by a given\nreward or potential function over the full sequence. In this work, we leverage\nthe rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic\ninference problems. In particular, we use learned twist functions to estimate\nthe expected future value of the potential at each timestep, which enables us\nto focus inference-time computation on promising partial sequences. We propose\na novel contrastive method for learning the twist functions, and establish\nconnections with the rich literature of soft reinforcement learning. As a\ncomplementary application of our twisted SMC framework, we present methods for\nevaluating the accuracy of language model inference techniques using novel\nbidirectional SMC bounds on the log partition function. These bounds can be\nused to estimate the KL divergence between the inference and target\ndistributions in both directions. We apply our inference evaluation techniques\nto show that twisted SMC is effective for sampling undesirable outputs from a\npretrained model (a useful component of harmlessness training and automated\nred-teaming), generating reviews with varied sentiment, and performing\ninfilling tasks.",
      "authors": [
        "Stephen Zhao",
        "Rob Brekelmans",
        "Alireza Makhzani",
        "Roger Grosse"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17546v1",
        "http://arxiv.org/pdf/2404.17546v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17525v2",
      "title": "Large Language Model Agent as a Mechanical Designer",
      "published": "2024-04-26T16:41:24Z",
      "updated": "2024-05-09T15:31:08Z",
      "summary": "Conventional mechanical design paradigms rely on experts systematically\nrefining concepts through experience-guided modification and FEA to meet\nspecific requirements. However, this approach can be time-consuming and heavily\ndependent on prior knowledge and experience. While numerous machine learning\nmodels have been developed to streamline this intensive and expert-driven\niterative process, these methods typically demand extensive training data and\nconsiderable computational resources. Furthermore, methods based on deep\nlearning are usually restricted to the specific domains and tasks for which\nthey were trained, limiting their applicability across different tasks. This\ncreates a trade-off between the efficiency of automation and the demand for\nresources. In this study, we present a novel approach that integrates\npre-trained LLMs with a FEM module. The FEM module evaluates each design and\nprovides essential feedback, guiding the LLMs to continuously learn, plan,\ngenerate, and optimize designs without the need for domain-specific training.\nWe demonstrate the effectiveness of our proposed framework in managing the\niterative optimization of truss structures, showcasing its capability to reason\nabout and refine designs according to structured feedback and criteria. Our\nresults reveal that these LLM-based agents can successfully generate truss\ndesigns that comply with natural language specifications with a success rate of\nup to 90%, which varies according to the applied constraints. By employing\nprompt-based optimization techniques we show that LLM based agents exhibit\noptimization behavior when provided with solution-score pairs to iteratively\nrefine designs to meet specifications. This ability of LLM agents to produce\nviable designs and optimize them based on their inherent reasoning capabilities\nhighlights their potential to develop and implement effective design strategies\nautonomously.",
      "authors": [
        "Yayati Jadhav",
        "Amir Barati Farimani"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17525v2",
        "http://arxiv.org/pdf/2404.17525v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2404.17521v1",
      "title": "Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual\n  and Action Representations",
      "published": "2024-04-26T16:40:17Z",
      "updated": "2024-04-26T16:40:17Z",
      "summary": "Autonomous robotic systems capable of learning novel manipulation tasks are\npoised to transform industries from manufacturing to service automation.\nHowever, modern methods (e.g., VIP and R3M) still face significant hurdles,\nnotably the domain gap among robotic embodiments and the sparsity of successful\ntask executions within specific action spaces, resulting in misaligned and\nambiguous task representations. We introduce Ag2Manip (Agent-Agnostic\nrepresentations for Manipulation), a framework aimed at surmounting these\nchallenges through two key innovations: a novel agent-agnostic visual\nrepresentation derived from human manipulation videos, with the specifics of\nembodiments obscured to enhance generalizability; and an agent-agnostic action\nrepresentation abstracting a robot's kinematics to a universal agent proxy,\nemphasizing crucial interactions between end-effector and object. Ag2Manip's\nempirical validation across simulated benchmarks like FrankaKitchen, ManiSkill,\nand PartManip shows a 325% increase in performance, achieved without\ndomain-specific demonstrations. Ablation studies underline the essential\ncontributions of the visual and action representations to this success.\nExtending our evaluations to the real world, Ag2Manip significantly improves\nimitation learning success rates from 50% to 77.5%, demonstrating its\neffectiveness and generalizability across both simulated and physical\nenvironments.",
      "authors": [
        "Puhao Li",
        "Tengyu Liu",
        "Yuyang Li",
        "Muzhi Han",
        "Haoran Geng",
        "Shu Wang",
        "Yixin Zhu",
        "Song-Chun Zhu",
        "Siyuan Huang"
      ],
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2404.17521v1",
        "http://arxiv.org/pdf/2404.17521v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}