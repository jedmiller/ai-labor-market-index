{
  "query": "all:machine learning AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-03-21T23:03:10.414921",
  "target_period": "2024-10",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2411.00217v1",
      "title": "ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated\n  Distributed Adaptive Penetration Testing",
      "published": "2024-10-31T21:32:17Z",
      "updated": "2024-10-31T21:32:17Z",
      "summary": "The integration of AI into modern critical infrastructure systems, such as\nhealthcare, has introduced new vulnerabilities that can significantly impact\nworkflow, efficiency, and safety. Additionally, the increased connectivity has\nmade traditional human-driven penetration testing insufficient for assessing\nrisks and developing remediation strategies. Consequently, there is a pressing\nneed for a distributed, adaptive, and efficient automated penetration testing\nframework that not only identifies vulnerabilities but also provides\ncountermeasures to enhance security posture. This work presents ADAPT, a\ngame-theoretic and neuro-symbolic framework for automated distributed adaptive\npenetration testing, specifically designed to address the unique cybersecurity\nchallenges of AI-enabled healthcare infrastructure networks. We use a\nhealthcare system case study to illustrate the methodologies within ADAPT. The\nproposed solution enables a learning-based risk assessment. Numerical\nexperiments are used to demonstrate effective countermeasures against various\ntactical techniques employed by adversarial AI.",
      "authors": [
        "Haozhe Lei",
        "Yunfei Ge",
        "Quanyan Zhu"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.GT"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00217v1",
        "http://arxiv.org/pdf/2411.00217v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00200v1",
      "title": "MEDS-Tab: Automated tabularization and baseline methods for MEDS\n  datasets",
      "published": "2024-10-31T20:36:37Z",
      "updated": "2024-10-31T20:36:37Z",
      "summary": "Effective, reliable, and scalable development of machine learning (ML)\nsolutions for structured electronic health record (EHR) data requires the\nability to reliably generate high-quality baseline models for diverse\nsupervised learning tasks in an efficient and performant manner. Historically,\nproducing such baseline models has been a largely manual effort--individual\nresearchers would need to decide on the particular featurization and\ntabularization processes to apply to their individual raw, longitudinal data;\nand then train a supervised model over those data to produce a baseline result\nto compare novel methods against, all for just one task and one dataset. In\nthis work, powered by complementary advances in core data standardization\nthrough the MEDS framework, we dramatically simplify and accelerate this\nprocess of tabularizing irregularly sampled time-series data, providing\nresearchers the ability to automatically and scalably featurize and tabularize\ntheir longitudinal EHR data across tens of thousands of individual features,\nhundreds of millions of clinical events, and diverse windowing horizons and\naggregation strategies, all before ultimately leveraging these tabular data to\nautomatically produce high-caliber XGBoost baselines in a highly\ncomputationally efficient manner. This system scales to dramatically larger\ndatasets than tabularization tools currently available to the community and\nenables researchers with any MEDS format dataset to immediately begin producing\nreliable and performant baseline prediction results on various tasks, with\nminimal human effort required. This system will greatly enhance the\nreliability, reproducibility, and ease of development of powerful ML solutions\nfor health problems across diverse datasets and clinical settings.",
      "authors": [
        "Nassim Oufattole",
        "Teya Bergamaschi",
        "Aleksia Kolo",
        "Hyewon Jeong",
        "Hanna Gaggin",
        "Collin M. Stultz",
        "Matthew B. A. McDermott"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00200v1",
        "http://arxiv.org/pdf/2411.00200v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00173v1",
      "title": "Beyond Label Attention: Transparency in Language Models for Automated\n  Medical Coding via Dictionary Learning",
      "published": "2024-10-31T19:39:40Z",
      "updated": "2024-10-31T19:39:40Z",
      "summary": "Medical coding, the translation of unstructured clinical text into\nstandardized medical codes, is a crucial but time-consuming healthcare\npractice. Though large language models (LLM) could automate the coding process\nand improve the efficiency of such tasks, interpretability remains paramount\nfor maintaining patient trust. Current efforts in interpretability of medical\ncoding applications rely heavily on label attention mechanisms, which often\nleads to the highlighting of extraneous tokens irrelevant to the ICD code. To\nfacilitate accurate interpretability in medical language models, this paper\nleverages dictionary learning that can efficiently extract sparsely activated\nrepresentations from dense language model embeddings in superposition. Compared\nwith common label attention mechanisms, our model goes beyond token-level\nrepresentations by building an interpretable dictionary which enhances the\nmechanistic-based explanations for each ICD code prediction, even when the\nhighlighted tokens are medically irrelevant. We show that dictionary features\ncan steer model behavior, elucidate the hidden meanings of upwards of 90% of\nmedically irrelevant tokens, and are human interpretable.",
      "authors": [
        "John Wu",
        "David Wu",
        "Jimeng Sun"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00173v1",
        "http://arxiv.org/pdf/2411.00173v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00137v1",
      "title": "Cost-Aware Query Policies in Active Learning for Efficient Autonomous\n  Robotic Exploration",
      "published": "2024-10-31T18:35:03Z",
      "updated": "2024-10-31T18:35:03Z",
      "summary": "In missions constrained by finite resources, efficient data collection is\ncritical. Informative path planning, driven by automated decision-making,\noptimizes exploration by reducing the costs associated with accurate\ncharacterization of a target in an environment. Previous implementations of\nactive learning did not consider the action cost for regression problems or\nonly considered the action cost for classification problems. This paper\nanalyzes an AL algorithm for Gaussian Process regression while incorporating\naction cost. The algorithm's performance is compared on various regression\nproblems to include terrain mapping on diverse simulated surfaces along metrics\nof root mean square error, samples and distance until convergence, and model\nvariance upon convergence. The cost-dependent acquisition policy doesn't\norganically optimize information gain over distance. Instead, the traditional\nuncertainty metric with a distance constraint best minimizes root-mean-square\nerror over trajectory distance. This studys impact is to provide insight into\nincorporating action cost with AL methods to optimize exploration under\nrealistic mission constraints.",
      "authors": [
        "Sapphira Akins",
        "Hans Mertens",
        "Frances Zhu"
      ],
      "categories": [
        "cs.RO",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00137v1",
        "http://arxiv.org/pdf/2411.00137v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.24185v2",
      "title": "DexMimicGen: Automated Data Generation for Bimanual Dexterous\n  Manipulation via Imitation Learning",
      "published": "2024-10-31T17:48:45Z",
      "updated": "2025-03-06T05:34:17Z",
      "summary": "Imitation learning from human demonstrations is an effective means to teach\nrobots manipulation skills. But data acquisition is a major bottleneck in\napplying this paradigm more broadly, due to the amount of cost and human effort\ninvolved. There has been significant interest in imitation learning for\nbimanual dexterous robots, like humanoids. Unfortunately, data collection is\neven more challenging here due to the challenges of simultaneously controlling\nmultiple arms and multi-fingered hands. Automated data generation in simulation\nis a compelling, scalable alternative to fuel this need for data. To this end,\nwe introduce DexMimicGen, a large-scale automated data generation system that\nsynthesizes trajectories from a handful of human demonstrations for humanoid\nrobots with dexterous hands. We present a collection of simulation environments\nin the setting of bimanual dexterous manipulation, spanning a range of\nmanipulation behaviors and different requirements for coordination among the\ntwo arms. We generate 21K demos across these tasks from just 60 source human\ndemos and study the effect of several data generation and policy learning\ndecisions on agent performance. Finally, we present a real-to-sim-to-real\npipeline and deploy it on a real-world humanoid can sorting task. Generated\ndatasets, simulation environments and additional results are at\nhttps://dexmimicgen.github.io/",
      "authors": [
        "Zhenyu Jiang",
        "Yuqi Xie",
        "Kevin Lin",
        "Zhenjia Xu",
        "Weikang Wan",
        "Ajay Mandlekar",
        "Linxi Fan",
        "Yuke Zhu"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.24185v2",
        "http://arxiv.org/pdf/2410.24185v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.24184v2",
      "title": "Group Crosscoders for Mechanistic Analysis of Symmetry",
      "published": "2024-10-31T17:47:01Z",
      "updated": "2024-11-01T03:29:29Z",
      "summary": "We introduce group crosscoders, an extension of crosscoders that\nsystematically discover and analyse symmetrical features in neural networks.\nWhile neural networks often develop equivariant representations without\nexplicit architectural constraints, understanding these emergent symmetries has\ntraditionally relied on manual analysis. Group crosscoders automate this\nprocess by performing dictionary learning across transformed versions of inputs\nunder a symmetry group. Applied to InceptionV1's mixed3b layer using the\ndihedral group $\\mathrm{D}_{32}$, our method reveals several key insights:\nFirst, it naturally clusters features into interpretable families that\ncorrespond to previously hypothesised feature types, providing more precise\nseparation than standard sparse autoencoders. Second, our transform block\nanalysis enables the automatic characterisation of feature symmetries,\nrevealing how different geometric features (such as curves versus lines)\nexhibit distinct patterns of invariance and equivariance. These results\ndemonstrate that group crosscoders can provide systematic insights into how\nneural networks represent symmetry, offering a promising new tool for\nmechanistic interpretability.",
      "authors": [
        "Liv Gorton"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.24184v2",
        "http://arxiv.org/pdf/2410.24184v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.24117v3",
      "title": "Repository-Level Compositional Code Translation and Validation",
      "published": "2024-10-31T16:46:52Z",
      "updated": "2025-02-24T21:17:25Z",
      "summary": "Code translation transforms programs from one programming language (PL) to\nanother. Several rule-based transpilers have been designed to automate code\ntranslation between different pairs of PLs. However, the rules can become\nobsolete as the PLs evolve and cannot generalize to other PLs. Recent studies\nhave explored the automation of code translation using Large Language Models\n(LLMs). One key observation is that such techniques may work well for crafted\nbenchmarks but fail to generalize to the scale and complexity of real-world\nprojects with dependencies, custom types, PL-specific features, etc.\n  We propose AlphaTrans, a neuro-symbolic approach to automate repository-level\ncode translation. AlphaTrans translates both source and test code, and employs\nmultiple levels of validation to ensure the translation preserves the\nfunctionality of the source program. To break down the problem for LLMs,\nAlphaTrans leverages program analysis to decompose the program into fragments\nand translates them in the reverse call order. We leveraged AlphaTrans to\ntranslate ten real-world open-source projects consisting of <836, 8575, 2719>\nclasses, methods, and tests. AlphaTrans breaks down these projects into 17874\nfragments and translates the entire repository. 96.40% of the translated\nfragments are syntactically correct, and AlphaTrans validates the translations'\nruntime behavior and functional correctness for 27.03% and 25.14% of fragments.\nOn average, the integrated translation and validation take 34 hours to\ntranslate a project, showing its scalability in practice. For the incorrect\ntranslations, AlphaTrans generates a report including existing translation,\nstack trace, test errors, or assertion failures. We provided these artifacts to\ntwo developers to fix the translation bugs in four projects. They were able to\nfix the issues in 20.1 hours on average and achieve all passing tests.",
      "authors": [
        "Ali Reza Ibrahimzada",
        "Kaiyao Ke",
        "Mrigank Pawagi",
        "Muhammad Salman Abid",
        "Rangeet Pan",
        "Saurabh Sinha",
        "Reyhaneh Jabbarvand"
      ],
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.24117v3",
        "http://arxiv.org/pdf/2410.24117v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.24105v1",
      "title": "Matchmaker: Self-Improving Large Language Model Programs for Schema\n  Matching",
      "published": "2024-10-31T16:34:03Z",
      "updated": "2024-10-31T16:34:03Z",
      "summary": "Schema matching -- the task of finding matches between attributes across\ndisparate data sources with different tables and hierarchies -- is critical for\ncreating interoperable machine learning (ML)-ready data. Addressing this\nfundamental data-centric problem has wide implications, especially in domains\nlike healthcare, finance and e-commerce -- but also has the potential to\nbenefit ML models more generally, by increasing the data available for ML model\ntraining. However, schema matching is a challenging ML task due to\nstructural/hierarchical and semantic heterogeneity between different schemas.\nPrevious ML approaches to automate schema matching have either required\nsignificant labeled data for model training, which is often unrealistic or\nsuffer from poor zero-shot performance. To this end, we propose Matchmaker - a\ncompositional language model program for schema matching, comprised of\ncandidate generation, refinement and confidence scoring. Matchmaker also\nself-improves in a zero-shot manner without the need for labeled demonstrations\nvia a novel optimization approach, which constructs synthetic in-context\ndemonstrations to guide the language model's reasoning process. Empirically, we\ndemonstrate on real-world medical schema matching benchmarks that Matchmaker\noutperforms previous ML-based approaches, highlighting its potential to\naccelerate data integration and interoperability of ML-ready data.",
      "authors": [
        "Nabeel Seedat",
        "Mihaela van der Schaar"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.24105v1",
        "http://arxiv.org/pdf/2410.24105v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.24098v1",
      "title": "Parameter choices in HaarPSI for IQA with medical images",
      "published": "2024-10-31T16:28:49Z",
      "updated": "2024-10-31T16:28:49Z",
      "summary": "When developing machine learning models, image quality assessment (IQA)\nmeasures are a crucial component for evaluation. However, commonly used IQA\nmeasures have been primarily developed and optimized for natural images. In\nmany specialized settings, such as medical images, this poses an\noften-overlooked problem regarding suitability. In previous studies, the IQA\nmeasure HaarPSI showed promising behavior for natural and medical images.\nHaarPSI is based on Haar wavelet representations and the framework allows\noptimization of two parameters. So far, these parameters have been aligned for\nnatural images. Here, we optimize these parameters for two annotated medical\ndata sets, a photoacoustic and a chest X-Ray data set. We observe that they are\nmore sensitive to the parameter choices than the employed natural images, and\non the other hand both medical data sets lead to similar parameter values when\noptimized. We denote the optimized setting, which improves the performance for\nthe medical images notably, by HaarPSI$_{MED}$. The results suggest that\nadapting common IQA measures within their frameworks for medical images can\nprovide a valuable, generalizable addition to the employment of more specific\ntask-based measures.",
      "authors": [
        "Clemens Karner",
        "Janek Gr\u00f6hl",
        "Ian Selby",
        "Judith Babar",
        "Jake Beckford",
        "Thomas R Else",
        "Timothy J Sadler",
        "Shahab Shahipasand",
        "Arthikkaa Thavakumar",
        "Michael Roberts",
        "James H. F. Rudd",
        "Carola-Bibiane Sch\u00f6nlieb",
        "Jonathan R Weir-McCall",
        "Anna Breger"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2410.24098v1",
        "http://arxiv.org/pdf/2410.24098v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23916v1",
      "title": "Transformer-based Model Predictive Control: Trajectory Optimization via\n  Sequence Modeling",
      "published": "2024-10-31T13:23:10Z",
      "updated": "2024-10-31T13:23:10Z",
      "summary": "Model predictive control (MPC) has established itself as the primary\nmethodology for constrained control, enabling general-purpose robot autonomy in\ndiverse real-world scenarios. However, for most problems of interest, MPC\nrelies on the recursive solution of highly non-convex trajectory optimization\nproblems, leading to high computational complexity and strong dependency on\ninitialization. In this work, we present a unified framework to combine the\nmain strengths of optimization-based and learning-based methods for MPC. Our\napproach entails embedding high-capacity, transformer-based neural network\nmodels within the optimization process for trajectory generation, whereby the\ntransformer provides a near-optimal initial guess, or target plan, to a\nnon-convex optimization problem. Our experiments, performed in simulation and\nthe real world onboard a free flyer platform, demonstrate the capabilities of\nour framework to improve MPC convergence and runtime. Compared to purely\noptimization-based approaches, results show that our approach can improve\ntrajectory generation performance by up to 75%, reduce the number of solver\niterations by up to 45%, and improve overall MPC runtime by 7x without loss in\nperformance.",
      "authors": [
        "Davide Celestini",
        "Daniele Gammelli",
        "Tommaso Guffanti",
        "Simone D'Amico",
        "Elisa Capello",
        "Marco Pavone"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.OC"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3466069",
        "http://arxiv.org/abs/2410.23916v1",
        "http://arxiv.org/pdf/2410.23916v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23894v1",
      "title": "Metamorphic Malware Evolution: The Potential and Peril of Large Language\n  Models",
      "published": "2024-10-31T12:53:56Z",
      "updated": "2024-10-31T12:53:56Z",
      "summary": "Code metamorphism refers to a computer programming exercise wherein the\nprogram modifies its own code (partial or entire) consistently and\nautomatically while retaining its core functionality. This technique is often\nused for online performance optimization and automated crash recovery in\ncertain mission-critical applications. However, the technique has been\nmisappropriated by malware creators to bypass signature-based detection\nmeasures instituted by anti-malware engines. However, current code mutation\nengines used by threat actors offer only a limited degree of mutation, which is\nfrequently detectable via static code analysis. The advent of large language\nmodels (LLMs), such as ChatGPT 4.0 and Google Bard may lead to a significant\nevolution in this landscape. These models have demonstrated a level of\nalgorithm comprehension and code synthesis capability that closely resembles\nhuman abilities. This advancement has sparked concerns among experts that such\nmodels could be exploited by threat actors to generate sophisticated\nmetamorphic malware. This paper explores the potential of several prominent\nLLMs for software code mutation that may be used to reconstruct (with mutation)\nexisting malware code bases or create new forms of embedded mutation engines\nfor next-gen metamorphic malwares. In this work, we introduce a framework for\ncreating self-testing program mutation engines based on LLM/Transformer-based\nmodels. The proposed framework serves as an essential tool in testing next-gen\nmetamorphic malware detection engines.",
      "authors": [
        "Pooria Madani"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://dx.doi.org/10.1109/TPS-ISA58951.2023.00019",
        "http://arxiv.org/abs/2410.23894v1",
        "http://arxiv.org/pdf/2410.23894v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23866v1",
      "title": "Evaluating and Improving ChatGPT-Based Expansion of Abbreviations",
      "published": "2024-10-31T12:20:24Z",
      "updated": "2024-10-31T12:20:24Z",
      "summary": "Source code identifiers often contain abbreviations. Such abbreviations may\nreduce the readability of the source code, which in turn hinders the\nmaintenance of the software applications. To this end, accurate and automated\napproaches to expanding abbreviations in source code are desirable and\nabbreviation expansion has been intensively investigated. However, to the best\nof our knowledge, most existing approaches are heuristics, and none of them has\neven employed deep learning techniques, let alone the most advanced large\nlanguage models (LLMs). LLMs have demonstrated cutting-edge performance in\nvarious software engineering tasks, and thus it has the potential to expand\nabbreviation automatically. To this end, in this paper, we present the first\nempirical study on LLM-based abbreviation expansion. Our evaluation results on\na public benchmark suggest that ChatGPT is substantially less accurate than the\nstate-of-the-art approach, reducing precision and recall by 28.2\\% and 27.8\\%,\nrespectively. We manually analyzed the failed cases, and discovered the root\ncauses for the failures: 1) Lack of contexts and 2) Inability to recognize\nabbreviations. In response to the first cause, we investigated the effect of\nvarious contexts and found surrounding source code is the best selection. In\nresponse to the second cause, we designed an iterative approach that identifies\nand explicitly marks missed abbreviations in prompts. Finally, we proposed a\npost-condition checking to exclude incorrect expansions that violate\ncommonsense. All such measures together make ChatGPT-based abbreviation\nexpansion comparable to the state of the art while avoiding expensive source\ncode parsing and deep analysis that are indispensable for state-of-the-art\napproaches.",
      "authors": [
        "Yanjie Jiang",
        "Hui Liu",
        "Lu Zhang"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23866v1",
        "http://arxiv.org/pdf/2410.23866v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00876v1",
      "title": "Resilience to the Flowing Unknown: an Open Set Recognition Framework for\n  Data Streams",
      "published": "2024-10-31T11:06:54Z",
      "updated": "2024-10-31T11:06:54Z",
      "summary": "Modern digital applications extensively integrate Artificial Intelligence\nmodels into their core systems, offering significant advantages for automated\ndecision-making. However, these AI-based systems encounter reliability and\nsafety challenges when handling continuously generated data streams in complex\nand dynamic scenarios. This work explores the concept of resilient AI systems,\nwhich must operate in the face of unexpected events, including instances that\nbelong to patterns that have not been seen during the training process. This is\nan issue that regular closed-set classifiers commonly encounter in streaming\nscenarios, as they are designed to compulsory classify any new observation into\none of the training patterns (i.e., the so-called \\textit{over-occupied space}\nproblem). In batch learning, the Open Set Recognition research area has\nconsistently confronted this issue by requiring models to robustly uphold their\nclassification performance when processing query instances from unknown\npatterns. In this context, this work investigates the application of an Open\nSet Recognition framework that combines classification and clustering to\naddress the \\textit{over-occupied space} problem in streaming scenarios.\nSpecifically, we systematically devise a benchmark comprising different\nclassification datasets with varying ratios of known to unknown classes.\nExperiments are presented on this benchmark to compare the performance of the\nproposed hybrid framework with that of individual incremental classifiers.\nDiscussions held over the obtained results highlight situations where the\nproposed framework performs best, and delineate the limitations and hurdles\nencountered by incremental classifiers in effectively resolving the challenges\nposed by open-world streaming environments.",
      "authors": [
        "Marcos Barcina-Blanco",
        "Jesus L. Lobo",
        "Pablo Garcia-Bringas",
        "Javier Del Ser"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "links": [
        "http://dx.doi.org/10.1007/978-3-031-74183-8_12",
        "http://arxiv.org/abs/2411.00876v1",
        "http://arxiv.org/pdf/2411.00876v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23584v1",
      "title": "End-to-End Ontology Learning with Large Language Models",
      "published": "2024-10-31T02:52:39Z",
      "updated": "2024-10-31T02:52:39Z",
      "summary": "Ontologies are useful for automatic machine processing of domain knowledge as\nthey represent it in a structured format. Yet, constructing ontologies requires\nsubstantial manual effort. To automate part of this process, large language\nmodels (LLMs) have been applied to solve various subtasks of ontology learning.\nHowever, this partial ontology learning does not capture the interactions\nbetween subtasks. We address this gap by introducing OLLM, a general and\nscalable method for building the taxonomic backbone of an ontology from\nscratch. Rather than focusing on subtasks, like individual relations between\nentities, we model entire subcomponents of the target ontology by finetuning an\nLLM with a custom regulariser that reduces overfitting on high-frequency\nconcepts. We introduce a novel suite of metrics for evaluating the quality of\nthe generated ontology by measuring its semantic and structural similarity to\nthe ground truth. In contrast to standard metrics, our metrics use deep\nlearning techniques to define more robust distance measures between graphs.\nBoth our quantitative and qualitative results on Wikipedia show that OLLM\noutperforms subtask composition methods, producing more semantically accurate\nontologies while maintaining structural integrity. We further demonstrate that\nour model can be effectively adapted to new domains, like arXiv, needing only a\nsmall number of training examples. Our source code and datasets are available\nat https://github.com/andylolu2/ollm.",
      "authors": [
        "Andy Lo",
        "Albert Q. Jiang",
        "Wenda Li",
        "Mateja Jamnik"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23584v1",
        "http://arxiv.org/pdf/2410.23584v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23578v1",
      "title": "Automating Quantum Software Maintenance: Flakiness Detection and Root\n  Cause Analysis",
      "published": "2024-10-31T02:43:04Z",
      "updated": "2024-10-31T02:43:04Z",
      "summary": "Flaky tests, which pass or fail inconsistently without code changes, are a\nmajor challenge in software engineering in general and in quantum software\nengineering in particular due to their complexity and probabilistic nature,\nleading to hidden issues and wasted developer effort.\n  We aim to create an automated framework to detect flaky tests in quantum\nsoftware and an extended dataset of quantum flaky tests, overcoming the\nlimitations of manual methods.\n  Building on prior manual analysis of 14 quantum software repositories, we\nexpanded the dataset and automated flaky test detection using transformers and\ncosine similarity. We conducted experiments with Large Language Models (LLMs)\nfrom the OpenAI GPT and Meta LLaMA families to assess their ability to detect\nand classify flaky tests from code and issue descriptions.\n  Embedding transformers proved effective: we identified 25 new flaky tests,\nexpanding the dataset by 54%. Top LLMs achieved an F1-score of 0.8871 for\nflakiness detection but only 0.5839 for root cause identification.\n  We introduced an automated flaky test detection framework using machine\nlearning, showing promising results but highlighting the need for improved root\ncause detection and classification in large quantum codebases. Future work will\nfocus on improving detection techniques and developing automatic flaky test\nfixes.",
      "authors": [
        "Janakan Sivaloganathan",
        "Ainaz Jamshidi",
        "Andriy Miranskyy",
        "Lei Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23578v1",
        "http://arxiv.org/pdf/2410.23578v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23535v1",
      "title": "Simulating User Agents for Embodied Conversational-AI",
      "published": "2024-10-31T00:56:08Z",
      "updated": "2024-10-31T00:56:08Z",
      "summary": "Embodied agents designed to assist users with tasks must engage in natural\nlanguage interactions, interpret instructions, execute actions, and communicate\neffectively to resolve issues. However, collecting large-scale, diverse\ndatasets of situated human-robot dialogues to train and evaluate such agents is\nexpensive, labor-intensive, and time-consuming. To address this challenge, we\npropose building a large language model (LLM)-based user agent that can\nsimulate user behavior during interactions with an embodied agent in a virtual\nenvironment. Given a user goal (e.g., make breakfast), at each time step, the\nuser agent may observe\" the robot actions or speak\" to either intervene with\nthe robot or answer questions. Such a user agent assists in improving the\nscalability and efficiency of embodied dialogues dataset generation and is\ncritical for enhancing and evaluating the robot's interaction and task\ncompletion ability, as well as for research in reinforcement learning using AI\nfeedback. We evaluate our user agent's ability to generate human-like behaviors\nby comparing its simulated dialogues with the TEACh dataset. We perform three\nexperiments: zero-shot prompting to predict dialogue acts, few-shot prompting,\nand fine-tuning on the TEACh training subset. Results show the LLM-based user\nagent achieves an F-measure of 42% with zero-shot prompting and 43.4% with\nfew-shot prompting in mimicking human speaking behavior. Through fine-tuning,\nperformance in deciding when to speak remained stable, while deciding what to\nsay improved from 51.1% to 62.5%. These findings showcase the feasibility of\nthe proposed approach for assessing and enhancing the effectiveness of robot\ntask completion through natural language communication.",
      "authors": [
        "Daniel Philipov",
        "Vardhan Dongre",
        "Gokhan Tur",
        "Dilek Hakkani-T\u00fcr"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23535v1",
        "http://arxiv.org/pdf/2410.23535v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23443v1",
      "title": "The Transformative Impact of AI and Deep Learning in Business: A\n  Literature Review",
      "published": "2024-10-30T20:35:03Z",
      "updated": "2024-10-30T20:35:03Z",
      "summary": "This paper aims to review the radical role of AI and deep learning in various\nfunctional areas of the business, such as marketing, finance, operations, human\nresources and customer service. Thus, based on the overview of the latest\nresearch and practices focusing on AI technologies in different industries, the\npossibilities of improving organizational efficiency by personalized AI for\nmaking decisions based on big data and personalizing clients' interactions with\norganizations are presented and discussed. Several operational issues, ethical\nconcerns, and regulatory concerns have also been discussed in the review of the\nliterature. Moreover, it covers material applications in the healthcare sector,\nthe retail and manufacturing industry, agriculture and farming, and finance\nbefore considering possible future developments and themes for further\ninvestigation. Drawing from this revolutionary ethnographic review,\norganizations aiming to implement strategic and responsible optimization\nbenefit from detailed guides.",
      "authors": [
        "Fabio S. Dias",
        "Grace A. Lauretta"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23443v1",
        "http://arxiv.org/pdf/2410.23443v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23428v1",
      "title": "Learning for Deformable Linear Object Insertion Leveraging Flexibility\n  Estimation from Visual Cues",
      "published": "2024-10-30T20:13:40Z",
      "updated": "2024-10-30T20:13:40Z",
      "summary": "Manipulation of deformable Linear objects (DLOs), including iron wire,\nrubber, silk, and nylon rope, is ubiquitous in daily life. These objects\nexhibit diverse physical properties, such as Young$'$s modulus and bending\nstiffness.Such diversity poses challenges for developing generalized\nmanipulation policies. However, previous research limited their scope to\nsingle-material DLOs and engaged in time-consuming data collection for the\nstate estimation. In this paper, we propose a two-stage manipulation approach\nconsisting of a material property (e.g., flexibility) estimation and policy\nlearning for DLO insertion with reinforcement learning. Firstly, we design a\nflexibility estimation scheme that characterizes the properties of different\ntypes of DLOs. The ground truth flexibility data is collected in simulation to\ntrain our flexibility estimation module. During the manipulation, the robot\ninteracts with the DLOs to estimate flexibility by analyzing their visual\nconfigurations. Secondly, we train a policy conditioned on the estimated\nflexibility to perform challenging DLO insertion tasks. Our pipeline trained\nwith diverse insertion scenarios achieves an 85.6% success rate in simulation\nand 66.67% in real robot experiments. Please refer to our project page:\nhttps://lmeee.github.io/DLOInsert/",
      "authors": [
        "Mingen Li",
        "Changhyun Choi"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://dx.doi.org/10.1109/ICRA57147.2024.10610419",
        "http://arxiv.org/abs/2410.23428v1",
        "http://arxiv.org/pdf/2410.23428v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23419v1",
      "title": "Stepping Out of the Shadows: Reinforcement Learning in Shadow Mode",
      "published": "2024-10-30T19:52:52Z",
      "updated": "2024-10-30T19:52:52Z",
      "summary": "Reinforcement learning (RL) is not yet competitive for many cyber-physical\nsystems, such as robotics, process automation, and power systems, as training\non a system with physical components cannot be accelerated, and simulation\nmodels do not exist or suffer from a large simulation-to-reality gap. During\nthe long training time, expensive equipment cannot be used and might even be\ndamaged due to inappropriate actions of the reinforcement learning agent. Our\nnovel approach addresses exactly this problem: We train the reinforcement agent\nin a so-called shadow mode with the assistance of an existing conventional\ncontroller, which does not have to be trained and instantaneously performs\nreasonably well. In shadow mode, the agent relies on the controller to provide\naction samples and guidance towards favourable states to learn the task, while\nsimultaneously estimating for which states the learned agent will receive a\nhigher reward than the conventional controller. The RL agent will then control\nthe system for these states and all other regions remain under the control of\nthe existing controller. Over time, the RL agent will take over for an\nincreasing amount of states, while leaving control to the baseline, where it\ncannot surpass its performance. Thus, we keep regret during training low and\nimprove the performance compared to only using conventional controllers or\nreinforcement learning. We present and evaluate two mechanisms for deciding\nwhether to use the RL agent or the conventional controller. The usefulness of\nour approach is demonstrated for a reach-avoid task, for which we are able to\neffectively train an agent, where standard approaches fail.",
      "authors": [
        "Philipp Gassert",
        "Matthias Althoff"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23419v1",
        "http://arxiv.org/pdf/2410.23419v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23166v2",
      "title": "SciPIP: An LLM-based Scientific Paper Idea Proposer",
      "published": "2024-10-30T16:18:22Z",
      "updated": "2025-02-17T08:59:45Z",
      "summary": "The rapid advancement of large language models (LLMs) has opened new\npossibilities for automating the proposal of innovative scientific ideas. This\nprocess involves two key phases: literature retrieval and idea generation.\nHowever, existing approaches often fall short due to their reliance on\nkeyword-based search tools during the retrieval phase, which neglects crucial\nsemantic information and frequently results in incomplete retrieval outcomes.\nSimilarly, in the idea generation phase, current methodologies tend to depend\nsolely on the internal knowledge of LLMs or metadata from retrieved papers,\nthereby overlooking significant valuable insights contained within the full\ntexts. To address these limitations, we introduce SciPIP, an innovative\nframework designed to enhance the LLM-based proposal of scientific ideas\nthrough improvements in both literature retrieval and idea generation. Our\napproach begins with the construction of a comprehensive literature database\nthat supports advanced retrieval based not only on keywords but also on\nsemantics and citation relationships. This is complemented by the introduction\nof a multi-granularity retrieval algorithm aimed at ensuring more thorough and\nexhaustive retrieval results. For the idea generation phase, we propose a\ndual-path framework that effectively integrates both the content of retrieved\npapers and the extensive internal knowledge of LLMs. This integration\nsignificantly boosts the novelty, feasibility, and practical value of proposed\nideas. Our experiments, conducted across various domains such as natural\nlanguage processing and computer vision, demonstrate SciPIP's capability to\ngenerate a multitude of innovative and useful ideas. These findings underscore\nSciPIP's potential as a valuable tool for researchers seeking to advance their\nfields with groundbreaking concepts.",
      "authors": [
        "Wenxiao Wang",
        "Lihui Gu",
        "Liye Zhang",
        "Yunxiang Luo",
        "Yi Dai",
        "Chen Shen",
        "Liang Xie",
        "Binbin Lin",
        "Xiaofei He",
        "Jieping Ye"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23166v2",
        "http://arxiv.org/pdf/2410.23166v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23161v1",
      "title": "Energy-Efficient Intra-Domain Network Slicing for Multi-Layer\n  Orchestration in Intelligent-Driven Distributed 6G Networks: Learning Generic\n  Assignment Skills with Unsupervised Reinforcement Learning",
      "published": "2024-10-30T16:14:27Z",
      "updated": "2024-10-30T16:14:27Z",
      "summary": "Since the 6th Generation (6G) of wireless networks is expected to provide a\nnew level of network services and meet the emerging expectations of the future,\nit will be a complex and intricate networking system. 6Gs sophistication and\nrobustness will be accompanied by complexities, which will require novel\nstrategies to tackle them. This research work focuses on decentralized and\nmulti-level system models for 6G networks and proposes an energy efficient\nautomation strategy for edge domain management and Network Slicing (NS) with\nthe main objective of reducing the networks complexity by leveraging\nscalability, efficiency, and generalization. Accordingly, we propose a\npre-train phase to discover useful assignment skills in network edge domains by\nutilizing unsupervised Reinforcement Learning (unsupervised RL). The suggested\ntechnique does not depend on the domain specifications and thus is applicable\nto all the edge domains. Our proposed approach not only enables scalability and\ndecentralization, but it also delivers efficiency by assisting domain\ncontrollers to provide various service types. We implemented the pre-training\nphase, and monitored that the discovered assignment skills span the entire\ninterval of possible resource assignment portions for every service type.",
      "authors": [
        "Navideh Ghafouri",
        "John S. Vardakas",
        "Kostas Ramantas",
        "Christos Verikoukis"
      ],
      "categories": [
        "cs.NI"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23161v1",
        "http://arxiv.org/pdf/2410.23161v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00856v1",
      "title": "AI in Investment Analysis: LLMs for Equity Stock Ratings",
      "published": "2024-10-30T15:06:57Z",
      "updated": "2024-10-30T15:06:57Z",
      "summary": "Investment Analysis is a cornerstone of the Financial Services industry. The\nrapid integration of advanced machine learning techniques, particularly Large\nLanguage Models (LLMs), offers opportunities to enhance the equity rating\nprocess. This paper explores the application of LLMs to generate multi-horizon\nstock ratings by ingesting diverse datasets. Traditional stock rating methods\nrely heavily on the expertise of financial analysts, and face several\nchallenges such as data overload, inconsistencies in filings, and delayed\nreactions to market events. Our study addresses these issues by leveraging LLMs\nto improve the accuracy and consistency of stock ratings. Additionally, we\nassess the efficacy of using different data modalities with LLMs for the\nfinancial domain.\n  We utilize varied datasets comprising fundamental financial, market, and news\ndata from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a\ntraining cutoff in Sep. 2021 to prevent information leakage). Our results show\nthat our benchmark method outperforms traditional stock rating methods when\nassessed by forward returns, specially when incorporating financial\nfundamentals. While integrating news data improves short-term performance,\nsubstituting detailed news summaries with sentiment scores reduces token use\nwithout loss of performance. In many cases, omitting news data entirely\nenhances performance by reducing bias.\n  Our research shows that LLMs can be leveraged to effectively utilize large\namounts of multimodal financial data, as showcased by their effectiveness at\nthe stock rating prediction task. Our work provides a reproducible and\nefficient framework for generating accurate stock ratings, serving as a\ncost-effective alternative to traditional methods. Future work will extend to\nlonger timeframes, incorporate diverse data, and utilize newer models for\nenhanced insights.",
      "authors": [
        "Kassiani Papasotiriou",
        "Srijan Sood",
        "Shayleen Reynolds",
        "Tucker Balch"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "68T50, 91G60 (Primary) 68T07 (Secondary)",
        "I.2.7"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3677052.3698694",
        "http://arxiv.org/abs/2411.00856v1",
        "http://arxiv.org/pdf/2411.00856v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23008v2",
      "title": "SoundCollage: Automated Discovery of New Classes in Audio Datasets",
      "published": "2024-10-30T13:34:19Z",
      "updated": "2025-01-20T21:21:51Z",
      "summary": "Developing new machine learning applications often requires the collection of\nnew datasets. However, existing datasets may already contain relevant\ninformation to train models for new purposes. We propose SoundCollage: a\nframework to discover new classes within audio datasets by incorporating (1) an\naudio pre-processing pipeline to decompose different sounds in audio samples,\nand (2) an automated model-based annotation mechanism to identify the\ndiscovered classes. Furthermore, we introduce the clarity measure to assess the\ncoherence of the discovered classes for better training new downstream\napplications. Our evaluations show that the accuracy of downstream audio\nclassifiers within discovered class samples and a held-out dataset improves\nover the baseline by up to 34.7% and 4.5%, respectively. These results\nhighlight the potential of SoundCollage in making datasets reusable by labeling\nwith newly discovered classes. To encourage further research in this area, we\nopen-source our code at\nhttps://github.com/nokia-bell-labs/audio-class-discovery.",
      "authors": [
        "Ryuhaerang Choi",
        "Soumyajit Chatterjee",
        "Dimitris Spathis",
        "Sung-Ju Lee",
        "Fahim Kawsar",
        "Mohammad Malekzadeh"
      ],
      "categories": [
        "cs.SD",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23008v2",
        "http://arxiv.org/pdf/2410.23008v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22995v1",
      "title": "VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning",
      "published": "2024-10-30T13:19:44Z",
      "updated": "2024-10-30T13:19:44Z",
      "summary": "Although previous research on large language models (LLMs) and large\nmulti-modal models (LMMs) has systematically explored mathematical\nproblem-solving (MPS) within visual contexts, the analysis of how these models\nprocess visual information during problem-solving remains insufficient. To\naddress this gap, we present VisAidMath, a benchmark for evaluating the MPS\nprocess related to visual information. We follow a rigorous data curation\npipeline involving both automated processes and manual annotations to ensure\ndata quality and reliability. Consequently, this benchmark includes 1,200\nchallenging problems from various mathematical branches, vision-aid\nformulations, and difficulty levels, collected from diverse sources such as\ntextbooks, examination papers, and Olympiad problems. Based on the proposed\nbenchmark, we conduct comprehensive evaluations on ten mainstream LLMs and\nLMMs, highlighting deficiencies in the visual-aided reasoning process. For\nexample, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning\ntask, even with a drop of 2 points when provided with golden visual aids.\nIn-depth analysis reveals that the main cause of deficiencies lies in\nhallucination regarding the implicit visual reasoning process, shedding light\non future research directions in the visual-aided MPS process.",
      "authors": [
        "Jingkun Ma",
        "Runzhe Zhan",
        "Derek F. Wong",
        "Yang Li",
        "Di Sun",
        "Hou Pong Chan",
        "Lidia S. Chao"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22995v1",
        "http://arxiv.org/pdf/2410.22995v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22992v1",
      "title": "Dynamic Matching with Post-allocation Service and its Application to\n  Refugee Resettlement",
      "published": "2024-10-30T13:17:38Z",
      "updated": "2024-10-30T13:17:38Z",
      "summary": "Motivated by our collaboration with a major refugee resettlement agency in\nthe U.S., we study a dynamic matching problem where each new arrival (a refugee\ncase) must be matched immediately and irrevocably to one of the static\nresources (a location with a fixed annual quota). In addition to consuming the\nstatic resource, each case requires post-allocation service from a server, such\nas a translator. Given the time-consuming nature of service, a server may not\nbe available at a given time, thus we refer to it as a dynamic resource. Upon\nmatching, the case will wait to avail service in a first-come-first-serve\nmanner. Bursty matching to a location may result in undesirable congestion at\nits corresponding server. Consequently, the central planner (the agency) faces\na dynamic matching problem with an objective that combines the matching reward\n(captured by pair-specific employment outcomes) with the cost for congestion\nfor dynamic resources and over-allocation for the static ones. Motivated by the\nobserved fluctuations in the composition of refugee pools across the years, we\ndesign algorithms that do not rely on distributional knowledge constructed\nbased on past years' data. To that end, we develop learning-based algorithms\nthat are asymptotically optimal in certain regimes, easy to interpret, and\ncomputationally fast. Our design is based on learning the dual variables of the\nunderlying optimization problem; however, the main challenge lies in the\ntime-varying nature of the dual variables associated with dynamic resources. To\novercome this challenge, our theoretical development brings together techniques\nfrom Lyapunov analysis, adversarial online learning, and stochastic\noptimization. On the application side, when tested on real data from our\npartner agency, our method outperforms existing ones making it a viable\ncandidate for replacing the current practice upon experimentation.",
      "authors": [
        "Kirk Bansak",
        "Soonbong Lee",
        "Vahideh Manshadi",
        "Rad Niazadeh",
        "Elisabeth Paulson"
      ],
      "categories": [
        "cs.DS",
        "cs.GT",
        "cs.LG",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22992v1",
        "http://arxiv.org/pdf/2410.22992v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22987v1",
      "title": "V2X-Assisted Distributed Computing and Control Framework for Connected\n  and Automated Vehicles under Ramp Merging Scenario",
      "published": "2024-10-30T12:56:49Z",
      "updated": "2024-10-30T12:56:49Z",
      "summary": "This paper investigates distributed computing and cooperative control of\nconnected and automated vehicles (CAVs) in ramp merging scenario under\ntransportation cyber-physical system. Firstly, a centralized cooperative\ntrajectory planning problem is formulated subject to the safely constraints and\ntraffic performance in ramp merging scenario, where the trajectories of all\nvehicles are jointly optimized. To get rid of the reliance on a central\ncontroller and reduce computation time, a distributed solution to this problem\nimplemented among CAVs through Vehicles-to-Everything (V2X) communication is\nproposed. Unlike existing method, our method can distribute the computational\ntask among CAVs and carry out parallel solving through V2X communication. Then,\na multi-vehicles model predictive control (MPC) problem aimed at maximizing\nsystem stability and minimizing control input is formulated based on the\nsolution of the first problem subject to strict safety constants and input\nlimits. Due to these complex constraints, this problem becomes\nhigh-dimensional, centralized, and non-convex. To solve it in a short time, a\ndecomposition and convex reformulation method, namely distributed cooperative\niterative model predictive control (DCIMPC), is proposed. This method leverages\nthe communication capability of CAVs to decompose the problem, making full use\nof the computational resources on vehicles to achieve fast solutions and\ndistributed control. The two above problems with their corresponding solving\nmethods form the systemic framework of the V2X assisted distributed computing\nand control. Simulations have been conducted to evaluate the framework's\nconvergence, safety, and solving speed. Additionally, extra experiments are\nconducted to validate the performance of DCIMPC. The results show that our\nmethod can greatly improve computation speed without sacrificing system\nperformance.",
      "authors": [
        "Qiong Wu",
        "Jiahou Chu",
        "Pingyi Fan",
        "Kezhi Wang",
        "Nan Cheng",
        "Wen Chen",
        "Khaled B. Letaief"
      ],
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.NI",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22987v1",
        "http://arxiv.org/pdf/2410.22987v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22946v1",
      "title": "KALAM: toolKit for Automating high-Level synthesis of Analog computing\n  systeMs",
      "published": "2024-10-30T12:04:22Z",
      "updated": "2024-10-30T12:04:22Z",
      "summary": "Diverse computing paradigms have emerged to meet the growing needs for\nintelligent energy-efficient systems. The Margin Propagation (MP) framework,\nbeing one such initiative in the analog computing domain, stands out due to its\nscalability across biasing conditions, temperatures, and diminishing process\ntechnology nodes. However, the lack of digital-like automation tools for\ndesigning analog systems (including that of MP analog) hinders their adoption\nfor designing large systems. The inherent scalability and modularity of MP\nsystems present a unique opportunity in this regard. This paper introduces\nKALAM (toolKit for Automating high-Level synthesis of Analog computing\nsysteMs), which leverages factor graphs as the foundational paradigm for\nsynthesizing MP-based analog computing systems. Factor graphs are the basis of\nvarious signal processing tasks and, when coupled with MP, can be used to\ndesign scalable and energy-efficient analog signal processors. Using Python\nscripting language, the KALAM automation flow translates an input factor graph\nto its equivalent SPICE-compatible circuit netlist that can be used to validate\nthe intended functionality. KALAM also allows the integration of design\noptimization strategies such as precision tuning, variable elimination, and\nmathematical simplification. We demonstrate KALAM's versatility for tasks such\nas Bayesian inference, Low-Density Parity Check (LDPC) decoding, and Artificial\nNeural Networks (ANN). Simulation results of the netlists align closely with\nsoftware implementations, affirming the efficacy of our proposed automation\ntool.",
      "authors": [
        "Ankita Nandi",
        "Krishil Gandhi",
        "Mahendra Pratap Singh",
        "Shantanu Chakrabartty",
        "Chetan Singh Thakur"
      ],
      "categories": [
        "eess.SY",
        "cs.AR",
        "cs.ET",
        "cs.LG",
        "cs.SY",
        "eess.SP"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22946v1",
        "http://arxiv.org/pdf/2410.22946v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00852v2",
      "title": "EF-LLM: Energy Forecasting LLM with AI-assisted Automation, Enhanced\n  Sparse Prediction, Hallucination Detection",
      "published": "2024-10-30T11:22:37Z",
      "updated": "2024-12-24T03:24:55Z",
      "summary": "Accurate prediction helps to achieve supply-demand balance in energy systems,\nsupporting decision-making and scheduling. Traditional models, lacking\nAI-assisted automation, rely on experts, incur high costs, and struggle with\nsparse data prediction. To address these challenges, we propose the Energy\nForecasting Large Language Model (EF-LLM), which integrates domain knowledge\nand temporal data for time-series forecasting, supporting both pre-forecast\noperations and post-forecast decision-support. EF-LLM's human-AI interaction\ncapabilities lower the entry barrier in forecasting tasks, reducing the need\nfor extra expert involvement. To achieve this, we propose a continual learning\napproach with updatable LoRA and a multi-channel architecture for aligning\nheterogeneous multimodal data, enabling EF-LLM to continually learn\nheterogeneous multimodal knowledge. In addition, EF-LLM enables accurate\npredictions under sparse data conditions through its ability to process\nmultimodal data. We propose Fusion Parameter-Efficient Fine-Tuning (F-PEFT)\nmethod to effectively leverage both time-series data and text for this purpose.\nEF-LLM is also the first energy-specific LLM to detect hallucinations and\nquantify their occurrence rate, achieved via multi-task learning, semantic\nsimilarity analysis, and ANOVA. We have achieved success in energy prediction\nscenarios for load, photovoltaic, and wind power forecast.",
      "authors": [
        "Zihang Qiu",
        "Chaojie Li",
        "Zhongyang Wang",
        "Renyou Xie",
        "Borui Zhang",
        "Huadong Mo",
        "Guo Chen",
        "Zhaoyang Dong"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00852v2",
        "http://arxiv.org/pdf/2411.00852v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00851v2",
      "title": "Automatic feature selection and weighting in molecular systems using\n  Differentiable Information Imbalance",
      "published": "2024-10-30T11:19:10Z",
      "updated": "2024-12-30T15:38:52Z",
      "summary": "Feature selection is essential in the analysis of molecular systems and many\nother fields, but several uncertainties remain: What is the optimal number of\nfeatures for a simplified, interpretable model that retains essential\ninformation? How should features with different units be aligned, and how\nshould their relative importance be weighted? Here, we introduce the\nDifferentiable Information Imbalance (DII), an automated method to rank\ninformation content between sets of features. Using distances in a ground truth\nfeature space, DII identifies a low-dimensional subset of features that best\npreserves these relationships. Each feature is scaled by a weight, which is\noptimized by minimizing the DII through gradient descent. This allows\nsimultaneously performing unit alignment and relative importance scaling, while\npreserving interpretability. DII can also produce sparse solutions and\ndetermine the optimal size of the reduced feature space. We demonstrate the\nusefulness of this approach on two benchmark molecular problems: (1)\nidentifying collective variables that describe conformations of a biomolecule,\nand (2) selecting features for training a machine-learning force field. These\nresults show the potential of DII in addressing feature selection challenges\nand optimizing dimensionality in various applications. The method is available\nin the Python library DADApy.",
      "authors": [
        "Romina Wild",
        "Felix Wodaczek",
        "Vittorio Del Tatto",
        "Bingqing Cheng",
        "Alessandro Laio"
      ],
      "categories": [
        "cs.LG",
        "physics.comp-ph",
        "stat.ML"
      ],
      "links": [
        "http://dx.doi.org/10.1038/s41467-024-55449-7",
        "http://arxiv.org/abs/2411.00851v2",
        "http://arxiv.org/pdf/2411.00851v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22869v1",
      "title": "Machine learning based stellar classification with highly sparse\n  photometry data",
      "published": "2024-10-30T10:06:29Z",
      "updated": "2024-10-30T10:06:29Z",
      "summary": "Identifying stars belonging to different classes is vital in order to build\nup statistical samples of different phases and pathways of stellar evolution.\nIn the era of surveys covering billions of stars, an automated method of\nidentifying these classes becomes necessary. Many classes of stars are\nidentified based on their emitted spectra. In this paper, we use a combination\nof the multi-class multi-label Machine Learning (ML) method XGBoost and the\nPySSED spectral-energy-distribution fitting algorithm to classify stars into\nnine different classes, based on their photometric data. The classifier is\ntrained on subsets of the SIMBAD database. Particular challenges are the very\nhigh sparsity (large fraction of missing values) of the underlying data as well\nas the high class imbalance. We discuss the different variables available, such\nas photometric measurements on the one hand, and indirect predictors such as\nGalactic position on the other hand. We show the difference in performance when\nexcluding certain variables, and discuss in which contexts which of the\nvariables should be used. Finally, we show that increasing the number of\nsamples of a particular type of star significantly increases the performance of\nthe model for that particular type, while having little to no impact on other\ntypes. The accuracy of the main classifier is ~0.7 with a macro F1 score of\n0.61. While the current accuracy of the classifier is not high enough to be\nreliably used in stellar classification, this work is an initial proof of\nfeasibility for using ML to classify stars based on photometry.",
      "authors": [
        "Sean Enis Cody",
        "Sebastian Scher",
        "Iain McDonald",
        "Albert Zijlstra",
        "Emma Alexander",
        "Nick L. J. Cox"
      ],
      "categories": [
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "links": [
        "http://dx.doi.org/10.12688/openreseurope.17023.2",
        "http://arxiv.org/abs/2410.22869v1",
        "http://arxiv.org/pdf/2410.22869v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22854v1",
      "title": "Hyperparameter Optimization in Machine Learning",
      "published": "2024-10-30T09:39:22Z",
      "updated": "2024-10-30T09:39:22Z",
      "summary": "Hyperparameters are configuration variables controlling the behavior of\nmachine learning algorithms. They are ubiquitous in machine learning and\nartificial intelligence and the choice of their values determine the\neffectiveness of systems based on these technologies. Manual hyperparameter\nsearch is often unsatisfactory and becomes unfeasible when the number of\nhyperparameters is large. Automating the search is an important step towards\nautomating machine learning, freeing researchers and practitioners alike from\nthe burden of finding a good set of hyperparameters by trial and error. In this\nsurvey, we present a unified treatment of hyperparameter optimization,\nproviding the reader with examples and insights into the state-of-the-art. We\ncover the main families of techniques to automate hyperparameter search, often\nreferred to as hyperparameter optimization or tuning, including random and\nquasi-random search, bandit-, model- and gradient- based approaches. We further\ndiscuss extensions, including online, constrained, and multi-objective\nformulations, touch upon connections with other fields such as meta-learning\nand neural architecture search, and conclude with open questions and future\nresearch directions.",
      "authors": [
        "Luca Franceschi",
        "Michele Donini",
        "Valerio Perrone",
        "Aaron Klein",
        "C\u00e9dric Archambeau",
        "Matthias Seeger",
        "Massimiliano Pontil",
        "Paolo Frasconi"
      ],
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22854v1",
        "http://arxiv.org/pdf/2410.22854v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.23322v1",
      "title": "The Heterogeneous Effects of Active Labour Market Policies in\n  Switzerland",
      "published": "2024-10-30T09:22:12Z",
      "updated": "2024-10-30T09:22:12Z",
      "summary": "Active labour market policies are widely used by the Swiss government,\nenrolling more than half of unemployed individuals. This paper analyses whether\nthe Swiss programmes increase future employment and earnings of the unemployed\nby using causal machine learning methods and leveraging an administrative\ndataset that captures the population of unemployed and their labour market\nhistories. The findings indicate a small positive average effect on employment\nand earnings three years after starting a specific Temporary Wage Subsidy\nprogramme. In contrast, we find negative effects for Basic Courses, such as job\napplication training, on both outcomes three years after starting the\nprogramme. We find no significant effect for Employment Programmes which are\nconducted outside the regular labour market and Training Courses, such as\nlanguage and computer courses. The programmes are most effective for\nindividuals with lower education levels and with a migration background from\nnon-EU countries. Last, shallow policy trees provide practical guidance on how\nthe allocation of individuals to programmes could be optimised.",
      "authors": [
        "Federica Mascolo",
        "Nora Bearth",
        "Fabian Muny",
        "Michael Lechner",
        "Jana Mareckova"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2410.23322v1",
        "http://arxiv.org/pdf/2410.23322v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22729v2",
      "title": "Identifying Drift, Diffusion, and Causal Structure from Temporal\n  Snapshots",
      "published": "2024-10-30T06:28:21Z",
      "updated": "2025-03-03T00:23:28Z",
      "summary": "Stochastic differential equations (SDEs) are a fundamental tool for modelling\ndynamic processes, including gene regulatory networks (GRNs), contaminant\ntransport, financial markets, and image generation. However, learning the\nunderlying SDE from data is a challenging task, especially if individual\ntrajectories are not observable. Motivated by burgeoning research in\nsingle-cell datasets, we present the first comprehensive approach for jointly\nidentifying the drift and diffusion of an SDE from its temporal marginals.\nAssuming linear drift and additive diffusion, we prove that these parameters\nare identifiable from marginals if and only if the initial distribution lacks\nany generalized rotational symmetries. We further prove that the causal graph\nof any SDE with additive diffusion can be recovered from the SDE parameters. To\ncomplement this theory, we adapt entropy-regularized optimal transport to\nhandle anisotropic diffusion, and introduce APPEX (Alternating Projection\nParameter Estimation from $X_0$), an iterative algorithm designed to estimate\nthe drift, diffusion, and causal graph of an additive noise SDE, solely from\ntemporal marginals. We show that APPEX iteratively decreases Kullback-Leibler\ndivergence to the true solution, and demonstrate its effectiveness on simulated\ndata from linear additive noise SDEs.",
      "authors": [
        "Vincent Guan",
        "Joseph Janssen",
        "Hossein Rahmani",
        "Andrew Warren",
        "Stephen Zhang",
        "Elina Robeva",
        "Geoffrey Schiebinger"
      ],
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22729v2",
        "http://arxiv.org/pdf/2410.22729v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22663v1",
      "title": "Automated Trustworthiness Oracle Generation for Machine Learning Text\n  Classifiers",
      "published": "2024-10-30T03:26:37Z",
      "updated": "2024-10-30T03:26:37Z",
      "summary": "Machine learning (ML) for text classification has been widely used in various\ndomains, such as toxicity detection, chatbot consulting, and review analysis.\nThese applications can significantly impact ethics, economics, and human\nbehavior, raising serious concerns about trusting ML decisions. Several studies\nindicate that traditional metrics, such as model confidence and accuracy, are\ninsufficient to build human trust in ML models. These models often learn\nspurious correlations during training and predict based on them during\ninference. In the real world, where such correlations are absent, their\nperformance can deteriorate significantly. To avoid this, a common practice is\nto test whether predictions are reasonable. Along with this, a challenge known\nas the trustworthiness oracle problem has been introduced. Due to the lack of\nautomated trustworthiness oracles, the assessment requires manual validation of\nthe decision process disclosed by explanation methods, which is time-consuming\nand not scalable. We propose TOKI, the first automated trustworthiness oracle\ngeneration method for text classifiers, which automatically checks whether the\nprediction-contributing words are related to the predicted class using\nexplanation methods and word embeddings. To demonstrate its practical\nusefulness, we introduce a novel adversarial attack method targeting\ntrustworthiness issues identified by TOKI. We compare TOKI with a naive\nbaseline based solely on model confidence using human-created ground truths of\n6,000 predictions. We also compare TOKI-guided adversarial attack method with\nA2T, a SOTA adversarial attack method. Results show that relying on prediction\nuncertainty cannot distinguish between trustworthy and untrustworthy\npredictions, TOKI achieves 142% higher accuracy than the naive baseline, and\nTOKI-guided adversarial attack method is more effective with fewer\nperturbations than A2T.",
      "authors": [
        "Lam Nguyen Tung",
        "Steven Cho",
        "Xiaoning Du",
        "Neelofar Neelofar",
        "Valerio Terragni",
        "Stefano Ruberto",
        "Aldeida Aleti"
      ],
      "categories": [
        "cs.SE",
        "cs.CL",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22663v1",
        "http://arxiv.org/pdf/2410.22663v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22657v1",
      "title": "Automatic programming via large language models with population\n  self-evolution for dynamic job shop scheduling problem",
      "published": "2024-10-30T02:54:31Z",
      "updated": "2024-10-30T02:54:31Z",
      "summary": "Heuristic dispatching rules (HDRs) are widely regarded as effective methods\nfor solving dynamic job shop scheduling problems (DJSSP) in real-world\nproduction environments. However, their performance is highly\nscenario-dependent, often requiring expert customization. To address this,\ngenetic programming (GP) and gene expression programming (GEP) have been\nextensively used for automatic algorithm design. Nevertheless, these approaches\noften face challenges due to high randomness in the search process and limited\ngeneralization ability, hindering the application of trained dispatching rules\nto new scenarios or dynamic environments. Recently, the integration of large\nlanguage models (LLMs) with evolutionary algorithms has opened new avenues for\nprompt engineering and automatic algorithm design. To enhance the capabilities\nof LLMs in automatic HDRs design, this paper proposes a novel population\nself-evolutionary (SeEvo) method, a general search framework inspired by the\nself-reflective design strategies of human experts. The SeEvo method\naccelerates the search process and enhances exploration capabilities.\nExperimental results show that the proposed SeEvo method outperforms GP, GEP,\nend-to-end deep reinforcement learning methods, and more than 10 common HDRs\nfrom the literature, particularly in unseen and dynamic scenarios.",
      "authors": [
        "Jin Huang",
        "Xinyu Li",
        "Liang Gao",
        "Qihao Liu",
        "Yue Teng"
      ],
      "categories": [
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22657v1",
        "http://arxiv.org/pdf/2410.22657v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22598v1",
      "title": "Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse",
      "published": "2024-10-29T23:37:49Z",
      "updated": "2024-10-29T23:37:49Z",
      "summary": "Machine learning models are often used to automate or support decisions in\napplications such as lending and hiring. In such settings, consumer protection\nrules mandate that we provide a list of \"principal reasons\" to consumers who\nreceive adverse decisions. In practice, lenders and employers identify\nprincipal reasons by returning the top-scoring features from a feature\nattribution method. In this work, we study how such practices align with one of\nthe underlying goals of consumer protection - recourse - i.e., educating\nindividuals on how they can attain a desired outcome. We show that standard\nattribution methods can mislead individuals by highlighting reasons without\nrecourse - i.e., by presenting consumers with features that cannot be changed\nto achieve recourse. We propose to address these issues by scoring features on\nthe basis of responsiveness - i.e., the probability that an individual can\nattain a desired outcome by changing a specific feature. We develop efficient\nmethods to compute responsiveness scores for any model and any dataset under\ncomplex actionability constraints. We present an extensive empirical study on\nthe responsiveness of explanations in lending and demonstrate how\nresponsiveness scores can be used to construct feature-highlighting\nexplanations that lead to recourse and mitigate harm by flagging instances with\nfixed predictions.",
      "authors": [
        "Seung Hyun Cheon",
        "Anneke Wernerfelt",
        "Sorelle A. Friedler",
        "Berk Ustun"
      ],
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22598v1",
        "http://arxiv.org/pdf/2410.22598v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22584v1",
      "title": "BENCHAGENTS: Automated Benchmark Creation with Agent Interaction",
      "published": "2024-10-29T22:56:18Z",
      "updated": "2024-10-29T22:56:18Z",
      "summary": "Evaluations are limited by benchmark availability. As models evolve, there is\na need to create benchmarks that can measure progress on new generative\ncapabilities. However, creating new benchmarks through human annotations is\nslow and expensive, restricting comprehensive evaluations for any capability.\nWe introduce BENCHAGENTS, a framework that methodically leverages large\nlanguage models (LLMs) to automate benchmark creation for complex capabilities\nwhile inherently ensuring data and metric quality. BENCHAGENTS decomposes the\nbenchmark creation process into planning, generation, data verification, and\nevaluation, each of which is executed by an LLM agent. These agents interact\nwith each other and utilize human-in-the-loop feedback from benchmark\ndevelopers to explicitly improve and flexibly control data diversity and\nquality. We use BENCHAGENTS to create benchmarks to evaluate capabilities\nrelated to planning and constraint satisfaction during text generation. We then\nuse these benchmarks to study seven state-of-the-art models and extract new\ninsights on common failure modes and model differences.",
      "authors": [
        "Natasha Butt",
        "Varun Chandrasekaran",
        "Neel Joshi",
        "Besmira Nushi",
        "Vidhisha Balachandran"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22584v1",
        "http://arxiv.org/pdf/2410.22584v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22568v1",
      "title": "Fast Deep Hedging with Second-Order Optimization",
      "published": "2024-10-29T22:17:52Z",
      "updated": "2024-10-29T22:17:52Z",
      "summary": "Hedging exotic options in presence of market frictions is an important risk\nmanagement task. Deep hedging can solve such hedging problems by training\nneural network policies in realistic simulated markets. Training these neural\nnetworks may be delicate and suffer from slow convergence, particularly for\noptions with long maturities and complex sensitivities to market parameters. To\naddress this, we propose a second-order optimization scheme for deep hedging.\nWe leverage pathwise differentiability to construct a curvature matrix, which\nwe approximate as block-diagonal and Kronecker-factored to efficiently\nprecondition gradients. We evaluate our method on a challenging and practically\nimportant problem: hedging a cliquet option on a stock with stochastic\nvolatility by trading in the spot and vanilla options. We find that our\nsecond-order scheme can optimize the policy in 1/4 of the number of steps that\nstandard adaptive moment-based optimization takes.",
      "authors": [
        "Konrad Mueller",
        "Amira Akkari",
        "Lukas Gonon",
        "Ben Wood"
      ],
      "categories": [
        "q-fin.RM",
        "cs.LG",
        "q-fin.CP"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22568v1",
        "http://arxiv.org/pdf/2410.22568v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22552v1",
      "title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large\n  Language Model Web Agents",
      "published": "2024-10-29T21:37:04Z",
      "updated": "2024-10-29T21:37:04Z",
      "summary": "In this paper, we introduce Auto-Intent, a method to adapt a pre-trained\nlarge language model (LLM) as an agent for a target domain without direct\nfine-tuning, where we empirically focus on web navigation tasks. Our approach\nfirst discovers the underlying intents from target domain demonstrations\nunsupervisedly, in a highly compact form (up to three words). With the\nextracted intents, we train our intent predictor to predict the next intent\ngiven the agent's past observations and actions. In particular, we propose a\nself-exploration approach where top-k probable intent predictions are provided\nas a hint to the pre-trained LLM agent, which leads to enhanced decision-making\ncapabilities. Auto-Intent substantially improves the performance of GPT-{3.5,\n4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation\nbenchmarks from Mind2Web and online navigation tasks from WebArena with its\ncross-benchmark generalization from Mind2Web.",
      "authors": [
        "Jaekyeom Kim",
        "Dong-Ki Kim",
        "Lajanugen Logeswaran",
        "Sungryull Sohn",
        "Honglak Lee"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22552v1",
        "http://arxiv.org/pdf/2410.22552v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22457v1",
      "title": "Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration\n  and Evaluation using Novel Metrics and Dataset",
      "published": "2024-10-29T18:45:13Z",
      "updated": "2024-10-29T18:45:13Z",
      "summary": "Advancements in Large Language Models (LLMs) are revolutionizing the\ndevelopment of autonomous agentic systems by enabling dynamic, context-aware\ntask decomposition and automated tool selection. These sophisticated systems\npossess significant automation potential across various industries, managing\ncomplex tasks, interacting with external systems to enhance knowledge, and\nexecuting actions independently. This paper presents three primary\ncontributions to advance this field:\n  - Advanced Agentic Framework: A system that handles multi-hop queries,\ngenerates and executes task graphs, selects appropriate tools, and adapts to\nreal-time changes.\n  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural\nSimilarity Index (SSI), and Tool F1 Score to comprehensively assess agentic\nsystems.\n  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing\nagent behavior across different task complexities.\n  Our findings reveal that asynchronous and dynamic task graph decomposition\nsignificantly enhances system responsiveness and scalability, particularly for\ncomplex, multi-step tasks. Detailed analysis shows that structural and\nnode-level metrics are crucial for sequential tasks, while tool-related metrics\nare more important for parallel tasks. Specifically, the Structural Similarity\nIndex (SSI) is the most significant predictor of performance in sequential\ntasks, and the Tool F1 Score is essential for parallel tasks. These insights\nhighlight the need for balanced evaluation methods that capture both structural\nand operational dimensions of agentic systems. Additionally, our evaluation\nframework, validated through empirical analysis and statistical testing,\nprovides valuable insights for improving the adaptability and reliability of\nagentic systems in dynamic environments.",
      "authors": [
        "Adrian Garret Gabriel",
        "Alaa Alameer Ahmad",
        "Shankar Kumar Jeyakumar"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22457v1",
        "http://arxiv.org/pdf/2410.22457v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22258v1",
      "title": "LipKernel: Lipschitz-Bounded Convolutional Neural Networks via\n  Dissipative Layers",
      "published": "2024-10-29T17:20:14Z",
      "updated": "2024-10-29T17:20:14Z",
      "summary": "We propose a novel layer-wise parameterization for convolutional neural\nnetworks (CNNs) that includes built-in robustness guarantees by enforcing a\nprescribed Lipschitz bound. Each layer in our parameterization is designed to\nsatisfy a linear matrix inequality (LMI), which in turn implies dissipativity\nwith respect to a specific supply rate. Collectively, these layer-wise LMIs\nensure Lipschitz boundedness for the input-output mapping of the neural\nnetwork, yielding a more expressive parameterization than through spectral\nbounds or orthogonal layers. Our new method LipKernel directly parameterizes\ndissipative convolution kernels using a 2-D Roesser-type state space model.\nThis means that the convolutional layers are given in standard form after\ntraining and can be evaluated without computational overhead. In numerical\nexperiments, we show that the run-time using our method is orders of magnitude\nfaster than state-of-the-art Lipschitz-bounded networks that parameterize\nconvolutions in the Fourier domain, making our approach particularly attractive\nfor improving robustness of learning-based real-time perception or control in\nrobotics, autonomous vehicles, or automation systems. We focus on CNNs, and in\ncontrast to previous works, our approach accommodates a wide variety of layers\ntypically used in CNNs, including 1-D and 2-D convolutional layers, maximum and\naverage pooling layers, as well as strided and dilated convolutions and zero\npadding. However, our approach naturally extends beyond CNNs as we can\nincorporate any layer that is incrementally dissipative.",
      "authors": [
        "Patricia Pauli",
        "Ruigang Wang",
        "Ian Manchester",
        "Frank Allg\u00f6wer"
      ],
      "categories": [
        "cs.LG",
        "cs.SY",
        "eess.IV",
        "eess.SY",
        "stat.ML"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22258v1",
        "http://arxiv.org/pdf/2410.22258v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.08910v1",
      "title": "Automated Feedback in Math Education: A Comparative Analysis of LLMs for\n  Open-Ended Responses",
      "published": "2024-10-29T16:57:45Z",
      "updated": "2024-10-29T16:57:45Z",
      "summary": "The effectiveness of feedback in enhancing learning outcomes is well\ndocumented within Educational Data Mining (EDM). Various prior research has\nexplored methodologies to enhance the effectiveness of feedback. Recent\ndevelopments in Large Language Models (LLMs) have extended their utility in\nenhancing automated feedback systems. This study aims to explore the potential\nof LLMs in facilitating automated feedback in math education. We examine the\neffectiveness of LLMs in evaluating student responses by comparing 3 different\nmodels: Llama, SBERT-Canberra, and GPT4 model. The evaluation requires the\nmodel to provide both a quantitative score and qualitative feedback on the\nstudent's responses to open-ended math problems. We employ Mistral, a version\nof Llama catered to math, and fine-tune this model for evaluating student\nresponses by leveraging a dataset of student responses and teacher-written\nfeedback for middle-school math problems. A similar approach was taken for\ntraining the SBERT model as well, while the GPT4 model used a zero-shot\nlearning approach. We evaluate the model's performance in scoring accuracy and\nthe quality of feedback by utilizing judgments from 2 teachers. The teachers\nutilized a shared rubric in assessing the accuracy and relevance of the\ngenerated feedback. We conduct both quantitative and qualitative analyses of\nthe model performance. By offering a detailed comparison of these methods, this\nstudy aims to further the ongoing development of automated feedback systems and\noutlines potential future directions for leveraging generative LLMs to create\nmore personalized learning experiences.",
      "authors": [
        "Sami Baral",
        "Eamon Worden",
        "Wen-Chiang Lim",
        "Zhuang Luo",
        "Christopher Santorelli",
        "Ashish Gurung",
        "Neil Heffernan"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2411.08910v1",
        "http://arxiv.org/pdf/2411.08910v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22159v3",
      "title": "Training LLMs for Generating IEC 61131-3 Structured Text with Online\n  Feedback",
      "published": "2024-10-29T15:54:09Z",
      "updated": "2024-12-18T17:09:46Z",
      "summary": "IEC 61131-3 Structured Text (ST) is a widely used programming language for\nprogrammable logic controllers (PLCs) in automation systems. However,\ngenerating ST code with LLMs poses unique challenges due to limited data in\npublic training datasets and the complexity of ST language syntax. This paper\nproposes an approach to fine-tune LLMs for the generation of ST code that\nleverages a preference-based learning method through an online process\ninvolving compiler feedback and evaluation from an LLM-based ST expert. In this\nframework, the model is iteratively refined and generates new training samples,\nwhich are subsequently evaluated by a compiler for syntactical correctness and\nby a specialized LLM that excels at assessing semantic accuracy, though it is\nnot optimized for code generation itself. This approach results in marked\nimprovements for the trained LLM, leading to higher compilation success rates\nand better semantic precision. As a result, the framework proves highly\nsuitable for industrial automation applications and outperforms\nstate-of-the-art models.",
      "authors": [
        "Aaron Haag",
        "Bertram Fuchs",
        "Altay Kacan",
        "Oliver Lohse"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2410.22159v3",
        "http://arxiv.org/pdf/2410.22159v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.22103v1",
      "title": "Joint Extraction and Classification of Danish Competences for Job\n  Matching",
      "published": "2024-10-29T15:00:40Z",
      "updated": "2024-10-29T15:00:40Z",
      "summary": "The matching of competences, such as skills, occupations or knowledges, is a\nkey desiderata for candidates to be fit for jobs. Automatic extraction of\ncompetences from CVs and Jobs can greatly promote recruiters' productivity in\nlocating relevant candidates for job vacancies. This work presents the first\nmodel that jointly extracts and classifies competence from Danish job postings.\nDifferent from existing works on skill extraction and skill classification, our\nmodel is trained on a large volume of annotated Danish corpora and is capable\nof extracting a wide range of Danish competences, including skills, occupations\nand knowledges of different categories. More importantly, as a single BERT-like\narchitecture for joint extraction and classification, our model is lightweight\nand efficient at inference. On a real-scenario job matching dataset, our model\nbeats the state-of-the-art models in the overall performance of Danish\ncompetence extraction and classification, and saves over 50% time at inference.",
      "authors": [
        "Qiuchi Li",
        "Christina Lioma"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "links": [
        "http://dx.doi.org/10.1007/978-3-031-28238-6_38",
        "http://arxiv.org/abs/2410.22103v1",
        "http://arxiv.org/pdf/2410.22103v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.00832v1",
      "title": "Advanced Hybrid Deep Learning Model for Enhanced Classification of\n  Osteosarcoma Histopathology Images",
      "published": "2024-10-29T13:54:08Z",
      "updated": "2024-10-29T13:54:08Z",
      "summary": "Recent advances in machine learning are transforming medical image analysis,\nparticularly in cancer detection and classification. Techniques such as deep\nlearning, especially convolutional neural networks (CNNs) and vision\ntransformers (ViTs), are now enabling the precise analysis of complex\nhistopathological images, automating detection, and enhancing classification\naccuracy across various cancer types. This study focuses on osteosarcoma (OS),\nthe most common bone cancer in children and adolescents, which affects the long\nbones of the arms and legs. Early and accurate detection of OS is essential for\nimproving patient outcomes and reducing mortality. However, the increasing\nprevalence of cancer and the demand for personalized treatments create\nchallenges in achieving precise diagnoses and customized therapies. We propose\na novel hybrid model that combines convolutional neural networks (CNN) and\nvision transformers (ViT) to improve diagnostic accuracy for OS using\nhematoxylin and eosin (H&E) stained histopathological images. The CNN model\nextracts local features, while the ViT captures global patterns from\nhistopathological images. These features are combined and classified using a\nMulti-Layer Perceptron (MLP) into four categories: non-tumor (NT), non-viable\ntumor (NVT), viable tumor (VT), and none-viable ratio (NVR). Using the Cancer\nImaging Archive (TCIA) dataset, the model achieved an accuracy of 99.08%,\nprecision of 99.10%, recall of 99.28%, and an F1-score of 99.23%. This is the\nfirst successful four-class classification using this dataset, setting a new\nbenchmark in OS research and offering promising potential for future diagnostic\nadvancements.",
      "authors": [
        "Arezoo Borji",
        "Gernot Kronreif",
        "Bernhard Angermayr",
        "Sepideh Hatamikia"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2411.00832v1",
        "http://arxiv.org/pdf/2411.00832v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.21968v1",
      "title": "Automated Vulnerability Detection Using Deep Learning Technique",
      "published": "2024-10-29T11:51:51Z",
      "updated": "2024-10-29T11:51:51Z",
      "summary": "Our work explores the utilization of deep learning, specifically leveraging\nthe CodeBERT model, to enhance code security testing for Python applications by\ndetecting SQL injection vulnerabilities. Unlike traditional security testing\nmethods that may be slow and error-prone, our approach transforms source code\ninto vector representations and trains a Long Short-Term Memory (LSTM) model to\nidentify vulnerable patterns. When compared with existing static application\nsecurity testing (SAST) tools, our model displays superior performance,\nachieving higher precision, recall, and F1-score. The study demonstrates that\ndeep learning techniques, particularly with CodeBERT's advanced contextual\nunderstanding, can significantly improve vulnerability detection, presenting a\nscalable methodology applicable to various programming languages and\nvulnerability types.",
      "authors": [
        "Guan-Yan Yang",
        "Yi-Heng Ko",
        "Farn Wang",
        "Kuo-Hui Yeh",
        "Haw-Shiang Chang",
        "Hsueh-Yi Chen"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE",
        "D.2.4; D.2.5"
      ],
      "links": [
        "http://arxiv.org/abs/2410.21968v1",
        "http://arxiv.org/pdf/2410.21968v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.21886v1",
      "title": "Bayesian Optimization for Hyperparameters Tuning in Neural Networks",
      "published": "2024-10-29T09:23:24Z",
      "updated": "2024-10-29T09:23:24Z",
      "summary": "This study investigates the application of Bayesian Optimization (BO) for the\nhyperparameter tuning of neural networks, specifically targeting the\nenhancement of Convolutional Neural Networks (CNN) for image classification\ntasks. Bayesian Optimization is a derivative-free global optimization method\nsuitable for expensive black-box functions with continuous inputs and limited\nevaluation budgets. The BO algorithm leverages Gaussian Process regression and\nacquisition functions like Upper Confidence Bound (UCB) and Expected\nImprovement (EI) to identify optimal configurations effectively. Using the Ax\nand BOTorch frameworks, this work demonstrates the efficiency of BO in reducing\nthe number of hyperparameter tuning trials while achieving competitive model\nperformance. Experimental outcomes reveal that BO effectively balances\nexploration and exploitation, converging rapidly towards optimal settings for\nCNN architectures. This approach underlines the potential of BO in automating\nneural network tuning, contributing to improved accuracy and computational\nefficiency in machine learning pipelines.",
      "authors": [
        "Gabriele Onorato"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2410.21886v1",
        "http://arxiv.org/pdf/2410.21886v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2410.21784v1",
      "title": "MARCO: Multi-Agent Real-time Chat Orchestration",
      "published": "2024-10-29T06:42:27Z",
      "updated": "2024-10-29T06:42:27Z",
      "summary": "Large language model advancements have enabled the development of multi-agent\nframeworks to tackle complex, real-world problems such as to automate tasks\nthat require interactions with diverse tools, reasoning, and human\ncollaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration\nframework for automating tasks using LLMs. MARCO addresses key challenges in\nutilizing LLMs for complex, multi-step task execution. It incorporates robust\nguardrails to steer LLM behavior, validate outputs, and recover from errors\nthat stem from inconsistent output formatting, function and parameter\nhallucination, and lack of domain knowledge. Through extensive experiments we\ndemonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on\ntask execution for Digital Restaurant Service Platform conversations and Retail\nconversations datasets respectively along with 44.91% improved latency and\n33.71% cost reduction. We also report effects of guardrails in performance gain\nalong with comparisons of various LLM models, both open-source and proprietary.\nThe modular and generic design of MARCO allows it to be adapted for automating\ntasks across domains and to execute complex usecases through multi-turn\ninteractions.",
      "authors": [
        "Anubhav Shrimal",
        "Stanley Kanagaraj",
        "Kriti Biswas",
        "Swarnalatha Raghuraman",
        "Anish Nediyanchath",
        "Yi Zhang",
        "Promod Yenigalla"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2410.21784v1",
        "http://arxiv.org/pdf/2410.21784v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.08900v1",
      "title": "RNA-GPT: Multimodal Generative System for RNA Sequence Understanding",
      "published": "2024-10-29T06:19:56Z",
      "updated": "2024-10-29T06:19:56Z",
      "summary": "RNAs are essential molecules that carry genetic information vital for life,\nwith profound implications for drug development and biotechnology. Despite this\nimportance, RNA research is often hindered by the vast literature available on\nthe topic. To streamline this process, we introduce RNA-GPT, a multi-modal RNA\nchat model designed to simplify RNA discovery by leveraging extensive RNA\nliterature. RNA-GPT integrates RNA sequence encoders with linear projection\nlayers and state-of-the-art large language models (LLMs) for precise\nrepresentation alignment, enabling it to process user-uploaded RNA sequences\nand deliver concise, accurate responses. Built on a scalable training pipeline,\nRNA-GPT utilizes RNA-QA, an automated system that gathers RNA annotations from\nRNACentral using a divide-and-conquer approach with GPT-4o and latent Dirichlet\nallocation (LDA) to efficiently handle large datasets and generate\ninstruction-tuning samples. Our experiments indicate that RNA-GPT effectively\naddresses complex RNA queries, thereby facilitating RNA research. Additionally,\nwe present RNA-QA, a dataset of 407,616 RNA samples for modality alignment and\ninstruction tuning, further advancing the potential of RNA research tools.",
      "authors": [
        "Yijia Xiao",
        "Edward Sun",
        "Yiqiao Jin",
        "Wei Wang"
      ],
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "q-bio.BM"
      ],
      "links": [
        "http://arxiv.org/abs/2411.08900v1",
        "http://arxiv.org/pdf/2411.08900v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2411.11848v1",
      "title": "Robust Graph Neural Networks for Stability Analysis in Dynamic Networks",
      "published": "2024-10-29T06:11:36Z",
      "updated": "2024-10-29T06:11:36Z",
      "summary": "In the current context of accelerated globalization and digitalization, the\ncomplexity and uncertainty of financial markets are increasing, and the\nidentification and prevention of economic risks have become a key link in\nmaintaining the stability of the financial system. Traditional risk\nidentification methods often have limitations because they are difficult to\ncope with the multi-level and dynamically changing complex relationships in\nfinancial networks. With the rapid development of financial technology, graph\nneural network (GNN) technology, as an emerging deep learning method, has\ngradually shown great potential in the field of financial risk management. GNN\ncan map transaction behaviors, financial institutions, individuals, and their\ninteractive relationships in financial networks into graph structures, and\neffectively capture potential patterns and abnormal signals in financial data\nthrough embedded representation learning. Using this technology, financial\ninstitutions can extract valuable information from complex transaction\nnetworks, identify hidden dangers or abnormal behaviors that may cause systemic\nrisks in a timely manner, optimize decision-making processes, and improve the\naccuracy of risk warnings. This paper explores the economic risk identification\nalgorithm based on the GNN algorithm, aiming to provide financial institutions\nand regulators with more intelligent technical tools to help maintain the\nsecurity and stability of the financial market. Improving the efficiency of\neconomic risk identification through innovative technical means is expected to\nfurther enhance the risk resistance of the financial system and lay the\nfoundation for building a robust global financial system.",
      "authors": [
        "Xin Zhang",
        "Zhen Xu",
        "Yue Liu",
        "Mengfang Sun",
        "Tong Zhou",
        "Wenying Sun"
      ],
      "categories": [
        "q-fin.ST",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2411.11848v1",
        "http://arxiv.org/pdf/2411.11848v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}