{
  "query": "all:large language models AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-03-21T23:03:22.240266",
  "target_period": "2024-12",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2501.00606v1",
      "title": "Time-Varying Graph Learning for Data with Heavy-Tailed Distribution",
      "published": "2024-12-31T19:09:57Z",
      "updated": "2024-12-31T19:09:57Z",
      "summary": "Graph models provide efficient tools to capture the underlying structure of\ndata defined over networks. Many real-world network topologies are subject to\nchange over time. Learning to model the dynamic interactions between entities\nin such networks is known as time-varying graph learning. Current methodology\nfor learning such models often lacks robustness to outliers in the data and\nfails to handle heavy-tailed distributions, a common feature in many real-world\ndatasets (e.g., financial data). This paper addresses the problem of learning\ntime-varying graph models capable of efficiently representing heavy-tailed\ndata. Unlike traditional approaches, we incorporate graph structures with\nspecific spectral properties to enhance data clustering in our model. Our\nproposed method, which can also deal with noise and missing values in the data,\nis based on a stochastic approach, where a non-negative vector auto-regressive\n(VAR) model captures the variations in the graph and a Student-t distribution\nmodels the signal originating from this underlying time-varying graph. We\npropose an iterative method to learn time-varying graph topologies within a\nsemi-online framework where only a mini-batch of data is used to update the\ngraph. Simulations with both synthetic and real datasets demonstrate the\nefficacy of our model in analyzing heavy-tailed data, particularly those found\nin financial markets.",
      "authors": [
        "Amirhossein Javaheri",
        "Jiaxi Ying",
        "Daniel P. Palomar",
        "Farokh Marvasti"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00606v1",
        "http://arxiv.org/pdf/2501.00606v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00562v2",
      "title": "An Overview and Discussion on Using Large Language Models for\n  Implementation Generation of Solutions to Open-Ended Problems",
      "published": "2024-12-31T17:48:33Z",
      "updated": "2025-01-03T06:28:02Z",
      "summary": "Large Language Models offer new opportunities to devise automated\nimplementation generation methods that can tackle problem solving activities\nbeyond traditional methods, which require algorithmic specifications and can\nuse only static domain knowledge, like performance metrics and libraries of\nbasic building blocks. Large Language Models could support creating new methods\nto support problem solving activities for open-ended problems, like problem\nframing, exploring possible solving approaches, feature elaboration and\ncombination, more advanced implementation assessment, and handling unexpected\nsituations. This report summarized the current work on Large Language Models,\nincluding model prompting, Reinforcement Learning, and Retrieval-Augmented\nGeneration. Future research requirements were also discussed.",
      "authors": [
        "Hashmath Shaik",
        "Alex Doboli"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00562v2",
        "http://arxiv.org/pdf/2501.00562v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00560v2",
      "title": "Re-evaluating Automatic LLM System Ranking for Alignment with Human\n  Preference",
      "published": "2024-12-31T17:46:51Z",
      "updated": "2025-02-11T10:02:55Z",
      "summary": "Evaluating and ranking the capabilities of different LLMs is crucial for\nunderstanding their performance and alignment with human preferences. Due to\nthe high cost and time-consuming nature of human evaluations, an automatic LLM\nbencher (i.e., an automatic evaluation framework that aims to rank LLMs based\non their alignment with human preferences) is indispensable. An automatic LLM\nbencher consists of four components: the input set (e.g., a user instruction),\nthe evaluation model (e.g., an LLM), the evaluation type (e.g., pairwise\ncomparison), and the aggregation method (e.g., the ELO rating system). However,\nprevious work has not thoroughly explored how to select these components or how\ntheir different combinations influence the results. In this work, through\ncontrolled experiments, we provide a series of recommendations on how to choose\neach component to better automate the evaluation of LLMs. Furthermore, we\ndiscovered that when evaluating LLMs with similar performance, the performance\nof the automatic LLM bencher declines sharply, underscoring the limitations of\ncurrent benchers and calling for future work. Lastly, we found that the\nevaluation models' performance at the instance level (e.g., the accuracy of\nselecting the best output) does not always align with their effectiveness when\nused as a component of a bencher, highlighting the importance of dedicated\nsystem-level evaluation of benchers.",
      "authors": [
        "Mingqi Gao",
        "Yixin Liu",
        "Xinyu Hu",
        "Xiaojun Wan",
        "Jonathan Bragg",
        "Arman Cohan"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00560v2",
        "http://arxiv.org/pdf/2501.00560v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00532v1",
      "title": "Variability-Aware Machine Learning Model Selection: Feature Modeling,\n  Instantiation, and Experimental Case Study",
      "published": "2024-12-31T16:29:37Z",
      "updated": "2024-12-31T16:29:37Z",
      "summary": "The emergence of machine learning (ML) has led to a transformative shift in\nsoftware techniques and guidelines for building software applications that\nsupport data analysis process activities such as data ingestion, modeling, and\ndeployment. Specifically, this shift is impacting ML model selection, which is\none of the key phases in this process. There have been several advances in\nmodel selection from the standpoint of core ML methods, including basic\nprobability measures and resampling methods. However, from a software\nengineering perspective, this selection is still an ad hoc and informal\nprocess, is not supported by a design approach and representation formalism\nthat explicitly captures the selection process and can not support the\nspecification of existing model selection procedures. The selection adapts to a\nvariety of contextual factors that affect the model selection, such as data\ncharacteristics, number of features, prediction type, and their intricate\ndependencies. Further, it does not provide an explanation for selecting a model\nand does not consider the contextual factors and their interdependencies when\nselecting a technique. Although the current literature provides a wide variety\nof ML techniques and algorithms, there is a lack of design approaches to\nsupport algorithm selection. In this paper, we present a variability-aware ML\nalgorithm selection approach that considers the commonalities and variations in\nthe model selection process. The approach's applicability is illustrated by an\nexperimental case study based on the Scikit-Learn heuristics, in which existing\nmodel selections presented in the literature are compared with selections\nsuggested by the approach. The proposed approach can be seen as a step towards\nproviding a more explicit, adaptive, transparent, interpretable, and automated\nbasis for model selection.",
      "authors": [
        "Cristina Tavares",
        "Nathalia Nascimento",
        "Paulo Alencar",
        "Donald Cowan"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00532v1",
        "http://arxiv.org/pdf/2501.00532v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00514v1",
      "title": "H-Net: A Multitask Architecture for Simultaneous 3D Force Estimation and\n  Stereo Semantic Segmentation in Intracardiac Catheters",
      "published": "2024-12-31T15:55:13Z",
      "updated": "2024-12-31T15:55:13Z",
      "summary": "The success rate of catheterization procedures is closely linked to the\nsensory data provided to the surgeon. Vision-based deep learning models can\ndeliver both tactile and visual information in a sensor-free manner, while also\nbeing cost-effective to produce. Given the complexity of these models for\ndevices with limited computational resources, research has focused on force\nestimation and catheter segmentation separately. However, there is a lack of a\ncomprehensive architecture capable of simultaneously segmenting the catheter\nfrom two different angles and estimating the applied forces in 3D. To bridge\nthis gap, this work proposes a novel, lightweight, multi-input, multi-output\nencoder-decoder-based architecture. It is designed to segment the catheter from\ntwo points of view and concurrently measure the applied forces in the x, y, and\nz directions. This network processes two simultaneous X-Ray images, intended to\nbe fed by a biplane fluoroscopy system, showing a catheter's deflection from\ndifferent angles. It uses two parallel sub-networks with shared parameters to\noutput two segmentation maps corresponding to the inputs. Additionally, it\nleverages stereo vision to estimate the applied forces at the catheter's tip in\n3D. The architecture features two input channels, two classification heads for\nsegmentation, and a regression head for force estimation through a single\nend-to-end architecture. The output of all heads was assessed and compared with\nthe literature, demonstrating state-of-the-art performance in both segmentation\nand force estimation. To the best of the authors' knowledge, this is the first\ntime such a model has been proposed",
      "authors": [
        "Pedram Fekri",
        "Mehrdad Zadeh",
        "Javad Dargahi"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3514513",
        "http://arxiv.org/abs/2501.00514v1",
        "http://arxiv.org/pdf/2501.00514v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00464v1",
      "title": "Addressing Challenges in Data Quality and Model Generalization for\n  Malaria Detection",
      "published": "2024-12-31T14:25:55Z",
      "updated": "2024-12-31T14:25:55Z",
      "summary": "Malaria remains a significant global health burden, particularly in\nresource-limited regions where timely and accurate diagnosis is critical to\neffective treatment and control. Deep Learning (DL) has emerged as a\ntransformative tool for automating malaria detection and it offers high\naccuracy and scalability. However, the effectiveness of these models is\nconstrained by challenges in data quality and model generalization including\nimbalanced datasets, limited diversity and annotation variability. These issues\nreduce diagnostic reliability and hinder real-world applicability.\n  This article provides a comprehensive analysis of these challenges and their\nimplications for malaria detection performance. Key findings highlight the\nimpact of data imbalances which can lead to a 20\\% drop in F1-score and\nregional biases which significantly hinder model generalization. Proposed\nsolutions, such as GAN-based augmentation, improved accuracy by 15-20\\% by\ngenerating synthetic data to balance classes and enhance dataset diversity.\nDomain adaptation techniques, including transfer learning, further improved\ncross-domain robustness by up to 25\\% in sensitivity.\n  Additionally, the development of diverse global datasets and collaborative\ndata-sharing frameworks is emphasized as a cornerstone for equitable and\nreliable malaria diagnostics. The role of explainable AI techniques in\nimproving clinical adoption and trustworthiness is also underscored. By\naddressing these challenges, this work advances the field of AI-driven malaria\ndetection and provides actionable insights for researchers and practitioners.\nThe proposed solutions aim to support the development of accessible and\naccurate diagnostic tools, particularly for resource-constrained populations.",
      "authors": [
        "Kiswendsida Kisito Kabore",
        "Desire Guel"
      ],
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "links": [
        "http://dx.doi.org/10.33140/JSNDC.04.03.09",
        "http://arxiv.org/abs/2501.00464v1",
        "http://arxiv.org/pdf/2501.00464v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00457v1",
      "title": "Differentiable Prompt Learning for Vision Language Models",
      "published": "2024-12-31T14:13:28Z",
      "updated": "2024-12-31T14:13:28Z",
      "summary": "Prompt learning is an effective way to exploit the potential of large-scale\npre-trained foundational models. Continuous prompts parameterize context tokens\nin prompts by turning them into differentiable vectors. Deep continuous prompts\ninsert prompts not only in the input but also in the intermediate hidden\nrepresentations. Manually designed deep continuous prompts exhibit a remarkable\nimprovement compared to the zero-shot pre-trained model on downstream tasks.\nHow to automate the continuous prompt design is an underexplored area, and a\nfundamental question arises, is manually designed deep prompt strategy optimal?\nTo answer this question, we propose a method dubbed differentiable prompt\nlearning (DPL). The DPL method is formulated as an optimization problem to\nautomatically determine the optimal context length of the prompt to be added to\neach layer, where the objective is to maximize the performance. We test the DPL\nmethod on the pre-trained CLIP. We empirically find that by using only limited\ndata, our DPL method can find deep continuous prompt configuration with high\nconfidence. The performance on the downstream tasks exhibits the superiority of\nthe automatic design: our method boosts the average test accuracy by 2.60% on\n11 datasets compared to baseline methods. Besides, our method focuses only on\nthe prompt configuration (i.e. context length for each layer), which means that\nour method is compatible with the baseline methods that have sophisticated\ndesigns to boost the performance. The DPL method can be deployed to large\nlanguage models or computer vision models at no cost.",
      "authors": [
        "Zhenhan Huang",
        "Tejaswini Pedapati",
        "Pin-Yu Chen",
        "Jianxi Gao"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00457v1",
        "http://arxiv.org/pdf/2501.00457v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00328v1",
      "title": "VoxVietnam: a Large-Scale Multi-Genre Dataset for Vietnamese Speaker\n  Recognition",
      "published": "2024-12-31T07:57:29Z",
      "updated": "2024-12-31T07:57:29Z",
      "summary": "Recent research in speaker recognition aims to address vulnerabilities due to\nvariations between enrolment and test utterances, particularly in the\nmulti-genre phenomenon where the utterances are in different speech genres.\nPrevious resources for Vietnamese speaker recognition are either limited in\nsize or do not focus on genre diversity, leaving studies in multi-genre effects\nunexplored. This paper introduces VoxVietnam, the first multi-genre dataset for\nVietnamese speaker recognition with over 187,000 utterances from 1,406 speakers\nand an automated pipeline to construct a dataset on a large scale from public\nsources. Our experiments show the challenges posed by the multi-genre\nphenomenon to models trained on a single-genre dataset, and demonstrate a\nsignificant increase in performance upon incorporating the VoxVietnam into the\ntraining process. Our experiments are conducted to study the challenges of the\nmulti-genre phenomenon in speaker recognition and the performance gain when the\nproposed dataset is used for multi-genre training.",
      "authors": [
        "Hoang Long Vu",
        "Phuong Tuan Dat",
        "Pham Thao Nhi",
        "Nguyen Song Hao",
        "Nguyen Thi Thu Trang"
      ],
      "categories": [
        "cs.SD",
        "cs.CL",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00328v1",
        "http://arxiv.org/pdf/2501.00328v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00274v1",
      "title": "LLM-Rubric: A Multidimensional, Calibrated Approach to Automated\n  Evaluation of Natural Language Texts",
      "published": "2024-12-31T04:57:01Z",
      "updated": "2024-12-31T04:57:01Z",
      "summary": "This paper introduces a framework for the automated evaluation of natural\nlanguage texts. A manually constructed rubric describes how to assess multiple\ndimensions of interest. To evaluate a text, a large language model (LLM) is\nprompted with each rubric question and produces a distribution over potential\nresponses. The LLM predictions often fail to agree well with human judges --\nindeed, the humans do not fully agree with one another. However, the multiple\nLLM distributions can be $\\textit{combined}$ to $\\textit{predict}$ each human\njudge's annotations on all questions, including a summary question that\nassesses overall quality or relevance. LLM-Rubric accomplishes this by training\na small feed-forward neural network that includes both judge-specific and\njudge-independent parameters. When evaluating dialogue systems in a human-AI\ninformation-seeking task, we find that LLM-Rubric with 9 questions (assessing\ndimensions such as naturalness, conciseness, and citation quality) predicts\nhuman judges' assessment of overall user satisfaction, on a scale of 1--4, with\nRMS error $< 0.5$, a $2\\times$ improvement over the uncalibrated baseline.",
      "authors": [
        "Helia Hashemi",
        "Jason Eisner",
        "Corby Rosset",
        "Benjamin Van Durme",
        "Chris Kedzie"
      ],
      "categories": [
        "cs.CL",
        "I.2.1; I.2.6; I.2.7"
      ],
      "links": [
        "http://dx.doi.org/10.18653/v1/2024.acl-long.745",
        "http://arxiv.org/abs/2501.00274v1",
        "http://arxiv.org/pdf/2501.00274v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00257v1",
      "title": "EQUATOR: A Deterministic Framework for Evaluating LLM Reasoning with\n  Open-Ended Questions. # v1.0.0-beta",
      "published": "2024-12-31T03:56:17Z",
      "updated": "2024-12-31T03:56:17Z",
      "summary": "Despite the remarkable coherence of Large Language Models (LLMs), existing\nevaluation methods often suffer from fluency bias and rely heavily on\nmultiple-choice formats, making it difficult to assess factual accuracy and\ncomplex reasoning effectively. LLMs thus frequently generate factually\ninaccurate responses, especially in complex reasoning tasks, highlighting two\nprominent challenges: (1) the inadequacy of existing methods to evaluate\nreasoning and factual accuracy effectively, and (2) the reliance on human\nevaluators for nuanced judgment, as illustrated by Williams and Huckle\n(2024)[1], who found manual grading indispensable despite automated grading\nadvancements.\n  To address evaluation gaps in open-ended reasoning tasks, we introduce the\nEQUATOR Evaluator (Evaluation of Question Answering Thoroughness in Open-ended\nReasoning). This framework combines deterministic scoring with a focus on\nfactual accuracy and robust reasoning assessment. Using a vector database,\nEQUATOR pairs open-ended questions with human-evaluated answers, enabling more\nprecise and scalable evaluations. In practice, EQUATOR significantly reduces\nreliance on human evaluators for scoring and improves scalability compared to\nWilliams and Huckle's (2004)[1] methods.\n  Our results demonstrate that this framework significantly outperforms\ntraditional multiple-choice evaluations while maintaining high accuracy\nstandards. Additionally, we introduce an automated evaluation process\nleveraging smaller, locally hosted LLMs. We used LLaMA 3.2B, running on the\nOllama binaries to streamline our assessments. This work establishes a new\nparadigm for evaluating LLM performance, emphasizing factual accuracy and\nreasoning ability, and provides a robust methodological foundation for future\nresearch.",
      "authors": [
        "Raymond Bernard",
        "Shaina Raza",
        "Subhabrata Das",
        "Rahul Murugan"
      ],
      "categories": [
        "cs.CL",
        "68T20",
        "I.2.7; I.2.6; H.3.3"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00257v1",
        "http://arxiv.org/pdf/2501.00257v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.01989v1",
      "title": "CRRG-CLIP: Automatic Generation of Chest Radiology Reports and\n  Classification of Chest Radiographs",
      "published": "2024-12-31T03:07:27Z",
      "updated": "2024-12-31T03:07:27Z",
      "summary": "The complexity of stacked imaging and the massive number of radiographs make\nwriting radiology reports complex and inefficient. Even highly experienced\nradiologists struggle to maintain accuracy and consistency in interpreting\nradiographs under prolonged high-intensity work. To address these issues, this\nwork proposes the CRRG-CLIP Model (Chest Radiology Report Generation and\nRadiograph Classification Model), an end-to-end model for automated report\ngeneration and radiograph classification. The model consists of two modules:\nthe radiology report generation module and the radiograph classification\nmodule. The generation module uses Faster R-CNN to identify anatomical regions\nin radiographs, a binary classifier to select key regions, and GPT-2 to\ngenerate semantically coherent reports. The classification module uses the\nunsupervised Contrastive Language Image Pretraining (CLIP) model, addressing\nthe challenges of high-cost labelled datasets and insufficient features. The\nresults show that the generation module performs comparably to high-performance\nbaseline models on BLEU, METEOR, and ROUGE-L metrics, and outperformed the\nGPT-4o model on BLEU-2, BLEU-3, BLEU-4, and ROUGE-L metrics. The classification\nmodule significantly surpasses the state-of-the-art model in AUC and Accuracy.\nThis demonstrates that the proposed model achieves high accuracy, readability,\nand fluency in report generation, while multimodal contrastive training with\nunlabelled radiograph-report pairs enhances classification performance.",
      "authors": [
        "Jianfei Xu",
        "Thanet Markchom",
        "Huizhi Liang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.01989v1",
        "http://arxiv.org/pdf/2501.01989v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00233v2",
      "title": "Zero-Shot Strategies for Length-Controllable Summarization",
      "published": "2024-12-31T02:53:27Z",
      "updated": "2025-02-11T12:33:13Z",
      "summary": "Large language models (LLMs) struggle with precise length control,\nparticularly in zero-shot settings. We conduct a comprehensive study evaluating\nLLMs' length control capabilities across multiple measures and propose\npractical methods to improve controllability. Our experiments with LLaMA 3\nreveal stark differences in length adherence across measures and highlight\ninherent biases of the model. To address these challenges, we introduce a set\nof methods: length approximation, target adjustment, sample filtering, and\nautomated revisions. By combining these methods, we demonstrate substantial\nimprovements in length compliance while maintaining or enhancing summary\nquality, providing highly effective zero-shot strategies for precise length\ncontrol without the need for model fine-tuning or architectural changes. With\nour work, we not only advance our understanding of LLM behavior in controlled\ntext generation but also pave the way for more reliable and adaptable\nsummarization systems in real-world applications.",
      "authors": [
        "Fabian Retkowski",
        "Alexander Waibel"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00233v2",
        "http://arxiv.org/pdf/2501.00233v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00217v1",
      "title": "The Potential of LLMs in Automating Software Testing: From Generation to\n  Reporting",
      "published": "2024-12-31T02:06:46Z",
      "updated": "2024-12-31T02:06:46Z",
      "summary": "Having a high quality software is essential in software engineering, which\nrequires robust validation and verification processes during testing\nactivities. Manual testing, while effective, can be time consuming and costly,\nleading to an increased demand for automated methods. Recent advancements in\nLarge Language Models (LLMs) have significantly influenced software\nengineering, particularly in areas like requirements analysis, test automation,\nand debugging. This paper explores an agent-oriented approach to automated\nsoftware testing, using LLMs to reduce human intervention and enhance testing\nefficiency. The proposed framework integrates LLMs to generate unit tests,\nvisualize call graphs, and automate test execution and reporting. Evaluations\nacross multiple applications in Python and Java demonstrate the system's high\ntest coverage and efficient operation. This research underscores the potential\nof LLM-powered agents to streamline software testing workflows while addressing\nchallenges in scalability and accuracy.",
      "authors": [
        "Betim Sherifi",
        "Khaled Slhoub",
        "Fitzroy Nembhard"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00217v1",
        "http://arxiv.org/pdf/2501.00217v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00210v1",
      "title": "Debunking the CUDA Myth Towards GPU-based AI Systems",
      "published": "2024-12-31T01:24:52Z",
      "updated": "2024-12-31T01:24:52Z",
      "summary": "With the rise of AI, NVIDIA GPUs have become the de facto standard for AI\nsystem design. This paper presents a comprehensive evaluation of Intel Gaudi\nNPUs as an alternative to NVIDIA GPUs for AI model serving. First, we create a\nsuite of microbenchmarks to compare Intel Gaudi-2 with NVIDIA A100, showing\nthat Gaudi-2 achieves competitive performance not only in primitive AI compute,\nmemory, and communication operations but also in executing several important AI\nworkloads end-to-end. We then assess Gaudi NPU's programmability by discussing\nseveral software-level optimization strategies to employ for implementing\ncritical FBGEMM operators and vLLM, evaluating their efficiency against\nGPU-optimized counterparts. Results indicate that Gaudi-2 achieves energy\nefficiency comparable to A100, though there are notable areas for improvement\nin terms of software maturity. Overall, we conclude that, with effective\nintegration into high-level AI frameworks, Gaudi NPUs could challenge NVIDIA\nGPU's dominance in the AI server market, though further improvements are\nnecessary to fully compete with NVIDIA's robust software ecosystem.",
      "authors": [
        "Yunjae Lee",
        "Juntaek Lim",
        "Jehyeon Bang",
        "Eunyeong Cho",
        "Huijong Jeong",
        "Taesu Kim",
        "Hyungjun Kim",
        "Joonhyung Lee",
        "Jinseop Im",
        "Ranggi Hwang",
        "Se Jung Kwon",
        "Dongsoo Lee",
        "Minsoo Rhu"
      ],
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00210v1",
        "http://arxiv.org/pdf/2501.00210v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00204v1",
      "title": "MSM-BD: Multimodal Social Media Bot Detection Using Heterogeneous\n  Information",
      "published": "2024-12-31T01:05:48Z",
      "updated": "2024-12-31T01:05:48Z",
      "summary": "Although social bots can be engineered for constructive applications, their\npotential for misuse in manipulative schemes and malware distribution cannot be\noverlooked. This dichotomy underscores the critical need to detect social bots\non social media platforms. Advances in artificial intelligence have improved\nthe abilities of social bots, allowing them to generate content that is almost\nindistinguishable from human-created content. These advancements require the\ndevelopment of more advanced detection techniques to accurately identify these\nautomated entities. Given the heterogeneous information landscape on social\nmedia, spanning images, texts, and user statistical features, we propose\nMSM-BD, a Multimodal Social Media Bot Detection approach using heterogeneous\ninformation. MSM-BD incorporates specialized encoders for heterogeneous\ninformation and introduces a cross-modal fusion technology, Cross-Modal\nResidual Cross-Attention (CMRCA), to enhance detection accuracy. We validate\nthe effectiveness of our model through extensive experiments using the\nTwiBot-22 dataset.",
      "authors": [
        "Tingxuan Wu",
        "Zhaorui Ma",
        "Yanjun Cui",
        "Ziyi Zhou",
        "Eric Wang"
      ],
      "categories": [
        "cs.MM",
        "cs.SI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00204v1",
        "http://arxiv.org/pdf/2501.00204v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00192v1",
      "title": "MLLM-as-a-Judge for Image Safety without Human Labeling",
      "published": "2024-12-31T00:06:04Z",
      "updated": "2024-12-31T00:06:04Z",
      "summary": "Image content safety has become a significant challenge with the rise of\nvisual media on online platforms. Meanwhile, in the age of AI-generated content\n(AIGC), many image generation models are capable of producing harmful content,\nsuch as images containing sexual or violent material. Thus, it becomes crucial\nto identify such unsafe images based on established safety rules. Pre-trained\nMultimodal Large Language Models (MLLMs) offer potential in this regard, given\ntheir strong pattern recognition abilities. Existing approaches typically\nfine-tune MLLMs with human-labeled datasets, which however brings a series of\ndrawbacks. First, relying on human annotators to label data following intricate\nand detailed guidelines is both expensive and labor-intensive. Furthermore,\nusers of safety judgment systems may need to frequently update safety rules,\nmaking fine-tuning on human-based annotation more challenging. This raises the\nresearch question: Can we detect unsafe images by querying MLLMs in a zero-shot\nsetting using a predefined safety constitution (a set of safety rules)? Our\nresearch showed that simply querying pre-trained MLLMs does not yield\nsatisfactory results. This lack of effectiveness stems from factors such as the\nsubjectivity of safety rules, the complexity of lengthy constitutions, and the\ninherent biases in the models. To address these challenges, we propose a\nMLLM-based method includes objectifying safety rules, assessing the relevance\nbetween rules and images, making quick judgments based on debiased token\nprobabilities with logically complete yet simplified precondition chains for\nsafety rules, and conducting more in-depth reasoning with cascaded\nchain-of-thought processes if necessary. Experiment results demonstrate that\nour method is highly effective for zero-shot image safety judgment tasks.",
      "authors": [
        "Zhenting Wang",
        "Shuming Hu",
        "Shiyu Zhao",
        "Xiaowen Lin",
        "Felix Juefei-Xu",
        "Zhuowei Li",
        "Ligong Han",
        "Harihar Subramanyam",
        "Li Chen",
        "Jianfa Chen",
        "Nan Jiang",
        "Lingjuan Lyu",
        "Shiqing Ma",
        "Dimitris N. Metaxas",
        "Ankit Jain"
      ],
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00192v1",
        "http://arxiv.org/pdf/2501.00192v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00191v1",
      "title": "Equilibria in Network Constrained Markets with Market Maker",
      "published": "2024-12-31T00:02:52Z",
      "updated": "2024-12-31T00:02:52Z",
      "summary": "We study a networked economic system composed of $n$ producers supplying a\nsingle homogeneous good to a number of geographically separated markets and of\na centralized authority, called the market maker. Producers compete \\`a la\nCournot, by choosing the quantities of good to supply to each market they have\naccess to in order to maximize their profit. Every market is characterized by\nits inverse demand functions returning the unit price of the considered good as\na function of the total available quantity. Markets are interconnected by a\ndispatch network through which quantities of the considered good can flow\nwithin finite capacity constraints. Such flows are determined by the market\nmaker, who aims at maximizing a designated welfare function. We model such\ncompetition as a strategic game with $n+1$ players: the producers and the\nmarket game. For this game, we first establish the existence of Nash equilibria\nunder standard concavity assumptions. We then identify sufficient conditions\nfor the game to be potential with an essentially unique Nash equilibrium. Next,\nwe present a general result that connects the optimal action of the market\nmaker with the capacity constraints imposed on the network. For the commonly\nused Walrasian welfare, our finding proves a connection between capacity\nbottlenecks in the market network and the emergence of price differences\nbetween markets separated by saturated lines. This phenomenon is frequently\nobserved in real-world scenarios, for instance in power networks. Finally, we\nvalidate the model with data from the Italian day-ahead electricity market.",
      "authors": [
        "Giacomo Como",
        "Fabio Fagnani",
        "Leonardo Massai",
        "Martina Vanelli"
      ],
      "categories": [
        "cs.GT",
        "cs.MA",
        "cs.SI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00191v1",
        "http://arxiv.org/pdf/2501.00191v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00164v1",
      "title": "Measuring Large Language Models Capacity to Annotate Journalistic\n  Sourcing",
      "published": "2024-12-30T22:15:57Z",
      "updated": "2024-12-30T22:15:57Z",
      "summary": "Since the launch of ChatGPT in late 2022, the capacities of Large Language\nModels and their evaluation have been in constant discussion and evaluation\nboth in academic research and in the industry. Scenarios and benchmarks have\nbeen developed in several areas such as law, medicine and math (Bommasani et\nal., 2023) and there is continuous evaluation of model variants. One area that\nhas not received sufficient scenario development attention is journalism, and\nin particular journalistic sourcing and ethics. Journalism is a crucial\ntruth-determination function in democracy (Vincent, 2023), and sourcing is a\ncrucial pillar to all original journalistic output. Evaluating the capacities\nof LLMs to annotate stories for the different signals of sourcing and how\nreporters justify them is a crucial scenario that warrants a benchmark\napproach. It offers potential to build automated systems to contrast more\ntransparent and ethically rigorous forms of journalism with everyday fare. In\nthis paper we lay out a scenario to evaluate LLM performance on identifying and\nannotating sourcing in news stories on a five-category schema inspired from\njournalism studies (Gans, 2004). We offer the use case, our dataset and metrics\nand as the first step towards systematic benchmarking. Our accuracy findings\nindicate LLM-based approaches have more catching to do in identifying all the\nsourced statements in a story, and equally, in matching the type of sources. An\neven harder task is spotting source justifications.",
      "authors": [
        "Subramaniam Vincent",
        "Phoebe Wang",
        "Zhan Shi",
        "Sahas Koka",
        "Yi Fang"
      ],
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00164v1",
        "http://arxiv.org/pdf/2501.00164v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.01451v1",
      "title": "Human-AI Teaming Using Large Language Models: Boosting Brain-Computer\n  Interfacing (BCI) and Brain Research",
      "published": "2024-12-30T20:26:03Z",
      "updated": "2024-12-30T20:26:03Z",
      "summary": "Recently, there is an increasing interest in using artificial intelligence\n(AI) to automate aspects of the research process, or even autonomously conduct\nthe full research cycle from idea generation, over data analysis, to composing\nand evaluation of scientific manuscripts. Examples of working AI scientist\nsystems have been demonstrated for computer science tasks and running molecular\nbiology labs. While some approaches aim for full autonomy of the scientific AI,\nothers rather aim for leveraging human-AI teaming. Here, we address how to\nadapt such approaches for boosting Brain-Computer Interface (BCI) development,\nas well as brain research resp. neuroscience at large. We argue that at this\ntime, a strong emphasis on human-AI teaming, in contrast to fully autonomous AI\nBCI researcher will be the most promising way forward. We introduce the\ncollaborative workspaces concept for human-AI teaming based on a set of\nJanusian design principles, looking both ways, to the human as well as to the\nAI side. Based on these principles, we present ChatBCI, a Python-based toolbox\nfor enabling human-AI collaboration based on interaction with Large Language\nModels (LLMs), designed for BCI research and development projects. We show how\nChatBCI was successfully used in a concrete BCI project on advancing motor\nimagery decoding from EEG signals. Our approach can be straightforwardly\nextended to broad neurotechnological and neuroscientific topics, and may by\ndesign facilitate human expert knowledge transfer to scientific AI systems in\ngeneral.",
      "authors": [
        "Maryna Kapitonova",
        "Tonio Ball"
      ],
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.01451v1",
        "http://arxiv.org/pdf/2501.01451v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00113v1",
      "title": "AltGen: AI-Driven Alt Text Generation for Enhancing EPUB Accessibility",
      "published": "2024-12-30T19:23:07Z",
      "updated": "2024-12-30T19:23:07Z",
      "summary": "Digital accessibility is a cornerstone of inclusive content delivery, yet\nmany EPUB files fail to meet fundamental accessibility standards, particularly\nin providing descriptive alt text for images. Alt text plays a critical role in\nenabling visually impaired users to understand visual content through assistive\ntechnologies. However, generating high-quality alt text at scale is a\nresource-intensive process, creating significant challenges for organizations\naiming to ensure accessibility compliance. This paper introduces AltGen, a\nnovel AI-driven pipeline designed to automate the generation of alt text for\nimages in EPUB files. By integrating state-of-the-art generative models,\nincluding advanced transformer-based architectures, AltGen achieves\ncontextually relevant and linguistically coherent alt text descriptions. The\npipeline encompasses multiple stages, starting with data preprocessing to\nextract and prepare relevant content, followed by visual analysis using\ncomputer vision models such as CLIP and ViT. The extracted visual features are\nenriched with contextual information from surrounding text, enabling the\nfine-tuned language models to generate descriptive and accurate alt text.\nValidation of the generated output employs both quantitative metrics, such as\ncosine similarity and BLEU scores, and qualitative feedback from visually\nimpaired users.\n  Experimental results demonstrate the efficacy of AltGen across diverse\ndatasets, achieving a 97.5% reduction in accessibility errors and high scores\nin similarity and linguistic fidelity metrics. User studies highlight the\npractical impact of AltGen, with participants reporting significant\nimprovements in document usability and comprehension. Furthermore, comparative\nanalyses reveal that AltGen outperforms existing approaches in terms of\naccuracy, relevance, and scalability.",
      "authors": [
        "Yixian Shen",
        "Hang Zhang",
        "Yanxin Shen",
        "Lun Wang",
        "Chuanqi Shi",
        "Shaoshuai Du",
        "Yiyi Tao"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00113v1",
        "http://arxiv.org/pdf/2501.00113v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21192v1",
      "title": "Rough differential equations for volatility",
      "published": "2024-12-30T18:57:29Z",
      "updated": "2024-12-30T18:57:29Z",
      "summary": "We introduce a canonical way of performing the joint lift of a Brownian\nmotion $W$ and a low-regularity adapted stochastic rough path $\\mathbf{X}$,\nextending [Diehl, Oberhauser and Riedel (2015). A L\\'evy area between Brownian\nmotion and rough paths with applications to robust nonlinear filtering and\nrough partial differential equations]. Applying this construction to the case\nwhere $\\mathbf{X}$ is the canonical lift of a one-dimensional fractional\nBrownian motion (possibly correlated with $W$) completes the partial rough path\nof [Fukasawa and Takano (2024). A partial rough path space for rough\nvolatility]. We use this to model rough volatility with the versatile toolkit\nof rough differential equations (RDEs), namely by taking the price and\nvolatility processes to be the solution to a single RDE. We argue that our\nframework is already interesting when $W$ and $X$ are independent, as\ncorrelation between the price and volatility can be introduced in the dynamics.\nThe lead-lag scheme of [Flint, Hambly, and Lyons (2016). Discretely sampled\nsignals and the rough Hoff process] is extended to our fractional setting as an\napproximation theory for the rough path in the correlated case. Continuity of\nthe solution map transforms this into a numerical scheme for RDEs. We\nnumerically test this framework and use it to calibrate a simple new rough\nvolatility model to market data.",
      "authors": [
        "Ofelia Bonesini",
        "Emilio Ferrucci",
        "Ioannis Gasteratos",
        "Antoine Jacquier"
      ],
      "categories": [
        "q-fin.MF",
        "math.PR",
        "60L20, 60L90, 60G22, 65C30, 91G20, 91G60"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21192v1",
        "http://arxiv.org/pdf/2412.21192v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21181v1",
      "title": "Causal Hangover Effects",
      "published": "2024-12-30T18:52:48Z",
      "updated": "2024-12-30T18:52:48Z",
      "summary": "It's not unreasonable to think that in-game sporting performance can be\naffected partly by what takes place off the court. We can't observe what\nhappens between games directly. Instead, we proxy for the possibility of\nathletes partying by looking at play following games in party cities. We are\ninterested to see if teams exhibit a decline in performance the day following a\ngame in a city with active nightlife; we call this a \"hangover effect\". Part of\nthe question is determining a reasonable way to measure levels of nightlife,\nand correspondingly which cities are notorious for it; we colloquially refer to\nsuch cities as \"party cities\". To carry out this study, we exploit data on\nbookmaker spreads: the expected score differential between two teams after\nconditioning on observable performance in past games and expectations about the\nupcoming game. We expect a team to meet the spread half the time, since this is\none of the easiest ways for bookmakers to guarantee a profit. We construct a\nmodel which attempts to estimate the causal effect of visiting a \"party city\"\non subsequent day performance as measured by the odds of beating the spread. In\nparticular, we only consider the hangover effect on games played back-to-back\nwithin 24 hours of each other. To the extent that odds of beating the spread\nagainst next day opponent is uncorrelated with playing in a party city the day\nbefore, which should be the case under an efficient betting market, we have\nidentification in our variable of interest. We find that visiting a city with\nactive nightlife the day prior to a game does have a statistically significant\nnegative effect on a team's likelihood of meeting bookmakers' expectations for\nboth NBA and MLB.",
      "authors": [
        "Andreas Santucci",
        "Eric Lax"
      ],
      "categories": [
        "econ.EM",
        "cs.IT",
        "math.IT",
        "stat.AP"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21181v1",
        "http://arxiv.org/pdf/2412.21181v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21154v1",
      "title": "Aviary: training language agents on challenging scientific tasks",
      "published": "2024-12-30T18:33:28Z",
      "updated": "2024-12-30T18:33:28Z",
      "summary": "Solving complex real-world tasks requires cycles of actions and observations.\nThis is particularly true in science, where tasks require many cycles of\nanalysis, tool use, and experimentation. Language agents are promising for\nautomating intellectual tasks in science because they can interact with tools\nvia natural language or code. Yet their flexibility creates conceptual and\npractical challenges for software implementations, since agents may comprise\nnon-standard components such as internal reasoning, planning, tool usage, as\nwell as the inherent stochasticity of temperature-sampled language models.\nHere, we introduce Aviary, an extensible gymnasium for language agents. We\nformalize agents as policies solving language-grounded partially observable\nMarkov decision processes, which we term language decision processes. We then\nimplement five environments, including three challenging scientific\nenvironments: (1) manipulating DNA constructs for molecular cloning, (2)\nanswering research questions by accessing scientific literature, and (3)\nengineering protein stability. These environments were selected for their focus\non multi-step reasoning and their relevance to contemporary biology research.\nFinally, with online training and scaling inference-time compute, we show that\nlanguage agents backed by open-source, non-frontier LLMs can match and exceed\nboth frontier LLM agents and human experts on multiple tasks at up to 100x\nlower inference cost.",
      "authors": [
        "Siddharth Narayanan",
        "James D. Braza",
        "Ryan-Rhys Griffiths",
        "Manu Ponnapati",
        "Albert Bou",
        "Jon Laurent",
        "Ori Kabeli",
        "Geemi Wellawatte",
        "Sam Cox",
        "Samuel G. Rodriques",
        "Andrew D. White"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21154v1",
        "http://arxiv.org/pdf/2412.21154v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00085v2",
      "title": "Machine Learning-Based Security Policy Analysis",
      "published": "2024-12-30T18:24:27Z",
      "updated": "2025-01-06T22:42:41Z",
      "summary": "Security-Enhanced Linux (SELinux) is a robust security mechanism that\nenforces mandatory access controls (MAC), but its policy language's complexity\ncreates challenges for policy analysis and management. This research\ninvestigates the automation of SELinux policy analysis using graph-based\ntechniques combined with machine learning approaches to detect policy\nanomalies. The study addresses two key questions: Can SELinux policy analysis\nbe automated through graph analysis, and how do different anomaly detection\nmodels compare in analyzing SELinux policies? We will be comparing different\nmachine learning models by evaluating their effectiveness in detecting policy\nviolations and anomalies. Our approach utilizes Neo4j for graph representation\nof policies, with Node2vec transforming these graph structures into meaningful\nvector embeddings that can be processed by our machine learning models. In our\nresults, the MLP Neural Network consistently demonstrated superior performance\nacross different dataset sizes, achieving 95% accuracy with balanced precision\nand recall metrics, while both Random Forest and SVM models showed competitive\nbut slightly lower performance in detecting policy violations. This combination\nof graph-based modeling and machine learning provides a more sophisticated and\nautomated approach to understanding and analyzing complex SELinux policies\ncompared to traditional manual analysis methods.",
      "authors": [
        "Krish Jain",
        "Joann Sum",
        "Pranav Kapoor",
        "Amir Eaman"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00085v2",
        "http://arxiv.org/pdf/2501.00085v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21065v1",
      "title": "Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight\n  Task-Specific Adapters for Automatic Scoring",
      "published": "2024-12-30T16:34:11Z",
      "updated": "2024-12-30T16:34:11Z",
      "summary": "The integration of Artificial Intelligence (AI) in education requires\nscalable and efficient frameworks that balance performance, adaptability, and\ncost. This paper addresses these needs by proposing a shared backbone model\narchitecture enhanced with lightweight LoRA adapters for task-specific\nfine-tuning, targeting the automated scoring of student responses across 27\nmutually exclusive tasks. By achieving competitive performance (average QWK of\n0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory\nconsumption by 60% and inference latency by 40%, the framework demonstrates\nsignificant efficiency gains. This approach aligns with the workshops' focus on\nimproving language models for educational tasks, creating responsible\ninnovations for cost-sensitive deployment, and supporting educators by\nstreamlining assessment workflows. The findings underscore the potential of\nscalable AI to enhance learning outcomes while maintaining fairness and\ntransparency in automated scoring systems.",
      "authors": [
        "Ehsan Latif",
        "Xiaoming Zhai"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21065v1",
        "http://arxiv.org/pdf/2412.21065v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21025v1",
      "title": "Considering experimental frame rates and robust segmentation analysis of\n  piecewise-linear microparticle trajectories",
      "published": "2024-12-30T15:50:27Z",
      "updated": "2024-12-30T15:50:27Z",
      "summary": "The movement of intracellular cargo transported by molecular motors is\ncommonly marked by switches between directed motion and stationary pauses. The\npredominant measure for assessing movement is effective diffusivity, which\npredicts the mean-squared displacement of particles over long time scales. In\nthis work, we consider an alternative analysis regime that focuses on shorter\ntime scales and relies on automated segmentation of paths. Due to intrinsic\nuncertainty in changepoint analysis, we highlight the importance of statistical\nsummaries that are robust with respect to the performance of segmentation\nalgorithms. In contrast to effective diffusivity, which averages over multiple\nbehaviors, we emphasize tools that highlight the different motor-cargo states,\nwith an eye toward identifying biophysical mechanisms that determine emergent\nwhole-cell transport properties. By developing a Markov chain model for noisy,\ncontinuous, piecewise-linear microparticle movement, and associated\nmathematical analysis, we provide insight into a common question posed by\nexperimentalists: how does the choice of observational frame rate affect what\nis inferred about transport properties?",
      "authors": [
        "Keisha J. Cook",
        "Nathan Rayens",
        "Linh Do",
        "Christine K. Payne",
        "Scott A. McKinley"
      ],
      "categories": [
        "q-bio.QM"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21025v1",
        "http://arxiv.org/pdf/2412.21025v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.21016v2",
      "title": "Assessing the Robustness of LLM-based NLP Software via Automated Testing",
      "published": "2024-12-30T15:33:34Z",
      "updated": "2025-03-17T13:42:06Z",
      "summary": "Benefiting from the advancements in LLMs, NLP software has undergone rapid\ndevelopment. Such software is widely employed in various safety-critical tasks,\nsuch as financial sentiment analysis, toxic content moderation, and log\ngeneration. Unlike traditional software, LLM-based NLP software relies on\nprompts and examples as inputs. Given the complexity of LLMs and the\nunpredictability of real-world inputs, quantitatively assessing the robustness\nof such software is crucial. However, to the best of our knowledge, no\nautomated robustness testing methods have been specifically designed to\nevaluate the overall inputs of LLM-based NLP software. To this end, this paper\nintroduces the first AutOmated Robustness Testing frAmework, AORTA, which\nreconceptualizes the testing process into a combinatorial optimization problem.\nExisting testing methods designed for DNN-based software can be applied to\nLLM-based software by AORTA, but their effectiveness is limited. To address\nthis, we propose a novel testing method for LLM-based software within AORTA\ncalled Adaptive Beam Search. ABS is tailored for the expansive feature space of\nLLMs and improves testing effectiveness through an adaptive beam width and the\ncapability for backtracking. We successfully embed 18 test methods in the\ndesigned framework AORTA and compared the test validity of ABS with three\ndatasets and five threat models. ABS facilitates a more comprehensive and\naccurate robustness assessment before software deployment, with an average test\nsuccess rate of 86.138%. Compared to the currently best-performing baseline\nPWWS, ABS significantly reduces the computational overhead by up to 3441.895\nseconds per successful test case and decreases the number of queries by 218.762\ntimes on average. Furthermore, test cases generated by ABS exhibit greater\nnaturalness and transferability.",
      "authors": [
        "Mingxuan Xiao",
        "Yan Xiao",
        "Shunhui Ji",
        "Hanbo Cai",
        "Lei Xue",
        "Pengcheng Zhang"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2412.21016v2",
        "http://arxiv.org/pdf/2412.21016v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20954v2",
      "title": "AGON: Automated Design Framework for Customizing Processors from ISA\n  Documents",
      "published": "2024-12-30T13:50:20Z",
      "updated": "2025-01-21T08:38:01Z",
      "summary": "Customized processors are attractive solutions for vast domain-specific\napplications due to their high energy efficiency. However, designing a\nprocessor in traditional flows is time-consuming and expensive. To address\nthis, researchers have explored methods including the use of agile development\ntools like Chisel or SpinalHDL, high-level synthesis (HLS) from programming\nlanguages like C or SystemC, and more recently, leveraging large language\nmodels (LLMs) to generate hardware description language (HDL) code from natural\nlanguage descriptions. However, each method has limitations in terms of\nexpressiveness, correctness, and performance, leading to a persistent\ncontradiction between the level of automation and the effectiveness of the\ndesign. Overall, how to automatically design highly efficient and practical\nprocessors with minimal human effort remains a challenge.\n  In this paper, we propose AGON, a novel framework designed to leverage LLMs\nfor the efficient design of out-of-order (OoO) customized processors with\nminimal human effort. Central to AGON is the nano-operator function (nOP\nfunction) based Intermediate Representation (IR), which bridges high-level\ndescriptions and hardware implementations while decoupling functionality from\nperformance optimization, thereby providing an automatic design framework that\nis expressive and efficient, has correctness guarantees, and enables PPA\n(Power, Performance, and Area) optimization.\n  Experimental results show that superior to previous LLM-assisted automatic\ndesign flows, AGON facilitates designing a series of customized OoO processors\nthat achieve on average 2.35 $\\times$ speedup compared with BOOM, a\ngeneral-purpose CPU designed by experts, with minimal design effort.",
      "authors": [
        "Chongxiao Li",
        "Di Huang",
        "Pengwei Jin",
        "Tianyun Ma",
        "Husheng Han",
        "Shuyao Cheng",
        "Yifan Hao",
        "Yongwei Zhao",
        "Guanglin Xu",
        "Zidong Du",
        "Rui Zhang",
        "Xiaqing Li",
        "Yuanbo Wen",
        "Xing Hu",
        "Qi Guo"
      ],
      "categories": [
        "cs.AR"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20954v2",
        "http://arxiv.org/pdf/2412.20954v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.14772v1",
      "title": "DropMicroFluidAgents (DMFAs): Autonomous Droplet Microfluidic Research\n  Framework Through Large Language Model Agents",
      "published": "2024-12-30T11:58:52Z",
      "updated": "2024-12-30T11:58:52Z",
      "summary": "Applying Large language models (LLMs) within specific domains requires\nsubstantial adaptation to account for the unique terminologies, nuances, and\ncontext-specific challenges inherent to those areas. Here, we introduce\nDropMicroFluidAgents (DMFAs), an advanced language-driven framework leveraging\nstate-of-the-art pre-trained LLMs. DMFAs employs LLM agents to perform two key\nfunctions: (1) delivering focused guidance, answers, and suggestions specific\nto droplet microfluidics and (2) generating machine learning models to optimise\nand automate the design of droplet microfluidic devices, including the creation\nof code-based computer-aided design (CAD) scripts to enable rapid and precise\ndesign execution. Experimental evaluations demonstrated that the integration of\nDMFAs with the LLAMA3.1 model yielded the highest accuracy of 76.15%,\nunderscoring the significant performance enhancement provided by agent\nintegration. This effect was particularly pronounced when DMFAs were paired\nwith the GEMMA2 model, resulting in a 34.47% improvement in accuracy compared\nto the standalone GEMMA2 configuration. This study demonstrates the effective\nuse of LLM agents in droplet microfluidics research as powerful tools for\nautomating workflows, synthesising knowledge, optimising designs, and\ninteracting with external systems. These capabilities enable their application\nacross education and industrial support, driving greater efficiency in\nscientific discovery and innovation.",
      "authors": [
        "Dinh-Nguyen Nguyen",
        "Raymond Kai-Yu Tong",
        "Ngoc-Duy Dinh"
      ],
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.14772v1",
        "http://arxiv.org/pdf/2501.14772v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.01984v1",
      "title": "Leveraging AI for Automatic Classification of PCOS Using Ultrasound\n  Imaging",
      "published": "2024-12-30T11:56:11Z",
      "updated": "2024-12-30T11:56:11Z",
      "summary": "The AUTO-PCOS Classification Challenge seeks to advance the diagnostic\ncapabilities of artificial intelligence (AI) in identifying Polycystic Ovary\nSyndrome (PCOS) through automated classification of healthy and unhealthy\nultrasound frames. This report outlines our methodology for building a robust\nAI pipeline utilizing transfer learning with the InceptionV3 architecture to\nachieve high accuracy in binary classification. Preprocessing steps ensured the\ndataset was optimized for training, validation, and testing, while\ninterpretability methods like LIME and saliency maps provided valuable insights\ninto the model's decision-making. Our approach achieved an accuracy of 90.52%,\nwith precision, recall, and F1-score metrics exceeding 90% on validation data,\ndemonstrating its efficacy. The project underscores the transformative\npotential of AI in healthcare, particularly in addressing diagnostic challenges\nlike PCOS. Key findings, challenges, and recommendations for future\nenhancements are discussed, highlighting the pathway for creating reliable,\ninterpretable, and scalable AI-driven medical diagnostic tools.",
      "authors": [
        "Atharva Divekar",
        "Atharva Sonawane"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.4.9"
      ],
      "links": [
        "http://arxiv.org/abs/2501.01984v1",
        "http://arxiv.org/pdf/2501.01984v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20867v1",
      "title": "Holistic Construction Automation with Modular Robots: From High-Level\n  Task Specification to Execution",
      "published": "2024-12-30T11:11:13Z",
      "updated": "2024-12-30T11:11:13Z",
      "summary": "In situ robotic automation in construction is challenging due to constantly\nchanging environments, a shortage of robotic experts, and a lack of\nstandardized frameworks bridging robotics and construction practices. This work\nproposes a holistic framework for construction task specification, optimization\nof robot morphology, and mission execution using a mobile modular\nreconfigurable robot. Users can specify and monitor the desired robot behavior\nthrough a graphical interface. Our framework identifies an optimized robot\nmorphology and enables automatic real-world execution by integrating Building\nInformation Modelling (BIM). By leveraging modular robot components, we ensure\nseamless and fast adaption to the specific demands of the construction task.\nExperimental validation demonstrates that our approach robustly enables the\nautonomous execution of robotic drilling.",
      "authors": [
        "Jonathan K\u00fclz",
        "Michael Terzer",
        "Marco Magri",
        "Andrea Giusti",
        "Matthias Althoff"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20867v1",
        "http://arxiv.org/pdf/2412.20867v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20864v1",
      "title": "Enhancing Annotated Bibliography Generation with LLM Ensembles",
      "published": "2024-12-30T11:07:05Z",
      "updated": "2024-12-30T11:07:05Z",
      "summary": "This work proposes a novel approach to enhancing annotated bibliography\ngeneration through Large Language Model (LLM) ensembles. In particular,\nmultiple LLMs in different roles -- controllable text generation, evaluation,\nand summarization -- are introduced and validated using a systematic\nmethodology to enhance model performance in scholarly tasks. Output diversity\namong the ensemble that generates text is obtained using different LLM\nparameters, followed by an LLM acting as a judge to assess relevance, accuracy,\nand coherence. Responses selected by several combining strategies are then\nmerged and refined through summarization and redundancy removal techniques. The\npreliminary experimental validation demonstrates that the combined outputs from\nthe LLM ensemble improve coherence and relevance compared to individual\nresponses, leading to a 38% improvement in annotation quality and a 51%\nreduction in content redundancy, thus highlighting the potential for automating\ncomplex scholarly tasks while maintaining high-quality standards.",
      "authors": [
        "Sergio Bermejo"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20864v1",
        "http://arxiv.org/pdf/2412.20864v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20838v1",
      "title": "Dual-Space Augmented Intrinsic-LoRA for Wind Turbine Segmentation",
      "published": "2024-12-30T10:06:02Z",
      "updated": "2024-12-30T10:06:02Z",
      "summary": "Accurate segmentation of wind turbine blade (WTB) images is critical for\neffective assessments, as it directly influences the performance of automated\ndamage detection systems. Despite advancements in large universal vision\nmodels, these models often underperform in domain-specific tasks like WTB\nsegmentation. To address this, we extend Intrinsic LoRA for image segmentation,\nand propose a novel dual-space augmentation strategy that integrates both\nimage-level and latent-space augmentations. The image-space augmentation is\nachieved through linear interpolation between image pairs, while the\nlatent-space augmentation is accomplished by introducing a noise-based latent\nprobabilistic model. Our approach significantly boosts segmentation accuracy,\nsurpassing current state-of-the-art methods in WTB image segmentation.",
      "authors": [
        "Shubh Singhal",
        "Ra\u00fcl P\u00e9rez-Gonzalo",
        "Andreas Espersen",
        "Antonio Agudo"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20838v1",
        "http://arxiv.org/pdf/2412.20838v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20830v1",
      "title": "ReFlow6D: Refraction-Guided Transparent Object 6D Pose Estimation via\n  Intermediate Representation Learning",
      "published": "2024-12-30T09:53:26Z",
      "updated": "2024-12-30T09:53:26Z",
      "summary": "Transparent objects are ubiquitous in daily life, making their perception and\nrobotics manipulation important. However, they present a major challenge due to\ntheir distinct refractive and reflective properties when it comes to accurately\nestimating the 6D pose. To solve this, we present ReFlow6D, a novel method for\ntransparent object 6D pose estimation that harnesses the\nrefractive-intermediate representation. Unlike conventional approaches, our\nmethod leverages a feature space impervious to changes in RGB image space and\nindependent of depth information. Drawing inspiration from image matting, we\nmodel the deformation of the light path through transparent objects, yielding a\nunique object-specific intermediate representation guided by light refraction\nthat is independent of the environment in which objects are observed. By\nintegrating these intermediate features into the pose estimation network, we\nshow that ReFlow6D achieves precise 6D pose estimation of transparent objects,\nusing only RGB images as input. Our method further introduces a novel\ntransparent object compositing loss, fostering the generation of superior\nrefractive-intermediate features. Empirical evaluations show that our approach\nsignificantly outperforms state-of-the-art methods on TOD and Trans32K-6D\ndatasets. Robot grasping experiments further demonstrate that ReFlow6D's pose\nestimation accuracy effectively translates to real-world robotics task. The\nsource code is available at: https://github.com/StoicGilgamesh/ReFlow6D and\nhttps://github.com/StoicGilgamesh/matting_rendering.",
      "authors": [
        "Hrishikesh Gupta",
        "Stefan Thalhammer",
        "Jean-Baptiste Weibel",
        "Alexander Haberl",
        "Markus Vincze"
      ],
      "categories": [
        "cs.CV",
        "cs.RO",
        "68T45",
        "I.4.8"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3455897",
        "http://arxiv.org/abs/2412.20830v1",
        "http://arxiv.org/pdf/2412.20830v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2502.17442v1",
      "title": "Thinking Before Running! Efficient Code Generation with Thorough\n  Exploration and Optimal Refinement",
      "published": "2024-12-30T07:02:15Z",
      "updated": "2024-12-30T07:02:15Z",
      "summary": "Code generation is crucial in software engineering for automating the coding\nprocess efficiently. While test-time computation methods show promise, they\nsuffer from high latency due to multiple computation rounds. To overcome this,\nwe introduce ThinkCoder, a framework that combines thorough exploration with\noptimal refinement. The exploration phase diversifies the solution space by\nsearching for potential solutions, followed by a refinement phase that enhances\nprecision. This approach allows us to select the best solution through careful\nconsideration before taking action, avoiding excessive trial and error. To\nfurther minimize test-time computation overhead, we introduce preference-driven\noptimization with Reinforced Self-Training (ReST), which uses exploration\ntrajectories from ThinkCoder to guide LLM's evolution. By learning preferences,\nthis approach improves LLM's exploration efficiency, reducing computational\ncosts while maintaining accuracy. ThinkCoder boosts the performance of multiple\nbase LLMs, excelling on benchmarks like HumanEval and MBPP. Compared to SOTA\nmodels, it improves Pass@1 by 1.5\\% over MapCoder with just 21.7\\% of the\ncomputation cost. Against AgentCoder, ThinkCoder achieves a 0.6\\% higher Pass@1\nafter 2 rounds, outperforming AgentCoder's 5 rounds. Additionally, ReST with\nsuccess trajectories enhances efficiency, allowing models like LLaMA2-7B to\nachieve competitive results using only 20\\% of the computational resources.\nThese results highlight the framework's effectiveness and scalability.",
      "authors": [
        "Xiaoqing Zhang",
        "Yuhan Liu",
        "Flood Sung",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2502.17442v1",
        "http://arxiv.org/pdf/2502.17442v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20735v2",
      "title": "HUNYUANPROVER: A Scalable Data Synthesis Framework and Guided Tree\n  Search for Automated Theorem Proving",
      "published": "2024-12-30T06:18:33Z",
      "updated": "2024-12-31T10:48:14Z",
      "summary": "We introduce HunyuanProver, an language model finetuned from the Hunyuan 7B\nfor interactive automatic theorem proving with LEAN4. To alleviate the data\nsparsity issue, we design a scalable framework to iterative synthesize data\nwith low cost. Besides, guided tree search algorithms are designed to enable\neffective ``system 2 thinking`` of the prover. HunyuanProver achieves\nstate-of-the-art (SOTA) performances on major benchmarks. Specifically, it\nachieves a pass of 68.4% on the miniF2F-test compared to 65.9%, the current\nSOTA results. It proves 4 IMO statements (imo_1960_p2, imo_1962_p2},\nimo_1964_p2 and imo_1983_p6) in miniF2F-test. To benefit the community, we will\nopen-source a dataset of 30k synthesized instances, where each instance\ncontains the original question in natural language, the converted statement by\nautoformalization, and the proof by HunyuanProver.",
      "authors": [
        "Yang Li",
        "Dong Du",
        "Linfeng Song",
        "Chen Li",
        "Weikang Wang",
        "Tao Yang",
        "Haitao Mi"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20735v2",
        "http://arxiv.org/pdf/2412.20735v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20680v1",
      "title": "Online Adaptive Platoon Control for Connected and Automated Vehicles via\n  Physics Enhanced Residual Learning",
      "published": "2024-12-30T03:21:44Z",
      "updated": "2024-12-30T03:21:44Z",
      "summary": "This paper introduces a physics enhanced residual learning (PERL) framework\nfor connected and automated vehicle (CAV) platoon control, addressing the\ndynamics and unpredictability inherent to platoon systems. The framework first\ndevelops a physics-based controller to model vehicle dynamics, using driving\nspeed as input to optimize safety and efficiency. Then the residual controller,\nbased on neural network (NN) learning, enriches the prior knowledge of the\nphysical model and corrects residuals caused by vehicle dynamics. By\nintegrating the physical model with data-driven online learning, the PERL\nframework retains the interpretability and transparency of physics-based models\nand enhances the adaptability and precision of data-driven learning, achieving\nsignificant improvements in computational efficiency and control accuracy in\ndynamic scenarios. Simulation and robot car platform tests demonstrate that\nPERL significantly outperforms pure physical and learning models, reducing\naverage cumulative absolute position and speed errors by up to 58.5% and 40.1%\n(physical model) and 58.4% and 47.7% (NN model). The reduced-scale robot car\nplatform tests further validate the adaptive PERL framework's superior accuracy\nand rapid convergence under dynamic disturbances, reducing position and speed\ncumulative errors by 72.73% and 99.05% (physical model) and 64.71% and 72.58%\n(NN model). PERL enhances platoon control performance through online parameter\nupdates when external disturbances are detected. Results demonstrate the\nadvanced framework's exceptional accuracy and rapid convergence capabilities,\nproving its effectiveness in maintaining platoon stability under diverse\nconditions.",
      "authors": [
        "Peng Zhang",
        "Heye Huang",
        "Hang Zhou",
        "Haotian Shi",
        "Keke Long",
        "Xiaopeng Li"
      ],
      "categories": [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20680v1",
        "http://arxiv.org/pdf/2412.20680v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20667v1",
      "title": "Highway Managed Lane Usage and Tolling for Mixed Traffic Flows with\n  Connected Automated Vehicles (CAVs) and High-Occupancy Vehicles (HOVs)",
      "published": "2024-12-30T02:48:02Z",
      "updated": "2024-12-30T02:48:02Z",
      "summary": "This paper investigates managed lane (ML) toll setting and its effect under\nmixed traffic of connected automated vehicles (CAVs), high-occupancy vehicles\n(HOVs), and human-driven vehicles (HDVs), with a goal to avoid flow breakdown\nand minimize total social cost. A mesoscopic finite-difference traffic\nsimulation model considers the flow-density relationship at different CAV\nmarket penetration rates, lane-changing behavior, and multiple entries/exits,\ninteracting with a reactive toll setting mechanism. The results of the Monte\nCarlo simulation suggest an optimal policy of untolled HOV/CAV use with HDV\ntolls in particular scenarios of limited CAV market penetration. Small and\ntargeted tolling avoids flow breakdown in ML while prioritizing HOVs and other\nvehicles with high values of time. Extensions of the formulation and\nsensitivity analysis quantify the benefits of converting high-occupancy HDVs to\nCAVs. The optimal tolling regime combines traffic science notions of flow\nstability and the economics of resource allocation.",
      "authors": [
        "Max T. M. Ng",
        "Hani S. Mahmassani"
      ],
      "categories": [
        "eess.SY",
        "cs.SY",
        "math.OC"
      ],
      "links": [
        "http://dx.doi.org/10.1177/03611981231185145",
        "http://arxiv.org/abs/2412.20667v1",
        "http://arxiv.org/pdf/2412.20667v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20635v1",
      "title": "NetFlowGen: Leveraging Generative Pre-training for Network Traffic\n  Dynamics",
      "published": "2024-12-30T00:47:49Z",
      "updated": "2024-12-30T00:47:49Z",
      "summary": "Understanding the traffic dynamics in networks is a core capability for\nautomated systems to monitor and analyze networking behaviors, reducing\nexpensive human efforts and economic risks through tasks such as traffic\nclassification, congestion prediction, and attack detection. However, it is\nstill challenging to accurately model network traffic with machine learning\napproaches in an efficient and broadly applicable manner. Task-specific models\ntrained from scratch are used for different networking applications, which\nlimits the efficiency of model development and generalization of model\ndeployment. Furthermore, while networking data is abundant, high-quality\ntask-specific labels are often insufficient for training individual models.\nLarge-scale self-supervised learning on unlabeled data provides a natural\npathway for tackling these challenges. We propose to pre-train a\ngeneral-purpose machine learning model to capture traffic dynamics with only\ntraffic data from NetFlow records, with the goal of fine-tuning for different\ndownstream tasks with small amount of labels. Our presented NetFlowGen\nframework goes beyond a proof-of-concept for network traffic pre-training and\naddresses specific challenges such as unifying network feature representations,\nlearning from large unlabeled traffic data volume, and testing on real\ndownstream tasks in DDoS attack detection. Experiments demonstrate promising\nresults of our pre-training framework on capturing traffic dynamics and\nadapting to different networking tasks.",
      "authors": [
        "Jiawei Zhou",
        "Woojeong Kim",
        "Zhiying Xu",
        "Alexander M. Rush",
        "Minlan Yu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20635v1",
        "http://arxiv.org/pdf/2412.20635v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20613v1",
      "title": "Do Current Video LLMs Have Strong OCR Abilities? A Preliminary Study",
      "published": "2024-12-29T23:20:01Z",
      "updated": "2024-12-29T23:20:01Z",
      "summary": "With the rise of multimodal large language models, accurately extracting and\nunderstanding textual information from video content, referred to as video\nbased optical character recognition (Video OCR), has become a crucial\ncapability. This paper introduces a novel benchmark designed to evaluate the\nvideo OCR performance of multi-modal models in videos. Comprising 1,028 videos\nand 2,961 question-answer pairs, this benchmark proposes several key challenges\nthrough 6 distinct subtasks: (1) Recognition of text content itself and its\nbasic visual attributes, (2)Semantic and Spatial Comprehension of OCR objects\nin videos (3) Dynamic Motion detection and Temporal Localization. We developed\nthis benchmark using a semi-automated approach that integrates the OCR ability\nof image LLMs with manual refinement, balancing efficiency, cost, and data\nquality. Our resource aims to help advance research in video LLMs and\nunderscores the need for improving OCR ability for video LLMs. The benchmark\nwill be released on https://github.com/YuHuiGao/FG-Bench.git.",
      "authors": [
        "Yulin Fei",
        "Yuhui Gao",
        "Xingyuan Xian",
        "Xiaojin Zhang",
        "Tao Wu",
        "Wei Chen"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20613v1",
        "http://arxiv.org/pdf/2412.20613v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20602v1",
      "title": "NLP-based Regulatory Compliance -- Using GPT 4.0 to Decode Regulatory\n  Documents",
      "published": "2024-12-29T22:14:59Z",
      "updated": "2024-12-29T22:14:59Z",
      "summary": "Large Language Models (LLMs) such as GPT-4.0 have shown significant promise\nin addressing the semantic complexities of regulatory documents, particularly\nin detecting inconsistencies and contradictions. This study evaluates GPT-4.0's\nability to identify conflicts within regulatory requirements by analyzing a\ncurated corpus with artificially injected ambiguities and contradictions,\ndesigned in collaboration with architects and compliance engineers. Using\nmetrics such as precision, recall, and F1 score, the experiment demonstrates\nGPT-4.0's effectiveness in detecting inconsistencies, with findings validated\nby human experts. The results highlight the potential of LLMs to enhance\nregulatory compliance processes, though further testing with larger datasets\nand domain-specific fine-tuning is needed to maximize accuracy and practical\napplicability. Future work will explore automated conflict resolution and\nreal-world implementation through pilot projects with industry partners.",
      "authors": [
        "Bimal Kumar",
        "Dmitri Roussinov"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20602v1",
        "http://arxiv.org/pdf/2412.20602v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20571v1",
      "title": "Segmentation of Muscularis Propria in Colon Histopathology Images Using\n  Vision Transformers for Hirschsprung's Disease",
      "published": "2024-12-29T20:43:43Z",
      "updated": "2024-12-29T20:43:43Z",
      "summary": "Hirschsprung's disease (HD) is a congenital birth defect diagnosed by\nidentifying the lack of ganglion cells within the colon's muscularis propria,\nspecifically within the myenteric plexus regions. There may be advantages for\nquantitative assessments of histopathology images of the colon, such as\ncounting the ganglion and assessing their spatial distribution; however, this\nwould be time-intensive for pathologists, costly, and subject to inter- and\nintra-rater variability. Previous research has demonstrated the potential for\ndeep learning approaches to automate histopathology image analysis, including\nsegmentation of the muscularis propria using convolutional neural networks\n(CNNs). Recently, Vision Transformers (ViTs) have emerged as a powerful deep\nlearning approach due to their self-attention. This study explores the\napplication of ViTs for muscularis propria segmentation in calretinin-stained\nhistopathology images and compares their performance to CNNs and shallow\nlearning methods. The ViT model achieved a DICE score of 89.9% and Plexus\nInclusion Rate (PIR) of 100%, surpassing the CNN (DICE score of 89.2%; PIR of\n96.0%) and k-means clustering method (DICE score of 80.7%; PIR 77.4%). Results\nassert that ViTs are a promising tool for advancing HD-related image analysis.",
      "authors": [
        "Youssef Megahed",
        "Anthony Fuller",
        "Saleh Abou-Alwan",
        "Dina El Demellawy",
        "Adrian D. C. Chan"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20571v1",
        "http://arxiv.org/pdf/2412.20571v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20538v1",
      "title": "Exploiting Aggregation and Segregation of Representations for Domain\n  Adaptive Human Pose Estimation",
      "published": "2024-12-29T17:59:45Z",
      "updated": "2024-12-29T17:59:45Z",
      "summary": "Human pose estimation (HPE) has received increasing attention recently due to\nits wide application in motion analysis, virtual reality, healthcare, etc.\nHowever, it suffers from the lack of labeled diverse real-world datasets due to\nthe time- and labor-intensive annotation. To cope with the label deficiency\nissue, one common solution is to train the HPE models with easily available\nsynthetic datasets (source) and apply them to real-world data (target) through\ndomain adaptation (DA). Unfortunately, prevailing domain adaptation techniques\nwithin the HPE domain remain predominantly fixated on effecting alignment and\naggregation between source and target features, often sidestepping the crucial\ntask of excluding domain-specific representations. To rectify this, we\nintroduce a novel framework that capitalizes on both representation aggregation\nand segregation for domain adaptive human pose estimation. Within this\nframework, we address the network architecture aspect by disentangling\nrepresentations into distinct domain-invariant and domain-specific components,\nfacilitating aggregation of domain-invariant features while simultaneously\nsegregating domain-specific ones. Moreover, we tackle the discrepancy\nmeasurement facet by delving into various keypoint relationships and applying\nseparate aggregation or segregation mechanisms to enhance alignment. Extensive\nexperiments on various benchmarks, e.g., Human3.6M, LSP, H3D, and FreiHand,\nshow that our method consistently achieves state-of-the-art performance. The\nproject is available at \\url{https://github.com/davidpengucf/EPIC}.",
      "authors": [
        "Qucheng Peng",
        "Ce Zheng",
        "Zhengming Ding",
        "Pu Wang",
        "Chen Chen"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20538v1",
        "http://arxiv.org/pdf/2412.20538v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20498v3",
      "title": "Regulating radiology AI medical devices that evolve in their lifecycle",
      "published": "2024-12-29T15:28:26Z",
      "updated": "2025-01-30T23:58:37Z",
      "summary": "Over time, the distribution of medical image data drifts due to factors such\nas shifts in patient demographics, acquisition devices, and disease\nmanifestations. While human radiologists can adjust their expertise to\naccommodate such variations, deep learning models cannot. In fact, such models\nare highly susceptible to even slight variations in image characteristics.\nConsequently, manufacturers must conduct regular updates to ensure that they\nremain safe and effective. Performing such updates in the United States and\nEuropean Union required, until recently, obtaining re-approval. Given the time\nand financial burdens associated with these processes, updates were infrequent,\nand obsolete systems remained in operation for too long. During 2024, several\nregulatory developments promised to streamline the safe rollout of model\nupdates: The European Artificial Intelligence Act came into effect last August,\nand the Food and Drug Administration (FDA) issued final marketing submission\nrecommendations for a Predetermined Change Control Plan (PCCP) in December. We\nprovide an overview of these developments and outline the key building blocks\nnecessary for successfully deploying dynamic systems. At the heart of these\nregulations - and as prerequisites for manufacturers to conduct model updates\nwithout re-approval - are clear descriptions of data collection and re-training\nprocesses, coupled with robust real-world quality monitoring mechanisms.",
      "authors": [
        "Camila Gonz\u00e1lez",
        "Moritz Fuchs",
        "Daniel Pinto dos Santos",
        "Philipp Matthies",
        "Manuel Trenz",
        "Maximilian Gr\u00fcning",
        "Akshay Chaudhari",
        "David B. Larson",
        "Ahmed Othman",
        "Moon Kim",
        "Felix Nensa",
        "Anirban Mukhopadhyay"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20498v3",
        "http://arxiv.org/pdf/2412.20498v3"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20489v1",
      "title": "Low-Thrust Under-Actuated Satellite Formation Guidance and Control\n  Strategies",
      "published": "2024-12-29T15:04:32Z",
      "updated": "2024-12-29T15:04:32Z",
      "summary": "This study presents autonomous guidance and control strategies for the\npurpose of reconfiguring close-range multi-satellite formations. The formation\nunder consideration includes $N$ under-actuated deputy satellites and an\nuncontrolled virtual or physical chief spacecraft. The guidance problem is\nformulated as a trajectory optimization problem that incorporates typical\ndynamical and physical constraints, alongside a minimum acceleration threshold.\nThis latter constraint arises from the physical limitations of the adopted\nlow-thrust technology, which is commonly employed for precise, close-range\nrelative orbital maneuvers. The guidance and control problem is addressed in\ntwo frameworks: centralized and distributed. The centralized approach provides\na fuel-optimal solution, but it is practical only for formations with a small\nnumber of deputies. The distributed approach is more scalable but yields\nsub-optimal solutions. In the centralized framework, the chief is a physical\nsatellite responsible for all calculations, while in the distributed framework,\nthe chief is treated as a virtual point mass orbiting the Earth, and each\ndeputy performs its own guidance and control calculations onboard. The study\nemphasizes the spaceborne implementation of the closed-loop control system,\naiming for a reliable and automated solution to the optimal control problem. To\nthis end, the risk of infeasibility is mitigated through first identifying the\nconstraints that pose a potential threat of infeasibility, then properly\nsoftening them. Two Model Predictive Control architectures are implemented and\ncompared, namely, a shrinking-horizon and a fixed-horizon schemes.\nPerformances, in terms of fuel expenditure and achieved control accuracy, are\nanalyzed on typical close-range reconfigurations requested by Earth observation\nmissions and are compared against different implementations proposed in the\nliterature.",
      "authors": [
        "Ahmed Mahfouz",
        "Gabriella Gaias",
        "Florio Dalla Vedova",
        "Holger Voos"
      ],
      "categories": [
        "eess.SY",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20489v1",
        "http://arxiv.org/pdf/2412.20489v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20420v1",
      "title": "Automated Demand Forecasting in small to medium-sized enterprises",
      "published": "2024-12-29T10:05:47Z",
      "updated": "2024-12-29T10:05:47Z",
      "summary": "In response to the growing demand for accurate demand forecasts, this\nresearch proposes a generalized automated sales forecasting pipeline tailored\nfor small- to medium-sized enterprises (SMEs). Unlike large corporations with\ndedicated data scientists for sales forecasting, SMEs often lack such\nresources. To address this, we developed a comprehensive forecasting pipeline\nthat automates time series sales forecasting, encompassing data preparation,\nmodel training, and selection based on validation results.\n  The development included two main components: model preselection and the\nforecasting pipeline. In the first phase, state-of-the-art methods were\nevaluated on a showcase dataset, leading to the selection of ARIMA, SARIMAX,\nHolt-Winters Exponential Smoothing, Regression Tree, Dilated Convolutional\nNeural Networks, and Generalized Additive Models. An ensemble prediction of\nthese models was also included. Long-Short-Term Memory (LSTM) networks were\nexcluded due to suboptimal prediction accuracy, and Facebook Prophet was\nomitted for compatibility reasons.\n  In the second phase, the proposed forecasting pipeline was tested with SMEs\nin the food and electric industries, revealing variable model performance\nacross different companies. While one project-based company derived no benefit,\nothers achieved superior forecasts compared to naive estimators.\n  Our findings suggest that no single model is universally superior. Instead, a\ndiverse set of models, when integrated within an automated validation\nframework, can significantly enhance forecasting accuracy for SMEs. These\nresults emphasize the importance of model diversity and automated validation in\naddressing the unique needs of each business. This research contributes to the\nfield by providing SMEs access to state-of-the-art sales forecasting tools,\nenabling data-driven decision-making and improving operational efficiency.",
      "authors": [
        "Thomas Gaertner",
        "Christoph Lippert",
        "Stefan Konigorski"
      ],
      "categories": [
        "econ.EM"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20420v1",
        "http://arxiv.org/pdf/2412.20420v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2501.00063v1",
      "title": "\"Generative Models for Financial Time Series Data: Enhancing\n  Signal-to-Noise Ratio and Addressing Data Scarcity in A-Share Market",
      "published": "2024-12-29T09:35:23Z",
      "updated": "2024-12-29T09:35:23Z",
      "summary": "The financial industry is increasingly seeking robust methods to address the\nchallenges posed by data scarcity and low signal-to-noise ratios, which limit\nthe application of deep learning techniques in stock market analysis. This\npaper presents two innovative generative model-based approaches to synthesize\nstock data, specifically tailored for different scenarios within the A-share\nmarket in China. The first method, a sector-based synthesis approach, enhances\nthe signal-to-noise ratio of stock data by classifying the characteristics of\nstocks from various sectors in China's A-share market. This method employs an\nApproximate Non-Local Total Variation algorithm to smooth the generated data, a\nbandpass filtering method based on Fourier Transform to eliminate noise, and\nDenoising Diffusion Implicit Models to accelerate sampling speed. The second\nmethod, a recursive stock data synthesis approach based on pattern recognition,\nis designed to synthesize data for stocks with short listing periods and\nlimited comparable companies. It leverages pattern recognition techniques and\nMarkov models to learn and generate variable-length stock sequences, while\nintroducing a sub-time-level data augmentation method to alleviate data\nscarcity issues.We validate the effectiveness of these methods through\nextensive experiments on various datasets, including those from the main board,\nSTAR Market, Growth Enterprise Market Board, Beijing Stock Exchange, NASDAQ,\nNYSE, and AMEX. The results demonstrate that our synthesized data not only\nimprove the performance of predictive models but also enhance the\nsignal-to-noise ratio of individual stock signals in price trading strategies.\nFurthermore, the introduction of sub-time-level data significantly improves the\nquality of synthesized data.",
      "authors": [
        "Guangming Che"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2501.00063v1",
        "http://arxiv.org/pdf/2501.00063v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20397v2",
      "title": "Learning Policies for Dynamic Coalition Formation in Multi-Robot Task\n  Allocation",
      "published": "2024-12-29T08:18:56Z",
      "updated": "2025-02-22T14:41:18Z",
      "summary": "We propose a decentralized, learning-based framework for dynamic coalition\nformation in Multi-Robot Task Allocation (MRTA). Our approach extends\nMulti-Agent Proximal Policy Optimization (MAPPO) by integrating spatial action\nmaps, robot motion planning, intention sharing, and task allocation revision to\nenable effective and adaptive coalition formation. Extensive simulation studies\nconfirm the effectiveness of our model, enabling each robot to rely solely on\nlocal information to learn timely revisions of task selections and form\ncoalitions with other robots to complete collaborative tasks. Additionally, our\nmodel significantly outperforms existing methods, including a market-based\nbaseline. Furthermore, we evaluate the scalability and generalizability of the\nproposed framework, highlighting its ability to handle large robot populations\nand adapt to scenarios featuring diverse task sets.",
      "authors": [
        "Lucas C. D. Bezerra",
        "Ata\u00edde M. G. dos Santos",
        "Shinkyu Park"
      ],
      "categories": [
        "cs.RO",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20397v2",
        "http://arxiv.org/pdf/2412.20397v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20395v1",
      "title": "A market-based efficient matching mechanism for crowdsourced delivery\n  systems with demand/supply elasticities",
      "published": "2024-12-29T08:13:17Z",
      "updated": "2024-12-29T08:13:17Z",
      "summary": "Crowdsourced delivery (CSD) is an emerging business model that leverages the\nunderutilized or excess capacity of individual drivers to fulfill delivery\ntasks. This paper presents a general formulation of a larege-scale two-sided\nCSD matching problem, considering demand/supply elasticity, heterogeneous\npreferences of both shippers and drivers, and task-bundling. We propose a set\nof methodologies to solve this problem. First, we reveal that the\nfluid-particle decomposition approach of Akamatsu and Oyama (2024) can be\nextended to our general formulation. This approach decomposes the original\nlarge-scale matching problem into a fluidly-approximated task partition problem\n(master problem) and small-scale particle matching problems (sub-problems). We\npropose to introduce a truthful auction mechanism to sub-problems, which\nenables the observation of privately perceived costs for each shipper/driver.\nFurthermore, by finding a theoretical link between auction problems and\nparturbed utility theory, we succeed in accurately reflecting the information\ncollected from auctions to the master problem. This reduces the master problem\nto a smooth convex optimization problem, theoretically guaranteeing the\ncomputational efficiency and solution accuracy of the fluid approximation.\nSecond, we transform the master problem into a traffic assignment problem (TAP)\nbased on a task-chain network. This transformation overcomes the difficulty in\nenumerating task bundles. Finally, we formulate the dual problem of the TAP,\nwhose decision variable is only a price/reward pattern at market equilibrium,\nand develop an efficient accelerated gradient descent method. The numerical\nexperiments clarify that our approach drastically reduces the computational\ncost of the matching problem (~700 times faster than a naive method) without\nsacrificing accuracy of the optimal solution (mostly within 0.5% errors).",
      "authors": [
        "Yuki Oyama",
        "Takashi Akamatsu"
      ],
      "categories": [
        "math.OC",
        "cs.GT"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20395v1",
        "http://arxiv.org/pdf/2412.20395v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2412.20358v1",
      "title": "Emittance Minimization for Aberration Correction I: Aberration\n  correction of an electron microscope without knowing the aberration\n  coefficients",
      "published": "2024-12-29T05:28:48Z",
      "updated": "2024-12-29T05:28:48Z",
      "summary": "Precise alignment of the electron beam is critical for successful application\nof scanning transmission electron microscopes (STEM) to understanding materials\nat atomic level. Despite the success of aberration correctors, aberration\ncorrection is still a complex process. Here we approach aberration correction\nfrom the perspective of accelerator physics and show it is equivalent to\nminimizing the emittance growth of the beam, the span of the phase space\ndistribution of the probe. We train a deep learning model to predict emittance\ngrowth from experimentally accessible Ronchigrams. Both simulation and\nexperimental results show the model can capture the emittance variation with\naberration coefficients accurately. We further demonstrate the model can act as\na fast-executing function for the global optimization of the lens parameters.\nOur approach enables new ways to quickly quantify and automate aberration\ncorrection that takes advantage of the rapid measurements possible with\nhigh-speed electron cameras. In part II of the paper, we demonstrate how the\nemittance metric enables rapid online tuning of the aberration corrector using\nBayesian optimization.",
      "authors": [
        "Desheng Ma",
        "Steven E. Zeltmann",
        "Chenyu Zhang",
        "Zhaslan Baraissov",
        "Yu-Tsun Shao",
        "Cameron Duncan",
        "Jared Maxson",
        "Auralee Edelen",
        "David A. Muller"
      ],
      "categories": [
        "physics.ins-det",
        "cond-mat.mtrl-sci",
        "physics.acc-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2412.20358v1",
        "http://arxiv.org/pdf/2412.20358v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}