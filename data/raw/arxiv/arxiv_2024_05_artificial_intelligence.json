{
  "query": "all:artificial intelligence AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-03-21T23:00:39.288844",
  "target_period": "2024-05",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2405.20880v2",
      "title": "Paying to Do Better: Games with Payments between Learning Agents",
      "published": "2024-05-31T14:55:11Z",
      "updated": "2025-02-11T16:29:04Z",
      "summary": "In repeated games, such as auctions, players typically use learning\nalgorithms to choose their actions. The use of such autonomous learning agents\nhas become widespread on online platforms. In this paper, we explore the impact\nof players incorporating monetary transfer policies into their agents'\nalgorithms, aiming to influence behavior in their favor through the dynamics\nbetween the agents. Our focus is on understanding when players have incentives\nto make use of monetary transfers, how such payments may affect learning\ndynamics, and what the implications are for welfare and its distribution among\nthe players. We propose a simple and general game-theoretic model to capture\nsuch scenarios. Our results on general games show that in a very broad class of\ngames, self-interested players benefit from letting their learning agents make\npayments to other learners during the game dynamics, and that in many cases,\nthis kind of behavior improves welfare for all players. Our results on first-\nand second-price auctions show that in equilibria of the ``payment policy\ngame,'' the agents' dynamics reach strong collusive outcomes with low revenue\nfor the auctioneer. These results raise new questions and highlight a challenge\nfor mechanism design in systems where automated learning agents can benefit\nfrom interacting with their peers in the digital ecosystem and outside the\nboundaries of the mechanism.",
      "authors": [
        "Yoav Kolumbus",
        "Joe Halpern",
        "\u00c9va Tardos"
      ],
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH",
        "91A05, 91A06, 91A10, 91A20, 91A40, 91A80",
        "F.0; I.2; I.2.6; J.4"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20880v2",
        "http://arxiv.org/pdf/2405.20880v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20656v5",
      "title": "Automatic Counting and Classification of Mosquito Eggs in Field Traps",
      "published": "2024-05-31T07:48:48Z",
      "updated": "2024-10-14T13:39:13Z",
      "summary": "Insect pest control poses a global challenge, affecting public health, food\nsafety, and the environment. Diseases transmitted by mosquitoes are expanding\nbeyond tropical regions due to climate change. Agricultural pests further\nexacerbate economic losses by damaging crops. The Sterile Insect Technique\n(SIT) emerges as an eco-friendly alternative to chemical pesticides, involving\nthe sterilization and release of male insects to curb population growth. This\nwork focuses on the automation of the analysis of field ovitraps used to\nfollow-up a SIT program for the Aedes albopictus mosquito in the Valencian\nCommunity, Spain, funded by the Conselleria de Agricultura, Agua, Ganaderia y\nPesca. Previous research has leveraged deep learning algorithms to automate egg\ncounting in ovitraps, yet faced challenges such as manual handling and limited\nanalysis capacity. Innovations in our study include classifying eggs as hatched\nor unhatched and reconstructing ovitraps from partial images, mitigating issues\nof duplicity and cut eggs. Also, our device can analyze multiple ovitraps\nsimultaneously without the need of manual replacement. This approach\nsignificantly enhances the accuracy of egg counting and classification,\nproviding a valuable tool for large-scale field studies.\n  This document describes part of the work of the project Application of\nIndustry 4.0 techniques to the production of tiger mosquitoes for the Sterile\nInsect Technique (MoTIA2,IMDEEA/2022/70), financed by the Valencian Institute\nfor Business Competitiveness (IVACE) and the FEDER funds. The participation of\nJ.Naranjo-Alcazar, J.Grau-Haro and P.Zuccarello has been possible thanks to\nfunding from IVACE and FEDER funds. The participation of D.Almenar has been\nfinanced by the Conselleria de Agricultura, Agua, Ganaderia y Pesca of the\nGeneralitat Valenciana and the Subdireccion de Innovacion y Desarrollo de\nServicios (TRAGSA group).",
      "authors": [
        "Javier Naranjo-Alcazar",
        "Jordi Grau-Haro",
        "Pedro Zuccarello",
        "David Almenar",
        "Jesus Lopez-Ballester"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20656v5",
        "http://arxiv.org/pdf/2405.20656v5"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20643v1",
      "title": "Learning Gaze-aware Compositional GAN",
      "published": "2024-05-31T07:07:54Z",
      "updated": "2024-05-31T07:07:54Z",
      "summary": "Gaze-annotated facial data is crucial for training deep neural networks\n(DNNs) for gaze estimation. However, obtaining these data is labor-intensive\nand requires specialized equipment due to the challenge of accurately\nannotating the gaze direction of a subject. In this work, we present a\ngenerative framework to create annotated gaze data by leveraging the benefits\nof labeled and unlabeled data sources. We propose a Gaze-aware Compositional\nGAN that learns to generate annotated facial images from a limited labeled\ndataset. Then we transfer this model to an unlabeled data domain to take\nadvantage of the diversity it provides. Experiments demonstrate our approach's\neffectiveness in generating within-domain image augmentations in the ETH-XGaze\ndataset and cross-domain augmentations in the CelebAMask-HQ dataset domain for\ngaze estimation DNN training. We also show additional applications of our work,\nwhich include facial image editing and gaze redirection.",
      "authors": [
        "Nerea Aranjuelo",
        "Siyu Huang",
        "Ignacio Arganda-Carreras",
        "Luis Unzueta",
        "Oihana Otaegui",
        "Hanspeter Pfister",
        "Donglai Wei"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3654706",
        "http://arxiv.org/abs/2405.20643v1",
        "http://arxiv.org/pdf/2405.20643v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20606v2",
      "title": "Vision-Language Meets the Skeleton: Progressively Distillation with\n  Cross-Modal Knowledge for 3D Action Representation Learning",
      "published": "2024-05-31T03:40:15Z",
      "updated": "2024-09-15T03:32:03Z",
      "summary": "Skeleton-based action representation learning aims to interpret and\nunderstand human behaviors by encoding the skeleton sequences, which can be\ncategorized into two primary training paradigms: supervised learning and\nself-supervised learning. However, the former one-hot classification requires\nlabor-intensive predefined action categories annotations, while the latter\ninvolves skeleton transformations (e.g., cropping) in the pretext tasks that\nmay impair the skeleton structure. To address these challenges, we introduce a\nnovel skeleton-based training framework (C$^2$VL) based on Cross-modal\nContrastive learning that uses the progressive distillation to learn\ntask-agnostic human skeleton action representation from the Vision-Language\nknowledge prompts. Specifically, we establish the vision-language action\nconcept space through vision-language knowledge prompts generated by\npre-trained large multimodal models (LMMs), which enrich the fine-grained\ndetails that the skeleton action space lacks. Moreover, we propose the\nintra-modal self-similarity and inter-modal cross-consistency softened targets\nin the cross-modal representation learning process to progressively control and\nguide the degree of pulling vision-language knowledge prompts and corresponding\nskeletons closer. These soft instance discrimination and self-knowledge\ndistillation strategies contribute to the learning of better skeleton-based\naction representations from the noisy skeleton-vision-language pairs. During\nthe inference phase, our method requires only the skeleton data as the input\nfor action recognition and no longer for vision-language prompts. Extensive\nexperiments on NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets demonstrate\nthat our method outperforms the previous methods and achieves state-of-the-art\nresults. Code is available at: https://github.com/cseeyangchen/C2VL.",
      "authors": [
        "Yang Chen",
        "Tian He",
        "Junfeng Fu",
        "Ling Wang",
        "Jingcai Guo",
        "Ting Hu",
        "Hong Cheng"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20606v2",
        "http://arxiv.org/pdf/2405.20606v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20585v1",
      "title": "GAMedX: Generative AI-based Medical Entity Data Extractor Using Large\n  Language Models",
      "published": "2024-05-31T02:53:22Z",
      "updated": "2024-05-31T02:53:22Z",
      "summary": "In the rapidly evolving field of healthcare and beyond, the integration of\ngenerative AI in Electronic Health Records (EHRs) represents a pivotal\nadvancement, addressing a critical gap in current information extraction\ntechniques. This paper introduces GAMedX, a Named Entity Recognition (NER)\napproach utilizing Large Language Models (LLMs) to efficiently extract entities\nfrom medical narratives and unstructured text generated throughout various\nphases of the patient hospital visit. By addressing the significant challenge\nof processing unstructured medical text, GAMedX leverages the capabilities of\ngenerative AI and LLMs for improved data extraction. Employing a unified\napproach, the methodology integrates open-source LLMs for NER, utilizing\nchained prompts and Pydantic schemas for structured output to navigate the\ncomplexities of specialized medical jargon. The findings reveal significant\nROUGE F1 score on one of the evaluation datasets with an accuracy of 98\\%. This\ninnovation enhances entity extraction, offering a scalable, cost-effective\nsolution for automated forms filling from unstructured data. As a result,\nGAMedX streamlines the processing of unstructured narratives, and sets a new\nstandard in NER applications, contributing significantly to theoretical and\npractical advancements beyond the medical technology sphere.",
      "authors": [
        "Mohammed-Khalil Ghali",
        "Abdelrahman Farrag",
        "Hajar Sakai",
        "Hicham El Baz",
        "Yu Jin",
        "Sarah Lam"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20585v1",
        "http://arxiv.org/pdf/2405.20585v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2407.13077v1",
      "title": "Visions of a Discipline: Analyzing Introductory AI Courses on YouTube",
      "published": "2024-05-31T01:48:42Z",
      "updated": "2024-05-31T01:48:42Z",
      "summary": "Education plays an indispensable role in fostering societal well-being and is\nwidely regarded as one of the most influential factors in shaping the future of\ngenerations to come. As artificial intelligence (AI) becomes more deeply\nintegrated into our daily lives and the workforce, educational institutions at\nall levels are directing their focus on resources that cater to AI education.\nOur work investigates the current landscape of introductory AI courses on\nYouTube, and the potential for introducing ethics in this context. We\nqualitatively analyze the 20 most watched introductory AI courses on YouTube,\ncoding a total of 92.2 hours of educational content viewed by close to 50\nmillion people. Introductory AI courses do not meaningfully engage with ethical\nor societal challenges of AI (RQ1). When \\textit{defining and framing AI},\nintroductory AI courses foreground excitement around AI's transformative role\nin society, over-exaggerate AI's current and future abilities, and\nanthropomorphize AI (RQ2). In \\textit{teaching AI}, we see a widespread\nreliance on corporate AI tools and frameworks as well as a prioritization on a\nhands-on approach to learning rather than on conceptual foundations (RQ3). In\npromoting key \\textit{AI practices}, introductory AI courses abstract away\nentirely the socio-technical nature of AI classification and prediction, for\nexample by favoring data quantity over data quality (RQ4). We extend our\nanalysis with recommendations that aim to integrate ethical reflections into\nintroductory AI courses. We recommend that introductory AI courses should (1)\nhighlight ethical challenges of AI to present a more balanced perspective, (2)\nraise ethical issues explicitly relevant to the technical concepts discussed\nand (3) nurture a sense of accountability in future AI developers.",
      "authors": [
        "Severin Engelmann",
        "Madiha Zahrah Choksi",
        "Angelina Wang",
        "Casey Fiesler"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2407.13077v1",
        "http://arxiv.org/pdf/2407.13077v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20529v1",
      "title": "An Automatic Question Usability Evaluation Toolkit",
      "published": "2024-05-30T23:04:53Z",
      "updated": "2024-05-30T23:04:53Z",
      "summary": "Evaluating multiple-choice questions (MCQs) involves either labor intensive\nhuman assessments or automated methods that prioritize readability, often\noverlooking deeper question design flaws. To address this issue, we introduce\nthe Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an\nopen-source tool that leverages the Item-Writing Flaws (IWF) rubric for a\ncomprehensive and automated quality evaluation of MCQs. By harnessing the\nlatest in large language models such as GPT-4, advanced word embeddings, and\nTransformers designed to analyze textual complexity, SAQUET effectively\npinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the\ndiscrepancy between commonly used automated evaluation metrics and the human\nassessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs\nacross the five domains of Chemistry, Statistics, Computer Science, Humanities,\nand Healthcare, showing how it effectively distinguishes between flawed and\nflawless questions, providing a level of analysis beyond what is achievable\nwith traditional metrics. With an accuracy rate of over 94% in detecting the\npresence of flaws identified by human evaluators, our findings emphasize the\nlimitations of existing evaluation methods and showcase potential in improving\nthe quality of educational assessments.",
      "authors": [
        "Steven Moore",
        "Eamon Costello",
        "Huy A. Nguyen",
        "John Stamper"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20529v1",
        "http://arxiv.org/pdf/2405.20529v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20526v1",
      "title": "Automated Generation and Tagging of Knowledge Components from\n  Multiple-Choice Questions",
      "published": "2024-05-30T22:57:49Z",
      "updated": "2024-05-30T22:57:49Z",
      "summary": "Knowledge Components (KCs) linked to assessments enhance the measurement of\nstudent learning, enrich analytics, and facilitate adaptivity. However,\ngenerating and linking KCs to assessment items requires significant effort and\ndomain-specific knowledge. To streamline this process for higher-education\ncourses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs)\nin Chemistry and E-Learning. We analyzed discrepancies between the KCs\ngenerated by the Large Language Model (LLM) and those made by humans through\nevaluation from three domain experts in each subject area. This evaluation\naimed to determine whether, in instances of non-matching KCs, evaluators showed\na preference for the LLM-generated KCs over their human-created counterparts.\nWe also developed an ontology induction algorithm to cluster questions that\nassess similar KCs based on their content. Our most effective LLM strategy\naccurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with\neven higher success when considering the top five KC suggestions. Human\nevaluators favored LLM-generated KCs, choosing them over human-assigned ones\napproximately two-thirds of the time, a preference that was statistically\nsignificant across both domains. Our clustering algorithm successfully grouped\nquestions by their underlying KCs without needing explicit labels or contextual\ninformation. This research advances the automation of KC generation and\nclassification for assessment items, alleviating the need for student data or\npredefined KC labels.",
      "authors": [
        "Steven Moore",
        "Robin Schmucker",
        "Tom Mitchell",
        "John Stamper"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3657604.3662030",
        "http://arxiv.org/abs/2405.20526v1",
        "http://arxiv.org/pdf/2405.20526v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20513v2",
      "title": "Deep Modeling of Non-Gaussian Aleatoric Uncertainty",
      "published": "2024-05-30T22:13:17Z",
      "updated": "2025-02-27T16:35:59Z",
      "summary": "Deep learning offers promising new ways to accurately model aleatoric\nuncertainty in robotic state estimation systems, particularly when the\nuncertainty distributions do not conform to traditional assumptions of being\nfixed and Gaussian. In this study, we formulate and evaluate three fundamental\ndeep learning approaches for conditional probability density modeling to\nquantify non-Gaussian aleatoric uncertainty: parametric, discretized, and\ngenerative modeling. We systematically compare the respective strengths and\nweaknesses of these three methods on simulated non-Gaussian densities as well\nas on real-world terrain-relative navigation data. Our results show that these\ndeep learning methods can accurately capture complex uncertainty patterns,\nhighlighting their potential for improving the reliability and robustness of\nestimation systems.",
      "authors": [
        "Aastha Acharya",
        "Caleb Lee",
        "Marissa D'Alonzo",
        "Jared Shamwell",
        "Nisar R. Ahmed",
        "Rebecca Russell"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2024.3511376",
        "http://arxiv.org/abs/2405.20513v2",
        "http://arxiv.org/pdf/2405.20513v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20501v1",
      "title": "ShelfHelp: Empowering Humans to Perform Vision-Independent Manipulation\n  Tasks with a Socially Assistive Robotic Cane",
      "published": "2024-05-30T21:42:54Z",
      "updated": "2024-05-30T21:42:54Z",
      "summary": "The ability to shop independently, especially in grocery stores, is important\nfor maintaining a high quality of life. This can be particularly challenging\nfor people with visual impairments (PVI). Stores carry thousands of products,\nwith approximately 30,000 new products introduced each year in the US market\nalone, presenting a challenge even for modern computer vision solutions.\nThrough this work, we present a proof-of-concept socially assistive robotic\nsystem we call ShelfHelp, and propose novel technical solutions for enhancing\ninstrumented canes traditionally meant for navigation tasks with additional\ncapability within the domain of shopping. ShelfHelp includes a novel visual\nproduct locator algorithm designed for use in grocery stores and a novel\nplanner that autonomously issues verbal manipulation guidance commands to guide\nthe user during product retrieval. Through a human subjects study, we show the\nsystem's success in locating and providing effective manipulation guidance to\nretrieve desired products with novice users. We compare two autonomous verbal\nguidance modes achieving comparable performance to a human assistance baseline\nand present encouraging findings that validate our system's efficiency and\neffectiveness and through positive subjective metrics including competence,\nintelligence, and ease of use.",
      "authors": [
        "Shivendra Agrawal",
        "Suresh Nayak",
        "Ashutosh Naik",
        "Bradley Hayes"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://dx.doi.org/10.5555/3545946.3598805",
        "http://arxiv.org/abs/2405.20501v1",
        "http://arxiv.org/pdf/2405.20501v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20450v1",
      "title": "Decentralized AI: Permissionless LLM Inference on POKT Network",
      "published": "2024-05-30T19:50:07Z",
      "updated": "2024-05-30T19:50:07Z",
      "summary": "POKT Network's decentralized Remote Procedure Call (RPC) infrastructure,\nsurpassing 740 billion requests since launching on MainNet in 2020, is\nwell-positioned to extend into providing AI inference services with minimal\ndesign or implementation modifications. This litepaper illustrates how the\nnetwork's open-source and permissionless design aligns incentives among model\nresearchers, hardware operators, API providers and users whom we term model\nSources, Suppliers, Gateways and Applications respectively. Through its Relay\nMining algorithm, POKT creates a transparent marketplace where costs and\nearnings directly reflect cryptographically verified usage. This decentralized\nframework offers large model AI researchers a new avenue to disseminate their\nwork and generate revenue without the complexities of maintaining\ninfrastructure or building end-user products. Supply scales naturally with\ndemand, as evidenced in recent years and the protocol's free market dynamics.\nPOKT Gateways facilitate network growth, evolution, adoption, and quality by\nacting as application-facing load balancers, providing value-added features\nwithout managing LLM nodes directly. This vertically decoupled network, battle\ntested over several years, is set up to accelerate the adoption, operation,\ninnovation and financialization of open-source models. It is the first mature\npermissionless network whose quality of service competes with centralized\nentities set up to provide application grade inference.",
      "authors": [
        "Daniel Olshansky",
        "Ramiro Rodriguez Colmeiro",
        "Bowen Li"
      ],
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20450v1",
        "http://arxiv.org/pdf/2405.20450v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20213v1",
      "title": "PostDoc: Generating Poster from a Long Multimodal Document Using Deep\n  Submodular Optimization",
      "published": "2024-05-30T16:16:25Z",
      "updated": "2024-05-30T16:16:25Z",
      "summary": "A poster from a long input document can be considered as a one-page\neasy-to-read multimodal (text and images) summary presented on a nice template\nwith good design elements. Automatic transformation of a long document into a\nposter is a very less studied but challenging task. It involves content\nsummarization of the input document followed by template generation and\nharmonization. In this work, we propose a novel deep submodular function which\ncan be trained on ground truth summaries to extract multimodal content from the\ndocument and explicitly ensures good coverage, diversity and alignment of text\nand images. Then, we use an LLM based paraphraser and propose to generate a\ntemplate with various design aspects conditioned on the input content. We show\nthe merits of our approach through extensive automated and human evaluations.",
      "authors": [
        "Vijay Jaisankar",
        "Sambaran Bandyopadhyay",
        "Kalp Vyas",
        "Varre Chaitanya",
        "Shwetha Somasundaram"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20213v1",
        "http://arxiv.org/pdf/2405.20213v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20142v2",
      "title": "MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis\n  of Sleep Disorders with Bidirectional Mamba",
      "published": "2024-05-30T15:16:53Z",
      "updated": "2024-05-31T03:31:23Z",
      "summary": "Monitoring sleep states is essential for evaluating sleep quality and\ndiagnosing sleep disorders. Traditional manual staging is time-consuming and\nprone to subjective bias, often resulting in inconsistent outcomes. Here, we\ndeveloped an automated model for sleep staging and disorder classification to\nenhance diagnostic accuracy and efficiency. Considering the characteristics of\npolysomnography (PSG) multi-lead sleep monitoring, we designed a multimodal\nsleep state classification model, MSSC-BiMamba, that combines an Efficient\nChannel Attention (ECA) mechanism with a Bidirectional State Space Model\n(BSSM). The ECA module allows for weighting data from different sensor\nchannels, thereby amplifying the influence of diverse sensor inputs.\nAdditionally, the implementation of bidirectional Mamba (BiMamba) enables the\nmodel to effectively capture the multidimensional features and long-range\ndependencies of PSG data. The developed model demonstrated impressive\nperformance on sleep stage classification tasks on both the ISRUC-S3 and\nISRUC-S1 datasets, respectively containing data with healthy and unhealthy\nsleep patterns. Also, the model exhibited a high accuracy for sleep health\nprediction when evaluated on a combined dataset consisting of ISRUC and\nSleep-EDF. Our model, which can effectively handle diverse sleep conditions, is\nthe first to apply BiMamba to sleep staging with multimodal PSG data, showing\nsubstantial gains in computational and memory efficiency over traditional\nTransformer-style models. This method enhances sleep health management by\nmaking monitoring more accessible and extending advanced healthcare through\ninnovative technology.",
      "authors": [
        "Chao Zhang",
        "Weirong Cui",
        "Jingjing Guo"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20142v2",
        "http://arxiv.org/pdf/2405.20142v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.20132v4",
      "title": "LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically\n  Generating Metaheuristics",
      "published": "2024-05-30T15:10:59Z",
      "updated": "2025-01-30T08:54:54Z",
      "summary": "Large Language Models (LLMs) such as GPT-4 have demonstrated their ability to\nunderstand natural language and generate complex code snippets. This paper\nintroduces a novel Large Language Model Evolutionary Algorithm (LLaMEA)\nframework, leveraging GPT models for the automated generation and refinement of\nalgorithms. Given a set of criteria and a task definition (the search space),\nLLaMEA iteratively generates, mutates and selects algorithms based on\nperformance metrics and feedback from runtime evaluations. This framework\noffers a unique approach to generating optimized algorithms without requiring\nextensive prior expertise. We show how this framework can be used to generate\nnovel black-box metaheuristic optimization algorithms automatically. LLaMEA\ngenerates multiple algorithms that outperform state-of-the-art optimization\nalgorithms (Covariance Matrix Adaptation Evolution Strategy and Differential\nEvolution) on the five dimensional black box optimization benchmark (BBOB). The\nalgorithms also show competitive performance on the 10- and 20-dimensional\ninstances of the test functions, although they have not seen such instances\nduring the automated generation process. The results demonstrate the\nfeasibility of the framework and identify future directions for automated\ngeneration and optimization of algorithms via LLMs.",
      "authors": [
        "Niki van Stein",
        "Thomas B\u00e4ck"
      ],
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.20132v4",
        "http://arxiv.org/pdf/2405.20132v4"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19982v1",
      "title": "A Deep Reinforcement Learning Approach for Trading Optimization in the\n  Forex Market with Multi-Agent Asynchronous Distribution",
      "published": "2024-05-30T12:07:08Z",
      "updated": "2024-05-30T12:07:08Z",
      "summary": "In today's forex market traders increasingly turn to algorithmic trading,\nleveraging computers to seek more profits. Deep learning techniques as\ncutting-edge advancements in machine learning, capable of identifying patterns\nin financial data. Traders utilize these patterns to execute more effective\ntrades, adhering to algorithmic trading rules. Deep reinforcement learning\nmethods (DRL), by directly executing trades based on identified patterns and\nassessing their profitability, offer advantages over traditional DL approaches.\nThis research pioneers the application of a multi-agent (MA) RL framework with\nthe state-of-the-art Asynchronous Advantage Actor-Critic (A3C) algorithm. The\nproposed method employs parallel learning across multiple asynchronous workers,\neach specialized in trading across multiple currency pairs to explore the\npotential for nuanced strategies tailored to different market conditions and\ncurrency pairs. Two different A3C with lock and without lock MA model was\nproposed and trained on single currency and multi-currency. The results\nindicate that both model outperform on Proximal Policy Optimization model. A3C\nwith lock outperforms other in single currency training scenario and A3C\nwithout Lock outperforms other in multi-currency scenario. The findings\ndemonstrate that this approach facilitates broader and faster exploration of\ndifferent currency pairs, significantly enhancing trading returns.\nAdditionally, the agent can learn a more profitable trading strategy in a\nshorter time.",
      "authors": [
        "Davoud Sarani",
        "Parviz Rashidi-Khazaee"
      ],
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CC"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19982v1",
        "http://arxiv.org/pdf/2405.19982v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19941v1",
      "title": "Synthetic Patients: Simulating Difficult Conversations with Multimodal\n  Generative AI for Medical Education",
      "published": "2024-05-30T11:02:08Z",
      "updated": "2024-05-30T11:02:08Z",
      "summary": "Problem: Effective patient-centered communication is a core competency for\nphysicians. However, both seasoned providers and medical trainees report\ndecreased confidence in leading conversations on sensitive topics such as goals\nof care or end-of-life discussions. The significant administrative burden and\nthe resources required to provide dedicated training in leading difficult\nconversations has been a long-standing problem in medical education.\n  Approach: In this work, we present a novel educational tool designed to\nfacilitate interactive, real-time simulations of difficult conversations in a\nvideo-based format through the use of multimodal generative artificial\nintelligence (AI). Leveraging recent advances in language modeling, computer\nvision, and generative audio, this tool creates realistic, interactive\nscenarios with avatars, or \"synthetic patients.\" These synthetic patients\ninteract with users throughout various stages of medical care using a\ncustom-built video chat application, offering learners the chance to practice\nconversations with patients from diverse belief systems, personalities, and\nethnic backgrounds.\n  Outcomes: While the development of this platform demanded substantial upfront\ninvestment in labor, it offers a highly-realistic simulation experience with\nminimal financial investment. For medical trainees, this educational tool can\nbe implemented within programs to simulate patient-provider conversations and\ncan be incorporated into existing palliative care curriculum to provide a\nscalable, high-fidelity simulation environment for mastering difficult\nconversations.\n  Next Steps: Future developments will explore enhancing the authenticity of\nthese encounters by working with patients to incorporate their histories and\npersonalities, as well as employing the use of AI-generated evaluations to\noffer immediate, constructive feedback to learners post-simulation.",
      "authors": [
        "Simon N. Chu",
        "Alex J. Goodell"
      ],
      "categories": [
        "cs.HC",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19941v1",
        "http://arxiv.org/pdf/2405.19941v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19837v1",
      "title": "Lifelong learning challenges in the era of artificial intelligence: a\n  computational thinking perspective",
      "published": "2024-05-30T08:46:11Z",
      "updated": "2024-05-30T08:46:11Z",
      "summary": "The rapid advancement of artificial intelligence (AI) has brought significant\nchallenges to the education and workforce skills required to take advantage of\nAI for human-AI collaboration in the workplace. As AI continues to reshape\nindustries and job markets, the need to define how AI literacy can be\nconsidered in lifelong learning has become increasingly critical (Cetindamar et\nal., 2022; Laupichler et al., 2022; Romero et al., 2023). Like any new\ntechnology, AI is the subject of both hopes and fears, and what it entails\ntoday presents major challenges (Cugurullo \\& Acheampong, 2023; Villani et al.,\n2018). It also raises profound questions about our own humanity. Will the\nmachine surpass the intelligence of the humans who designed it? What will be\nthe relationship between so-called AI and our human intelligences? How could\nhuman-AI collaboration be regulated in a way that serves the Sustainable\nDevelopment Goals (SDGs)? This paper provides a review of the challenges of\nlifelong learning in the era of AI from a computational thinking, critical\nthinking, and creative competencies perspective, highlighting the implications\nfor management and leadership in organizations.",
      "authors": [
        "Margarida Romero"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19837v1",
        "http://arxiv.org/pdf/2405.19837v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19815v1",
      "title": "Efficient Stimuli Generation using Reinforcement Learning in Design\n  Verification",
      "published": "2024-05-30T08:23:04Z",
      "updated": "2024-05-30T08:23:04Z",
      "summary": "The increasing design complexity of System-on-Chips (SoCs) has led to\nsignificant verification challenges, particularly in meeting coverage targets\nwithin a timely manner. At present, coverage closure is heavily dependent on\nconstrained random and coverage driven verification methodologies where the\nrandomized stimuli are bounded to verify certain scenarios and to reach\ncoverage goals. This process is said to be exhaustive and to consume a lot of\nproject time. In this paper, a novel methodology is proposed to generate\nefficient stimuli with the help of Reinforcement Learning (RL) to reach the\nmaximum code coverage of the Design Under Verification (DUV). Additionally, an\nautomated framework is created using metamodeling to generate a SystemVerilog\ntestbench and an RL environment for any given design. The proposed approach is\napplied to various designs and the produced results proves that the RL agent\nprovides effective stimuli to achieve code coverage faster in comparison with\nbaseline random simulations. Furthermore, various RL agents and reward schemes\nare analyzed in our work.",
      "authors": [
        "Deepak Narayan Gadde",
        "Thomas Nalapat",
        "Aman Kumar",
        "Djones Lettnin",
        "Wolfgang Kunz",
        "Sebastian Simon"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19815v1",
        "http://arxiv.org/pdf/2405.19815v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19784v2",
      "title": "PixelsDB: Serverless and NL-Aided Data Analytics with Flexible Service\n  Levels and Prices",
      "published": "2024-05-30T07:48:43Z",
      "updated": "2024-12-23T06:44:10Z",
      "summary": "Serverless query processing has become increasingly popular due to its\nadvantages, including automated resource management, high elasticity, and\npay-as-you-go pricing. For users who are not system experts, serverless query\nprocessing greatly reduces the cost of owning a data analytic system. However,\nit is still a significant challenge for non-expert users to transform their\ncomplex and evolving data analytic needs into proper SQL queries and select a\nserverless query service that delivers satisfactory performance and price for\neach type of query.\n  This paper presents PixelsDB, an open-source data analytic system that allows\nusers who lack system or SQL expertise to explore data efficiently. It allows\nusers to generate and debug SQL queries using a natural language interface\npowered by fine-tuned language models. The queries are then executed by a\nserverless query engine that offers varying prices for different performance\nservice levels (SLAs). The performance SLAs are natively supported by dedicated\narchitecture design and heterogeneous resource scheduling that can apply\ncost-efficient resources to process non-urgent queries. We demonstrate that the\ncombination of a serverless paradigm, a natural-language-aided interface, and\nflexible SLAs and prices will substantially improve the usability of cloud data\nanalytic systems.",
      "authors": [
        "Haoqiong Bian",
        "Dongyang Geng",
        "Haoyang Li",
        "Yunpeng Chai",
        "Anastasia Ailamaki"
      ],
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.DC",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19784v2",
        "http://arxiv.org/pdf/2405.19784v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19699v2",
      "title": "Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and\n  Future Directions",
      "published": "2024-05-30T05:25:14Z",
      "updated": "2024-06-02T22:11:32Z",
      "summary": "The recruitment process is crucial to an organization's ability to position\nitself for success, from finding qualified and well-fitting job candidates to\nimpacting its output and culture. Therefore, over the past century, human\nresources experts and industrial-organizational psychologists have established\nhiring practices such as attracting candidates with job ads, gauging a\ncandidate's skills with assessments, and using interview questions to assess\norganizational fit. However, the advent of big data and machine learning has\nled to a rapid transformation in the traditional recruitment process as many\norganizations have moved to using artificial intelligence (AI). Given the\nprevalence of AI-based recruitment, there is growing concern that human biases\nmay carry over to decisions made by these systems, which can amplify the effect\nthrough systematic application. Empirical studies have identified prevalent\nbiases in candidate ranking software and chatbot interactions, catalyzing a\ngrowing body of research dedicated to AI fairness over the last decade. This\npaper provides a comprehensive overview of this emerging field by discussing\nthe types of biases encountered in AI-driven recruitment, exploring various\nfairness metrics and mitigation methods, and examining tools for auditing these\nsystems. We highlight current challenges and outline future directions for\ndeveloping fair AI recruitment applications, ensuring equitable candidate\ntreatment and enhancing organizational outcomes.",
      "authors": [
        "Dena F. Mujtaba",
        "Nihar R. Mahapatra"
      ],
      "categories": [
        "cs.CY",
        "K.4.3; I.2.0; J.4"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19699v2",
        "http://arxiv.org/pdf/2405.19699v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19694v1",
      "title": "Grade Like a Human: Rethinking Automated Assessment with Large Language\n  Models",
      "published": "2024-05-30T05:08:15Z",
      "updated": "2024-05-30T05:08:15Z",
      "summary": "While large language models (LLMs) have been used for automated grading, they\nhave not yet achieved the same level of performance as humans, especially when\nit comes to grading complex questions. Existing research on this topic focuses\non a particular step in the grading procedure: grading using predefined\nrubrics. However, grading is a multifaceted procedure that encompasses other\ncrucial steps, such as grading rubrics design and post-grading review. There\nhas been a lack of systematic research exploring the potential of LLMs to\nenhance the entire grading~process.\n  In this paper, we propose an LLM-based grading system that addresses the\nentire grading procedure, including the following key components: 1) Developing\ngrading rubrics that not only consider the questions but also the student\nanswers, which can more accurately reflect students' performance. 2) Under the\nguidance of grading rubrics, providing accurate and consistent scores for each\nstudent, along with customized feedback. 3) Conducting post-grading review to\nbetter ensure accuracy and fairness. Additionally, we collected a new dataset\nnamed OS from a university operating system course and conducted extensive\nexperiments on both our new dataset and the widely used Mohler dataset.\nExperiments demonstrate the effectiveness of our proposed approach, providing\nsome new insights for developing automated grading systems based on LLMs.",
      "authors": [
        "Wenjing Xie",
        "Juxin Niu",
        "Chun Jason Xue",
        "Nan Guan"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19694v1",
        "http://arxiv.org/pdf/2405.19694v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19581v2",
      "title": "Source Code Foundation Models are Transferable Binary Analysis Knowledge\n  Bases",
      "published": "2024-05-30T00:17:44Z",
      "updated": "2024-10-30T16:12:36Z",
      "summary": "Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of\nbinary and source code, aiming to lift binary code to human-readable content\nrelevant to source code, thereby bridging the binary-source semantic gap.\nRecent advancements in uni-modal code model pre-training, particularly in\ngenerative Source Code Foundation Models (SCFMs) and binary understanding\nmodels, have laid the groundwork for transfer learning applicable to HOBRE.\nHowever, existing approaches for HOBRE rely heavily on uni-modal models like\nSCFMs for supervised fine-tuning or general LLMs for prompting, resulting in\nsub-optimal performance. Inspired by recent progress in large multi-modal\nmodels, we propose that it is possible to harness the strengths of uni-modal\ncode models from both sides to bridge the semantic gap effectively. In this\npaper, we introduce a novel probe-and-recover framework that incorporates a\nbinary-source encoder-decoder model and black-box LLMs for binary analysis. Our\napproach leverages the pre-trained knowledge within SCFMs to synthesize\nrelevant, symbol-rich code fragments as context. This additional context\nenables black-box LLMs to enhance recovery accuracy. We demonstrate significant\nimprovements in zero-shot binary summarization and binary function name\nrecovery, with a 10.3% relative gain in CHRF and a 16.7% relative gain in a\nGPT4-based metric for summarization, as well as a 6.7% and 7.4% absolute\nincrease in token-level precision and recall for name recovery, respectively.\nThese results highlight the effectiveness of our approach in automating and\nimproving binary code analysis.",
      "authors": [
        "Zian Su",
        "Xiangzhe Xu",
        "Ziyang Huang",
        "Kaiyuan Zhang",
        "Xiangyu Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19581v2",
        "http://arxiv.org/pdf/2405.19581v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2406.00062v1",
      "title": "Unlocking the Potential of Large Language Models for Clinical Text\n  Anonymization: A Comparative Study",
      "published": "2024-05-29T23:07:58Z",
      "updated": "2024-05-29T23:07:58Z",
      "summary": "Automated clinical text anonymization has the potential to unlock the\nwidespread sharing of textual health data for secondary usage while assuring\npatient privacy and safety. Despite the proposal of many complex and\ntheoretically successful anonymization solutions in literature, these\ntechniques remain flawed. As such, clinical institutions are still reluctant to\napply them for open access to their data. Recent advances in developing Large\nLanguage Models (LLMs) pose a promising opportunity to further the field, given\ntheir capability to perform various tasks. This paper proposes six new\nevaluation metrics tailored to the challenges of generative anonymization with\nLLMs. Moreover, we present a comparative study of LLM-based methods, testing\nthem against two baseline techniques. Our results establish LLM-based models as\na reliable alternative to common approaches, paving the way toward trustworthy\nanonymization of clinical text.",
      "authors": [
        "David Pissarra",
        "Isabel Curioso",
        "Jo\u00e3o Alveira",
        "Duarte Pereira",
        "Bruno Ribeiro",
        "Tom\u00e1s Souper",
        "Vasco Gomes",
        "Andr\u00e9 V. Carreiro",
        "Vitor Rolla"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "I.2.7"
      ],
      "links": [
        "http://arxiv.org/abs/2406.00062v1",
        "http://arxiv.org/pdf/2406.00062v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19501v1",
      "title": "MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision\n  Transformer",
      "published": "2024-05-29T20:28:04Z",
      "updated": "2024-05-29T20:28:04Z",
      "summary": "In this paper, we present a novel methodology we call MDS-ViTNet (Multi\nDecoder Saliency by Vision Transformer Network) for enhancing visual saliency\nprediction or eye-tracking. This approach holds significant potential for\ndiverse fields, including marketing, medicine, robotics, and retail. We propose\na network architecture that leverages the Vision Transformer, moving beyond the\nconventional ImageNet backbone. The framework adopts an encoder-decoder\nstructure, with the encoder utilizing a Swin transformer to efficiently embed\nmost important features. This process involves a Transfer Learning method,\nwherein layers from the Vision Transformer are converted by the Encoder\nTransformer and seamlessly integrated into a CNN Decoder. This methodology\nensures minimal information loss from the original input image. The decoder\nemploys a multi-decoding technique, utilizing dual decoders to generate two\ndistinct attention maps. These maps are subsequently combined into a singular\noutput via an additional CNN model. Our trained model MDS-ViTNet achieves\nstate-of-the-art results across several benchmarks. Committed to fostering\nfurther collaboration, we intend to make our code, models, and datasets\naccessible to the public.",
      "authors": [
        "Polezhaev Ignat",
        "Goncharenko Igor",
        "Iurina Natalya"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19501v1",
        "http://arxiv.org/pdf/2405.19501v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19495v1",
      "title": "Qiskit Code Assistant: Training LLMs for generating Quantum Computing\n  Code",
      "published": "2024-05-29T20:21:00Z",
      "updated": "2024-05-29T20:21:00Z",
      "summary": "Code Large Language Models (Code LLMs) have emerged as powerful tools,\nrevolutionizing the software development landscape by automating the coding\nprocess and reducing time and effort required to build applications. This paper\nfocuses on training Code LLMs to specialize in the field of quantum computing.\nWe begin by discussing the unique needs of quantum computing programming, which\ndiffer significantly from classical programming approaches or languages. A Code\nLLM specializing in quantum computing requires a foundational understanding of\nquantum computing and quantum information theory. However, the scarcity of\navailable quantum code examples and the rapidly evolving field, which\nnecessitates continuous dataset updates, present significant challenges.\nMoreover, we discuss our work on training Code LLMs to produce high-quality\nquantum code using the Qiskit library. This work includes an examination of the\nvarious aspects of the LLMs used for training and the specific training\nconditions, as well as the results obtained with our current models. To\nevaluate our models, we have developed a custom benchmark, similar to\nHumanEval, which includes a set of tests specifically designed for the field of\nquantum computing programming using Qiskit. Our findings indicate that our\nmodel outperforms existing state-of-the-art models in quantum computing tasks.\nWe also provide examples of code suggestions, comparing our model to other\nrelevant code LLMs. Finally, we introduce a discussion on the potential\nbenefits of Code LLMs for quantum computing computational scientists,\nresearchers, and practitioners. We also explore various features and future\nwork that could be relevant in this context.",
      "authors": [
        "Nicolas Dupuis",
        "Luca Buratti",
        "Sanjay Vishwakarma",
        "Aitana Viudes Forrat",
        "David Kremer",
        "Ismael Faro",
        "Ruchir Puri",
        "Juan Cruz-Benito"
      ],
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19495v1",
        "http://arxiv.org/pdf/2405.19495v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19464v2",
      "title": "Leveraging Generative AI for Urban Digital Twins: A Scoping Review on\n  the Autonomous Generation of Urban Data, Scenarios, Designs, and 3D City\n  Models for Smart City Advancement",
      "published": "2024-05-29T19:23:07Z",
      "updated": "2024-08-06T18:32:39Z",
      "summary": "The digital transformation of modern cities by integrating advanced\ninformation, communication, and computing technologies has marked the epoch of\ndata-driven smart city applications for efficient and sustainable urban\nmanagement. Despite their effectiveness, these applications often rely on\nmassive amounts of high-dimensional and multi-domain data for monitoring and\ncharacterizing different urban sub-systems, presenting challenges in\napplication areas that are limited by data quality and availability, as well as\ncostly efforts for generating urban scenarios and design alternatives. As an\nemerging research area in deep learning, Generative Artificial Intelligence\n(AI) models have demonstrated their unique values in data and code generation.\nThis survey paper aims to explore the innovative integration of generative AI\ntechniques and urban digital twins to address challenges in the realm of smart\ncities in various urban sectors, such as transportation and mobility\nmanagement, energy system operations, building and infrastructure management,\nand urban design. The survey starts with the introduction of popular generative\nAI models with their application areas, followed by a structured review of the\nexisting urban science applications that leverage the autonomous capability of\nthe generative AI techniques to facilitate (a) data augmentation for promoting\nurban monitoring and predictive analytics, (b) synthetic data and scenario\ngeneration, (c) automated 3D city modeling, and (d) generative urban design and\noptimization. Based on the review, this survey discusses potential\nopportunities and technical strategies that integrate generative AI models into\nthe next-generation urban digital twins for more reliable, scalable, and\nautomated management of smart cities.",
      "authors": [
        "Haowen Xu",
        "Femi Omitaomu",
        "Soheil Sabri",
        "Sisi Zlatanova",
        "Xiao Li",
        "Yongze Song"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19464v2",
        "http://arxiv.org/pdf/2405.19464v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19458v4",
      "title": "MemControl: Mitigating Memorization in Diffusion Models via Automated\n  Parameter Selection",
      "published": "2024-05-29T19:12:08Z",
      "updated": "2025-02-11T12:41:08Z",
      "summary": "Diffusion models excel in generating images that closely resemble their\ntraining data but are also susceptible to data memorization, raising privacy,\nethical, and legal concerns, particularly in sensitive domains such as medical\nimaging. We hypothesize that this memorization stems from the\noverparameterization of deep models and propose that regularizing model\ncapacity during fine-tuning can mitigate this issue. Firstly, we empirically\nshow that regulating the model capacity via Parameter-efficient fine-tuning\n(PEFT) mitigates memorization to some extent, however, it further requires the\nidentification of the exact parameter subsets to be fine-tuned for high-quality\ngeneration. To identify these subsets, we introduce a bi-level optimization\nframework, MemControl, that automates parameter selection using memorization\nand generation quality metrics as rewards during fine-tuning. The parameter\nsubsets discovered through MemControl achieve a superior tradeoff between\ngeneration quality and memorization. For the task of medical image generation,\nour approach outperforms existing state-of-the-art memorization mitigation\nstrategies by fine-tuning as few as 0.019% of model parameters. Moreover, we\ndemonstrate that the discovered parameter subsets are transferable to\nnon-medical domains. Our framework is scalable to large datasets, agnostic to\nreward functions, and can be integrated with existing approaches for further\nmemorization mitigation. To the best of our knowledge, this is the first study\nto empirically evaluate memorization in medical images and propose a targeted\nyet universal mitigation strategy. The code is available at\nhttps://github.com/Raman1121/Diffusion_Memorization_HPO.",
      "authors": [
        "Raman Dutt",
        "Ondrej Bohdal",
        "Pedro Sanchez",
        "Sotirios A. Tsaftaris",
        "Timothy Hospedales"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19458v4",
        "http://arxiv.org/pdf/2405.19458v4"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19456v1",
      "title": "An Automated Startup Evaluation Pipeline: Startup Success Forecasting\n  Framework (SSFF)",
      "published": "2024-05-29T19:07:42Z",
      "updated": "2024-05-29T19:07:42Z",
      "summary": "Evaluating startups in their early stages is a complex task that requires\ndetailed analysis by experts. While automating this process on a large scale\ncan significantly impact businesses, the inherent complexity poses challenges.\nThis paper addresses this challenge by introducing the Startup Success\nForecasting Framework (SSFF), a new automated system that combines traditional\nmachine learning with advanced language models. This intelligent agent-based\narchitecture is designed to reason, act, synthesize, and decide like a venture\ncapitalist to perform the analysis end-to-end. The SSFF is made up of three\nmain parts: - Prediction Block: Uses random forests and neural networks to make\npredictions. - Analyst Block: Simulates VC analysis scenario and uses SOTA\nprompting techniques - External Knowledge Block: Gathers real-time information\nfrom external sources. This framework requires minimal input data about the\nfounder and startup description, enhances it with additional data from external\nresources, and performs a detailed analysis with high accuracy, all in an\nautomated manner",
      "authors": [
        "Xisen Wang",
        "Yigit Ihlamur"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19456v1",
        "http://arxiv.org/pdf/2405.19456v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19255v3",
      "title": "Towards Next-Generation Urban Decision Support Systems through\n  AI-Powered Construction of Scientific Ontology using Large Language Models --\n  A Case in Optimizing Intermodal Freight Transportation",
      "published": "2024-05-29T16:40:31Z",
      "updated": "2024-09-06T20:04:22Z",
      "summary": "The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making.",
      "authors": [
        "Jose Tupayachi",
        "Haowen Xu",
        "Olufemi A. Omitaomu",
        "Mustafa Can Camur",
        "Aliza Sharmin",
        "Xueping Li"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.3390/smartcities7050094",
        "http://arxiv.org/abs/2405.19255v3",
        "http://arxiv.org/pdf/2405.19255v3"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19236v1",
      "title": "Exploring the impact of traffic signal control and connected and\n  automated vehicles on intersections safety: A deep reinforcement learning\n  approach",
      "published": "2024-05-29T16:17:19Z",
      "updated": "2024-05-29T16:17:19Z",
      "summary": "In transportation networks, intersections pose significant risks of\ncollisions due to conflicting movements of vehicles approaching from different\ndirections. To address this issue, various tools can exert influence on traffic\nsafety both directly and indirectly. This study focuses on investigating the\nimpact of adaptive signal control and connected and automated vehicles (CAVs)\non intersection safety using a deep reinforcement learning approach. The\nobjective is to assess the individual and combined effects of CAVs and adaptive\ntraffic signal control on traffic safety, considering rear-end and crossing\nconflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals\nand driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses\nTime To Collision (TTC) metric to evaluate safety. The findings demonstrate a\nsignificant reduction in rear-end and crossing conflicts through the combined\nimplementation of CAVs and DQNs-based traffic signal control. Additionally, the\nlong-term positive effects of CAVs on safety are similar to the short-term\neffects of combined CAVs and DQNs-based traffic signal control. Overall, the\nstudy emphasizes the potential benefits of integrating CAVs and adaptive\ntraffic signal control approaches in order to enhance traffic safety. The\nfindings of this study could provide valuable insights for city officials and\ntransportation authorities in developing effective strategies to improve safety\nat signalized intersections.",
      "authors": [
        "Amir Hossein Karbasi",
        "Hao Yang",
        "Saiedeh Razavi"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19236v1",
        "http://arxiv.org/pdf/2405.19236v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19188v1",
      "title": "Personalized Interiors at Scale: Leveraging AI for Efficient and\n  Customizable Design Solutions",
      "published": "2024-05-29T15:29:21Z",
      "updated": "2024-05-29T15:29:21Z",
      "summary": "In this paper, we introduce an innovative application of artificial\nintelligence in the realm of interior design through the integration of Stable\nDiffusion and Dreambooth models. This paper explores the potential of these\nadvanced generative models to streamline and democratize the process of room\ninterior generation, offering a significant departure from conventional,\nlabor-intensive techniques. Our approach leverages the capabilities of Stable\nDiffusion for generating high-quality images and Dreambooth for rapid\ncustomization with minimal training data, addressing the need for efficiency\nand personalization in the design industry. We detail a comprehensive\nmethodology that combines these models, providing a robust framework for the\ncreation of tailored room interiors that reflect individual tastes and\nfunctional requirements. We presents an extensive evaluation of our method,\nsupported by experimental results that demonstrate its effectiveness and a\nseries of case studies that illustrate its practical application in interior\ndesign projects. Our study contributes to the ongoing discourse on the role of\nAI in creative fields, highlighting the benefits of leveraging generative\nmodels to enhance creativity and reshape the future of interior design.",
      "authors": [
        "Kaiwen Zhou",
        "Tianyu Wang"
      ],
      "categories": [
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19188v1",
        "http://arxiv.org/pdf/2405.19188v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.19026v2",
      "title": "DiveR-CT: Diversity-enhanced Red Teaming Large Language Model Assistants\n  with Relaxing Constraints",
      "published": "2024-05-29T12:12:09Z",
      "updated": "2024-12-20T07:37:32Z",
      "summary": "Recent advances in large language model assistants have made them\nindispensable, raising significant concerns over managing their safety.\nAutomated red teaming offers a promising alternative to the labor-intensive and\nerror-prone manual probing for vulnerabilities, providing more consistent and\nscalable safety evaluations. However, existing approaches often compromise\ndiversity by focusing on maximizing attack success rate. Additionally, methods\nthat decrease the cosine similarity from historical embeddings with semantic\ndiversity rewards lead to novelty stagnation as history grows. To address these\nissues, we introduce DiveR-CT, which relaxes conventional constraints on the\nobjective and semantic reward, granting greater freedom for the policy to\nenhance diversity. Our experiments demonstrate DiveR-CT's marked superiority\nover baselines by 1) generating data that perform better in various diversity\nmetrics across different attack success rate levels, 2) better-enhancing\nresiliency in blue team models through safety tuning based on collected data,\n3) allowing dynamic control of objective weights for reliable and controllable\nattack success rates, and 4) reducing susceptibility to reward\noveroptimization. Overall, our method provides an effective and efficient\napproach to LLM red teaming, accelerating real-world deployment.",
      "authors": [
        "Andrew Zhao",
        "Quentin Xu",
        "Matthieu Lin",
        "Shenzhi Wang",
        "Yong-jin Liu",
        "Zilong Zheng",
        "Gao Huang"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2405.19026v2",
        "http://arxiv.org/pdf/2405.19026v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2406.02579v1",
      "title": "An Open-Source Framework for Efficient Numerically-Tailored Computations",
      "published": "2024-05-29T10:10:53Z",
      "updated": "2024-05-29T10:10:53Z",
      "summary": "We present a versatile open-source framework designed to facilitate\nefficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The\nframework offers two primary contributions: first, a fine-tuned, automated\npipeline for arithmetic datapath generation, enabling highly customizable\nsystolic MMM kernels; second, seamless integration of the generated kernels\ninto user code, irrespective of the programming language employed, without\nnecessitating modifications.\n  The framework demonstrates a systematic enhancement in accuracy per energy\ncost across diverse High Performance Computing (HPC) workloads displaying a\nvariety of numerical requirements, such as Artificial Intelligence (AI)\ninference and Sea Surface Height (SSH) computation. For AI inference, we\nconsider a set of state-of-the-art neural network models, namely ResNet18,\nResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in\nconjunction with two datasets, two computer formats, and 27 distinct\nintermediate arithmetic datapaths. Our approach consistently reduces energy\nconsumption across all cases, with a notable example being the reduction by\nfactors of $3.3\\times$ for IEEE754-32 and $1.4\\times$ for Bfloat16 during\nImageNet inference with ResNet50. This is accomplished while maintaining\naccuracies of $82.3\\%$ and $86\\%$, comparable to those achieved with\nconventional Floating-Point Units (FPUs). In the context of SSH computation,\nour method achieves fully-reproducible results using double-precision words,\nsurpassing the accuracy of conventional double- and quad-precision arithmetic\nin FPUs. Our approach enhances SSH computation accuracy by a minimum of\n$5\\times$ and $27\\times$ compared to IEEE754-64 and IEEE754-128, respectively,\nresulting in $5.6\\times$ and $15.1\\times$ improvements in accuracy per power\ncost.",
      "authors": [
        "Louis Ledoux",
        "Marc Casas"
      ],
      "categories": [
        "cs.MS",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "links": [
        "http://dx.doi.org/10.1109/FPL60245.2023.00011",
        "http://arxiv.org/abs/2406.02579v1",
        "http://arxiv.org/pdf/2406.02579v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18891v1",
      "title": "Inverse Design of Promising Alloys for Electrocatalytic CO$_2$ Reduction\n  via Generative Graph Neural Networks Combined with Bird Swarm Algorithm",
      "published": "2024-05-29T08:47:53Z",
      "updated": "2024-05-29T08:47:53Z",
      "summary": "Directly generating material structures with optimal properties is a\nlong-standing goal in material design. One of the fundamental challenges lies\nin how to overcome the limitation of traditional generative models to\nefficiently explore the global chemical space rather than a small localized\nspace. Herein, we develop a framework named MAGECS to address this dilemma, by\nintegrating the bird swarm algorithm and supervised graph neural network to\neffectively navigate the generative model in the immense chemical space towards\nmaterials with target properties. As a demonstration, MAGECS is applied to\ndesign compelling alloy electrocatalysts for CO$_2$ reduction reaction\n(CO$_2$RR) and works extremely well. Specifically, the chemical space of\nCO$_2$RR is effectively explored, where over 250,000 promising structures with\nhigh activity have been generated and notably, the proportion of desired\nstructures is 2.5-fold increased. Moreover, five predicted alloys, i.e., CuAl,\nAlPd, Sn$_2$Pd$_5$, Sn$_9$Pd$_7$, and CuAlSe$_2$ are successfully synthesized\nand characterized experimentally, two of which exhibit about 90% Faraday\nefficiency of CO$_2$RR, and CuAl achieved 76% efficiency for C$_2$ products.\nThis pioneering application of inverse design in CO$_2$RR catalysis showcases\nthe potential of MAGECS to dramatically accelerate the development of\nfunctional materials, paving the way for fully automated, artificial\nintelligence-driven material design.",
      "authors": [
        "Zhilong Song",
        "Linfeng Fan",
        "Shuaihua Lu",
        "Qionghua Zhou",
        "Chongyi Ling",
        "Jinlan Wang"
      ],
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18891v1",
        "http://arxiv.org/pdf/2405.18891v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18810v1",
      "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
      "published": "2024-05-29T06:53:18Z",
      "updated": "2024-05-29T06:53:18Z",
      "summary": "Post-training Sparsity (PTS) is a recently emerged avenue that chases\nefficient network sparsity with limited data in need. Existing PTS methods,\nhowever, undergo significant performance degradation compared with traditional\nmethods that retrain the sparse networks via the whole dataset, especially at\nhigh sparsity ratios. In this paper, we attempt to reconcile this disparity by\ntransposing three cardinal factors that profoundly alter the performance of\nconventional sparsity into the context of PTS. Our endeavors particularly\ncomprise (1) A base-decayed sparsity objective that promotes efficient\nknowledge transferring from dense network to the sparse counterpart. (2) A\nreducing-regrowing search algorithm designed to ascertain the optimal sparsity\ndistribution while circumventing overfitting to the small calibration set in\nPTS. (3) The employment of dynamic sparse training predicated on the preceding\naspects, aimed at comprehensively optimizing the sparsity structure while\nensuring training stability. Our proposed framework, termed UniPTS, is\nvalidated to be much superior to existing PTS methods across extensive\nbenchmarks. As an illustration, it amplifies the performance of POT, a recently\nproposed recipe, from 3.9% to 68.6% when pruning ResNet-50 at 90% sparsity\nratio on ImageNet. We release the code of our paper at\nhttps://github.com/xjjxmu/UniPTS.",
      "authors": [
        "Jingjing Xie",
        "Yuxin Zhang",
        "Mingbao Lin",
        "Zhihang Lin",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18810v1",
        "http://arxiv.org/pdf/2405.18810v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18681v2",
      "title": "A random-key GRASP for combinatorial optimization",
      "published": "2024-05-29T01:07:38Z",
      "updated": "2024-05-30T13:06:27Z",
      "summary": "This paper proposes a problem-independent GRASP metaheuristic using the\nrandom-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search\nprocedure) is a metaheuristic for combinatorial optimization that repeatedly\napplies a semi-greedy construction procedure followed by a local search\nprocedure. The best solution found over all iterations is returned as the\nsolution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for\ncontinuous optimization in the unit hypercube. A random-key optimizer (RKO)\nuses a vector of random keys to encode a solution to a combinatorial\noptimization problem. It uses a decoder to evaluate a solution encoded by the\nvector of random keys. A random-key GRASP is a C-GRASP where points in the unit\nhypercube are evaluated employing a decoder. We describe random key GRASP\nconsisting of a problem-independent component and a problem-dependent decoder.\nAs a proof of concept, the random-key GRASP is tested on five NP-hard\ncombinatorial optimization problems: traveling salesman problem, tree of hubs\nlocation problem, Steiner triple covering problem, node capacitated graph\npartitioning problem, and job sequencing and tool switching problem.",
      "authors": [
        "Antonio A. Chaves",
        "Mauricio G. C. Resende",
        "Ricardo M. A. Silva"
      ],
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.OC",
        "90-02, 90B40, 90C27",
        "G.1.6; G.2.1; I.2.8"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18681v2",
        "http://arxiv.org/pdf/2405.18681v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18649v2",
      "title": "LeDex: Training LLMs to Better Self-Debug and Explain Code",
      "published": "2024-05-28T23:20:24Z",
      "updated": "2025-02-13T23:32:38Z",
      "summary": "In the domain of code generation, self-debugging is crucial. It allows LLMs\nto refine their generated code based on execution feedback. This is\nparticularly important because generating correct solutions in one attempt\nproves challenging for complex tasks. Prior works on self-debugging mostly\nfocus on prompting methods by providing LLMs with few-shot examples, which work\npoorly on small open-sourced LLMs. In this work, we propose LeDex, a training\nframework that significantly improves the self-debugging capability of LLMs.\nIntuitively, we observe that a chain of explanations on the wrong code followed\nby code refinement helps LLMs better analyze the wrong code and do refinement.\nWe thus propose an automated pipeline to collect a high-quality dataset for\ncode explanation and refinement by generating a number of explanations and\nrefinement trajectories from the LLM itself or a larger teacher model and\nfiltering via execution verification. We perform supervised fine-tuning (SFT)\nand further reinforcement learning (RL) on both success and failure\ntrajectories with a novel reward design considering code explanation and\nrefinement quality. SFT improves the pass@1 by up to 15.92% and pass@10 by\n9.30% over four benchmarks. RL training brings additional up to 3.54%\nimprovement on pass@1 and 2.55% improvement on pass@10. The trained LLMs show\niterative refinement ability and can keep refining code continuously. Lastly,\nour human evaluation shows that the LLMs trained with our framework generate\nmore useful code explanations and help developers better understand bugs in\nsource code.",
      "authors": [
        "Nan Jiang",
        "Xiaopeng Li",
        "Shiqi Wang",
        "Qiang Zhou",
        "Soneya Binta Hossain",
        "Baishakhi Ray",
        "Varun Kumar",
        "Xiaofei Ma",
        "Anoop Deoras"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18649v2",
        "http://arxiv.org/pdf/2405.18649v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18581v1",
      "title": "Unleashing the Potential of Text-attributed Graphs: Automatic Relation\n  Decomposition via Large Language Models",
      "published": "2024-05-28T20:54:47Z",
      "updated": "2024-05-28T20:54:47Z",
      "summary": "Recent advancements in text-attributed graphs (TAGs) have significantly\nimproved the quality of node features by using the textual modeling\ncapabilities of language models. Despite this success, utilizing text\nattributes to enhance the predefined graph structure remains largely\nunexplored. Our extensive analysis reveals that conventional edges on TAGs,\ntreated as a single relation (e.g., hyperlinks) in previous literature,\nactually encompass mixed semantics (e.g., \"advised by\" and \"participates in\").\nThis simplification hinders the representation learning process of Graph Neural\nNetworks (GNNs) on downstream tasks, even when integrated with advanced node\nfeatures. In contrast, we discover that decomposing these edges into distinct\nsemantic relations significantly enhances the performance of GNNs. Despite\nthis, manually identifying and labeling of edges to corresponding semantic\nrelations is labor-intensive, often requiring domain expertise. To this end, we\nintroduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel\nframework that leverages the capability of Large Language Models (LLMs) to\ndecompose the graph structure by analyzing raw text attributes - in a fully\nautomated manner. RoSE operates in two stages: (1) identifying meaningful\nrelations using an LLM-based generator and discriminator, and (2) categorizing\neach edge into corresponding relations by analyzing textual contents associated\nwith connected nodes via an LLM-based decomposer. Extensive experiments\ndemonstrate that our model-agnostic framework significantly enhances node\nclassification performance across various datasets, with improvements of up to\n16% on the Wisconsin dataset.",
      "authors": [
        "Hyunjin Seo",
        "Taewon Kim",
        "June Yong Yang",
        "Eunho Yang"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18581v1",
        "http://arxiv.org/pdf/2405.18581v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18580v3",
      "title": "Artificial Intelligence in Industry 4.0: A Review of Integration\n  Challenges for Industrial Systems",
      "published": "2024-05-28T20:54:41Z",
      "updated": "2024-12-17T07:35:35Z",
      "summary": "In Industry 4.0, Cyber-Physical Systems (CPS) generate vast data sets that\ncan be leveraged by Artificial Intelligence (AI) for applications including\npredictive maintenance and production planning. However, despite the\ndemonstrated potential of AI, its widespread adoption in sectors like\nmanufacturing remains limited. Our comprehensive review of recent literature,\nincluding standards and reports, pinpoints key challenges: system integration,\ndata-related issues, managing workforce-related concerns and ensuring\ntrustworthy AI. A quantitative analysis highlights particular challenges and\ntopics that are important for practitioners but still need to be sufficiently\ninvestigated by academics. The paper briefly discusses existing solutions to\nthese challenges and proposes avenues for future research. We hope that this\nsurvey serves as a resource for practitioners evaluating the cost-benefit\nimplications of AI in CPS and for researchers aiming to address these urgent\nchallenges.",
      "authors": [
        "Alexander Windmann",
        "Philipp Wittenberg",
        "Marvin Schieseck",
        "Oliver Niggemann"
      ],
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.1"
      ],
      "links": [
        "http://dx.doi.org/10.1109/INDIN58382.2024.10774364",
        "http://arxiv.org/abs/2405.18580v3",
        "http://arxiv.org/pdf/2405.18580v3"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18539v2",
      "title": "Automation in Model-Driven Engineering: A look back, and ahead",
      "published": "2024-05-28T19:14:16Z",
      "updated": "2025-02-10T16:09:59Z",
      "summary": "Model-Driven Engineering (MDE) provides a huge body of knowledge of\nautomation for many different engineering tasks, especially those involving\ntransitioning from design to implementation. With the huge progress made in\nArtificial Intelligence (AI), questions arise about the future of MDE, such as\nhow existing MDE techniques and technologies can be improved or how other\nactivities that currently lack dedicated support can also be automated.\nHowever, at the same time, it has to be revisited where and how models should\nbe used to keep the engineers in the loop for creating, operating, and\nmaintaining complex systems. To trigger dedicated research on these open\npoints, we discuss the history of automation in MDE and present perspectives on\nhow automation in MDE can be further improved and which obstacles have to be\novercome in both the medium and long-term.",
      "authors": [
        "Lola Burgue\u00f1o",
        "Davide Di Ruscio",
        "Houari Sahraoui",
        "Manuel Wimmer"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18539v2",
        "http://arxiv.org/pdf/2405.18539v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2407.01572v1",
      "title": "Exploring Sectoral Profitability in the Indian Stock Market Using Deep\n  Learning",
      "published": "2024-05-28T17:55:54Z",
      "updated": "2024-05-28T17:55:54Z",
      "summary": "This paper explores using a deep learning Long Short-Term Memory (LSTM) model\nfor accurate stock price prediction and its implications for portfolio design.\nDespite the efficient market hypothesis suggesting that predicting stock prices\nis impossible, recent research has shown the potential of advanced algorithms\nand predictive models. The study builds upon existing literature on stock price\nprediction methods, emphasizing the shift toward machine learning and deep\nlearning approaches. Using historical stock prices of 180 stocks across 18\nsectors listed on the NSE, India, the LSTM model predicts future prices. These\npredictions guide buy/sell decisions for each stock and analyze sector\nprofitability. The study's main contributions are threefold: introducing an\noptimized LSTM model for robust portfolio design, utilizing LSTM predictions\nfor buy/sell transactions, and insights into sector profitability and\nvolatility. Results demonstrate the efficacy of the LSTM model in accurately\npredicting stock prices and informing investment decisions. By comparing sector\nprofitability and prediction accuracy, the work provides valuable insights into\nthe dynamics of the current financial markets in India.",
      "authors": [
        "Jaydip Sen",
        "Hetvi Waghela",
        "Sneha Rakshit"
      ],
      "categories": [
        "q-fin.CP",
        "cs.LG",
        "q-fin.PM"
      ],
      "links": [
        "http://arxiv.org/abs/2407.01572v1",
        "http://arxiv.org/pdf/2407.01572v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18406v3",
      "title": "RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives",
      "published": "2024-05-28T17:46:36Z",
      "updated": "2024-10-31T23:27:09Z",
      "summary": "Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.",
      "authors": [
        "Jaehong Yoon",
        "Shoubin Yu",
        "Mohit Bansal"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18406v3",
        "http://arxiv.org/pdf/2405.18406v3"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18383v2",
      "title": "Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy\n  Planning Automated Segmentation",
      "published": "2024-05-28T17:25:43Z",
      "updated": "2024-08-15T19:04:26Z",
      "summary": "The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)\nchallenge aims to advance automated segmentation algorithms using the largest\nknown multi-institutional dataset of radiotherapy planning brain MRIs with\nexpert-annotated target labels for patients with intact or postoperative\nmeningioma that underwent either conventional external beam radiotherapy or\nstereotactic radiosurgery. Each case includes a defaced 3D post-contrast\nT1-weighted radiotherapy planning MRI in its native acquisition space,\naccompanied by a single-label \"target volume\" representing the gross tumor\nvolume (GTV) and any at-risk postoperative site. Target volume annotations\nadhere to established radiotherapy planning protocols, ensuring consistency\nacross cases and institutions. For preoperative meningiomas, the target volume\nencompasses the entire GTV and associated nodular dural tail, while for\npostoperative cases, it includes at-risk resection cavity margins as determined\nby the treating institution. Case annotations were reviewed and approved by\nexpert neuroradiologists and radiation oncologists. Participating teams will\ndevelop, containerize, and evaluate automated segmentation models using this\ncomprehensive dataset. Model performance will be assessed using an adapted\nlesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The\ntop-performing teams will be recognized at the Medical Image Computing and\nComputer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is\nexpected to significantly advance automated radiotherapy planning by enabling\nprecise tumor segmentation and facilitating tailored treatment, ultimately\nimproving patient outcomes.",
      "authors": [
        "Dominic LaBella",
        "Katherine Schumacher",
        "Michael Mix",
        "Kevin Leu",
        "Shan McBurney-Lin",
        "Pierre Nedelec",
        "Javier Villanueva-Meyer",
        "Jonathan Shapey",
        "Tom Vercauteren",
        "Kazumi Chia",
        "Omar Al-Salihi",
        "Justin Leu",
        "Lia Halasz",
        "Yury Velichko",
        "Chunhao Wang",
        "John Kirkpatrick",
        "Scott Floyd",
        "Zachary J. Reitman",
        "Trey Mullikin",
        "Ulas Bagci",
        "Sean Sachdev",
        "Jona A. Hattangadi-Gluth",
        "Tyler Seibert",
        "Nikdokht Farid",
        "Connor Puett",
        "Matthew W. Pease",
        "Kevin Shiue",
        "Syed Muhammad Anwar",
        "Shahriar Faghani",
        "Muhammad Ammar Haider",
        "Pranav Warman",
        "Jake Albrecht",
        "Andr\u00e1s Jakab",
        "Mana Moassefi",
        "Verena Chung",
        "Alejandro Aristizabal",
        "Alexandros Karargyris",
        "Hasan Kassem",
        "Sarthak Pati",
        "Micah Sheller",
        "Christina Huang",
        "Aaron Coley",
        "Siddharth Ghanta",
        "Alex Schneider",
        "Conrad Sharp",
        "Rachit Saluja",
        "Florian Kofler",
        "Philipp Lohmann",
        "Phillipp Vollmuth",
        "Louis Gagnon",
        "Maruf Adewole",
        "Hongwei Bran Li",
        "Anahita Fathi Kazerooni",
        "Nourel Hoda Tahon",
        "Udunna Anazodo",
        "Ahmed W. Moawad",
        "Bjoern Menze",
        "Marius George Linguraru",
        "Mariam Aboian",
        "Benedikt Wiestler",
        "Ujjwal Baid",
        "Gian-Marco Conte",
        "Andreas M. Rauschecker",
        "Ayman Nada",
        "Aly H. Abayazeed",
        "Raymond Huang",
        "Maria Correia de Verdier",
        "Jeffrey D. Rudie",
        "Spyridon Bakas",
        "Evan Calabrese"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18383v2",
        "http://arxiv.org/pdf/2405.18383v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18369v2",
      "title": "PromptWizard: Task-Aware Prompt Optimization Framework",
      "published": "2024-05-28T17:08:31Z",
      "updated": "2024-10-03T09:45:47Z",
      "summary": "Large language models (LLMs) have transformed AI across diverse domains, with\nprompting being central to their success in guiding model outputs. However,\nmanual prompt engineering is both labor-intensive and domain-specific,\nnecessitating the need for automated solutions. We introduce PromptWizard, a\nnovel, fully automated framework for discrete prompt optimization, utilizing a\nself-evolving, self-adapting mechanism. Through a feedback-driven critique and\nsynthesis process, PromptWizard achieves an effective balance between\nexploration and exploitation, iteratively refining both prompt instructions and\nin-context examples to generate human-readable, task-specific prompts. This\nguided approach systematically improves prompt quality, resulting in superior\nperformance across 45 tasks. PromptWizard excels even with limited training\ndata, smaller LLMs, and various LLM architectures. Additionally, our cost\nanalysis reveals a substantial reduction in API calls, token usage, and overall\ncost, demonstrating PromptWizard's efficiency, scalability, and advantages over\nexisting prompt optimization strategies.",
      "authors": [
        "Eshaan Agarwal",
        "Joykirat Singh",
        "Vivek Dani",
        "Raghav Magazine",
        "Tanuja Ganu",
        "Akshay Nambi"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18369v2",
        "http://arxiv.org/pdf/2405.18369v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18258v1",
      "title": "Text-only Synthesis for Image Captioning",
      "published": "2024-05-28T15:11:17Z",
      "updated": "2024-05-28T15:11:17Z",
      "summary": "From paired image-text training to text-only training for image captioning,\nthe pursuit of relaxing the requirements for high-cost and large-scale\nannotation of good quality data remains consistent. In this paper, we propose\nText-only Synthesis for Image Captioning (ToCa), which further advances this\nrelaxation with fewer human labor and less computing time. Specifically, we\ndeconstruct caption text into structures and lexical words, which serve as the\nfundamental components of the caption. By combining different structures and\nlexical words as inputs to the large language model, massive captions that\ncontain various patterns of lexical words are generated. This method not only\napproaches the target domain but also surpasses it by generating new captions,\nthereby enhancing the zero-shot generalization ability of the model.\nConsidering the different levels of data access in the real world, we define\nthree synthesis scenarios: cross-domain synthesis, in-domain synthesis, and\ndata-efficient synthesis. Experiments in these scenarios demonstrate the\ngeneralizability, transferability and practicability of ToCa with a nearly 5\nCIDEr improvement for zero-shot cross-domain captioning and a maximum increase\nof over 20 CIDEr for data-efficient captioning.",
      "authors": [
        "Qing Zhou",
        "Junlin Huang",
        "Qiang Li",
        "Junyu Gao",
        "Qi Wang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18258v1",
        "http://arxiv.org/pdf/2405.18258v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18165v1",
      "title": "Time Series Representation Models",
      "published": "2024-05-28T13:25:31Z",
      "updated": "2024-05-28T13:25:31Z",
      "summary": "Time series analysis remains a major challenge due to its sparse\ncharacteristics, high dimensionality, and inconsistent data quality. Recent\nadvancements in transformer-based techniques have enhanced capabilities in\nforecasting and imputation; however, these methods are still resource-heavy,\nlack adaptability, and face difficulties in integrating both local and global\nattributes of time series. To tackle these challenges, we propose a new\narchitectural concept for time series analysis based on introspection. Central\nto this concept is the self-supervised pretraining of Time Series\nRepresentation Models (TSRMs), which once learned can be easily tailored and\nfine-tuned for specific tasks, such as forecasting and imputation, in an\nautomated and resource-efficient manner. Our architecture is equipped with a\nflexible and hierarchical representation learning process, which is robust\nagainst missing data and outliers. It can capture and learn both local and\nglobal features of the structure, semantics, and crucial patterns of a given\ntime series category, such as heart rate data. Our learned time series\nrepresentation models can be efficiently adapted to a specific task, such as\nforecasting or imputation, without manual intervention. Furthermore, our\narchitecture's design supports explainability by highlighting the significance\nof each input value for the task at hand. Our empirical study using four\nbenchmark datasets shows that, compared to investigated state-of-the-art\nbaseline methods, our architecture improves imputation and forecasting errors\nby up to 90.34% and 71.54%, respectively, while reducing the required trainable\nparameters by up to 92.43%. The source code is available at\nhttps://github.com/RobertLeppich/TSRM.",
      "authors": [
        "Robert Leppich",
        "Vanessa Borst",
        "Veronika Lesch",
        "Samuel Kounev"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18165v1",
        "http://arxiv.org/pdf/2405.18165v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18139v1",
      "title": "Unlocking Futures: A Natural Language Driven Career Prediction System\n  for Computer Science and Software Engineering Students",
      "published": "2024-05-28T12:56:57Z",
      "updated": "2024-05-28T12:56:57Z",
      "summary": "A career is a crucial aspect for any person to fulfill their desires through\nhard work. During their studies, students cannot find the best career\nsuggestions unless they receive meaningful guidance tailored to their skills.\nTherefore, we developed an AI-assisted model for early prediction to provide\nbetter career suggestions. Although the task is difficult, proper guidance can\nmake it easier. Effective career guidance requires understanding a student's\nacademic skills, interests, and skill-related activities. In this research, we\ncollected essential information from Computer Science (CS) and Software\nEngineering (SWE) students to train a machine learning (ML) model that predicts\ncareer paths based on students' career-related information. To adequately train\nthe models, we applied Natural Language Processing (NLP) techniques and\ncompleted dataset pre-processing. For comparative analysis, we utilized\nmultiple classification ML algorithms and deep learning (DL) algorithms. This\nstudy contributes valuable insights to educational advising by providing\nspecific career suggestions based on the unique features of CS and SWE\nstudents. Additionally, the research helps individual CS and SWE students find\nsuitable jobs that match their skills, interests, and skill-related activities.",
      "authors": [
        "Sakir Hossain Faruque",
        "Sharun Akter Khushbu",
        "Sharmin Akter"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18139v1",
        "http://arxiv.org/pdf/2405.18139v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18114v1",
      "title": "Fatigue and mental underload further pronounced in L3 conditionally\n  automated driving: Results from an EEG experiment on a test track",
      "published": "2024-05-28T12:23:24Z",
      "updated": "2024-05-28T12:23:24Z",
      "summary": "Drivers' role changes with increasing automation from the primary driver to a\nsystem supervisor. This study investigates how supervising an SAE L2 and L3\nautomated vehicle (AV) affects drivers' mental workload and sleepiness compared\nto manual driving. Using an AV prototype on a test track, the oscillatory brain\nactivity of 23 adult participants was recorded during L2, L3, and manual\ndriving. Results showed decreased mental workload and increased sleepiness in\nL3 drives compared to L2 and manual drives, indicated by self-report scales and\nchanges in the frontal alpha and theta power spectral density. These findings\nsuggest that fatigue and mental underload are significant issues in L3 driving\nand should be considered when designing future AV interfaces.",
      "authors": [
        "Nikol Figalov\u00e1",
        "Hans Joachim Bieg",
        "Michael Schulz",
        "J\u00fcrgen Pichen",
        "Martin Baumann",
        "Lewis Chuang",
        "Olga Pollatos"
      ],
      "categories": [
        "cs.HC"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3581754.3584133",
        "http://arxiv.org/abs/2405.18114v1",
        "http://arxiv.org/pdf/2405.18114v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18113v1",
      "title": "Facilitating Multi-Role and Multi-Behavior Collaboration of Large\n  Language Models for Online Job Seeking and Recruiting",
      "published": "2024-05-28T12:23:16Z",
      "updated": "2024-05-28T12:23:16Z",
      "summary": "The emergence of online recruitment services has revolutionized the\ntraditional landscape of job seeking and recruitment, necessitating the\ndevelopment of high-quality industrial applications to improve person-job\nfitting. Existing methods generally rely on modeling the latent semantics of\nresumes and job descriptions and learning a matching function between them.\nInspired by the powerful role-playing capabilities of Large Language Models\n(LLMs), we propose to introduce a mock interview process between LLM-played\ninterviewers and candidates. The mock interview conversations can provide\nadditional evidence for candidate evaluation, thereby augmenting traditional\nperson-job fitting based solely on resumes and job descriptions. However,\ncharacterizing these two roles in online recruitment still presents several\nchallenges, such as developing the skills to raise interview questions,\nformulating appropriate answers, and evaluating two-sided fitness. To this end,\nwe propose MockLLM, a novel applicable framework that divides the person-job\nmatching process into two modules: mock interview generation and two-sided\nevaluation in handshake protocol, jointly enhancing their performance through\ncollaborative behaviors between interviewers and candidates. We design a\nrole-playing framework as a multi-role and multi-behavior paradigm to enable a\nsingle LLM agent to effectively behave with multiple functions for both\nparties. Moreover, we propose reflection memory generation and dynamic prompt\nmodification techniques to refine the behaviors of both sides, enabling\ncontinuous optimization of the augmented additional evidence. Extensive\nexperimental results show that MockLLM can achieve the best performance on\nperson-job matching accompanied by high mock interview quality, envisioning its\nemerging application in real online recruitment in the future.",
      "authors": [
        "Hongda Sun",
        "Hongzhan Lin",
        "Haiyu Yan",
        "Chen Zhu",
        "Yang Song",
        "Xin Gao",
        "Shuo Shang",
        "Rui Yan"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18113v1",
        "http://arxiv.org/pdf/2405.18113v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2405.18092v2",
      "title": "LLM experiments with simulation: Large Language Model Multi-Agent System\n  for Simulation Model Parametrization in Digital Twins",
      "published": "2024-05-28T11:59:40Z",
      "updated": "2024-07-22T14:03:48Z",
      "summary": "This paper presents a novel design of a multi-agent system framework that\napplies large language models (LLMs) to automate the parametrization of\nsimulation models in digital twins. This framework features specialized LLM\nagents tasked with observing, reasoning, decision-making, and summarizing,\nenabling them to dynamically interact with digital twin simulations to explore\nparametrization possibilities and determine feasible parameter settings to\nachieve an objective. The proposed approach enhances the usability of\nsimulation model by infusing it with knowledge heuristics from LLM and enables\nautonomous search for feasible parametrization to solve a user task.\nFurthermore, the system has the potential to increase user-friendliness and\nreduce the cognitive load on human users by assisting in complex\ndecision-making processes. The effectiveness and functionality of the system\nare demonstrated through a case study, and the visualized demos and codes are\navailable at a GitHub Repository:\nhttps://github.com/YuchenXia/LLMDrivenSimulation",
      "authors": [
        "Yuchen Xia",
        "Daniel Dittler",
        "Nasser Jazdi",
        "Haonan Chen",
        "Michael Weyrich"
      ],
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2405.18092v2",
        "http://arxiv.org/pdf/2405.18092v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}