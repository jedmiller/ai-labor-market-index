{
  "query": "all:large language models AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-05-03T02:36:51.907590",
  "target_period": "2025-04",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2505.00222v1",
      "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
      "published": "2025-04-30T23:55:44Z",
      "updated": "2025-04-30T23:55:44Z",
      "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.",
      "authors": [
        "Peter Yichen Chen",
        "Pingchuan Ma",
        "Niklas Hagemann",
        "John Romanishin",
        "Wei Wang",
        "Daniela Rus",
        "Wojciech Matusik"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "physics.comp-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00222v1",
        "http://arxiv.org/pdf/2505.00222v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00212v1",
      "title": "Which Agent Causes Task Failures and When? On Automated Failure\n  Attribution of LLM Multi-Agent Systems",
      "published": "2025-04-30T23:09:44Z",
      "updated": "2025-04-30T23:09:44Z",
      "summary": "Failure attribution in LLM multi-agent systems-identifying the agent and step\nresponsible for task failures-provides crucial clues for systems debugging but\nremains underexplored and labor-intensive. In this paper, we propose and\nformulate a new research area: automated failure attribution for LLM\nmulti-agent systems. To support this initiative, we introduce the Who&When\ndataset, comprising extensive failure logs from 127 LLM multi-agent systems\nwith fine-grained annotations linking failures to specific agents and decisive\nerror steps. Using the Who&When, we develop and evaluate three automated\nfailure attribution methods, summarizing their corresponding pros and cons. The\nbest method achieves 53.5% accuracy in identifying failure-responsible agents\nbut only 14.2% in pinpointing failure steps, with some methods performing below\nrandom. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to\nachieve practical usability. These results highlight the task's complexity and\nthe need for further research in this area. Code and dataset are available at\nhttps://github.com/mingyin1/Agents_Failure_Attribution",
      "authors": [
        "Shaokun Zhang",
        "Ming Yin",
        "Jieyu Zhang",
        "Jiale Liu",
        "Zhiguang Han",
        "Jingyang Zhang",
        "Beibin Li",
        "Chi Wang",
        "Huazheng Wang",
        "Yiran Chen",
        "Qingyun Wu"
      ],
      "categories": [
        "cs.MA",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00212v1",
        "http://arxiv.org/pdf/2505.00212v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00205v1",
      "title": "Optimal Platform Design",
      "published": "2025-04-30T22:10:52Z",
      "updated": "2025-04-30T22:10:52Z",
      "summary": "Search and matching increasingly takes place on online platforms. These\nplatforms have elements of centralized and decentralized matching; platforms\ncan alter the search process for its users, but are unable to eliminate search\nfrictions entirely. I study a model where platforms can change the distribution\nof potential partners that an agent searches over and characterize search\nequilibria on platforms. When agents possess private information about their\nmatch characteristics and the platform designer acts as a profit maximizing\nmonopolist, I characterize the optimal platform. If match characteristics are\ncomplementary and utility is transferable, I show that the solution to this\nscreening problem is efficient, despite the presence of hidden information and\nmarket power. Matching under the optimal platform is perfectly assortative --\nthere is no equilibrium mismatch.",
      "authors": [
        "Cole Wittbrodt"
      ],
      "categories": [
        "econ.TH"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00205v1",
        "http://arxiv.org/pdf/2505.00205v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00174v1",
      "title": "Real-World Gaps in AI Governance Research",
      "published": "2025-04-30T20:44:42Z",
      "updated": "2025-04-30T20:44:42Z",
      "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.",
      "authors": [
        "Ilan Strauss",
        "Isobel Moure",
        "Tim O'Reilly",
        "Sruly Rosenblat"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.35650/AIDP.4112.d.2025",
        "http://arxiv.org/abs/2505.00174v1",
        "http://arxiv.org/pdf/2505.00174v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21798v1",
      "title": "SWE-smith: Scaling Data for Software Engineering Agents",
      "published": "2025-04-30T16:56:06Z",
      "updated": "2025-04-30T16:56:06Z",
      "summary": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.",
      "authors": [
        "John Yang",
        "Kilian Leret",
        "Carlos E. Jimenez",
        "Alexander Wettig",
        "Kabir Khandpur",
        "Yanzhe Zhang",
        "Binyuan Hui",
        "Ofir Press",
        "Ludwig Schmidt",
        "Diyi Yang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21798v1",
        "http://arxiv.org/pdf/2504.21798v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21789v1",
      "title": "Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation",
      "published": "2025-04-30T16:48:00Z",
      "updated": "2025-04-30T16:48:00Z",
      "summary": "Magnetic Resonance Imaging (MRI) plays an important role in identifying\nclinically significant prostate cancer (csPCa), yet automated methods face\nchallenges such as data imbalance, variable tumor sizes, and a lack of\nannotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which\nincorporates anomaly maps derived from biparametric MRI sequences into a deep\nlearning-based segmentation framework to improve csPCa identification. We\nconduct a comparative analysis of anomaly detection methods and evaluate the\nintegration of anomaly maps into the segmentation pipeline. Anomaly maps,\ngenerated using Fixed-Point GAN reconstruction, highlight deviations from\nnormal prostate tissue, guiding the segmentation model to potential cancerous\nregions. We compare the performance by using the average score, computed as the\nmean of the AUROC and Average Precision (AP). On the external test set, adU-Net\nachieves the best average score of 0.618, outperforming the baseline nnU-Net\nmodel (0.605). The results demonstrate that incorporating anomaly detection\ninto segmentation improves generalization and performance, particularly with\nADC-based anomaly maps, offering a promising direction for automated csPCa\nidentification.",
      "authors": [
        "Alessia Hu",
        "Regina Beets-Tan",
        "Lishan Cai",
        "Eduardo Pooch"
      ],
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21789v1",
        "http://arxiv.org/pdf/2504.21789v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21751v1",
      "title": "CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code\n  Generation",
      "published": "2025-04-30T15:45:28Z",
      "updated": "2025-04-30T15:45:28Z",
      "summary": "Real world development demands code that is readable, extensible, and\ntestable by organizing the implementation into modular components and\niteratively reuse pre-implemented code. We term this iterative, multi-turn\nprocess codeflow and introduce CodeFlowBench, the first benchmark designed for\ncomprehensively evaluating LLMs' ability to perform codeflow, namely to\nimplement new functionality by reusing existing functions over multiple turns.\nCodeFlowBench comprises 5258 problems drawn from Codeforces and is continuously\nupdated via an automated pipeline that decomposes each problem into a series of\nfunction-level subproblems based on its dependency tree and each subproblem is\npaired with unit tests. We further propose a novel evaluation framework with\ntasks and metrics tailored to multi-turn code reuse to assess model\nperformance. In experiments across various LLMs under both multi-turn and\nsingle-turn patterns. We observe models' poor performance on CodeFlowBench,\nwith a substantial performance drop in the iterative codeflow scenario. For\ninstance, o1-mini achieves a pass@1 of 20.8% in multi-turn pattern versus 37.8%\nin single-turn pattern. Further analysis shows that different models excel at\ndifferent dependency depths, yet all struggle to correctly solve structurally\ncomplex problems, highlighting challenges for current LLMs to serve as code\ngeneration tools when performing codeflow. Overall, CodeFlowBench offers a\ncomprehensive benchmark and new insights into LLM capabilities for multi-turn,\niterative code generation, guiding future advances in code generation tasks.",
      "authors": [
        "Sizhe Wang",
        "Zhengren Wang",
        "Dongsheng Ma",
        "Yongan Yu",
        "Rui Ling",
        "Zhiyu Li",
        "Feiyu Xiong",
        "Wentao Zhang"
      ],
      "categories": [
        "cs.SE",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21751v1",
        "http://arxiv.org/pdf/2504.21751v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00061v1",
      "title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer\n  Grading Systems",
      "published": "2025-04-30T14:53:09Z",
      "updated": "2025-04-30T14:53:09Z",
      "summary": "This study examines vulnerabilities in transformer-based automated\nshort-answer grading systems used in medical education, with a focus on how\nthese systems can be manipulated through adversarial gaming strategies. Our\nresearch identifies three main types of gaming strategies that exploit the\nsystem's weaknesses, potentially leading to false positives. To counteract\nthese vulnerabilities, we implement several adversarial training methods\ndesigned to enhance the systems' robustness. Our results indicate that these\nmethods significantly reduce the susceptibility of grading systems to such\nmanipulations, especially when combined with ensemble techniques like majority\nvoting and ridge regression, which further improve the system's defense against\nsophisticated adversarial inputs. Additionally, employing large language models\nsuch as GPT-4 with varied prompting techniques has shown promise in recognizing\nand scoring gaming strategies effectively. The findings underscore the\nimportance of continuous improvements in AI-driven educational tools to ensure\ntheir reliability and fairness in high-stakes settings.",
      "authors": [
        "Sahar Yarmohammadtoosky",
        "Yiyun Zhou",
        "Victoria Yaneva",
        "Peter Baldwin",
        "Saed Rezayi",
        "Brian Clauser",
        "Polina Harikeo"
      ],
      "categories": [
        "cs.CL",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00061v1",
        "http://arxiv.org/pdf/2505.00061v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21694v1",
      "title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries\n  and Validation",
      "published": "2025-04-30T14:34:56Z",
      "updated": "2025-04-30T14:34:56Z",
      "summary": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.",
      "authors": [
        "Tom Westermann",
        "Malte Ramonat",
        "Johannes Hujer",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21694v1",
        "http://arxiv.org/pdf/2504.21694v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21574v1",
      "title": "Generative AI in Financial Institution: A Global Survey of\n  Opportunities, Threats, and Regulation",
      "published": "2025-04-30T12:25:30Z",
      "updated": "2025-04-30T12:25:30Z",
      "summary": "Generative Artificial Intelligence (GenAI) is rapidly reshaping the global\nfinancial landscape, offering unprecedented opportunities to enhance customer\nengagement, automate complex workflows, and extract actionable insights from\nvast financial data. This survey provides an overview of GenAI adoption across\nthe financial ecosystem, examining how banks, insurers, asset managers, and\nfintech startups worldwide are integrating large language models and other\ngenerative tools into their operations. From AI-powered virtual assistants and\npersonalized financial advisory to fraud detection and compliance automation,\nGenAI is driving innovation across functions. However, this transformation\ncomes with significant cybersecurity and ethical risks. We discuss emerging\nthreats such as AI-generated phishing, deepfake-enabled fraud, and adversarial\nattacks on AI systems, as well as concerns around bias, opacity, and data\nmisuse. The evolving global regulatory landscape is explored in depth,\nincluding initiatives by major financial regulators and international efforts\nto develop risk-based AI governance. Finally, we propose best practices for\nsecure and responsible adoption - including explainability techniques,\nadversarial testing, auditability, and human oversight. Drawing from academic\nliterature, industry case studies, and policy frameworks, this chapter offers a\nperspective on how the financial sector can harness GenAI's transformative\npotential while navigating the complex risks it introduces.",
      "authors": [
        "Bikash Saha",
        "Nanda Rani",
        "Sandeep Kumar Shukla"
      ],
      "categories": [
        "cs.CR",
        "cs.CE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21574v1",
        "http://arxiv.org/pdf/2504.21574v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21530v1",
      "title": "RoboGround: Robotic Manipulation with Grounded Vision-Language Priors",
      "published": "2025-04-30T11:26:40Z",
      "updated": "2025-04-30T11:26:40Z",
      "summary": "Recent advancements in robotic manipulation have highlighted the potential of\nintermediate representations for improving policy generalization. In this work,\nwe explore grounding masks as an effective intermediate representation,\nbalancing two key advantages: (1) effective spatial guidance that specifies\ntarget objects and placement areas while also conveying information about\nobject shape and size, and (2) broad generalization potential driven by\nlarge-scale vision-language models pretrained on diverse grounding datasets. We\nintroduce RoboGround, a grounding-aware robotic manipulation system that\nleverages grounding masks as an intermediate representation to guide policy\nnetworks in object manipulation tasks. To further explore and enhance\ngeneralization, we propose an automated pipeline for generating large-scale,\nsimulated data with a diverse set of objects and instructions. Extensive\nexperiments show the value of our dataset and the effectiveness of grounding\nmasks as intermediate guidance, significantly enhancing the generalization\nabilities of robot policies.",
      "authors": [
        "Haifeng Huang",
        "Xinyi Chen",
        "Yilun Chen",
        "Hao Li",
        "Xiaoshen Han",
        "Zehan Wang",
        "Tai Wang",
        "Jiangmiao Pang",
        "Zhou Zhao"
      ],
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21530v1",
        "http://arxiv.org/pdf/2504.21530v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00054v1",
      "title": "Algorithmic Addiction by Design: Big Tech's Leverage of Dark Patterns to\n  Maintain Market Dominance and its Challenge for Content Moderation",
      "published": "2025-04-30T10:43:18Z",
      "updated": "2025-04-30T10:43:18Z",
      "summary": "Today's largest technology corporations, especially ones with consumer-facing\nproducts such as social media platforms, use a variety of unethical and often\noutright illegal tactics to maintain their dominance. One tactic that has risen\nto the level of the public consciousness is the concept of addictive design,\nevidenced by the fact that excessive social media use has become a salient\nproblem, particularly in the mental and social development of adolescents and\nyoung adults. As tech companies have developed more and more sophisticated\nartificial intelligence (AI) models to power their algorithmic recommender\nsystems, they will become more successful at their goal of ensuring addiction\nto their platforms. This paper explores how online platforms intentionally\ncultivate addictive user behaviors and the broad societal implications,\nincluding on the health and well-being of children and adolescents. It presents\nthe usage of addictive design - including the usage of dark patterns,\npersuasive design elements, and recommender algorithms - as a tool leveraged by\ntechnology corporations to maintain their dominance. Lastly, it describes the\nchallenge of content moderation to address the problem and gives an overview of\nsolutions at the policy level to counteract addictive design.",
      "authors": [
        "Michelle Nie"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00054v1",
        "http://arxiv.org/pdf/2505.00054v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21502v1",
      "title": "Concurrency Constrained Scheduling with Tree-Like Constraints",
      "published": "2025-04-30T10:43:15Z",
      "updated": "2025-04-30T10:43:15Z",
      "summary": "This paper investigates concurrency-constrained scheduling problems, where\nthe objective is to construct a schedule for a set of jobs subject to\nconcurrency restrictions. Formally, we are given a conflict graph $G$ defined\nover a set of $n$ jobs, where an edge between two jobs in $G$ indicates that\nthese jobs cannot be executed concurrently. Each job may have distinct\nattributes, such as processing time, due date, weight, and release time. The\ngoal is to determine a schedule that optimizes a specified scheduling criterion\nwhile adhering to all concurrency constraints. This framework offers a\nversatile model for analyzing resource allocation problems where processes\ncompete for shared resources, such as access to shared memory. From a\ntheoretical perspective, it encompasses several classical graph coloring\nproblems, including Chromatic Number, Sum Coloring, and Interval Chromatic\nNumber.\n  Given that even the simplest concurrency-constrained scheduling problems are\nNP-hard for general conflict graphs, this study focuses on conflict graphs with\nbounded treewidth. Our results establish a dichotomy: Some problems in this\nsetting can be solved in FPT time, while others are shown to be XALP-complete\nfor treewidth as parameter. Along the way, we generalize several previously\nknown results on coloring problems for bounded treewidth graphs. Several of the\nFPT algorithms are based on the insight that completion times are bounded by\nthe Grundy number of the conflict graph - the fact that this number is bounded\nby the product of treewidth and the logarithm of the number of vertices then\nleads to the FPT time bound.",
      "authors": [
        "Hans L. Bodlaender",
        "Danny Hermelin",
        "Erik Jan van Leeuwen"
      ],
      "categories": [
        "cs.DM",
        "cs.CC",
        "68Q25 (Primary) 90B35 (Secondary)"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21502v1",
        "http://arxiv.org/pdf/2504.21502v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21464v1",
      "title": "VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep\n  Network for Diabetic Retinopathy Classification",
      "published": "2025-04-30T09:38:47Z",
      "updated": "2025-04-30T09:38:47Z",
      "summary": "Diabetic retinopathy is a severe eye condition caused by diabetes where the\nretinal blood vessels get damaged and can lead to vision loss and blindness if\nnot treated. Early and accurate detection is key to intervention and stopping\nthe disease progressing. For addressing this disease properly, this paper\npresents a comprehensive approach for automated diabetic retinopathy detection\nby proposing a new hybrid deep learning model called VR-FuseNet. Diabetic\nretinopathy is a major eye disease and leading cause of blindness especially\namong diabetic patients so accurate and efficient automated detection methods\nare required. To address the limitations of existing methods including dataset\nimbalance, diversity and generalization issues this paper presents a hybrid\ndataset created from five publicly available diabetic retinopathy datasets.\nEssential preprocessing techniques such as SMOTE for class balancing and CLAHE\nfor image enhancement are applied systematically to the dataset to improve the\nrobustness and generalizability of the dataset. The proposed VR-FuseNet model\ncombines the strengths of two state-of-the-art convolutional neural networks,\nVGG19 which captures fine-grained spatial features and ResNet50V2 which is\nknown for its deep hierarchical feature extraction. This fusion improves the\ndiagnostic performance and achieves an accuracy of 91.824%. The model\noutperforms individual architectures on all performance metrics demonstrating\nthe effectiveness of hybrid feature extraction in Diabetic Retinopathy\nclassification tasks. To make the proposed model more clinically useful and\ninterpretable this paper incorporates multiple XAI techniques. These techniques\ngenerate visual explanations that clearly indicate the retinal features\naffecting the model's prediction such as microaneurysms, hemorrhages and\nexudates so that clinicians can interpret and validate.",
      "authors": [
        "Shamim Rahim Refat",
        "Ziyan Shirin Raha",
        "Shuvashis Sarker",
        "Faika Fairuj Preotee",
        "MD. Musfikur Rahman",
        "Tashreef Muhammad",
        "Mohammad Shafiul Islam"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21464v1",
        "http://arxiv.org/pdf/2504.21464v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21400v1",
      "title": "Who Gets the Callback? Generative AI and Gender Bias",
      "published": "2025-04-30T07:55:52Z",
      "updated": "2025-04-30T07:55:52Z",
      "summary": "Generative artificial intelligence (AI), particularly large language models\n(LLMs), is being rapidly deployed in recruitment and for candidate\nshortlisting. We audit several mid-sized open-source LLMs for gender bias using\na dataset of 332,044 real-world online job postings. For each posting, we\nprompt the model to recommend whether an equally qualified male or female\ncandidate should receive an interview callback. We find that most models tend\nto favor men, especially for higher-wage roles. Mapping job descriptions to the\nStandard Occupational Classification system, we find lower callback rates for\nwomen in male-dominated occupations and higher rates in female-associated ones,\nindicating occupational segregation. A comprehensive analysis of linguistic\nfeatures in job ads reveals strong alignment of model recommendations with\ntraditional gender stereotypes. To examine the role of recruiter identity, we\nsteer model behavior by infusing Big Five personality traits and simulating the\nperspectives of historical figures. We find that less agreeable personas reduce\nstereotyping, consistent with an agreeableness bias in LLMs. Our findings\nhighlight how AI-driven hiring may perpetuate biases in the labor market and\nhave implications for fairness and diversity within firms.",
      "authors": [
        "Sugat Chaturvedi",
        "Rochana Chaturvedi"
      ],
      "categories": [
        "econ.GN",
        "cs.CL",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21400v1",
        "http://arxiv.org/pdf/2504.21400v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21336v1",
      "title": "UniBiomed: A Universal Foundation Model for Grounded Biomedical Image\n  Interpretation",
      "published": "2025-04-30T05:51:48Z",
      "updated": "2025-04-30T05:51:48Z",
      "summary": "Multi-modal interpretation of biomedical images opens up novel opportunities\nin biomedical image analysis. Conventional AI approaches typically rely on\ndisjointed training, i.e., Large Language Models (LLMs) for clinical text\ngeneration and segmentation models for target extraction, which results in\ninflexible real-world deployment and a failure to leverage holistic biomedical\ninformation. To this end, we introduce UniBiomed, the first universal\nfoundation model for grounded biomedical image interpretation. UniBiomed is\nbased on a novel integration of Multi-modal Large Language Model (MLLM) and\nSegment Anything Model (SAM), which effectively unifies the generation of\nclinical texts and the segmentation of corresponding biomedical objects for\ngrounded interpretation. In this way, UniBiomed is capable of tackling a wide\nrange of biomedical tasks across ten diverse biomedical imaging modalities. To\ndevelop UniBiomed, we curate a large-scale dataset comprising over 27 million\ntriplets of images, annotations, and text descriptions across ten imaging\nmodalities. Extensive validation on 84 internal and external datasets\ndemonstrated that UniBiomed achieves state-of-the-art performance in\nsegmentation, disease recognition, region-aware diagnosis, visual question\nanswering, and report generation. Moreover, unlike previous models that rely on\nclinical experts to pre-diagnose images and manually craft precise textual or\nvisual prompts, UniBiomed can provide automated and end-to-end grounded\ninterpretation for biomedical image analysis. This represents a novel paradigm\nshift in clinical workflows, which will significantly improve diagnostic\nefficiency. In summary, UniBiomed represents a novel breakthrough in biomedical\nAI, unlocking powerful grounded interpretation capabilities for more accurate\nand efficient biomedical image analysis.",
      "authors": [
        "Linshan Wu",
        "Yuxiang Nie",
        "Sunan He",
        "Jiaxin Zhuang",
        "Hao Chen"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21336v1",
        "http://arxiv.org/pdf/2504.21336v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21330v1",
      "title": "Does the Prompt-based Large Language Model Recognize Students'\n  Demographics and Introduce Bias in Essay Scoring?",
      "published": "2025-04-30T05:36:28Z",
      "updated": "2025-04-30T05:36:28Z",
      "summary": "Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\ndue to their ability to capture semantic meaning. Traditional fine-tuning\napproaches required technical expertise, limiting accessibility for educators\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\nhave made AES more accessible, enabling educators to obtain machine-generated\nscores using natural-language prompts (i.e., the prompt-based paradigm).\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\nparticularly against disadvantaged groups. It remains unclear whether such\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\ntools. Since such biases are believed to stem from the demographic information\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\npredict demographic attributes), this study explores the relationship between\nthe model's predictive power of students' demographic attributes based on their\nwritten works and its predictive bias in the scoring task in the prompt-based\nparadigm. Using a publicly available dataset of over 25,000 students'\nargumentative essays, we designed prompts to elicit demographic inferences\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\nautomated scoring. Then we conducted multivariate regression analysis to\nexplore the impact of the model's ability to predict demographics on its\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\ninfer students' demographics, particularly their first-language backgrounds,\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\ncorrectly predicts students' first-language background than when it does not;\nand (iii) scoring error for non-native English speakers increases when the LLM\ncorrectly identifies them as non-native.",
      "authors": [
        "Kaixun Yang",
        "Mladen Rakovi\u0107",
        "Dragan Ga\u0161evi\u0107",
        "Guanliang Chen"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21330v1",
        "http://arxiv.org/pdf/2504.21330v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21312v1",
      "title": "Annotating and Auditing the Safety Properties of Unsafe Rust",
      "published": "2025-04-30T04:53:35Z",
      "updated": "2025-04-30T04:53:35Z",
      "summary": "Unsafe code is a critical topic in ensuring the security of system software\ndevelopment in Rust. It is the sole source of potential undefined behaviors,\nassuming the compiler is sound. To avoid the misuse of unsafe code, Rust\ndevelopers should provide clear safety property annotations for unsafe APIs.\nHowever, there is limited official guidance and few best practices for\nannotating unsafe code. Even the current best practices for safety property\nannotations in the Rust standard library are ad hoc and informal. In this\npaper, we design a domain-specific language to describe the safety properties\nof unsafe APIs, which may serve as a precursor for automated verification in\nthe future. Furthermore, to ensure that the caller of an unsafe API properly\ndelegates the safety property required by the callee, we propose a novel\nunsafety propagation graph to model the usage and propagation of unsafe code.\nBased on this graph, we further introduce a method to partition the graph into\nsmaller graphs, such that each graph serves as a self-contained audit unit for\nexamining the soundness of unsafe code encapsulation and safety property\nannotation. We applied our approach to the Rust standard library, and the\nexperimental results demonstrate that our method is both practical and\neffective. Additionally, we have fixed safety property description issues in 23\nAPIs.",
      "authors": [
        "Zihao Rao",
        "Hongliang Tian",
        "Xin Wang",
        "Hui Xu"
      ],
      "categories": [
        "cs.PL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21312v1",
        "http://arxiv.org/pdf/2504.21312v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21275v1",
      "title": "Hurdle Network Model With Latent Dynamic Shrinkage For Enhanced Edge\n  Prediction in Zero-Inflated Directed Network Time Series",
      "published": "2025-04-30T03:09:17Z",
      "updated": "2025-04-30T03:09:17Z",
      "summary": "This article aims to model international trade relationships among 29\ncountries in the apparel industry between 1994 and 2013. Bilateral trade flows\ncan be represented as a directed network, where nodes correspond to countries\nand directed edges indicate trade flows (i.e., whether one country exported to\nanother in a given year). Additionally, node (e.g., GDP) and edge-specific\n(e.g., labor provision) covariates are also available. The study focuses on two\nkey challenges: (1) capturing multiple forms of temporal and network\ndependence, and dependence on covariates; and (2) accounting for potential\ntrade volume as an important but partially observed edge-specific covariate,\nwhich is only available for country pairs that engaged in trade.\n  To address these challenges, we introduce the dynamic hurdle network model\n(Hurdle-Net) for zero-inflated directed network time series that incorporates\nseveral novel features. First, it represents the time series as a paired binary\nand continuous time series and utilizes a hurdle model that effectively handles\nsparsity in edge occurrence. Second, the model captures evolving network\ndependencies using node-specific latent variables governed by a dynamic\nshrinkage process. Third, it leverages a shared latent structure across the\nbinary and continuous components, reflecting the fact that both networks\ninvolve the same nodes. Finally, the model employs a generalized logistic link\nfunction to relate edge occurrence to edge weight, allowing for a parsimonious\nand coherent hierarchical Bayesian framework that jointly models both network\ncomponents. Compared to static or independent models, Hurdle-Net provides\nimproved model selection, estimation, and prediction performance for analyzing\ninternational trade patterns. Its effectiveness is demonstrated through\nsimulation studies and an application to bilateral trade flow data.",
      "authors": [
        "Sandipan Pramanik",
        "Raymond Robertson",
        "Yang Ni"
      ],
      "categories": [
        "stat.ME",
        "stat.AP"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21275v1",
        "http://arxiv.org/pdf/2504.21275v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00045v1",
      "title": "Noise Modeling in One Hour: Minimizing Preparation Efforts for\n  Self-supervised Low-Light RAW Image Denoising",
      "published": "2025-04-30T01:56:09Z",
      "updated": "2025-04-30T01:56:09Z",
      "summary": "Noise synthesis is a promising solution for addressing the data shortage\nproblem in data-driven low-light RAW image denoising. However, accurate noise\nsynthesis methods often necessitate labor-intensive calibration and profiling\nprocedures during preparation, preventing them from landing to practice at\nscale. This work introduces a practically simple noise synthesis pipeline based\non detailed analyses of noise properties and extensive justification of\nwidespread techniques. Compared to other approaches, our proposed pipeline\neliminates the cumbersome system gain calibration and signal-independent noise\nprofiling steps, reducing the preparation time for noise synthesis from days to\nhours. Meanwhile, our method exhibits strong denoising performance, showing an\nup to 0.54dB PSNR improvement over the current state-of-the-art noise synthesis\ntechnique. Code is released at\nhttps://github.com/SonyResearch/raw_image_denoising",
      "authors": [
        "Feiran Li",
        "Haiyang Jiang",
        "Daisuke Iso"
      ],
      "categories": [
        "eess.IV"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00045v1",
        "http://arxiv.org/pdf/2505.00045v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21245v1",
      "title": "Database and deep-learning scalability of anharmonic phonon properties\n  by automated brute-force first-principles calculations",
      "published": "2025-04-30T00:54:32Z",
      "updated": "2025-04-30T00:54:32Z",
      "summary": "Understanding the anharmonic phonon properties of crystal compounds -- such\nas phonon lifetimes and thermal conductivities -- is essential for\ninvestigating and optimizing their thermal transport behaviors. These\nproperties also impact optical, electronic, and magnetic characteristics\nthrough interactions between phonons and other quasiparticles and fields. In\nthis study, we develop an automated first-principles workflow to calculate\nanharmonic phonon properties and build a comprehensive database encompassing\nmore than 6,000 inorganic compounds. Utilizing this dataset, we train a graph\nneural network model to predict thermal conductivity values and spectra from\nstructural parameters, demonstrating a scaling law in which prediction accuracy\nimproves with increasing training data size. High-throughput screening with the\nmodel enables the identification of materials exhibiting extreme thermal\nconductivities -- both high and low. The resulting database offers valuable\ninsights into the anharmonic behavior of phonons, thereby accelerating the\ndesign and development of advanced functional materials.",
      "authors": [
        "Masato Ohnishi",
        "Tianqi Deng",
        "Pol Torres",
        "Zhihao Xu",
        "Terumasa Tadano",
        "Haoming Zhang",
        "Wei Nong",
        "Masatoshi Hanai",
        "Zhiting Tian",
        "Ming Hu",
        "Xiulin Ruan",
        "Ryo Yoshida",
        "Toyotaro Suzumura",
        "Lucas Lindsay",
        "Alan J. H. McGaughey",
        "Tengfei Luo",
        "Kedar Hippalgaonkar",
        "Junichiro Shiomi"
      ],
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21245v1",
        "http://arxiv.org/pdf/2504.21245v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21211v1",
      "title": "A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in\n  Online Marketplaces",
      "published": "2025-04-29T22:34:42Z",
      "updated": "2025-04-29T22:34:42Z",
      "summary": "Wildlife trafficking remains a critical global issue, significantly impacting\nbiodiversity, ecological stability, and public health. Despite efforts to\ncombat this illicit trade, the rise of e-commerce platforms has made it easier\nto sell wildlife products, putting new pressure on wild populations of\nendangered and threatened species. The use of these platforms also opens a new\nopportunity: as criminals sell wildlife products online, they leave digital\ntraces of their activity that can provide insights into trafficking activities\nas well as how they can be disrupted. The challenge lies in finding these\ntraces. Online marketplaces publish ads for a plethora of products, and\nidentifying ads for wildlife-related products is like finding a needle in a\nhaystack. Learning classifiers can automate ad identification, but creating\nthem requires costly, time-consuming data labeling that hinders support for\ndiverse ads and research questions. This paper addresses a critical challenge\nin the data science pipeline for wildlife trafficking analytics: generating\nquality labeled data for classifiers that select relevant data. While large\nlanguage models (LLMs) can directly label advertisements, doing so at scale is\nprohibitively expensive. We propose a cost-effective strategy that leverages\nLLMs to generate pseudo labels for a small sample of the data and uses these\nlabels to create specialized classification models. Our novel method\nautomatically gathers diverse and representative samples to be labeled while\nminimizing the labeling costs. Our experimental evaluation shows that our\nclassifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We\npresent real use cases that demonstrate the effectiveness of our approach in\nenabling analyses of different aspects of wildlife trafficking.",
      "authors": [
        "Juliana Barbosa",
        "Ulhas Gondhali",
        "Gohar Petrossian",
        "Kinshuk Sharma",
        "Sunandan Chakraborty",
        "Jennifer Jacquet",
        "Juliana Freire"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3725256",
        "http://arxiv.org/abs/2504.21211v1",
        "http://arxiv.org/pdf/2504.21211v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21202v1",
      "title": "Automatic Legal Writing Evaluation of LLMs",
      "published": "2025-04-29T22:16:39Z",
      "updated": "2025-04-29T22:16:39Z",
      "summary": "Despite the recent advances in Large Language Models, benchmarks for\nevaluating legal writing remain scarce due to the inherent complexity of\nassessing open-ended responses in this domain. One of the key challenges in\nevaluating language models on domain-specific tasks is finding test datasets\nthat are public, frequently updated, and contain comprehensive evaluation\nguidelines. The Brazilian Bar Examination meets these requirements. We\nintroduce oab-bench, a benchmark comprising 105 questions across seven areas of\nlaw from recent editions of the exam. The benchmark includes comprehensive\nevaluation guidelines and reference materials used by human examiners to ensure\nconsistent grading. We evaluate the performance of four LLMs on oab-bench,\nfinding that Claude-3.5 Sonnet achieves the best results with an average score\nof 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can\nserve as reliable automated judges for evaluating legal writing. Our\nexperiments show that frontier models like OpenAI's o1 achieve a strong\ncorrelation with human scores when evaluating approved exams, suggesting their\npotential as reliable automated evaluators despite the inherently subjective\nnature of legal writing assessment. The source code and the benchmark --\ncontaining questions, evaluation guidelines, model-generated responses, and\ntheir respective automated evaluations -- are publicly available.",
      "authors": [
        "Ramon Pires",
        "Roseval Malaquias Junior",
        "Rodrigo Nogueira"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21202v1",
        "http://arxiv.org/pdf/2504.21202v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21194v1",
      "title": "Geolocating Earth Imagery from ISS: Integrating Machine Learning with\n  Astronaut Photography for Enhanced Geographic Mapping",
      "published": "2025-04-29T22:00:02Z",
      "updated": "2025-04-29T22:00:02Z",
      "summary": "This paper presents a novel approach to geolocating images captured from the\nInternational Space Station (ISS) using advanced machine learning algorithms.\nDespite having precise ISS coordinates, the specific Earth locations depicted\nin astronaut-taken photographs often remain unidentified. Our research\naddresses this gap by employing three distinct image processing pipelines: a\nNeural Network based approach, a SIFT based method, and GPT-4 model. Each\npipeline is tailored to process high-resolution ISS imagery, identifying both\nnatural and man-made geographical features. Through extensive evaluation on a\ndiverse dataset of over 140 ISS images, our methods demonstrate significant\npromise in automated geolocation with varied levels of success. The NN approach\nshowed a high success rate in accurately matching geographical features, while\nthe SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided\nenriched geographical descriptions alongside location predictions. This\nresearch contributes to the fields of remote sensing and Earth observation by\nenhancing the accuracy and efficiency of geolocating space-based imagery,\nthereby aiding environmental monitoring and global mapping efforts.",
      "authors": [
        "Vedika Srivastava",
        "Hemant Kumar Singh",
        "Jaisal Singh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21194v1",
        "http://arxiv.org/pdf/2504.21194v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21190v1",
      "title": "TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse\n  Mixture-of-Experts",
      "published": "2025-04-29T21:46:43Z",
      "updated": "2025-04-29T21:46:43Z",
      "summary": "We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA\nMoE), a novel computational framework integrating Parameter-Efficient\nFine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in\nlarge model deployments. Unlike traditional MoE approaches, which face\nsubstantial computational overhead as expert counts grow, TT-LoRA MoE\ndecomposes training into two distinct, optimized stages. First, we\nindependently train lightweight, tensorized low-rank adapters (TT-LoRA\nexperts), each specialized for specific tasks. Subsequently, these expert\nadapters remain frozen, eliminating inter-task interference and catastrophic\nforgetting in multi-task setting. A sparse MoE router, trained separately,\ndynamically leverages base model representations to select exactly one\nspecialized adapter per input at inference time, automating expert selection\nwithout explicit task specification. Comprehensive experiments confirm our\narchitecture retains the memory efficiency of low-rank adapters, seamlessly\nscales to large expert pools, and achieves robust task-level optimization. This\nstructured decoupling significantly enhances computational efficiency and\nflexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion\nparameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling\npractical and scalable multi-task inference deployments.",
      "authors": [
        "Pradip Kunwar",
        "Minh N. Vu",
        "Maanak Gupta",
        "Mahmoud Abdelsalam",
        "Manish Bhattarai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21190v1",
        "http://arxiv.org/pdf/2504.21190v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21185v2",
      "title": "AI-in-the-Loop Planning for Transportation Electrification: Case Studies\n  from Austin, Texas",
      "published": "2025-04-29T21:42:02Z",
      "updated": "2025-05-01T15:07:50Z",
      "summary": "This study explores the integration of AI in transportation electrification\nplanning in Austin, TX, focusing on the use of Geospatial AI (GeoAI),\nGenerative AI (GenAI), and Large Language Models (LLMs). GeoAI enhances site\nselection, localized GenAI models support meta-level estimations, and LLMs\nenable scenario simulations. These AI applications require human oversight.\nGeoAI outputs must be evaluated with land use data, GenAI models are not always\naccurate, and LLMs are prone to hallucinations. To ensure accountable planning,\nhuman planners must work alongside AI agents. Establishing a community feedback\nloop is essential to audit automated decisions. Planners should place Community\nExperience (CX) at the center of Urban Planning AI.",
      "authors": [
        "Seung Jun Choi"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21185v2",
        "http://arxiv.org/pdf/2504.21185v2"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21174v1",
      "title": "Efficient LLMs with AMP: Attention Heads and MLP Pruning",
      "published": "2025-04-29T20:50:08Z",
      "updated": "2025-04-29T20:50:08Z",
      "summary": "Deep learning drives a new wave in computing systems and triggers the\nautomation of increasingly complex problems. In particular, Large Language\nModels (LLMs) have significantly advanced cognitive tasks, often matching or\neven surpassing human-level performance. However, their extensive parameters\nresult in high computational costs and slow inference, posing challenges for\ndeployment in resource-limited settings. Among the strategies to overcome the\naforementioned challenges, pruning emerges as a successful mechanism since it\nreduces model size while maintaining predictive ability. In this paper, we\nintroduce AMP: Attention Heads and MLP Pruning, a novel structured pruning\nmethod that efficiently compresses LLMs by removing less critical structures\nwithin Multi-Head Attention (MHA) and Multilayer Perceptron (MLP). By\nprojecting the input data onto weights, AMP assesses structural importance and\novercomes the limitations of existing techniques, which often fall short in\nflexibility or efficiency. In particular, AMP surpasses the current\nstate-of-the-art on commonsense reasoning tasks by up to 1.49 percentage\npoints, achieving a 30% pruning ratio with minimal impact on zero-shot task\nperformance. Moreover, AMP also improves inference speeds, making it\nwell-suited for deployment in resource-constrained environments. We confirm the\nflexibility of AMP on different families of LLMs, including LLaMA and Phi.",
      "authors": [
        "Leandro Giusti Mugnaini",
        "Bruno Lopes Yamamoto",
        "Lucas Lauton de Alcantara",
        "Victor Zacarias",
        "Edson Bollis",
        "Lucas Pellicer",
        "Anna Helena Reali Costa",
        "Artur Jordao"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21174v1",
        "http://arxiv.org/pdf/2504.21174v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21166v1",
      "title": "Dance Style Recognition Using Laban Movement Analysis",
      "published": "2025-04-29T20:35:01Z",
      "updated": "2025-04-29T20:35:01Z",
      "summary": "The growing interest in automated movement analysis has presented new\nchallenges in recognition of complex human activities including dance. This\nstudy focuses on dance style recognition using features extracted using Laban\nMovement Analysis. Previous studies for dance style recognition often focus on\ncross-frame movement analysis, which limits the ability to capture temporal\ncontext and dynamic transitions between movements. This gap highlights the need\nfor a method that can add temporal context to LMA features. For this, we\nintroduce a novel pipeline which combines 3D pose estimation, 3D human mesh\nreconstruction, and floor aware body modeling to effectively extract LMA\nfeatures. To address the temporal limitation, we propose a sliding window\napproach that captures movement evolution across time in features. These\nfeatures are then used to train various machine learning methods for\nclassification, and their explainability explainable AI methods to evaluate the\ncontribution of each feature to classification performance. Our proposed method\nachieves a highest classification accuracy of 99.18\\% which shows that the\naddition of temporal context significantly improves dance style recognition\nperformance.",
      "authors": [
        "Muhammad Turab",
        "Philippe Colantoni",
        "Damien Muselet",
        "Alain Tremeau"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21166v1",
        "http://arxiv.org/pdf/2504.21166v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21085v1",
      "title": "Automated detection and modeling of binary microlensing events in\n  OGLE-IV data. I. Events with well-separated bumps",
      "published": "2025-04-29T18:00:02Z",
      "updated": "2025-04-29T18:00:02Z",
      "summary": "Gravitational microlensing depends primarily on the lens mass and presents a\nlarger occurrence rate in crowded regions, which makes it the best tool to\nuncover the initial mass function (IMF) of low-mass stars in the Galactic\nbulge. The bulge IMF can be obtained from the luminosity function measured with\nthe Hubble Space Telescope if one knows the statistics of binary stellar\nsystems in the bulge. We aim to analyse a statistically significant number of\nbinary-lens/single-source and single-lens/binary-source events, in order to\nexplore the lower-mass end of the bulge IMF even in unresolved binary systems.\nThis paper deals with events with clearly separated bumps and no caustic\ncrossing or approach, whereas other types will be analysed in following works.\nA fully-automated approach in the search and modeling of binary events was\nimplemented. Event detection was carried out with a modified version of the\nalgorithm used in previous studies. Model fitting was carried out with Markov\nchain Monte Carlo and nested sampling methods, in order to find the most\nprobable solution among binary lens or binary source models. We retrieved 107\nbinary events in Optical Gravitational Lensing Experiment (OGLE) light curves\nspanning ten years in 9 high-cadence and 112 low-cadence fields towards the\nbulge. Several criteria were applied to reduce false positives, resulting in 55\nmost likely binary lenses and 52 binary sources. The tools were effective\ndetecting a bona-fide sample of binary events, with a distribution of Einstein\ntimescales around 35-40 days and flat distributions for mass ratio and source\nflux ratio. After proper consideration of detection efficiency, the statistics\nfor binary fraction and mass ratio will provide valuable constraints for the\nbulge IMF.",
      "authors": [
        "R. A. P. Oliveira",
        "R. Poleski",
        "P. Mr\u00f3z",
        "A. Udalski",
        "J. Skowron",
        "M. Mr\u00f3z",
        "M. K. Szyma\u0144ski",
        "I. Soszy\u0144ski",
        "K. Ulaczyk",
        "P. Pietrukowicz",
        "K. Rybicki",
        "P. Iwanek",
        "M. Wrona",
        "M. Gromadzki"
      ],
      "categories": [
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21085v1",
        "http://arxiv.org/pdf/2504.21085v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20993v1",
      "title": "GDP-GFCF Dynamics Across Global Economies: A Comparative Study of Panel\n  Regressions and Random Forest",
      "published": "2025-04-29T17:58:47Z",
      "updated": "2025-04-29T17:58:47Z",
      "summary": "This study examines the relationship between GDP growth and Gross Fixed\nCapital Formation (GFCF) across developed economies (G7, EU-15, OECD) and\nemerging markets (BRICS). We integrate Random Forest machine learning\n(non-linear regression) with traditional econometric models (linear regression)\nto better capture non-linear interactions in investment analysis. Our findings\nreveal that while GDP growth positively influences corporate investment, its\nimpact varies significantly by region. Developed economies show stronger\nGDP-GFCF linkages due to stable financial systems, while emerging markets\ndemonstrate weaker connections due to economic heterogeneity and structural\nconstraints. Random Forest models indicate that GDP growth's importance is\nlower than suggested by traditional econometrics, with lagged GFCF emerging as\nthe dominant predictor-confirming investment follows path-dependent patterns\nrather than short-term GDP fluctuations. Regional variations in investment\ndrivers are substantial: taxation significantly influences developed economies\nbut minimally affects BRICS, while unemployment strongly drives investment in\nBRICS but less so elsewhere. We introduce a parallelized p-value importance\nalgorithm for Random Forest that enhances computational efficiency while\nmaintaining statistical rigor through sequential testing methods (SPRT and\nSAPT). The research demonstrates that hybrid methodologies combining machine\nlearning with econometric techniques provide more nuanced understanding of\ninvestment dynamics, supporting region-specific policy design and improving\nforecasting accuracy.",
      "authors": [
        "Alina Landowska",
        "Robert A. K\u0142opotek",
        "Dariusz Filip",
        "Konrad Raczkowski"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20993v1",
        "http://arxiv.org/pdf/2504.20993v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20970v1",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep\n  Features",
      "published": "2025-04-29T17:39:16Z",
      "updated": "2025-04-29T17:39:16Z",
      "summary": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.",
      "authors": [
        "Mete Erdogan",
        "Sebnem Demirtas"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20970v1",
        "http://arxiv.org/pdf/2504.20970v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20965v1",
      "title": "AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM\n  Security",
      "published": "2025-04-29T17:36:05Z",
      "updated": "2025-04-29T17:36:05Z",
      "summary": "We introduce AegisLLM, a cooperative multi-agent defense against adversarial\nattacks and information leakage. In AegisLLM, a structured workflow of\nautonomous agents - orchestrator, deflector, responder, and evaluator -\ncollaborate to ensure safe and compliant LLM outputs, while self-improving over\ntime through prompt optimization. We show that scaling agentic reasoning system\nat test-time - both by incorporating additional agent roles and by leveraging\nautomated prompt optimization (such as DSPy)- substantially enhances robustness\nwithout compromising model utility. This test-time defense enables real-time\nadaptability to evolving attacks, without requiring model retraining.\nComprehensive evaluations across key threat scenarios, including unlearning and\njailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning\nbenchmark, AegisLLM achieves near-perfect unlearning with only 20 training\nexamples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve\n51% improvement compared to the base model on StrongReject, with false refusal\nrates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our\nresults highlight the advantages of adaptive, agentic reasoning over static\ndefenses, establishing AegisLLM as a strong runtime alternative to traditional\napproaches based on model modifications. Code is available at\nhttps://github.com/zikuicai/aegisllm",
      "authors": [
        "Zikui Cai",
        "Shayan Shabihi",
        "Bang An",
        "Zora Che",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Tom Goldstein",
        "Furong Huang"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20965v1",
        "http://arxiv.org/pdf/2504.20965v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20938v1",
      "title": "Towards Understanding the Nature of Attention with Low-Rank Sparse\n  Decomposition",
      "published": "2025-04-29T17:03:03Z",
      "updated": "2025-04-29T17:03:03Z",
      "summary": "We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.",
      "authors": [
        "Zhengfu He",
        "Junxuan Wang",
        "Rui Lin",
        "Xuyang Ge",
        "Wentao Shu",
        "Qiong Tang",
        "Junping Zhang",
        "Xipeng Qiu"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20938v1",
        "http://arxiv.org/pdf/2504.20938v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20910v1",
      "title": "When Testing AI Tests Us: Safeguarding Mental Health on the Digital\n  Frontlines",
      "published": "2025-04-29T16:27:20Z",
      "updated": "2025-04-29T16:27:20Z",
      "summary": "Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.",
      "authors": [
        "Sachin R. Pendse",
        "Darren Gergle",
        "Rachel Kornfield",
        "Jonah Meyerhoff",
        "David Mohr",
        "Jina Suh",
        "Annie Wescott",
        "Casey Williams",
        "Jessica Schleider"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20910v1",
        "http://arxiv.org/pdf/2504.20910v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20906v1",
      "title": "GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In\n  Industrial Control Systems",
      "published": "2025-04-29T16:24:11Z",
      "updated": "2025-04-29T16:24:11Z",
      "summary": "The continuous monitoring of the interactions between cyber-physical\ncomponents of any industrial control system (ICS) is required to secure\nautomation of the system controls, and to guarantee plant processes are\nfail-safe and remain in an acceptably safe state. Safety is achieved by\nmanaging actuation (where electric signals are used to trigger physical\nmovement), dependent on corresponding sensor readings; used as ground truth in\ndecision making. Timely detection of anomalies (attacks, faults and\nunascertained states) in ICSs is crucial for the safe running of a plant, the\nsafety of its personnel, and for the safe provision of any services provided.\nWe propose an anomaly detection method that involves accurate linearization of\nthe non-linear forms arising from sensor-actuator(s) relationships, primarily\nbecause solving linear models is easier and well understood. Further, the time\ncomplexity of the anomaly detection scenario/problem at hand is lowered using\ndimensionality reduction of the actuator(s) in relationship with a sensor. We\naccomplish this by using a well-known water treatment testbed as a use case.\nOur experiments show millisecond time response to detect anomalies and provide\nexplainability; that are not simultaneously achieved by other state of the art\nAI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we\npin-point the sensor(s) and its actuation state for which anomaly was detected.",
      "authors": [
        "Sarad Venugopalan",
        "Sridhar Adepu"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20906v1",
        "http://arxiv.org/pdf/2504.20906v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21569v1",
      "title": "A Systematic Literature Review of Parameter-Efficient Fine-Tuning for\n  Large Code Models",
      "published": "2025-04-29T16:19:25Z",
      "updated": "2025-04-29T16:19:25Z",
      "summary": "The rise of Artificial Intelligence (AI)-and particularly Large Language\nModels (LLMs) for code-has reshaped Software Engineering (SE) by enabling the\nautomation of tasks such as code generation, bug detection, and repair.\nHowever, these models require significant computational resources for training\nand fine-tuning, posing challenges for real-world adoption in\nresource-constrained environments. To address this, the research community has\nincreasingly turned to Parameter-Efficient Fine-Tuning (PEFT)-a class of\ntechniques that enables the adaptation of large models by updating only a small\nsubset of parameters, rather than the entire model. In this Systematic\nLiterature Review (SLR), we examine the growing application of PEFT\ntechniques-across a wide range of software engineering tasks. We analyze how\nthese methods are used to optimize various deep learning (DL) architectures,\nfocusing on their impact on both performance and efficiency. Our study\nsynthesizes findings from 27 peer-reviewed papers, identifying patterns in\nconfiguration strategies and adaptation trade-offs. The outcome of this review\nis a comprehensive taxonomy that categorizes PEFT usage by task type,\ndistinguishing between generative (e.g., Code Summarization) and non-generative\n(e.g., Code Clone Detection) scenarios. Our findings aim to inform future\nresearch and guide the practical deployment of PEFT in sustainable, AI-powered\nsoftware development. Our artifacts are publicly available at\nhttps://github.com/alvi75/SLR-PEFT",
      "authors": [
        "Md Zahidul Haque",
        "Saima Afrin",
        "Antonio Mastropaolo"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21569v1",
        "http://arxiv.org/pdf/2504.21569v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20898v1",
      "title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report\n  Generation with Multi-Agent RAG and Concept Bottleneck Models",
      "published": "2025-04-29T16:14:55Z",
      "updated": "2025-04-29T16:14:55Z",
      "summary": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.",
      "authors": [
        "Hasan Md Tusfiqur Alam",
        "Devansh Srivastav",
        "Abdulrahman Mohamed Selim",
        "Md Abdul Kadir",
        "Md Moktadiurl Hoque Shuvo",
        "Daniel Sonntag"
      ],
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3731406.3731970",
        "http://arxiv.org/abs/2504.20898v1",
        "http://arxiv.org/pdf/2504.20898v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20896v1",
      "title": "LELANTE: LEveraging LLM for Automated ANdroid TEsting",
      "published": "2025-04-29T16:13:49Z",
      "updated": "2025-04-29T16:13:49Z",
      "summary": "Given natural language test case description for an Android application,\nexisting testing approaches require developers to manually write scripts using\ntools such as Appium and Espresso to execute the corresponding test case. This\nprocess is labor-intensive and demands significant effort to maintain as UI\ninterfaces evolve throughout development. In this work, we introduce LELANTE, a\nnovel framework that utilizes large language models (LLMs) to automate test\ncase execution without requiring pre-written scripts. LELANTE interprets\nnatural language test case descriptions, iteratively generate action plans, and\nperform the actions directly on the Android screen using its GUI. LELANTE\nemploys a screen refinement process to enhance LLM interpretability, constructs\na structured prompt for LLMs, and implements an action generation mechanism\nbased on chain-of-thought reasoning of LLMs. To further reduce computational\ncost and enhance scalability, LELANTE utilizes model distillation using a\nfoundational LLM. In experiments across 390 test cases spanning 10 popular\nAndroid applications, LELANTE achieved a 73% test execution success rate. Our\nresults demonstrate that LLMs can effectively bridge the gap between natural\nlanguage test case description and automated execution, making mobile testing\nmore scalable and adaptable.",
      "authors": [
        "Shamit Fatin",
        "Mehbubul Hasan Al-Quvi",
        "Haz Sameen Shahgir",
        "Sukarna Barua",
        "Anindya Iqbal",
        "Sadia Sharmin",
        "Md. Mostofa Akbar",
        "Kallol Kumar Pal",
        "A. Asif Al Rashid"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20896v1",
        "http://arxiv.org/pdf/2504.20896v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20889v1",
      "title": "A Decision Diagram Approach for the Parallel Machine Scheduling Problem\n  with Chance Constraints",
      "published": "2025-04-29T16:07:01Z",
      "updated": "2025-04-29T16:07:01Z",
      "summary": "The Chance-Constrained Parallel Machine Scheduling Problem (CC-PMSP) assigns\njobs with uncertain processing times to machines, ensuring that each machine's\navailability constraints are met with a certain probability. We present a\ndecomposition approach where the master problem assigns jobs to machines, and\nthe subproblems schedule the jobs on each machine while verifying the\nsolution's feasibility under the chance constraint. We propose two different\nDecision Diagram (DD) formulations to solve the subproblems and generate cuts.\nThe first formulation employs DDs with a linear cost function, while the second\nuses a non-linear cost function to reduce the diagram's size. We show how to\ngenerate no-good and irreducible infeasible subsystem (IIS) cuts based on our\nDDs. Additionally, we extend the cuts proposed by Lozano & Smith (2018) to\nsolve two-stage stochastic programming models. Our DD-based methodology\noutperforms traditional integer programming (IP) models designed to solve the\nCC-PMSP in several instances. Specifically, our best DD-based approach solves\n55 more instances than the best IP alternative (from a total of 405) and\ntypically achieves smaller gaps (50% vs. 120% gap on average).",
      "authors": [
        "Nicol\u00e1s Casassus",
        "Margarita Castro",
        "Gustavo Angulo"
      ],
      "categories": [
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20889v1",
        "http://arxiv.org/pdf/2504.20889v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21071v1",
      "title": "Automated Parking Trajectory Generation Using Deep Reinforcement\n  Learning",
      "published": "2025-04-29T15:25:34Z",
      "updated": "2025-04-29T15:25:34Z",
      "summary": "Autonomous parking is a key technology in modern autonomous driving systems,\nrequiring high precision, strong adaptability, and efficiency in complex\nenvironments. This paper proposes a Deep Reinforcement Learning (DRL) framework\nbased on the Soft Actor-Critic (SAC) algorithm to optimize autonomous parking\ntasks. SAC, an off-policy method with entropy regularization, is particularly\nwell-suited for continuous action spaces, enabling fine-grained vehicle\ncontrol. We model the parking task as a Markov Decision Process (MDP) and train\nan agent to maximize cumulative rewards while balancing exploration and\nexploitation through entropy maximization. The proposed system integrates\nmultiple sensor inputs into a high-dimensional state space and leverages SAC's\ndual critic networks and policy network to achieve stable learning. Simulation\nresults show that the SAC-based approach delivers high parking success rates,\nreduced maneuver times, and robust handling of dynamic obstacles, outperforming\ntraditional rule-based methods and other DRL algorithms. This study\ndemonstrates SAC's potential in autonomous parking and lays the foundation for\nreal-world applications.",
      "authors": [
        "Zheyu Zhang",
        "Yutong Luo",
        "Yongzhou Chen",
        "Haopeng Zhao",
        "Zhichao Ma",
        "Hao Liu"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21071v1",
        "http://arxiv.org/pdf/2504.21071v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20849v1",
      "title": "JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated\n  Marketing Text in the Music Industry",
      "published": "2025-04-29T15:19:06Z",
      "updated": "2025-04-29T15:19:06Z",
      "summary": "Online platforms are increasingly interested in using Data-to-Text\ntechnologies to generate content and help their users. Unfortunately,\ntraditional generative methods often fall into repetitive patterns, resulting\nin monotonous galleries of texts after only a few iterations. In this paper, we\ninvestigate LLM-based data-to-text approaches to automatically generate\nmarketing texts that are of sufficient quality and diverse enough for broad\nadoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in\nconjunction with fine-tuning, few-shot, and zero-shot approaches to set a\nbaseline for diverse marketing texts. We also introduce a metric JaccDiv to\nevaluate the diversity of a set of texts. This research extends its relevance\nbeyond the music industry, proving beneficial in various fields where\nrepetitive automated content generation is prevalent.",
      "authors": [
        "Anum Afzal",
        "Alexandre Mercier",
        "Florian Matthes"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20849v1",
        "http://arxiv.org/pdf/2504.20849v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20726v1",
      "title": "Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization",
      "published": "2025-04-29T13:08:27Z",
      "updated": "2025-04-29T13:08:27Z",
      "summary": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.",
      "authors": [
        "Hattan Althebeiti",
        "Mohammed Alkinoon",
        "Manar Mohaisen",
        "Saeed Salem",
        "DaeHun Nyang",
        "David Mohaisen"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20726v1",
        "http://arxiv.org/pdf/2504.20726v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20684v1",
      "title": "Identifying Uncertainty in Self-Adaptive Robotics with Large Language\n  Models",
      "published": "2025-04-29T12:07:39Z",
      "updated": "2025-04-29T12:07:39Z",
      "summary": "Future self-adaptive robots are expected to operate in highly dynamic\nenvironments while effectively managing uncertainties. However, identifying the\nsources and impacts of uncertainties in such robotic systems and defining\nappropriate mitigation strategies is challenging due to the inherent complexity\nof self-adaptive robots and the lack of comprehensive knowledge about the\nvarious factors influencing uncertainty. Hence, practitioners often rely on\nintuition and past experiences from similar systems to address uncertainties.\nIn this article, we evaluate the potential of large language models (LLMs) in\nenabling a systematic and automated approach to identify uncertainties in\nself-adaptive robotics throughout the software engineering lifecycle. For this\nevaluation, we analyzed 10 advanced LLMs with varying capabilities across four\nindustrial-sized robotics case studies, gathering the practitioners'\nperspectives on the LLM-generated responses related to uncertainties. Results\nshowed that practitioners agreed with 63-88% of the LLM responses and expressed\nstrong interest in the practicality of LLMs for this purpose.",
      "authors": [
        "Hassan Sartaj",
        "Jalil Boudjadar",
        "Mirgita Frasheri",
        "Shaukat Ali",
        "Peter Gorm Larsen"
      ],
      "categories": [
        "cs.RO",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20684v1",
        "http://arxiv.org/pdf/2504.20684v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20679v1",
      "title": "Are Information Retrieval Approaches Good at Harmonising Longitudinal\n  Survey Questions in Social Science?",
      "published": "2025-04-29T12:00:33Z",
      "updated": "2025-04-29T12:00:33Z",
      "summary": "Automated detection of semantically equivalent questions in longitudinal\nsocial science surveys is crucial for long-term studies informing empirical\nresearch in the social, economic, and health sciences. Retrieving equivalent\nquestions faces dual challenges: inconsistent representation of theoretical\nconstructs (i.e. concept/sub-concept) across studies as well as between\nquestion and response options, and the evolution of vocabulary and structure in\nlongitudinal text. To address these challenges, our multi-disciplinary\ncollaboration of computer scientists and survey specialists presents a new\ninformation retrieval (IR) task of identifying concept (e.g. Housing, Job,\netc.) equivalence across question and response options to harmonise\nlongitudinal population studies. This paper investigates multiple unsupervised\napproaches on a survey dataset spanning 1946-2020, including probabilistic\nmodels, linear probing of language models, and pre-trained neural networks\nspecialised for IR. We show that IR-specialised neural models achieve the\nhighest overall performance with other approaches performing comparably.\nAdditionally, the re-ranking of the probabilistic model's results with neural\nmodels only introduces modest improvements of 0.07 at most in F1-score.\nQualitative post-hoc evaluation by survey specialists shows that models\ngenerally have a low sensitivity to questions with high lexical overlap,\nparticularly in cases where sub-concepts are mismatched. Altogether, our\nanalysis serves to further research on harmonising longitudinal studies in\nsocial science.",
      "authors": [
        "Wing Yan Li",
        "Zeqiang Wang",
        "Jon Johnson",
        "Suparna De"
      ],
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20679v1",
        "http://arxiv.org/pdf/2504.20679v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20615v1",
      "title": "Multi-Sensor Fusion for Quadruped Robot State Estimation using Invariant\n  Filtering and Smoothing",
      "published": "2025-04-29T10:29:00Z",
      "updated": "2025-04-29T10:29:00Z",
      "summary": "This letter introduces two multi-sensor state estimation frameworks for\nquadruped robots, built on the Invariant Extended Kalman Filter (InEKF) and\nInvariant Smoother (IS). The proposed methods, named E-InEKF and E-IS, fuse\nkinematics, IMU, LiDAR, and GPS data to mitigate position drift, particularly\nalong the z-axis, a common issue in proprioceptive-based approaches. We derived\nobservation models that satisfy group-affine properties to integrate LiDAR\nodometry and GPS into InEKF and IS. LiDAR odometry is incorporated using\nIterative Closest Point (ICP) registration on a parallel thread, preserving the\ncomputational efficiency of proprioceptive-based state estimation. We evaluate\nE-InEKF and E-IS with and without exteroceptive sensors, benchmarking them\nagainst LiDAR-based odometry methods in indoor and outdoor experiments using\nthe KAIST HOUND2 robot. Our methods achieve lower Relative Position Errors\n(RPE) and significantly reduce Absolute Trajectory Error (ATE), with\nimprovements of up to 28% indoors and 40% outdoors compared to LIO-SAM and\nFAST-LIO2. Additionally, we compare E-InEKF and E-IS in terms of computational\nefficiency and accuracy.",
      "authors": [
        "Ylenia Nistic\u00f2",
        "Hajun Kim",
        "Jo\u00e3o Carlos Virgolino Soares",
        "Geoff Fink",
        "Hae-Won Park",
        "Claudio Semini"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2025.3564711",
        "http://arxiv.org/abs/2504.20615v1",
        "http://arxiv.org/pdf/2504.20615v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20612v1",
      "title": "The Hidden Risks of LLM-Generated Web Application Code: A\n  Security-Centric Evaluation of Code Generation Capabilities in Large Language\n  Models",
      "published": "2025-04-29T10:23:11Z",
      "updated": "2025-04-29T10:23:11Z",
      "summary": "The rapid advancement of Large Language Models (LLMs) has enhanced software\ndevelopment processes, minimizing the time and effort required for coding and\nenhancing developer productivity. However, despite their potential benefits,\ncode generated by LLMs has been shown to generate insecure code in controlled\nenvironments, raising critical concerns about their reliability and security in\nreal-world applications. This paper uses predefined security parameters to\nevaluate the security compliance of LLM-generated code across multiple models,\nsuch as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals\ncritical vulnerabilities in authentication mechanisms, session management,\ninput validation and HTTP security headers. Although some models implement\nsecurity measures to a limited extent, none fully align with industry best\npractices, highlighting the associated risks in automated software development.\nOur findings underscore that human expertise is crucial to ensure secure\nsoftware deployment or review of LLM-generated code. Also, there is a need for\nrobust security assessment frameworks to enhance the reliability of\nLLM-generated code in real-world applications.",
      "authors": [
        "Swaroop Dora",
        "Deven Lunkad",
        "Naziya Aslam",
        "S. Venkatesan",
        "Sandeep Kumar Shukla"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20612v1",
        "http://arxiv.org/pdf/2504.20612v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21062v1",
      "title": "A Hamiltonian Higher-Order Elasticity Framework for Dynamic\n  Diagnostics(2HOED)",
      "published": "2025-04-29T10:12:52Z",
      "updated": "2025-04-29T10:12:52Z",
      "summary": "Machine learning detects patterns, block chain guarantees trust and\nimmutability, and modern causal inference identifies directional linkages, yet\nnone alone exposes the full energetic anatomy of complex systems; the\nHamiltonian Higher Order Elasticity Dynamics(2HOED) framework bridges these\ngaps. Grounded in classical mechanics but extended to Economics order\nelasticity terms, 2HOED represents economic, social, and physical systems as\nenergy-based Hamiltonians whose position, velocity, acceleration, and jerk of\nelasticity jointly determine systemic power, Inertia, policy sensitivity, and\nmarginal responses. Because the formalism is scaling free and coordinate\nagnostic, it transfers seamlessly from financial markets to climate science,\nfrom supply chain logistics to epidemiology, thus any discipline in which\nadaptation and shocks coexist. By embedding standard econometric variables\ninside a Hamiltonian, 2HOED enriches conventional economic analysis with\nrigorous diagnostics of resilience, tipping points, and feedback loops,\nrevealing failure modes invisible to linear models. Wavelet spectra, phase\nspace attractors, and topological persistence diagrams derived from 2HOED\nexpose multistage policy leverage that machine learning detects only\nempirically and block chain secures only after the fact. For economists,\nphysicians and other scientists, the method opens a new causal energetic\nchannel linking biological or mechanical elasticity to macro level outcomes.\nPortable, interpretable, and computationally light, 2HOED turns data streams\ninto dynamical energy maps, empowering decision makers to anticipate crises,\ndesign adaptive policies, and engineer robust systems delivering the predictive\npunch of AI with the explanatory clarity of physics.",
      "authors": [
        "Ngueuleweu Tiwang Gildas"
      ],
      "categories": [
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21062v1",
        "http://arxiv.org/pdf/2504.21062v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20510v1",
      "title": "SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable\n  Detection of Surface Defects",
      "published": "2025-04-29T07:51:58Z",
      "updated": "2025-04-29T07:51:58Z",
      "summary": "Automating the quality control of shot-blasted steel surfaces is crucial for\nimproving manufacturing efficiency and consistency. This study presents a\ndataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as\neither \"ready for paint\" or \"needs shot-blasting.\" The dataset captures\nreal-world surface defects, including discoloration, welding lines, scratches\nand corrosion, making it well-suited for training computer vision models.\nAdditionally, three classification approaches were evaluated: Compact\nConvolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50\nfeature extraction, and a Convolutional Autoencoder (CAE). The supervised\nmethods (CCT and SVM) achieve 95% classification accuracy on the test set, with\nCCT leveraging transformer-based attention mechanisms and SVM offering a\ncomputationally efficient alternative. The CAE approach, while less effective,\nestablishes a baseline for unsupervised quality control. We present\ninterpretable decision-making by all three neural networks, allowing industry\nusers to visually pinpoint problematic regions and understand the model's\nrationale. By releasing the dataset and baseline codes, this work aims to\nsupport further research in defect detection, advance the development of\ninterpretable computer vision models for quality control, and encourage the\nadoption of automated inspection systems in industrial applications.",
      "authors": [
        "Irina Ruzavina",
        "Lisa Sophie Theis",
        "Jesse Lemeer",
        "Rutger de Groen",
        "Leo Ebeling",
        "Andrej Hulak",
        "Jouaria Ali",
        "Guangzhi Tang",
        "Rico Mockel"
      ],
      "categories": [
        "cs.CV",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20510v1",
        "http://arxiv.org/pdf/2504.20510v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20501v1",
      "title": "SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image\n  Segmentation",
      "published": "2025-04-29T07:43:37Z",
      "updated": "2025-04-29T07:43:37Z",
      "summary": "One-shot medical image segmentation (MIS) is crucial for medical analysis due\nto the burden of medical experts on manual annotation. The recent emergence of\nthe segment anything model (SAM) has demonstrated remarkable adaptation in MIS\nbut cannot be directly applied to one-shot medical image segmentation (MIS) due\nto its reliance on labor-intensive user interactions and the high computational\ncost. To cope with these limitations, we propose a novel SAM-guided robust\nrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot\n3D MIS, which exploits the strong generalization capabilities of the SAM\nencoder to learn better feature representation. We devise a dual-stage\nknowledge distillation (DSKD) strategy to distill general knowledge between\nnatural and medical images from the foundation model to train a lightweight\nencoder, and then adopt a mutual exponential moving average (mutual-EMA) to\nupdate the weights of the general lightweight encoder and medical-specific\nencoder. Specifically, pseudo labels from the registration network are used to\nperform mutual supervision for such two encoders. Moreover, we introduce an\nauto-prompting (AP) segmentation decoder which adopts the mask generated from\nthe general lightweight model as a prompt to assist the medical-specific model\nin boosting the final segmentation performance. Extensive experiments conducted\non three public datasets, i.e., OASIS, CT-lung demonstrate that the proposed\nRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for both\nsegmentation and registration tasks. Especially, our lightweight encoder uses\nonly 3\\% of the parameters compared to the encoder of SAM-Base.",
      "authors": [
        "Jia Wang",
        "Yunan Mei",
        "Jiarui Liu",
        "Xin Fan"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20501v1",
        "http://arxiv.org/pdf/2504.20501v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20471v1",
      "title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams",
      "published": "2025-04-29T07:13:28Z",
      "updated": "2025-04-29T07:13:28Z",
      "summary": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.",
      "authors": [
        "Baining Chen",
        "Yiming Zhang",
        "Yuqiao Han",
        "Ruyue Zhang",
        "Ruihuan Du",
        "Zhishuo Zhou",
        "Zhengdan Zhu",
        "Xun Liu",
        "Jiecheng Guo"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20471v1",
        "http://arxiv.org/pdf/2504.20471v1"
      ],
      "primary_search_term": "large language models",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}