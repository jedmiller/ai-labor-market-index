{
  "query": "all:machine learning AND (labor market OR employment OR jobs OR workforce OR automation)",
  "target_period": "2025-03",
  "date_collected": "2025-03-20T15:52:54.637243",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2503.15474v1",
      "title": "Toward task-driven satellite image super-resolution",
      "published": "2025-03-19T17:49:27Z",
      "updated": "2025-03-19T17:49:27Z",
      "summary": "Super-resolution is aimed at reconstructing high-resolution images from\nlow-resolution observations. State-of-the-art approaches underpinned with deep\nlearning allow for obtaining outstanding results, generating images of high\nperceptual quality. However, it often remains unclear whether the reconstructed\ndetails are close to the actual ground-truth information and whether they\nconstitute a more valuable source for image analysis algorithms. In the\nreported work, we address the latter problem, and we present our efforts toward\nlearning super-resolution algorithms in a task-driven way to make them suitable\nfor generating high-resolution images that can be exploited for automated image\nanalysis. In the reported initial research, we propose a methodological\napproach for assessing the existing models that perform computer vision tasks\nin terms of whether they can be used for evaluating super-resolution\nreconstruction algorithms, as well as training them in a task-driven way. We\nsupport our analysis with experimental study and we expect it to establish a\nsolid foundation for selecting appropriate computer vision tasks that will\nadvance the capabilities of real-world super-resolution.",
      "authors": [
        "Maciej Ziaja",
        "Pawel Kowaleczko",
        "Daniel Kostrzewa",
        "Nicolas Long\u00e9p\u00e9",
        "Michal Kawulok"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://dx.doi.org/10.1109/IGARSS53475.2024.10642397",
        "http://arxiv.org/abs/2503.15474v1",
        "http://arxiv.org/pdf/2503.15474v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15415v1",
      "title": "Automated Processing of eXplainable Artificial Intelligence Outputs in\n  Deep Learning Models for Fault Diagnostics of Large Infrastructures",
      "published": "2025-03-19T16:57:00Z",
      "updated": "2025-03-19T16:57:00Z",
      "summary": "Deep Learning (DL) models processing images to recognize the health state of\nlarge infrastructure components can exhibit biases and rely on non-causal\nshortcuts. eXplainable Artificial Intelligence (XAI) can address these issues\nbut manually analyzing explanations generated by XAI techniques is\ntime-consuming and prone to errors. This work proposes a novel framework that\ncombines post-hoc explanations with semi-supervised learning to automatically\nidentify anomalous explanations that deviate from those of correctly classified\nimages and may therefore indicate model abnormal behaviors. This significantly\nreduces the workload for maintenance decision-makers, who only need to manually\nreclassify images flagged as having anomalous explanations. The proposed\nframework is applied to drone-collected images of insulator shells for power\ngrid infrastructure monitoring, considering two different Convolutional Neural\nNetworks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly\nDetection. The average classification accuracy on two faulty classes is\nimproved by 8% and maintenance operators are required to manually reclassify\nonly 15% of the images. We compare the proposed framework with a\nstate-of-the-art approach based on the faithfulness metric: the experimental\nresults obtained demonstrate that the proposed framework consistently achieves\nF_1 scores larger than those of the faithfulness-based approach. Additionally,\nthe proposed framework successfully identifies correct classifications that\nresult from non-causal shortcuts, such as the presence of ID tags printed on\ninsulator shells.",
      "authors": [
        "Giovanni Floreale",
        "Piero Baraldi",
        "Enrico Zio",
        "Olga Fink"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15415v1",
        "http://arxiv.org/pdf/2503.15415v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15407v1",
      "title": "Exploiting Prior Knowledge in Preferential Learning of Individualized\n  Autonomous Vehicle Driving Styles",
      "published": "2025-03-19T16:47:56Z",
      "updated": "2025-03-19T16:47:56Z",
      "summary": "Trajectory planning for automated vehicles commonly employs optimization over\na moving horizon - Model Predictive Control - where the cost function\ncritically influences the resulting driving style. However, finding a suitable\ncost function that results in a driving style preferred by passengers remains\nan ongoing challenge. We employ preferential Bayesian optimization to learn the\ncost function by iteratively querying a passenger's preference. Due to\nincreasing dimensionality of the parameter space, preference learning\napproaches might struggle to find a suitable optimum with a limited number of\nexperiments and expose the passenger to discomfort when exploring the parameter\nspace. We address these challenges by incorporating prior knowledge into the\npreferential Bayesian optimization framework. Our method constructs a virtual\ndecision maker from real-world human driving data to guide parameter sampling.\nIn a simulation experiment, we achieve faster convergence of the\nprior-knowledge-informed learning procedure compared to existing preferential\nBayesian optimization approaches and reduce the number of inadequate driving\nstyles sampled.",
      "authors": [
        "Lukas Theiner",
        "Sebastian Hirt",
        "Alexander Steinke",
        "Rolf Findeisen"
      ],
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15407v1",
        "http://arxiv.org/pdf/2503.15407v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15403v1",
      "title": "HQNN-FSP: A Hybrid Classical-Quantum Neural Network for Regression-Based\n  Financial Stock Market Prediction",
      "published": "2025-03-19T16:44:21Z",
      "updated": "2025-03-19T16:44:21Z",
      "summary": "Financial time-series forecasting remains a challenging task due to complex\ntemporal dependencies and market fluctuations. This study explores the\npotential of hybrid quantum-classical approaches to assist in financial trend\nprediction by leveraging quantum resources for improved feature representation\nand learning. A custom Quantum Neural Network (QNN) regressor is introduced,\ndesigned with a novel ansatz tailored for financial applications. Two hybrid\noptimization strategies are proposed: (1) a sequential approach where classical\nrecurrent models (RNN/LSTM) extract temporal dependencies before quantum\nprocessing, and (2) a joint learning framework that optimizes classical and\nquantum parameters simultaneously. Systematic evaluation using TimeSeriesSplit,\nk-fold cross-validation, and predictive error analysis highlights the ability\nof these hybrid models to integrate quantum computing into financial\nforecasting workflows. The findings demonstrate how quantum-assisted learning\ncan contribute to financial modeling, offering insights into the practical role\nof quantum resources in time-series analysis.",
      "authors": [
        "Prashant Kumar Choudhary",
        "Nouhaila Innan",
        "Muhammad Shafique",
        "Rajeev Singh"
      ],
      "categories": [
        "q-fin.ST",
        "cs.LG",
        "quant-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15403v1",
        "http://arxiv.org/pdf/2503.15403v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15373v1",
      "title": "Priority-driven Constraints Softening in Safe MPC for Perturbed Systems",
      "published": "2025-03-19T16:11:25Z",
      "updated": "2025-03-19T16:11:25Z",
      "summary": "This paper presents a safe model predictive control (SMPC) framework designed\nto ensure the satisfaction of hard constraints for systems perturbed by an\nexternal disturbance. Such safety guarantees are ensured, despite the\ndisturbance, by online softening a subset of adjustable constraints defined by\nthe designer. The selection of the constraints to be softened is made online\nbased on a predefined priority assigned to each adjustable constraint. The\ndesign of a learning-based algorithm enables real-time computation while\npreserving the original safety properties.\n  Simulations results, obtained from an automated driving application, show\nthat the proposed approach provides guarantees of collision-avoidance hard\nconstraints despite the unpredicted behaviors of the surrounding environment.",
      "authors": [
        "Ying Shuai Quan",
        "Mohammad Jeddi",
        "Francesco Prignoli",
        "Paolo Falcone"
      ],
      "categories": [
        "eess.SY",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15373v1",
        "http://arxiv.org/pdf/2503.15373v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15325v1",
      "title": "Euclid Quick Data Release (Q1) The Strong Lensing Discovery Engine B --\n  Early strong lens candidates from visual inspection of high velocity\n  dispersion galaxies",
      "published": "2025-03-19T15:27:20Z",
      "updated": "2025-03-19T15:27:20Z",
      "summary": "We present a search for strong gravitational lenses in Euclid imaging with\nhigh stellar velocity dispersion ($\\sigma_\\nu > 180$ km/s) reported by SDSS and\nDESI. We performed expert visual inspection and classification of $11\\,660$\n\\Euclid images. We discovered 38 grade A and 40 grade B candidate lenses,\nconsistent with an expected sample of $\\sim$32. Palomar spectroscopy confirmed\n5 lens systems, while DESI spectra confirmed one, provided ambiguous results\nfor another, and help to discard one. The \\Euclid automated lens modeler\nmodelled 53 candidates, confirming 38 as lenses, failing to model 9, and ruling\nout 6 grade B candidates. For the remaining 25 candidates we could not gather\nadditional information. More importantly, our expert-classified non-lenses\nprovide an excellent training set for machine learning lens classifiers. We\ncreate high-fidelity simulations of \\Euclid lenses by painting realistic lensed\nsources behind the expert tagged (non-lens) luminous red galaxies. This\ntraining set is the foundation stone for the \\Euclid galaxy-galaxy strong\nlensing discovery engine.",
      "authors": [
        " Euclid Collaboration",
        "K. Rojas",
        "T. E. Collett",
        "J. A. Acevedo Barroso",
        "J. W. Nightingale",
        "D. Stern",
        "L. A. Moustakas",
        "S. Schuldt",
        "G. Despali",
        "A. Melo",
        "M. Walmsley",
        "D. J. Ballard",
        "W. J. R. Enzi",
        "T. Li",
        "A. Sainz de Murieta",
        "I. T. Andika",
        "B. Cl\u00e9ment",
        "F. Courbin",
        "L. R. Ecker",
        "R. Gavazzi",
        "N. Jackson",
        "A. Kov\u00e1cs",
        "P. Matavulj",
        "M. Meneghetti",
        "S. Serjeant",
        "D. Sluse",
        "C. Tortora",
        "A. Verma",
        "L. Marchetti",
        "C. M. O'Riordan",
        "K. McCarthy",
        "S. H. Suyu",
        "R. B. Metcalf",
        "N. Aghanim",
        "B. Altieri",
        "A. Amara",
        "S. Andreon",
        "N. Auricchio",
        "H. Aussel",
        "C. Baccigalupi",
        "M. Baldi",
        "A. Balestra",
        "S. Bardelli",
        "P. Battaglia",
        "R. Bender",
        "A. Biviano",
        "A. Bonchi",
        "E. Branchini",
        "M. Brescia",
        "J. Brinchmann",
        "S. Camera",
        "G. Ca\u00f1as-Herrera",
        "V. Capobianco",
        "C. Carbone",
        "V. F. Cardone",
        "J. Carretero",
        "S. Casas",
        "M. Castellano",
        "G. Castignani",
        "S. Cavuoti",
        "K. C. Chambers",
        "A. Cimatti",
        "C. Colodro-Conde",
        "G. Congedo",
        "C. J. Conselice",
        "L. Conversi",
        "Y. Copin",
        "H. M. Courtois",
        "M. Cropper",
        "A. Da Silva",
        "H. Degaudenzi",
        "G. De Lucia",
        "A. M. Di Giorgio",
        "C. Dolding",
        "H. Dole",
        "F. Dubath",
        "X. Dupac",
        "S. Escoffier",
        "M. Fabricius",
        "M. Farina",
        "R. Farinelli",
        "F. Faustini",
        "S. Ferriol",
        "F. Finelli",
        "S. Fotopoulou",
        "M. Frailis",
        "E. Franceschi",
        "S. Galeotta",
        "K. George",
        "W. Gillard",
        "B. Gillis",
        "C. Giocoli",
        "P. G\u00f3mez-Alvarez",
        "J. Gracia-Carpio",
        "B. R. Granett",
        "A. Grazian",
        "F. Grupp",
        "L. Guzzo",
        "S. Gwyn",
        "S. V. H. Haugan",
        "W. Holmes",
        "I. M. Hook",
        "F. Hormuth",
        "A. Hornstrup",
        "P. Hudelot",
        "K. Jahnke",
        "M. Jhabvala",
        "E. Keih\u00e4nen",
        "S. Kermiche",
        "A. Kiessling",
        "B. Kubik",
        "K. Kuijken",
        "M. K\u00fcmmel",
        "M. Kunz",
        "H. Kurki-Suonio",
        "Q. Le Boulc'h",
        "A. M. C. Le Brun",
        "D. Le Mignant",
        "P. Liebing",
        "S. Ligori",
        "P. B. Lilje",
        "V. Lindholm",
        "I. Lloro",
        "G. Mainetti",
        "D. Maino",
        "E. Maiorano",
        "O. Mansutti",
        "S. Marcin",
        "O. Marggraf",
        "M. Martinelli",
        "N. Martinet",
        "F. Marulli",
        "R. Massey",
        "S. Maurogordato",
        "H. J. McCracken",
        "E. Medinaceli",
        "S. Mei",
        "M. Melchior",
        "Y. Mellier",
        "E. Merlin",
        "G. Meylan",
        "A. Mora",
        "M. Moresco",
        "L. Moscardini",
        "R. Nakajima",
        "C. Neissner",
        "R. C. Nichol",
        "S. -M. Niemi",
        "C. Padilla",
        "S. Paltani",
        "F. Pasian",
        "K. Pedersen",
        "W. J. Percival",
        "V. Pettorino",
        "S. Pires",
        "G. Polenta",
        "M. Poncet",
        "L. A. Popa",
        "L. Pozzetti",
        "F. Raison",
        "R. Rebolo",
        "A. Renzi",
        "J. Rhodes",
        "G. Riccio",
        "E. Romelli",
        "M. Roncarelli",
        "R. Saglia",
        "Z. Sakr",
        "A. G. S\u00e1nchez",
        "D. Sapone",
        "B. Sartoris",
        "J. A. Schewtschenko",
        "M. Schirmer",
        "P. Schneider",
        "T. Schrabback",
        "A. Secroun",
        "G. Seidel",
        "M. Seiffert",
        "S. Serrano",
        "P. Simon",
        "C. Sirignano",
        "G. Sirri",
        "L. Stanco",
        "J. Steinwagner",
        "P. Tallada-Cresp\u00ed",
        "A. N. Taylor",
        "I. Tereno",
        "S. Toft",
        "R. Toledo-Moreo",
        "F. Torradeflot",
        "I. Tutusaus",
        "L. Valenziano",
        "J. Valiviita",
        "T. Vassallo",
        "G. Verdoes Kleijn",
        "A. Veropalumbo",
        "Y. Wang",
        "J. Weller",
        "A. Zacchei",
        "G. Zamorani",
        "F. M. Zerbi",
        "E. Zucca",
        "M. Ballardini",
        "M. Bolzonella",
        "E. Bozzo",
        "C. Burigana",
        "R. Cabanac",
        "A. Cappi",
        "D. Di Ferdinando",
        "J. A. Escartin Vigo",
        "L. Gabarra",
        "J. Mart\u00edn-Fleitas",
        "S. Matthew",
        "N. Mauri",
        "A. Pezzotta",
        "M. P\u00f6ntinen",
        "C. Porciani",
        "I. Risso",
        "V. Scottez",
        "M. Sereno",
        "M. Tenti",
        "M. Viel",
        "M. Wiesmann",
        "Y. Akrami",
        "S. Alvi",
        "S. Anselmi",
        "M. Archidiacono",
        "F. Atrio-Barandela",
        "C. Benoist",
        "K. Benson",
        "P. Bergamini",
        "D. Bertacca",
        "M. Bethermin",
        "A. Blanchard",
        "L. Blot",
        "M. L. Brown",
        "S. Bruton",
        "A. Calabro",
        "B. Camacho Quevedo",
        "F. Caro",
        "C. S. Carvalho",
        "T. Castro",
        "F. Cogato",
        "A. R. Cooray",
        "O. Cucciati",
        "S. Davini",
        "F. De Paolis",
        "G. Desprez",
        "A. D\u00edaz-S\u00e1nchez",
        "J. J. Diaz",
        "S. Di Domizio",
        "J. M. Diego",
        "P. -A. Duc",
        "A. Enia",
        "Y. Fang",
        "A. G. Ferrari",
        "P. G. Ferreira",
        "A. Finoguenov",
        "A. Fontana",
        "A. Franco",
        "K. Ganga",
        "J. Garc\u00eda-Bellido",
        "T. Gasparetto",
        "V. Gautard",
        "E. Gaztanaga",
        "F. Giacomini",
        "F. Gianotti",
        "G. Gozaliasl",
        "M. Guidi",
        "C. M. Gutierrez",
        "A. Hall",
        "W. G. Hartley",
        "C. Hern\u00e1ndez-Monteagudo",
        "H. Hildebrandt",
        "J. Hjorth",
        "J. J. E. Kajava",
        "Y. Kang",
        "V. Kansal",
        "D. Karagiannis",
        "K. Kiiveri",
        "C. C. Kirkpatrick",
        "S. Kruk",
        "J. Le Graet",
        "L. Legrand",
        "M. Lembo",
        "F. Lepori",
        "G. Leroy",
        "G. F. Lesci",
        "J. Lesgourgues",
        "L. Leuzzi",
        "T. I. Liaudat",
        "A. Loureiro",
        "J. Macias-Perez",
        "G. Maggio",
        "M. Magliocchetti",
        "E. A. Magnier",
        "F. Mannucci",
        "R. Maoli",
        "C. J. A. P. Martins",
        "L. Maurin",
        "M. Miluzio",
        "P. Monaco",
        "C. Moretti",
        "G. Morgante",
        "S. Nadathur",
        "K. Naidoo",
        "A. Navarro-Alsina",
        "S. Nesseris",
        "F. Passalacqua",
        "K. Paterson",
        "L. Patrizii",
        "A. Pisani",
        "D. Potter",
        "S. Quai",
        "M. Radovich",
        "P. -F. Rocci",
        "S. Sacquegna",
        "M. Sahl\u00e9n",
        "D. B. Sanders",
        "E. Sarpa",
        "C. Scarlata",
        "A. Schneider",
        "D. Sciotti",
        "E. Sellentin",
        "L. C. Smith",
        "K. Tanidis",
        "G. Testera",
        "R. Teyssier",
        "A. Troja",
        "M. Tucci",
        "C. Valieri",
        "A. Venhola",
        "D. Vergani",
        "G. Vernardos",
        "G. Verza",
        "P. Vielzeuf",
        "N. A. Walton",
        "J. Wilde",
        "D. Scott"
      ],
      "categories": [
        "astro-ph.GA",
        "astro-ph.CO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15325v1",
        "http://arxiv.org/pdf/2503.15325v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15270v1",
      "title": "Automating Comment Generation for Smart Contract from Bytecode",
      "published": "2025-03-19T14:45:40Z",
      "updated": "2025-03-19T14:45:40Z",
      "summary": "Recently, smart contracts have played a vital role in automatic financial and\nbusiness transactions. To help end users without programming background to\nbetter understand the logic of smart contracts, previous studies have proposed\nmodels for automatically translating smart contract source code into their\ncorresponding code summaries. However, in practice, only 13% of smart contracts\ndeployed on the Ethereum blockchain are associated with source code. The\npractical usage of these existing tools is significantly restricted.\nConsidering that bytecode is always necessary when deploying smart contracts,\nin this paper, we first introduce the task of automatically generating smart\ncontract code summaries from bytecode. We propose a novel approach, named\nSmartBT (Smart contract Bytecode Translator) for automatically translating\nsmart contract bytecode into fine-grained natural language description\ndirectly. Two key challenges are posed for this task: structural code logic\nhidden in bytecode and the huge semantic gap between bytecode and natural\nlanguage descriptions. To address the first challenge, we transform bytecode\ninto CFG (Control-Flow Graph) to learn code structural and logic details.\nRegarding the second challenge, we introduce an information retrieval component\nto fetch similar comments for filling the semantic gap. Then the structural\ninput and semantic input are used to build an attentional sequence-to-sequence\nneural network model. The copy mechanism is employed to copy rare words\ndirectly from similar comments and the coverage mechanism is employed to\neliminate repetitive outputs. The automatic evaluation results show that\nSmartBT outperforms a set of baselines by a large margin, and the human\nevaluation results show the effectiveness and potential of SmartBT in producing\nmeaningful and accurate comments for smart contract code from bytecode\ndirectly.",
      "authors": [
        "Jianhang Xiang",
        "Zhipeng Gao",
        "Lingfeng Bao",
        "Xing Hu",
        "Jiayuan Chen",
        "Xin Xia"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3699597",
        "http://arxiv.org/abs/2503.15270v1",
        "http://arxiv.org/pdf/2503.15270v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15260v1",
      "title": "DEPT: Deep Extreme Point Tracing for Ultrasound Image Segmentation",
      "published": "2025-03-19T14:32:14Z",
      "updated": "2025-03-19T14:32:14Z",
      "summary": "Automatic medical image segmentation plays a crucial role in computer aided\ndiagnosis. However, fully supervised learning approaches often require\nextensive and labor-intensive annotation efforts. To address this challenge,\nweakly supervised learning methods, particularly those using extreme points as\nsupervisory signals, have the potential to offer an effective solution. In this\npaper, we introduce Deep Extreme Point Tracing (DEPT) integrated with\nFeature-Guided Extreme Point Masking (FGEPM) algorithm for ultrasound image\nsegmentation. Notably, our method generates pseudo labels by identifying the\nlowest-cost path that connects all extreme points on the feature map-based cost\nmatrix. Additionally, an iterative training strategy is proposed to refine\npseudo labels progressively, enabling continuous network improvement.\nExperimental results on two public datasets demonstrate the effectiveness of\nour proposed method. The performance of our method approaches that of the fully\nsupervised method and outperforms several existing weakly supervised methods.",
      "authors": [
        "Lei Shi",
        "Xi Fang",
        "Naiyu Wang",
        "Junxing Zhang"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15260v1",
        "http://arxiv.org/pdf/2503.15260v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15250v1",
      "title": "ImputeGAP: A Comprehensive Library for Time Series Imputation",
      "published": "2025-03-19T14:24:20Z",
      "updated": "2025-03-19T14:24:20Z",
      "summary": "With the prevalence of sensor failures, imputation--the process of estimating\nmissing values--has emerged as the cornerstone of time series data preparation.\nWhile numerous imputation algorithms have been developed to address these data\ngaps, existing libraries provide limited support. Furthermore, they often lack\nthe ability to simulate realistic patterns of time series missing data and fail\nto account for the impact of imputation on subsequent downstream analysis.\n  This paper introduces ImputeGAP, a comprehensive library for time series\nimputation that supports a diverse range of imputation methods and modular\nmissing data simulation catering to datasets with varying characteristics. The\nlibrary includes extensive customization options, such as automated\nhyperparameter tuning, benchmarking, explainability, downstream evaluation, and\ncompatibility with popular time series frameworks.",
      "authors": [
        "Quentin Nater",
        "Mourad Khayati",
        "Jacques Pasquier"
      ],
      "categories": [
        "cs.LG",
        "cs.DB"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15250v1",
        "http://arxiv.org/pdf/2503.15250v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15184v1",
      "title": "Role-Selection Game in Block Production under Proposer-Builder\n  Separation",
      "published": "2025-03-19T13:12:58Z",
      "updated": "2025-03-19T13:12:58Z",
      "summary": "To address the risks of validator centralization, the Ethereum community\nintroduced Proposer-Builder Separation (PBS), which divides the roles of block\nbuilding and block proposing to foster a more equitable environment for\nblockchain participants. PBS creates a two-sided market, wherein searchers\nprovide valuable bundles with bids to builders with the demand for their\ninclusion in a block, and builders vie for order flows from searchers to secure\nvictory in the block-building auction. In this work, we propose a novel\nco-evolutionary framework to analyze the behavior of participants in the\naforementioned two-sided market. Leveraging agent-based simulations enables us\nto observe the strategy evolution results of autonomous agents and understand\nhow each profit-seeking actor can benefit from the block-building process under\ndifferent market conditions. We observe that searchers and builders can develop\ndistinct bidding and rebate strategies under varying conditions (conflict\nprobabilities between bundles), with searchers learning to differentiate their\nbids based on the rebates offered by different builders. Through empirical\ngame-theoretic analysis, we compute the dynamic equilibrium solution of agents'\nstrategies under two meta-strategies, which predicts the frequency at which\nagents employ block building and bundle sharing strategies in the two-sided\nmarket. Our analysis reveals that agents achieve a dynamic equilibrium as\nsearchers when the probability of conflict between bundles is low. As this\nconflict probability rises to a certain critical level, the dynamic equilibrium\ntransitions to favor agents becoming builders.",
      "authors": [
        "Yanzhen Li",
        "Zining Wang"
      ],
      "categories": [
        "cs.GT",
        "cs.DC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15184v1",
        "http://arxiv.org/pdf/2503.15184v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.15095v1",
      "title": "Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive\n  Control",
      "published": "2025-03-19T10:48:26Z",
      "updated": "2025-03-19T10:48:26Z",
      "summary": "We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic\nframework for uncertainty-aware prediction and decision-making in partially\nobservable stochastic systems by integrating diffusion-based time series\nforecasting models in Model Predictive Control algorithms. In our approach, a\ndiffusion-based time series forecasting model is used to probabilistically\nestimate the evolution of the system's stochastic components. These forecasts\nare then incorporated into MPC algorithms to estimate future trajectories and\noptimize action selection under the uncertainty of the future. We evaluate the\nframework on the task of energy arbitrage, where a Battery Energy Storage\nSystem participates in the day-ahead electricity market of the New York state.\nExperimental results indicate that our model-based approach with a\ndiffusion-based forecaster significantly outperforms both implementations with\nclassical forecasting methods and model-free reinforcement learning baselines.",
      "authors": [
        "Stelios Zarifis",
        "Ioannis Kordonis",
        "Petros Maragos"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2.6; I.5.1"
      ],
      "links": [
        "http://arxiv.org/abs/2503.15095v1",
        "http://arxiv.org/pdf/2503.15095v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14933v1",
      "title": "A Language Vision Model Approach for Automated Tumor Contouring in\n  Radiation Oncology",
      "published": "2025-03-19T06:41:37Z",
      "updated": "2025-03-19T06:41:37Z",
      "summary": "Background: Lung cancer ranks as the leading cause of cancer-related\nmortality worldwide. The complexity of tumor delineation, crucial for radiation\ntherapy, requires expertise often unavailable in resource-limited settings.\nArtificial Intelligence(AI), particularly with advancements in deep learning\n(DL) and natural language processing (NLP), offers potential solutions yet is\nchallenged by high false positive rates. Purpose: The Oncology Contouring\nCopilot (OCC) system is developed to leverage oncologist expertise for precise\ntumor contouring using textual descriptions, aiming to increase the efficiency\nof oncological workflows by combining the strengths of AI with human oversight.\nMethods: Our OCC system initially identifies nodule candidates from CT scans.\nEmploying Language Vision Models (LVMs) like GPT-4V, OCC then effectively\nreduces false positives with clinical descriptive texts, merging textual and\nvisual data to automate tumor delineation, designed to elevate the quality of\noncology care by incorporating knowledge from experienced domain experts.\nResults: Deployments of the OCC system resulted in a significant reduction in\nthe false discovery rate by 35.0%, a 72.4% decrease in false positives per\nscan, and an F1-score of 0.652 across our dataset for unbiased evaluation.\nConclusions: OCC represents a significant advance in oncology care,\nparticularly through the use of the latest LVMs to improve contouring results\nby (1) streamlining oncology treatment workflows by optimizing tumor\ndelineation, reducing manual processes; (2) offering a scalable and intuitive\nframework to reduce false positives in radiotherapy planning using LVMs; (3)\nintroducing novel medical language vision prompt techniques to minimize LVMs\nhallucinations with ablation study, and (4) conducting a comparative analysis\nof LVMs, highlighting their potential in addressing medical language vision\nchallenges.",
      "authors": [
        "Yi Luo",
        "Hamed Hooshangnejad",
        "Xue Feng",
        "Gaofeng Huang",
        "Xiaojian Chen",
        "Rui Zhang",
        "Quan Chen",
        "Wil Ngwa",
        "Kai Ding"
      ],
      "categories": [
        "eess.IV",
        "cs.CV",
        "physics.med-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14933v1",
        "http://arxiv.org/pdf/2503.14933v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14852v1",
      "title": "UntrustVul: An Automated Approach for Identifying Untrustworthy Alerts\n  in Vulnerability Detection Models",
      "published": "2025-03-19T03:18:45Z",
      "updated": "2025-03-19T03:18:45Z",
      "summary": "Machine learning (ML) has shown promise in detecting vulnerabilities. To\nreview vulnerabilities detected by ML predictions, developers manually assess\nsuspicious lines in their interpretations. However, studies have revealed that\nthese models often learn and predict based on irrelevant features frequently\nappearing in vulnerable code. This leads to predictions that may correctly flag\nvulnerable functions but for the wrong reasons, which we call untrustworthy.\nThese predictions can mislead developers, hindering them from locating the\nvulnerabilities. This increases the efforts of manual assessment and, worse,\nrisks creating flawed patches that fail to address existing vulnerabilities and\neven introduce new ones. Hence, automated approaches are needed to detect\nuntrustworthy predictions, preventing overlooked vulnerabilities and\nalleviating the burden of manual assessment.\n  We propose UntrustVul, the first automated approach to identify untrustworthy\nvulnerability predictions. Given a vulnerability prediction during inference,\nUntrustVul systematically assesses whether suspicious lines annotated by the\nprediction are vulnerability-unrelated. It simulates developers' rationales,\nconsidering a line unrelated if (1) it is absent from historical\nvulnerabilities and (2) it cannot reach any vulnerabilities in execution flows.\nUntrustVul assesses (1) by analysing its syntactic meaning using deep\nrepresentations to determine whether it is syntax-benign. To assess (2),\nUntrustVul traces dependencies of the syntax-benign lines on other suspicious\nlines using static and rule-based analyses. We evaluate UntrustVul on 155K\nvulnerability predictions by four models across three datasets. UntrustVul\neffectively detects untrustworthy predictions with an F1-score of 82%-94% and\nhelps improve the ability of models to detect vulnerabilities by up to 321% in\nF1-score and 100% in trustworthiness.",
      "authors": [
        "Lam Nguyen Tung",
        "Xiaoning Du",
        "Neelofar Neelofar",
        "Aldeida Aleti"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14852v1",
        "http://arxiv.org/pdf/2503.14852v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14838v1",
      "title": "Think Like Human Developers: Harnessing Community Knowledge for\n  Structured Code Reasoning",
      "published": "2025-03-19T02:45:13Z",
      "updated": "2025-03-19T02:45:13Z",
      "summary": "Large Language Models (LLMs) have significantly advanced automated code\ngeneration, yet they struggle with complex coding tasks requiring multi-step\nlogical reasoning. High-quality reasoning data is crucial for improving LLMs'\nreasoning capabilities, but such datasets remain scarce. Existing approaches\neither rely on computationally expensive reinforcement learning (RL) or\nerror-prone reasoning chains synthesized by LLMs, posing challenges in\nscalability and accuracy.\n  To address this challenge, we propose SVRC (Structured and Validated\nReasoning Chains for Code Generation), a novel framework that mines,\nrestructures, and enriches reasoning chains from community-driven discussions\non software engineering platforms. SVRC refines unstructured and incomplete\ndiscussions of coding problems by aligning them with Software Development Life\nCycle (SDLC) principles, ensuring that reasoning chains capture real-world\nproblem-solving strategies and support iterative refinement.\n  To evaluate the effectiveness of SVRC, we introduce CodeThinker, an LLM\nfine-tuned on 12,444 reasoning-augmented samples generated by SVRC. Experiments\non LiveCodeBench show that CodeThinker surpasses its base model by 42.86\\% on\nmedium-level code problems in terms of pass@1 and outperforms GPT-4o-mini and\nGPT-4o by 73.14\\% and 115.86\\%, respectively. Our ablation study further\nhighlights that each component of SVRC contributes to the reasoning\ncapabilities of CodeThinker.",
      "authors": [
        "Chengran Yang",
        "Zhensu Sun",
        "Hong Jin Kang",
        "Jieke Shi",
        "David Lo"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14838v1",
        "http://arxiv.org/pdf/2503.14838v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14829v1",
      "title": "Stochastic Volatility Model with Sticky Drawdown and Drawup Processes: A\n  Deep Learning Approach",
      "published": "2025-03-19T02:09:34Z",
      "updated": "2025-03-19T02:09:34Z",
      "summary": "We propose a new financial model, the stochastic volatility model with sticky\ndrawdown and drawup processes (SVSDU model), which enables us to capture the\nfeatures of winning and losing streaks that are common across financial markets\nbut can not be captured simultaneously by the existing financial models.\nMoreover, the SVSDU model retains the advantages of the stochastic volatility\nmodels. Since there are not closed-form option pricing formulas under the SVSDU\nmodel and the existing simulation methods for the sticky diffusion processes\nare really time-consuming, we develop a deep neural network to solve the\ncorresponding high-dimensional parametric partial differential equation (PDE),\nwhere the solution to the PDE is the pricing function of a European option\naccording to the Feynman-Kac Theorem, and validate the accuracy and efficiency\nof our deep learning approach. We also propose a novel calibration framework\nfor our model, and demonstrate the calibration performances of our models on\nboth simulated data and historical data. The calibration results on SPX option\ndata show that the SVSDU model is a good representation of the asset value\ndynamic, and both winning and losing streaks are accounted for in option\nvalues. Our model opens new horizons for modeling and predicting the dynamics\nof asset prices in financial markets.",
      "authors": [
        "Yuhao Liu",
        "Pingping Jiang",
        "Gongqiu Zhang"
      ],
      "categories": [
        "q-fin.MF",
        "q-fin.PR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14829v1",
        "http://arxiv.org/pdf/2503.14829v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14716v1",
      "title": "Construction Site Scaffolding Completeness Detection Based on Mask R-CNN\n  and Hough Transform",
      "published": "2025-03-18T20:27:22Z",
      "updated": "2025-03-18T20:27:22Z",
      "summary": "Construction site scaffolding is essential for many building projects, and\nensuring its safety is crucial to prevent accidents. The safety inspector must\ncheck the scaffolding's completeness and integrity, where most violations\noccur. The inspection process includes ensuring all the components are in the\nright place since workers often compromise safety for convenience and\ndisassemble parts such as cross braces. This paper proposes a deep\nlearning-based approach to detect the scaffolding and its cross braces using\ncomputer vision. A scaffold image dataset with annotated labels is used to\ntrain a convolutional neural network (CNN) model. With the proposed approach,\nwe can automatically detect the completeness of cross braces from images taken\nat construction sites, without the need for manual inspection, saving a\nsignificant amount of time and labor costs. This non-invasive and efficient\nsolution for detecting scaffolding completeness can help improve safety in\nconstruction sites.",
      "authors": [
        "Pei-Hsin Lin",
        "Jacob J. Lin",
        "Shang-Hsien Hsieh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14716v1",
        "http://arxiv.org/pdf/2503.14716v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14630v1",
      "title": "Assessing Large Language Models for Automated Feedback Generation in\n  Learning Programming Problem Solving",
      "published": "2025-03-18T18:31:36Z",
      "updated": "2025-03-18T18:31:36Z",
      "summary": "Providing effective feedback is important for student learning in programming\nproblem-solving. In this sense, Large Language Models (LLMs) have emerged as\npotential tools to automate feedback generation. However, their reliability and\nability to identify reasoning errors in student code remain not well\nunderstood. This study evaluates the performance of four LLMs (GPT-4o, GPT-4o\nmini, GPT-4-Turbo, and Gemini-1.5-pro) on a benchmark dataset of 45 student\nsolutions. We assessed the models' capacity to provide accurate and insightful\nfeedback, particularly in identifying reasoning mistakes. Our analysis reveals\nthat 63\\% of feedback hints were accurate and complete, while 37\\% contained\nmistakes, including incorrect line identification, flawed explanations, or\nhallucinated issues. These findings highlight the potential and limitations of\nLLMs in programming education and underscore the need for improvements to\nenhance reliability and minimize risks in educational applications.",
      "authors": [
        "Priscylla Silva",
        "Evandro Costa"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14630v1",
        "http://arxiv.org/pdf/2503.14630v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14499v1",
      "title": "Measuring AI Ability to Complete Long Tasks",
      "published": "2025-03-18T17:59:31Z",
      "updated": "2025-03-18T17:59:31Z",
      "summary": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark\nperformance remains unclear. To quantify the capabilities of AI systems in\nterms of human capabilities, we propose a new metric: 50%-task-completion time\nhorizon. This is the time humans typically take to complete tasks that AI\nmodels can complete with 50% success rate. We first timed humans with relevant\ndomain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter\ntasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet\nhave a 50% time horizon of around 50 minutes. Furthermore, frontier AI time\nhorizon has been doubling approximately every seven months since 2019, though\nthe trend may have accelerated in 2024. The increase in AI models' time\nhorizons seems to be primarily driven by greater reliability and ability to\nadapt to mistakes, combined with better logical reasoning and tool use\ncapabilities. We discuss the limitations of our results -- including their\ndegree of external validity -- and the implications of increased autonomy for\ndangerous capabilities. If these results generalize to real-world software\ntasks, extrapolation of this trend predicts that within 5 years, AI systems\nwill be capable of automating many software tasks that currently take humans a\nmonth.",
      "authors": [
        "Thomas Kwa",
        "Ben West",
        "Joel Becker",
        "Amy Deng",
        "Katharyn Garcia",
        "Max Hasin",
        "Sami Jawhar",
        "Megan Kinniment",
        "Nate Rush",
        "Sydney Von Arx",
        "Ryan Bloom",
        "Thomas Broadley",
        "Haoxing Du",
        "Brian Goodrich",
        "Nikola Jurkovic",
        "Luke Harold Miles",
        "Seraphina Nix",
        "Tao Lin",
        "Neev Parikh",
        "David Rein",
        "Lucas Jun Koba Sato",
        "Hjalmar Wijk",
        "Daniel M. Ziegler",
        "Elizabeth Barnes",
        "Lawrence Chan"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14499v1",
        "http://arxiv.org/pdf/2503.14499v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14473v1",
      "title": "EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using\n  Classical Data",
      "published": "2025-03-18T17:48:03Z",
      "updated": "2025-03-18T17:48:03Z",
      "summary": "Amplitude embedding (AE) is essential in quantum machine learning (QML) for\nencoding classical data onto quantum circuits. However, conventional AE methods\nsuffer from deep, variable-length circuits that introduce high output error due\nto extensive gate usage and variable error rates across samples, resulting in\nnoise-driven inconsistencies that degrade model accuracy. We introduce EnQode,\na fast AE technique based on symbolic representation that addresses these\nlimitations by clustering dataset samples and solving for cluster mean states\nthrough a low-depth, machine-specific ansatz. Optimized to reduce physical\ngates and SWAP operations, EnQode ensures all samples face consistent, low\nnoise levels by standardizing circuit depth and composition. With over 90%\nfidelity in data mapping, EnQode enables robust, high-performance QML on noisy\nintermediate-scale quantum (NISQ) devices. Our open-source solution provides a\nscalable and efficient alternative for integrating classical data with quantum\nmodels.",
      "authors": [
        "Jason Han",
        "Nicholas S. DiBrita",
        "Younghyun Cho",
        "Hengrui Luo",
        "Tirthak Patel"
      ],
      "categories": [
        "quant-ph",
        "cs.ET",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14473v1",
        "http://arxiv.org/pdf/2503.14473v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14443v1",
      "title": "EnvBench: A Benchmark for Automated Environment Setup",
      "published": "2025-03-18T17:19:12Z",
      "updated": "2025-03-18T17:19:12Z",
      "summary": "Recent advances in Large Language Models (LLMs) have enabled researchers to\nfocus on practical repository-level tasks in software engineering domain. In\nthis work, we consider a cornerstone task for automating work with software\nrepositories-environment setup, i.e., a task of configuring a\nrepository-specific development environment on a system. Existing studies on\nenvironment setup introduce innovative agentic strategies, but their evaluation\nis often based on small datasets that may not capture the full range of\nconfiguration challenges encountered in practice. To address this gap, we\nintroduce a comprehensive environment setup benchmark EnvBench. It encompasses\n329 Python and 665 JVM-based (Java, Kotlin) repositories, with a focus on\nrepositories that present genuine configuration challenges, excluding projects\nthat can be fully configured by simple deterministic scripts. To enable further\nbenchmark extension and usage for model tuning, we implement two automatic\nmetrics: a static analysis check for missing imports in Python and a\ncompilation check for JVM languages. We demonstrate the applicability of our\nbenchmark by evaluating three environment setup approaches, including a simple\nzero-shot baseline and two agentic workflows, that we test with two powerful\nLLM backbones, GPT-4o and GPT-4o-mini. The best approach manages to\nsuccessfully configure 6.69% repositories for Python and 29.47% repositories\nfor JVM, suggesting that EnvBench remains challenging for current approaches.\nOur benchmark suite is publicly available at\nhttps://github.com/JetBrains-Research/EnvBench. The dataset and experiment\ntrajectories are available at https://jb.gg/envbench.",
      "authors": [
        "Aleksandra Eliseeva",
        "Alexander Kovrigin",
        "Ilia Kholkin",
        "Egor Bogomolov",
        "Yaroslav Zharov"
      ],
      "categories": [
        "cs.LG",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14443v1",
        "http://arxiv.org/pdf/2503.14443v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14434v1",
      "title": "LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as\n  Evolutionary Optimizers",
      "published": "2025-03-18T17:11:24Z",
      "updated": "2025-03-18T17:11:24Z",
      "summary": "Automated feature engineering plays a critical role in improving predictive\nmodel performance for tabular learning tasks. Traditional automated feature\nengineering methods are limited by their reliance on pre-defined\ntransformations within fixed, manually designed search spaces, often neglecting\ndomain knowledge. Recent advances using Large Language Models (LLMs) have\nenabled the integration of domain knowledge into the feature engineering\nprocess. However, existing LLM-based approaches use direct prompting or rely\nsolely on validation scores for feature selection, failing to leverage insights\nfrom prior feature discovery experiments or establish meaningful reasoning\nbetween feature generation and data-driven performance. To address these\nchallenges, we propose LLM-FE, a novel framework that combines evolutionary\nsearch with the domain knowledge and reasoning capabilities of LLMs to\nautomatically discover effective features for tabular learning tasks. LLM-FE\nformulates feature engineering as a program search problem, where LLMs propose\nnew feature transformation programs iteratively, and data-driven feedback\nguides the search process. Our results demonstrate that LLM-FE consistently\noutperforms state-of-the-art baselines, significantly enhancing the performance\nof tabular prediction models across diverse classification and regression\nbenchmarks.",
      "authors": [
        "Nikhil Abhyankar",
        "Parshin Shojaee",
        "Chandan K. Reddy"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14434v1",
        "http://arxiv.org/pdf/2503.14434v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14432v1",
      "title": "PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via\n  Tool Play",
      "published": "2025-03-18T17:09:57Z",
      "updated": "2025-03-18T17:09:57Z",
      "summary": "Large language models (LLMs) are increasingly integrated with specialized\nexternal tools, yet many tasks demand zero-shot tool usage with minimal or\nnoisy documentation. Existing solutions rely on manual rewriting or labeled\ndata for validation, making them inapplicable in true zero-shot settings. To\naddress these challenges, we propose PLAY2PROMPT, an automated framework that\nsystematically \"plays\" with each tool to explore its input-output behaviors.\nThrough this iterative trial-and-error process, PLAY2PROMPT refines tool\ndocumentation and generates usage examples without any labeled data. These\nexamples not only guide LLM inference but also serve as validation to further\nenhance tool utilization. Extensive experiments on real-world tasks demonstrate\nthat PLAY2PROMPT significantly improves zero-shot tool performance across both\nopen and closed models, offering a scalable and effective solution for\ndomain-specific tool integration.",
      "authors": [
        "Wei Fang",
        "Yang Zhang",
        "Kaizhi Qian",
        "James Glass",
        "Yada Zhu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14432v1",
        "http://arxiv.org/pdf/2503.14432v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14575v1",
      "title": "The Exoplanet Citizen Science Pipeline: Human Factors and Machine\n  Learning",
      "published": "2025-03-18T15:54:00Z",
      "updated": "2025-03-18T15:54:00Z",
      "summary": "We present the progress of work to streamline and simplify the process of\nexoplanet observation by citizen scientists. International collaborations such\nas ExoClock and Exoplanet Watch enable citizen scientists to use small\ntelescopes to carry out transit observations. These studies provide essential\nsupports for space missions such as JWST and ARIEL. Contributions include\nmaintenance or recovery of ephemerides, follow up confirmation and transit time\nvariations. Ongoing observation programs benefit from a large pool of\nobservers, with a wide variety of experience levels. Our projects work closely\nwith these communities to streamline their observation pipelines and enable\nwider participation. Two complementary approaches are taken: Star Guide applies\nhuman-centric design and community consultation to identify points of friction\nwithin existing systems and provide complementary online tools and resources to\nreduce barriers to entry to the observing community. Machine Learning is used\nto accelerate data processing and automate steps which are currently manual,\nproviding a streamlined tool for citizen science and a scalable solution for\nlarge-scale archival research.",
      "authors": [
        "Ois\u00edn Creaner",
        "Anna Preis",
        "Cormac Ryan",
        "Nika Gorchakova"
      ],
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14575v1",
        "http://arxiv.org/pdf/2503.14575v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14352v1",
      "title": "Flying in Highly Dynamic Environments with End-to-end Learning Approach",
      "published": "2025-03-18T15:32:07Z",
      "updated": "2025-03-18T15:32:07Z",
      "summary": "Obstacle avoidance for unmanned aerial vehicles like quadrotors is a popular\nresearch topic. Most existing research focuses only on static environments, and\nobstacle avoidance in environments with multiple dynamic obstacles remains\nchallenging. This paper proposes a novel deep-reinforcement learning-based\napproach for the quadrotors to navigate through highly dynamic environments. We\npropose a lidar data encoder to extract obstacle information from the massive\npoint cloud data from the lidar. Multi frames of historical scans will be\ncompressed into a 2-dimension obstacle map while maintaining the obstacle\nfeatures required. An end-to-end deep neural network is trained to extract the\nkinematics of dynamic and static obstacles from the obstacle map, and it will\ngenerate acceleration commands to the quadrotor to control it to avoid these\nobstacles. Our approach contains perception and navigating functions in a\nsingle neural network, which can change from a navigating state into a hovering\nstate without mode switching. We also present simulations and real-world\nexperiments to show the effectiveness of our approach while navigating in\nhighly dynamic cluttered environments.",
      "authors": [
        "Xiyu Fan",
        "Minghao Lu",
        "Bowen Xu",
        "Peng Lu"
      ],
      "categories": [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://dx.doi.org/10.1109/LRA.2025.3547306",
        "http://arxiv.org/abs/2503.14352v1",
        "http://arxiv.org/pdf/2503.14352v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14340v1",
      "title": "MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG\n  and Multi-Agent LLM Collaboration",
      "published": "2025-03-18T15:16:51Z",
      "updated": "2025-03-18T15:16:51Z",
      "summary": "Maintaining and scaling software systems relies heavily on effective code\nrefactoring, yet this process remains labor-intensive, requiring developers to\ncarefully analyze existing codebases and prevent the introduction of new\ndefects. Although recent advancements have leveraged Large Language Models\n(LLMs) to automate refactoring tasks, current solutions are constrained in\nscope and lack mechanisms to guarantee code compilability and successful test\nexecution. In this work, we introduce MANTRA, a comprehensive LLM agent-based\nframework that automates method-level refactoring. MANTRA integrates\nContext-Aware Retrieval-Augmented Generation, coordinated Multi-Agent\nCollaboration, and Verbal Reinforcement Learning to emulate human\ndecision-making during refactoring while preserving code correctness and\nreadability. Our empirical study, conducted on 703 instances of \"pure\nrefactorings\" (i.e., code changes exclusively involving structural\nimprovements), drawn from 10 representative Java projects, covers the six most\nprevalent refactoring operations. Experimental results demonstrate that MANTRA\nsubstantially surpasses a baseline LLM model (RawGPT ), achieving an 82.8%\nsuccess rate (582/703) in producing code that compiles and passes all tests,\ncompared to just 8.7% (61/703) with RawGPT. Moreover, in comparison to\nIntelliJ's LLM-powered refactoring tool (EM-Assist), MANTRA exhibits a 50%\nimprovement in generating Extract Method transformations. A usability study\ninvolving 37 professional developers further shows that refactorings performed\nby MANTRA are perceived to be as readable and reusable as human-written code,\nand in certain cases, even more favorable. These results highlight the\npractical advantages of MANTRA and emphasize the growing potential of LLM-based\nsystems in advancing the automation of software refactoring tasks.",
      "authors": [
        "Yisen Xu",
        "Feng Lin",
        "Jinqiu Yang",
        " Tse-Hsun",
        " Chen",
        "Nikolaos Tsantalis"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14340v1",
        "http://arxiv.org/pdf/2503.14340v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14331v1",
      "title": "ADAPT: An Autonomous Forklift for Construction Site Operation",
      "published": "2025-03-18T15:03:28Z",
      "updated": "2025-03-18T15:03:28Z",
      "summary": "Efficient material logistics play a critical role in controlling costs and\nschedules in the construction industry. However, manual material handling\nremains prone to inefficiencies, delays, and safety risks. Autonomous forklifts\noffer a promising solution to streamline on-site logistics, reducing reliance\non human operators and mitigating labor shortages. This paper presents the\ndevelopment and evaluation of the Autonomous Dynamic All-terrain Pallet\nTransporter (ADAPT), a fully autonomous off-road forklift designed for\nconstruction environments. Unlike structured warehouse settings, construction\nsites pose significant challenges, including dynamic obstacles, unstructured\nterrain, and varying weather conditions. To address these challenges, our\nsystem integrates AI-driven perception techniques with traditional approaches\nfor decision making, planning, and control, enabling reliable operation in\ncomplex environments. We validate the system through extensive real-world\ntesting, comparing its long-term performance against an experienced human\noperator across various weather conditions. We also provide a comprehensive\nanalysis of challenges and key lessons learned, contributing to the advancement\nof autonomous heavy machinery. Our findings demonstrate that autonomous outdoor\nforklifts can operate near human-level performance, offering a viable path\ntoward safer and more efficient construction logistics.",
      "authors": [
        "Johannes Huemer",
        "Markus Murschitz",
        "Matthias Sch\u00f6rghuber",
        "Lukas Reisinger",
        "Thomas Kadiofsky",
        "Christoph Weidinger",
        "Mario Niedermeyer",
        "Benedikt Widy",
        "Marcel Zeilinger",
        "Csaba Beleznai",
        "Tobias Gl\u00fcck",
        "Andreas Kugi",
        "Patrik Zips"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14331v1",
        "http://arxiv.org/pdf/2503.14331v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14273v2",
      "title": "Manual Labelling Artificially Inflates Deep Learning-Based Segmentation\n  Performance on RGB Images of Closed Canopy: Validation Using TLS",
      "published": "2025-03-18T14:09:00Z",
      "updated": "2025-03-19T16:17:19Z",
      "summary": "Monitoring forest dynamics at an individual tree scale is essential for\naccurately assessing ecosystem responses to climate change, yet traditional\nmethods relying on field-based forest inventories are labor-intensive and\nlimited in spatial coverage. Advances in remote sensing using drone-acquired\nRGB imagery combined with deep learning models have promised precise individual\ntree crown (ITC) segmentation; however, existing methods are frequently\nvalidated against human-annotated images, lacking rigorous independent ground\ntruth. In this study, we generate high-fidelity validation labels from\nco-located Terrestrial Laser Scanning (TLS) data for drone imagery of mixed\nunmanaged boreal and Mediterranean forests. We evaluate the performance of two\nwidely used deep learning ITC segmentation models - DeepForest (RetinaNet) and\nDetectree2 (Mask R-CNN) - on these data, and compare to performance on further\nMediterranean forest data labelled manually. When validated against TLS-derived\nground truth from Mediterranean forests, model performance decreased\nsignificantly compared to assessment based on hand-labelled from an\necologically similar site (AP50: 0.094 vs. 0.670). Restricting evaluation to\nonly canopy trees shrank this gap considerably (Canopy AP50: 0.365), although\nperformance was still far lower than on similar hand-labelled data. Models also\nperformed poorly on boreal forest data (AP50: 0.142), although again increasing\nwhen evaluated on canopy trees only (Canopy AP50: 0.308). Both models showed\nvery poor localisation accuracy at stricter IoU thresholds, even when\nrestricted to canopy trees (Max AP75: 0.051). Similar results have been\nobserved in studies using aerial LiDAR data, suggesting fundamental limitations\nin aerial-based segmentation approaches in closed canopy forests.",
      "authors": [
        "Matthew J. Allen",
        "Harry J. F. Owen",
        "Stuart W. D. Grieve",
        "Emily R. Lines"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4; I.4.6; I.4.8; I.4.9; I.5; I.5.4"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14273v2",
        "http://arxiv.org/pdf/2503.14273v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14260v1",
      "title": "Automating Experimental Optics with Sample Efficient Machine Learning\n  Methods",
      "published": "2025-03-18T13:50:44Z",
      "updated": "2025-03-18T13:50:44Z",
      "summary": "As free-space optical systems grow in scale and complexity, troubleshooting\nbecomes increasingly time-consuming and, in the case of remote installations,\nperhaps impractical. An example of a task that is often laborious is the\nalignment of a high-finesse optical resonator, which is highly sensitive to the\nmode of the input beam. In this work, we demonstrate how machine learning can\nbe used to achieve autonomous mode-matching of a free-space optical resonator\nwith minimal supervision. Our approach leverages sample-efficient algorithms to\nreduce data requirements while maintaining a simple architecture for easy\ndeployment. The reinforcement learning scheme that we have developed shows that\nautomation is feasible even in systems prone to drift in experimental\nparameters, as may well be the case in real-world applications.",
      "authors": [
        "Arindam Saha",
        "Baramee Charoensombutamon",
        "Thibault Michel",
        "V. Vijendran",
        "Lachlan Walker",
        "Akira Furusawa",
        "Syed M. Assad",
        "Ben C. Buchler",
        "Ping Koy Lam",
        "Aaron D. Tranter"
      ],
      "categories": [
        "physics.optics",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14260v1",
        "http://arxiv.org/pdf/2503.14260v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14258v1",
      "title": "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal\n  System",
      "published": "2025-03-18T13:48:18Z",
      "updated": "2025-03-18T13:48:18Z",
      "summary": "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https://github.com/oneal2000/JuDGE.",
      "authors": [
        "Weihang Su",
        "Baoqing Yue",
        "Qingyao Ai",
        "Yiran Hu",
        "Jiaqi Li",
        "Changyue Wang",
        "Kaiyuan Zhang",
        "Yueyue Wu",
        "Yiqun Liu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14258v1",
        "http://arxiv.org/pdf/2503.14258v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14231v1",
      "title": "Multi-task Learning for Identification of Porcelain in Song and Yuan\n  Dynasties",
      "published": "2025-03-18T13:09:00Z",
      "updated": "2025-03-18T13:09:00Z",
      "summary": "Chinese porcelain holds immense historical and cultural value, making its\naccurate classification essential for archaeological research and cultural\nheritage preservation. Traditional classification methods rely heavily on\nexpert analysis, which is time-consuming, subjective, and difficult to scale.\nThis paper explores the application of DL and transfer learning techniques to\nautomate the classification of porcelain artifacts across four key attributes:\ndynasty, glaze, ware, and type. We evaluate four Convolutional Neural Networks\n(CNNs) - ResNet50, MobileNetV2, VGG16, and InceptionV3 - comparing their\nperformance with and without pre-trained weights. Our results demonstrate that\ntransfer learning significantly enhances classification accuracy, particularly\nfor complex tasks like type classification, where models trained from scratch\nexhibit lower performance. MobileNetV2 and ResNet50 consistently achieve high\naccuracy and robustness across all tasks, while VGG16 struggles with more\ndiverse classifications. We further discuss the impact of dataset limitations\nand propose future directions, including domain-specific pre-training,\nintegration of attention mechanisms, explainable AI methods, and generalization\nto other cultural artifacts.",
      "authors": [
        "Ziyao Ling",
        "Giovanni Delnevo",
        "Paola Salomoni",
        "Silvia Mirri"
      ],
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14231v1",
        "http://arxiv.org/pdf/2503.14231v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14197v1",
      "title": "Opportunities and Challenges in Unsupervised Learning: The Case of\n  Aqueous Electrolyte Solutions",
      "published": "2025-03-18T12:18:21Z",
      "updated": "2025-03-18T12:18:21Z",
      "summary": "Machine learning has emerged as a powerful tool in atomistic simulations,\nenabling the identification of complex patterns in molecular systems limiting\nhuman intervention and bias. However, the practical implementation of these\nmethods presents significant technical challenges, particularly in the\nselection of hyperparameters and in the physical interpretability of\nmachine-learned descriptors. In this work, we systematically investigate these\nchallenges by applying an unsupervised learning protocol to a fundamental\nproblem in physical chemistry namely, how ions perturb the local structure of\nwater. Using the Smooth Overlap of Atomic Positions(SOAP) descriptors, we\ndemonstrate how the intrinsic dimension (ID) serves as a guide for selecting\nhyperparameters and interpreting structural complexity. Furthermore, we\nconstruct a high-dimensional free energy landscape encompassing all water\nenvironments surrounding different ions. This analysis reveals how the physical\nproperties of ions are intricately reflected in their hydration shells, shaping\nthe landscape through specific connections between different minima. Our\nfindings highlight the difficulty in balancing algorithmic automation with the\nneed of employing both physical and chemical intuition, particularly for the\nconstruction of meaningful descriptors and for the interpretation of final\nresults. By critically assessing the methodological hurdles associated with\nunsupervised learning, we provide a road map for researchers looking to harness\nthese techniques for studying electrolyte and aqueous solutions in general.",
      "authors": [
        "Giulia Sormani",
        "Alex Rodriguez",
        "Ali Hassanali"
      ],
      "categories": [
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14197v1",
        "http://arxiv.org/pdf/2503.14197v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14153v1",
      "title": "Speculative Decoding for Verilog: Speed and Quality, All in One",
      "published": "2025-03-18T11:21:53Z",
      "updated": "2025-03-18T11:21:53Z",
      "summary": "The rapid advancement of large language models (LLMs) has revolutionized code\ngeneration tasks across various programming languages. However, the unique\ncharacteristics of programming languages, particularly those like Verilog with\nspecific syntax and lower representation in training datasets, pose significant\nchallenges for conventional tokenization and decoding approaches. In this\npaper, we introduce a novel application of speculative decoding for Verilog\ncode generation, showing that it can improve both inference speed and output\nquality, effectively achieving speed and quality all in one. Unlike standard\nLLM tokenization schemes, which often fragment meaningful code structures, our\napproach aligns decoding stops with syntactically significant tokens, making it\neasier for models to learn the token distribution. This refinement addresses\ninherent tokenization issues and enhances the model's ability to capture\nVerilog's logical constructs more effectively. Our experimental results show\nthat our method achieves up to a 5.05x speedup in Verilog code generation and\nincreases pass@10 functional accuracy on RTLLM by up to 17.19% compared to\nconventional training strategies. These findings highlight speculative decoding\nas a promising approach to bridge the quality gap in code generation for\nspecialized programming languages.",
      "authors": [
        "Changran Xu",
        "Yi Liu",
        "Yunhao Zhou",
        "Shan Huang",
        "Ningyi Xu",
        "Qiang Xu"
      ],
      "categories": [
        "cs.LG",
        "cs.AR",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14153v1",
        "http://arxiv.org/pdf/2503.14153v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14138v1",
      "title": "Exploring Disparity-Accuracy Trade-offs in Face Recognition Systems: The\n  Role of Datasets, Architectures, and Loss Functions",
      "published": "2025-03-18T11:04:57Z",
      "updated": "2025-03-18T11:04:57Z",
      "summary": "Automated Face Recognition Systems (FRSs), developed using deep learning\nmodels, are deployed worldwide for identity verification and facial attribute\nanalysis. The performance of these models is determined by a complex\ninterdependence among the model architecture, optimization/loss function and\ndatasets. Although FRSs have surpassed human-level accuracy, they continue to\nbe disparate against certain demographics. Due to the ubiquity of applications,\nit is extremely important to understand the impact of the three components --\nmodel architecture, loss function and face image dataset on the\naccuracy-disparity trade-off to design better, unbiased platforms. In this\nwork, we perform an in-depth analysis of three FRSs for the task of gender\nprediction, with various architectural modifications resulting in ten\ndeep-learning models coupled with four loss functions and benchmark them on\nseven face datasets across 266 evaluation configurations. Our results show that\nall three components have an individual as well as a combined impact on both\naccuracy and disparity. We identify that datasets have an inherent property\nthat causes them to perform similarly across models, independent of the choice\nof loss functions. Moreover, the choice of dataset determines the model's\nperceived bias -- the same model reports bias in opposite directions for three\ngender-balanced datasets of ``in-the-wild'' face images of popular individuals.\nStudying the facial embeddings shows that the models are unable to generalize a\nuniform definition of what constitutes a ``female face'' as opposed to a ``male\nface'', due to dataset diversity. We provide recommendations to model\ndevelopers on using our study as a blueprint for model development and\nsubsequent deployment.",
      "authors": [
        "Siddharth D Jaiswal",
        "Sagnik Basu",
        "Sandipan Sikdar",
        "Animesh Mukherjee"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14138v1",
        "http://arxiv.org/pdf/2503.14138v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14023v1",
      "title": "Synthetic Data Generation Using Large Language Models: Advances in Text\n  and Code",
      "published": "2025-03-18T08:34:03Z",
      "updated": "2025-03-18T08:34:03Z",
      "summary": "Large language models (LLMs) have unlocked new possibilities for generating\nsynthetic training data in both natural language and code. By producing\nartificial but task-relevant examples, these models can significantly augment\nor even replace real-world datasets, especially when labeled data is scarce or\nsensitive. This paper surveys recent advances in using LLMs to create synthetic\ntext and code, emphasizing prompt-based generation, retrieval-augmented\npipelines, and iterative self-refinement. We show how these methods enrich\nlow-resource tasks such as classification and question answering, as well as\ncode-centric applications such as instruction tuning, code translation, and bug\nrepair, by enabling automated verification of functional correctness. Alongside\npotential benefits like cost-effectiveness, broad coverage, and controllable\ndiversity, we address challenges such as factual inaccuracies in generated\ntext, lack of stylistic realism, and the risk of bias amplification. Proposed\nmitigations include filtering and weighting outputs and reinforcement learning\nwith execution feedback for code. We conclude with open research directions\nlike automated prompt engineering, cross-modal data synthesis, and robust\nevaluation frameworks, highlighting the importance of LLM-generated synthetic\ndata in advancing AI while emphasizing ethical and quality safeguards.",
      "authors": [
        "Mihai Nadas",
        "Laura Diosan",
        "Andreea Tomescu"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14023v1",
        "http://arxiv.org/pdf/2503.14023v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14002v1",
      "title": "MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific\n  Generative Modeling",
      "published": "2025-03-18T08:09:24Z",
      "updated": "2025-03-18T08:09:24Z",
      "summary": "Generative models have recently made remarkable progress in the field of 3D\nobjects. However, their practical application in fields like engineering\nremains limited since they fail to deliver the accuracy, quality, and\ncontrollability needed for domain-specific tasks. Fine-tuning large generative\nmodels is a promising perspective for making these models available in these\nfields. Creating high-quality, domain-specific 3D datasets is crucial for\nfine-tuning large generative models, yet the data filtering and annotation\nprocess remains a significant bottleneck. We present MeshFleet, a filtered and\nannotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive\npublicly available collection of 3D objects. Our approach proposes a pipeline\nfor automated data filtering based on a quality classifier. This classifier is\ntrained on a manually labeled subset of Objaverse, incorporating DINOv2 and\nSigLIP embeddings, refined through caption-based analysis and uncertainty\nestimation. We demonstrate the efficacy of our filtering method through a\ncomparative analysis against caption and image aesthetic score-based techniques\nand fine-tuning experiments with SV3D, highlighting the importance of targeted\ndata selection for domain-specific 3D generative modeling.",
      "authors": [
        "Damian Boborzi",
        "Phillip Mueller",
        "Jonas Emrich",
        "Dominik Schmid",
        "Sebastian Mueller",
        "Lars Mikelsons"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14002v1",
        "http://arxiv.org/pdf/2503.14002v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13989v1",
      "title": "Rethinking Cell Counting Methods: Decoupling Counting and Localization",
      "published": "2025-03-18T07:50:03Z",
      "updated": "2025-03-18T07:50:03Z",
      "summary": "Cell counting in microscopy images is vital in medicine and biology but\nextremely tedious and time-consuming to perform manually. While automated\nmethods have advanced in recent years, state-of-the-art approaches tend to\nincreasingly complex model designs. In this paper, we propose a conceptually\nsimple yet effective decoupled learning scheme for automated cell counting,\nconsisting of separate counter and localizer networks. In contrast to jointly\nlearning counting and density map estimation, we show that decoupling these\nobjectives surprisingly improves results. The counter operates on intermediate\nfeature maps rather than pixel space to leverage global context and produce\ncount estimates, while also generating coarse density maps. The localizer then\nreconstructs high-resolution density maps that precisely localize individual\ncells, conditional on the original images and coarse density maps from the\ncounter. Besides, to boost counting accuracy, we further introduce a global\nmessage passing module to integrate cross-region patterns. Extensive\nexperiments on four datasets demonstrate that our approach, despite its\nsimplicity, challenges common practice and achieves state-of-the-art\nperformance by significant margins. Our key insight is that decoupled learning\nalleviates the need to learn counting on high-resolution density maps directly,\nallowing the model to focus on global features critical for accurate estimates.\nCode is available at https://github.com/MedAITech/DCL.",
      "authors": [
        "Zixuan Zheng",
        "Yilei Shi",
        "Chunlei Li",
        "Jingliang Hu",
        "Xiao Xiang Zhu",
        "Lichao Mou"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13989v1",
        "http://arxiv.org/pdf/2503.13989v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13987v1",
      "title": "Striving for Simplicity: Simple Yet Effective Prior-Aware\n  Pseudo-Labeling for Semi-Supervised Ultrasound Image Segmentation",
      "published": "2025-03-18T07:44:09Z",
      "updated": "2025-03-18T07:44:09Z",
      "summary": "Medical ultrasound imaging is ubiquitous, but manual analysis struggles to\nkeep pace. Automated segmentation can help but requires large labeled datasets,\nwhich are scarce. Semi-supervised learning leveraging both unlabeled and\nlimited labeled data is a promising approach. State-of-the-art methods use\nconsistency regularization or pseudo-labeling but grow increasingly complex.\nWithout sufficient labels, these models often latch onto artifacts or allow\nanatomically implausible segmentations. In this paper, we present a simple yet\neffective pseudo-labeling method with an adversarially learned shape prior to\nregularize segmentations. Specifically, we devise an encoder-twin-decoder\nnetwork where the shape prior acts as an implicit shape model, penalizing\nanatomically implausible but not ground-truth-deviating predictions. Without\nbells and whistles, our simple approach achieves state-of-the-art performance\non two benchmarks under different partition protocols. We provide a strong\nbaseline for future semi-supervised medical image segmentation. Code is\navailable at https://github.com/WUTCM-Lab/Shape-Prior-Semi-Seg.",
      "authors": [
        "Yaxiong Chen",
        "Yujie Wang",
        "Zixuan Zheng",
        "Jingliang Hu",
        "Yilei Shi",
        "Shengwu Xiong",
        "Xiao Xiang Zhu",
        "Lichao Mou"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13987v1",
        "http://arxiv.org/pdf/2503.13987v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13923v1",
      "title": "ConSCompF: Consistency-focused Similarity Comparison Framework for\n  Generative Large Language Models",
      "published": "2025-03-18T05:38:04Z",
      "updated": "2025-03-18T05:38:04Z",
      "summary": "Large language models (LLMs) have been one of the most important discoveries\nin machine learning in recent years. LLM-based artificial intelligence (AI)\nassistants, such as ChatGPT, have consistently attracted the attention from\nresearchers, investors, and the general public, driving the rapid growth of\nthis industry. With the frequent introduction of new LLMs to the market, it\nbecomes increasingly difficult to differentiate between them, creating a demand\nfor new LLM comparison methods.\n  In this research, the Consistency-focused Similarity Comparison Framework\n(ConSCompF) for generative large language models is proposed. It compares texts\ngenerated by two LLMs and produces a similarity score, indicating the overall\ndegree of similarity between their responses. The main advantage of this\nframework is that it can operate on a small number of unlabeled data, such as\nchatbot instruction prompts, and does not require LLM developers to disclose\nany information about their product.\n  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying\nsimilarities between multiple LLMs are conducted. Additionally, these\nexperiments examine the correlation between the similarity scores generated by\nConSCompF and the differences in the outputs produced by other benchmarking\ntechniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison\nexperiments is conducted to evaluate the performance of ConSCompF in a few-shot\nLLM comparison scenario.\n  The proposed framework can be used for calculating similarity matrices of\nmultiple LLMs, which can be effectively visualized using principal component\nanalysis (PCA). The ConSCompF output may provide useful insights into data that\nmight have been used during LLM training and help detect possible investment\nfraud attempts.",
      "authors": [
        "Alexey Karev",
        "Dong Xu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1613/jair.1.17028",
        "http://arxiv.org/abs/2503.13923v1",
        "http://arxiv.org/pdf/2503.13923v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13896v1",
      "title": "Evaluating Global Geo-alignment for Precision Learned Autonomous Vehicle\n  Localization using Aerial Data",
      "published": "2025-03-18T04:44:43Z",
      "updated": "2025-03-18T04:44:43Z",
      "summary": "Recently there has been growing interest in the use of aerial and satellite\nmap data for autonomous vehicles, primarily due to its potential for\nsignificant cost reduction and enhanced scalability. Despite the advantages,\naerial data also comes with challenges such as a sensor-modality gap and a\nviewpoint difference gap. Learned localization methods have shown promise for\novercoming these challenges to provide precise metric localization for\nautonomous vehicles. Most learned localization methods rely on coarsely aligned\nground truth, or implicit consistency-based methods to learn the localization\ntask -- however, in this paper we find that improving the alignment between\naerial data and autonomous vehicle sensor data at training time is critical to\nthe performance of a learning-based localization system. We compare two data\nalignment methods using a factor graph framework and, using these methods, we\nthen evaluate the effects of closely aligned ground truth on learned\nlocalization accuracy through ablation studies. Finally, we evaluate a learned\nlocalization system using the data alignment methods on a comprehensive\n(1600km) autonomous vehicle dataset and demonstrate localization error below\n0.3m and 0.5$^{\\circ}$ sufficient for autonomous vehicle applications.",
      "authors": [
        "Yi Yang",
        "Xuran Zhao",
        "H. Charles Zhao",
        "Shumin Yuan",
        "Samuel M. Bateman",
        "Tiffany A. Huang",
        "Chris Beall",
        "Will Maddern"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "I.2.9"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13896v1",
        "http://arxiv.org/pdf/2503.13896v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13882v1",
      "title": "MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented\n  Generation for Embodied AI Environments",
      "published": "2025-03-18T04:27:02Z",
      "updated": "2025-03-18T04:27:02Z",
      "summary": "While human cognition inherently retrieves information from diverse and\nspecialized knowledge sources during decision-making processes, current\nRetrieval-Augmented Generation (RAG) systems typically operate through\nsingle-source knowledge retrieval, leading to a cognitive-algorithmic\ndiscrepancy. To bridge this gap, we introduce MoK-RAG, a novel multi-source RAG\nframework that implements a mixture of knowledge paths enhanced retrieval\nmechanism through functional partitioning of a large language model (LLM)\ncorpus into distinct sections, enabling retrieval from multiple specialized\nknowledge paths. Applied to the generation of 3D simulated environments, our\nproposed MoK-RAG3D enhances this paradigm by partitioning 3D assets into\ndistinct sections and organizing them based on a hierarchical knowledge tree\nstructure. Different from previous methods that only use manual evaluation, we\npioneered the introduction of automated evaluation methods for 3D scenes. Both\nautomatic and human evaluations in our experiments demonstrate that MoK-RAG3D\ncan assist Embodied AI agents in generating diverse scenes.",
      "authors": [
        "Zhengsheng Guo",
        "Linwei Zheng",
        "Xinyang Chen",
        "Xuefeng Bai",
        "Kehai Chen",
        "Min Zhang"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13882v1",
        "http://arxiv.org/pdf/2503.13882v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14557v1",
      "title": "Generating Causal Explanations of Vehicular Agent Behavioural\n  Interactions with Learnt Reward Profiles",
      "published": "2025-03-18T01:53:59Z",
      "updated": "2025-03-18T01:53:59Z",
      "summary": "Transparency and explainability are important features that responsible\nautonomous vehicles should possess, particularly when interacting with humans,\nand causal reasoning offers a strong basis to provide these qualities. However,\neven if one assumes agents act to maximise some concept of reward, it is\ndifficult to make accurate causal inferences of agent planning without\ncapturing what is of importance to the agent. Thus our work aims to learn a\nweighting of reward metrics for agents such that explanations for agent\ninteractions can be causally inferred. We validate our approach quantitatively\nand qualitatively across three real-world driving datasets, demonstrating a\nfunctional improvement over previous methods and competitive performance across\nevaluation metrics.",
      "authors": [
        "Rhys Howard",
        "Nick Hawes",
        "Lars Kunze"
      ],
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "I.2.0; I.2.6; I.2.9; I.2.11; I.6.0"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14557v1",
        "http://arxiv.org/pdf/2503.14557v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13817v1",
      "title": "VARP: Reinforcement Learning from Vision-Language Model Feedback with\n  Agent Regularized Preferences",
      "published": "2025-03-18T01:51:27Z",
      "updated": "2025-03-18T01:51:27Z",
      "summary": "Designing reward functions for continuous-control robotics often leads to\nsubtle misalignments or reward hacking, especially in complex tasks.\nPreference-based RL mitigates some of these pitfalls by learning rewards from\ncomparative feedback rather than hand-crafted signals, yet scaling human\nannotations remains challenging. Recent work uses Vision-Language Models (VLMs)\nto automate preference labeling, but a single final-state image generally fails\nto capture the agent's full motion. In this paper, we present a two-part\nsolution that both improves feedback accuracy and better aligns reward learning\nwith the agent's policy. First, we overlay trajectory sketches on final\nobservations to reveal the path taken, allowing VLMs to provide more reliable\npreferences-improving preference accuracy by approximately 15-20% in metaworld\ntasks. Second, we regularize reward learning by incorporating the agent's\nperformance, ensuring that the reward model is optimized based on data\ngenerated by the current policy; this addition boosts episode returns by 20-30%\nin locomotion tasks. Empirical studies on metaworld demonstrate that our method\nachieves, for instance, around 70-80% success rate in all tasks, compared to\nbelow 50% for standard approaches. These results underscore the efficacy of\ncombining richer visual representations with agent-aware reward regularization.",
      "authors": [
        "Anukriti Singh",
        "Amisha Bhaskar",
        "Peihong Yu",
        "Souradip Chakraborty",
        "Ruthwik Dasyam",
        "Amrit Bedi",
        "Pratap Tokekar"
      ],
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13817v1",
        "http://arxiv.org/pdf/2503.13817v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13799v1",
      "title": "SMILE: a Scale-aware Multiple Instance Learning Method for Multicenter\n  STAS Lung Cancer Histopathology Diagnosis",
      "published": "2025-03-18T01:09:52Z",
      "updated": "2025-03-18T01:09:52Z",
      "summary": "Spread through air spaces (STAS) represents a newly identified aggressive\npattern in lung cancer, which is known to be associated with adverse prognostic\nfactors and complex pathological features. Pathologists currently rely on time\nconsuming manual assessments, which are highly subjective and prone to\nvariation. This highlights the urgent need for automated and precise diag\nnostic solutions. 2,970 lung cancer tissue slides are comprised from multiple\ncenters, re-diagnosed them, and constructed and publicly released three lung\ncancer STAS datasets: STAS CSU (hospital), STAS TCGA, and STAS CPTAC. All STAS\ndatasets provide corresponding pathological feature diagnoses and related\nclinical data. To address the bias, sparse and heterogeneous nature of STAS, we\npropose an scale-aware multiple instance learning(SMILE) method for STAS\ndiagnosis of lung cancer. By introducing a scale-adaptive attention mechanism,\nthe SMILE can adaptively adjust high attention instances, reducing\nover-reliance on local regions and promoting consistent detection of STAS\nlesions. Extensive experiments show that SMILE achieved competitive diagnostic\nresults on STAS CSU, diagnosing 251 and 319 STAS samples in CPTAC\nandTCGA,respectively, surpassing clinical average AUC. The 11 open baseline\nresults are the first to be established for STAS research, laying the\nfoundation for the future expansion, interpretability, and clinical integration\nof computational pathology technologies. The datasets and code are available at\nhttps://anonymous.4open.science/r/IJCAI25-1DA1.",
      "authors": [
        "Liangrui Pan",
        "Xiaoyu Li",
        "Yutao Dou",
        "Qiya Song",
        "Jiadi Luo",
        "Qingchun Liang",
        "Shaoliang Peng"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13799v1",
        "http://arxiv.org/pdf/2503.13799v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13778v1",
      "title": "Using 3D reconstruction from image motion to predict total leaf area in\n  dwarf tomato plants",
      "published": "2025-03-17T23:51:19Z",
      "updated": "2025-03-17T23:51:19Z",
      "summary": "Accurate estimation of total leaf area (TLA) is crucial for evaluating plant\ngrowth, photosynthetic activity, and transpiration. However, it remains\nchallenging for bushy plants like dwarf tomatoes due to their complex canopies.\nTraditional methods are often labor-intensive, damaging to plants, or limited\nin capturing canopy complexity. This study evaluated a non-destructive method\ncombining sequential 3D reconstructions from RGB images and machine learning to\nestimate TLA for three dwarf tomato cultivars: Mohamed, Hahms Gelbe Topftomate,\nand Red Robin -- grown under controlled greenhouse conditions. Two experiments\n(spring-summer and autumn-winter) included 73 plants, yielding 418 TLA\nmeasurements via an \"onion\" approach. High-resolution videos were recorded, and\n500 frames per plant were used for 3D reconstruction. Point clouds were\nprocessed using four algorithms (Alpha Shape, Marching Cubes, Poisson's, Ball\nPivoting), and meshes were evaluated with seven regression models:\nMultivariable Linear Regression, Lasso Regression, Ridge Regression, Elastic\nNet Regression, Random Forest, Extreme Gradient Boosting, and Multilayer\nPerceptron. The Alpha Shape reconstruction ($\\alpha = 3$) with Extreme Gradient\nBoosting achieved the best performance ($R^2 = 0.80$, $MAE = 489 cm^2$).\nCross-experiment validation showed robust results ($R^2 = 0.56$, $MAE = 579\ncm^2$). Feature importance analysis identified height, width, and surface area\nas key predictors. This scalable, automated TLA estimation method is suited for\nurban farming and precision agriculture, offering applications in automated\npruning, resource efficiency, and sustainable food production. The approach\ndemonstrated robustness across variable environmental conditions and canopy\nstructures.",
      "authors": [
        "Dmitrii Usenko",
        "David Helman",
        "Chen Giladi"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13778v1",
        "http://arxiv.org/pdf/2503.13778v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13734v1",
      "title": "Mechanical Performance Database for Low-Temperature Alloys",
      "published": "2025-03-17T21:42:09Z",
      "updated": "2025-03-17T21:42:09Z",
      "summary": "Low-temperature alloys are important for a wide spectrum of modern\ntechnologies ranging from liquid hydrogen, and superconductivity to quantum\ntechnology. These applications push the limit of material performance into\nextreme coldness, often demanding a combination of strength and toughness to\naddress various challenges. Steel is one of the most widely used materials in\ncryogenic applications. With the deployment in aerospace liquid hydrogen\nstorage and the transportation industry, aluminum and titanium alloys are also\ngaining increasing attention. Emerging medium-entropy alloys (MEAs) and\nhigh-entropy alloys (HEAs) demonstrate excellent low-temperature mechanical\nperformance with a much-expanded space of material design. A database of\nlow-temperature metallic alloys is collected from the literature and hosted in\nan open repository. The workflow of data collection includes automated\nextraction based on machine learning and natural language processing,\nsupplemented by manual inspection and correction, to enhance data extraction\nefficiency and database quality. The product datasets cover key performance\nparameters including yield strength, tensile strength, elongation at fracture,\nCharpy impact energy, as well as detailed information on materials such as\ntheir types, chemical compositions, processing and testing conditions. Data\nstatistics are analyzed to elucidate the research and development patterns and\nclarify the challenges in both scientific exploration and engineering\ndeployment.",
      "authors": [
        "Haoxuan Tang",
        "Zhiyuan Chen",
        "Xin Yao",
        "Zhiping Xu"
      ],
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13734v1",
        "http://arxiv.org/pdf/2503.13734v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13733v1",
      "title": "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual,\n  Multi-Generator and Multi-Domain Settings",
      "published": "2025-03-17T21:41:37Z",
      "updated": "2025-03-17T21:41:37Z",
      "summary": "Large language models (LLMs) have revolutionized code generation, automating\nprogramming with remarkable efficiency. However, these advancements challenge\nprogramming skills, ethics, and assessment integrity, making the detection of\nLLM-generated code essential for maintaining accountability and standards.\nWhile, there has been some research on this problem, it generally lacks domain\ncoverage and robustness, and only covers a small number of programming\nlanguages. To this end, we propose a framework capable of distinguishing\nbetween human- and LLM-written code across multiple programming languages, code\ngenerators, and domains. We use a large-scale dataset from renowned platforms\nand LLM-based code generators, alongside applying rigorous data quality checks,\nfeature engineering, and comparative analysis using evaluation of traditional\nmachine learning models, pre-trained language models (PLMs), and LLMs for code\ndetection. We perform an evaluation on out-of-domain scenarios, such as\ndetecting the authorship and hybrid authorship of generated code and\ngeneralizing to unseen models, domains, and programming languages. Moreover,\nour extensive experiments show that our framework effectively distinguishes\nhuman- from LLM-written code and sets a new benchmark for this task.",
      "authors": [
        "Daniil Orel",
        "Dilshod Azizov",
        "Preslav Nakov"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13733v1",
        "http://arxiv.org/pdf/2503.13733v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14550v1",
      "title": "Novel AI-Based Quantification of Breast Arterial Calcification to\n  Predict Cardiovascular Risk",
      "published": "2025-03-17T19:38:17Z",
      "updated": "2025-03-17T19:38:17Z",
      "summary": "Women are underdiagnosed and undertreated for cardiovascular disease.\nAutomatic quantification of breast arterial calcification on screening\nmammography can identify women at risk for cardiovascular disease and enable\nearlier treatment and management of disease. In this retrospective study of\n116,135 women from two healthcare systems, a transformer-based neural network\nquantified BAC severity (no BAC, mild, moderate, and severe) on screening\nmammograms. Outcomes included major adverse cardiovascular events (MACE) and\nall-cause mortality. BAC severity was independently associated with MACE after\nadjusting for cardiovascular risk factors, with increasing hazard ratios from\nmild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22)\nacross datasets (all p<0.001). This association remained significant across all\nage groups, with even mild BAC indicating increased risk in women under 50. BAC\nremained an independent predictor when analyzed alongside ASCVD risk scores,\nshowing significant associations with myocardial infarction, stroke, heart\nfailure, and mortality (all p<0.005). Automated BAC quantification enables\nopportunistic cardiovascular risk assessment during routine mammography without\nadditional radiation or cost. This approach provides value beyond traditional\nrisk factors, particularly in younger women, offering potential for early CVD\nrisk stratification in the millions of women undergoing annual mammography.",
      "authors": [
        "Theodorus Dapamede",
        "Aisha Urooj",
        "Vedant Joshi",
        "Gabrielle Gershon",
        "Frank Li",
        "Mohammadreza Chavoshi",
        "Beatrice Brown-Mulry",
        "Rohan Satya Isaac",
        "Aawez Mansuri",
        "Chad Robichaux",
        "Chadi Ayoub",
        "Reza Arsanjani",
        "Laurence Sperling",
        "Judy Gichoya",
        "Marly van Assen",
        "Charles W. ONeill",
        "Imon Banerjee",
        "Hari Trivedi"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14550v1",
        "http://arxiv.org/pdf/2503.14550v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13441v1",
      "title": "Humanoid Policy ~ Human Policy",
      "published": "2025-03-17T17:59:09Z",
      "updated": "2025-03-17T17:59:09Z",
      "summary": "Training manipulation policies for humanoid robots with diverse data enhances\ntheir robustness and generalization across tasks and platforms. However,\nlearning solely from robot demonstrations is labor-intensive, requiring\nexpensive tele-operated data collection which is difficult to scale. This paper\ninvestigates a more scalable data source, egocentric human demonstrations, to\nserve as cross-embodiment training data for robot learning. We mitigate the\nembodiment gap between humanoids and humans from both the data and modeling\nperspectives. We collect an egocentric task-oriented dataset (PH2D) that is\ndirectly aligned with humanoid manipulation demonstrations. We then train a\nhuman-humanoid behavior policy, which we term Human Action Transformer (HAT).\nThe state-action space of HAT is unified for both humans and humanoid robots\nand can be differentiably retargeted to robot actions. Co-trained with\nsmaller-scale robot data, HAT directly models humanoid robots and humans as\ndifferent embodiments without additional supervision. We show that human data\nimproves both generalization and robustness of HAT with significantly better\ndata collection efficiency. Code and data: https://human-as-robot.github.io/",
      "authors": [
        "Ri-Zhao Qiu",
        "Shiqi Yang",
        "Xuxin Cheng",
        "Chaitanya Chawla",
        "Jialong Li",
        "Tairan He",
        "Ge Yan",
        "Lars Paulsen",
        "Ge Yang",
        "Sha Yi",
        "Guanya Shi",
        "Xiaolong Wang"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13441v1",
        "http://arxiv.org/pdf/2503.13441v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13413v3",
      "title": "DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization\n  Framework from a Deep-Learning Perspective",
      "published": "2025-03-17T17:42:51Z",
      "updated": "2025-03-19T14:18:01Z",
      "summary": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, largely driven by well-designed prompts. However, crafting and selecting\nsuch prompts often requires considerable human effort, significantly limiting\nits scalability. To mitigate this, recent studies have explored automated\nprompt optimization as a promising solution. Despite these efforts, existing\nmethods still face critical challenges in robustness, efficiency, and\ngeneralization. To systematically address these challenges, we first conduct an\nempirical analysis to identify the limitations of current reflection-based\nprompt optimization paradigm. Building on these insights, we propose 7\ninnovative approaches inspired by traditional deep learning paradigms for\nprompt optimization (DLPO), seamlessly integrating these concepts into\ntext-based gradient optimization. Through these advancements, we progressively\ntackle the aforementioned challenges and validate our methods through extensive\nexperimentation. We hope our study not only provides valuable guidance for\nfuture research but also offers a comprehensive understanding of the challenges\nand potential solutions in prompt optimization. Our code is available at\nhttps://github.com/sfasfaffa/DLPO.",
      "authors": [
        "Dengyun Peng",
        "Yuhang Zhou",
        "Qiguang Chen",
        "Jinhao Liu",
        "Jingjing Chen",
        "Libo Qin"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13413v3",
        "http://arxiv.org/pdf/2503.13413v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13389v1",
      "title": "Investigating the effect of CPT in lateral spreading prediction using\n  Explainable AI",
      "published": "2025-03-17T17:22:15Z",
      "updated": "2025-03-17T17:22:15Z",
      "summary": "This study proposes an autoencoder approach to extract latent features from\ncone penetration test profiles to evaluate the potential of incorporating CPT\ndata in an AI model. We employ autoencoders to compress 200 CPT profiles of\nsoil behavior type index (Ic) and normalized cone resistance (qc1Ncs) into ten\nlatent features while preserving critical information. We then utilize the\nextracted latent features with site parameters to train XGBoost models for\npredicting lateral spreading occurrences in the 2011 Christchurch earthquake.\nModels using the latent CPT features outperformed models with conventional CPT\nmetrics or no CPT data, achieving over 83% accuracy. Explainable AI revealed\nthe most crucial latent feature corresponding to soil behavior between 1-3\nmeter depths, highlighting this depth range's criticality for liquefaction\nevaluation. The autoencoder approach provides an automated technique for\ncondensing CPT profiles into informative latent features for machine-learning\nliquefaction models.",
      "authors": [
        "Cheng-Hsi Hsiao",
        "Ellen Rathje",
        "Krishna Kumar"
      ],
      "categories": [
        "cs.LG",
        "physics.geo-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13389v1",
        "http://arxiv.org/pdf/2503.13389v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13579v1",
      "title": "ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative\n  Prior",
      "published": "2025-03-17T15:59:02Z",
      "updated": "2025-03-17T15:59:02Z",
      "summary": "Despite the growing accessibility of skeletal motion data, integrating it for\nanimating character meshes remains challenging due to diverse configurations of\nboth skeletons and meshes. Specifically, the body scale and bone lengths of the\nskeleton should be adjusted in accordance with the size and proportions of the\nmesh, ensuring that all joints are accurately positioned within the character\nmesh. Furthermore, defining skinning weights is complicated by variations in\nskeletal configurations, such as the number of joints and their hierarchy, as\nwell as differences in mesh configurations, including their connectivity and\nshapes. While existing approaches have made efforts to automate this process,\nthey hardly address the variations in both skeletal and mesh configurations. In\nthis paper, we present a novel method for the automatic rigging and skinning of\ncharacter meshes using skeletal motion data, accommodating arbitrary\nconfigurations of both meshes and skeletons. The proposed method predicts the\noptimal skeleton aligned with the size and proportion of the mesh as well as\ndefines skinning weights for various mesh-skeleton configurations, without\nrequiring explicit supervision tailored to each of them. By incorporating\nDiffusion 3D Features (Diff3F) as semantic descriptors of character meshes, our\nmethod achieves robust generalization across different configurations. To\nassess the performance of our method in comparison to existing approaches, we\nconducted comprehensive evaluations encompassing both quantitative and\nqualitative analyses, specifically examining the predicted skeletons, skinning\nweights, and deformation quality.",
      "authors": [
        "Seokhyeon Hong",
        "Soojin Choi",
        "Chaelin Kim",
        "Sihun Cha",
        "Junyong Noh"
      ],
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13579v1",
        "http://arxiv.org/pdf/2503.13579v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13578v1",
      "title": "Convolutional neural network for early detection of lameness and\n  irregularity in horses using an IMU sensor",
      "published": "2025-03-17T15:05:01Z",
      "updated": "2025-03-17T15:05:01Z",
      "summary": "Lameness and gait irregularities are significant concerns in equine health\nmanagement, affecting performance, welfare, and economic value. Traditional\nobservational methods rely on subjective expert assessments, which can lead to\ninconsistencies in detecting subtle or early-stage lameness. While AI-based\napproaches have emerged, many require multiple sensors, force plates, or video\nsystems, making them costly and impractical for field deployment. In this\napplied research study, we present a stride-level classification system that\nutilizes a single inertial measurement unit (IMU) and a one-dimensional\nconvolutional neural network (1D CNN) to objectively differentiate between\nsound and lame horses, with a primary focus on the trot gait. The proposed\nsystem was tested under real-world conditions, achieving a 90% session-level\naccuracy with no false positives, demonstrating its robustness for practical\napplications. By employing a single, non-intrusive, and readily available\nsensor, our approach significantly reduces the complexity and cost of hardware\nrequirements while maintaining high classification performance. These results\nhighlight the potential of our CNN-based method as a field-tested, scalable\nsolution for automated lameness detection. By enabling early diagnosis, this\nsystem offers a valuable tool for preventing minor gait irregularities from\ndeveloping into severe conditions, ultimately contributing to improved equine\nwelfare and performance in veterinary and equestrian practice.",
      "authors": [
        "Beno\u00eet Savoini",
        "Jonathan Bertolaccini",
        "St\u00e9phane Montavon",
        "Michel Deriaz"
      ],
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13578v1",
        "http://arxiv.org/pdf/2503.13578v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13231v1",
      "title": "Synthetic Spectroscopy for White Dwarf Classification: Addressing Label\n  Uncertainty and Class Imbalance",
      "published": "2025-03-17T14:42:49Z",
      "updated": "2025-03-17T14:42:49Z",
      "summary": "With the imminent data releases from next-generation spectroscopic surveys,\nhundreds of thousands of white dwarf spectra are expected to become available\nwithin the next few years, increasing the data volume by an order of magnitude.\nThis surge in data has created a pressing need for automated tools to\nefficiently analyze and classify these spectra. Although machine learning\nalgorithms have recently been applied to classify large spectroscopic datasets,\nthey remain constrained by the limited availability of training data. The Sloan\nDigital Sky Survey (SDSS) serves as the current standard training set, as it\nprovides the largest collection of labeled spectra; however, it faces\nchallenges related to severe class imbalance and uncertain label consistency\nacross different surveys. In this work, we address these limitations by\ntraining histogram gradient-boosted classifiers on a synthetic SDSS dataset to\nidentify six ubiquitous chemical signatures in the atmosphere of white dwarfs,\nand test them on 14,246 objects with SNR$>$10 SDSS spectroscopy. We show our\napproach not only surpasses human expert performance, but also enables subtype\nclassification and effectively resolves label transferability issues. The\nmethodology developed here is adaptable to any spectroscopic survey, providing\na critical tool for the astronomical community.",
      "authors": [
        "Olivier Vincent",
        "Pierre Bergeron",
        "Patrick Dufour"
      ],
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.IM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13231v1",
        "http://arxiv.org/pdf/2503.13231v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14538v1",
      "title": "Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal\n  Approach Combining Imaging and Clinical Data",
      "published": "2025-03-17T14:08:35Z",
      "updated": "2025-03-17T14:08:35Z",
      "summary": "Background: This study introduces a Vision-Language Model (VLM) leveraging\nSIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB)\nscreening. By integrating chest X-ray images and clinical notes, the model aims\nto enhance diagnostic accuracy and efficiency, particularly in resource-limited\nsettings.\n  Methods: The VLM combines visual data from chest X-rays with clinical context\nto generate detailed, context-aware diagnostic reports. The architecture\nemploys SIGLIP for visual encoding and Gemma-3b for decoding, ensuring\neffective representation of acute TB-specific pathologies and clinical\ninsights.\n  Results: Key acute TB pathologies, including consolidation, cavities, and\nnodules, were detected with high precision (97percent) and recall (96percent).\nThe model demonstrated strong spatial localization capabilities and robustness\nin distinguishing TB-positive cases, making it a reliable tool for acute TB\ndiagnosis.\n  Conclusion: The multimodal capability of the VLM reduces reliance on\nradiologists, providing a scalable solution for acute TB screening. Future work\nwill focus on improving the detection of subtle pathologies and addressing\ndataset biases to enhance its generalizability and application in diverse\nglobal healthcare settings.",
      "authors": [
        "Ananya Ganapthy",
        "Praveen Shastry",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Varshinipriya M",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 68T45, 92C55, 92C50, 68U10"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14538v1",
        "http://arxiv.org/pdf/2503.14538v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13171v1",
      "title": "HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of\n  Imitation Learning",
      "published": "2025-03-17T13:49:43Z",
      "updated": "2025-03-17T13:49:43Z",
      "summary": "The acquisition of large-scale and diverse demonstration data are essential\nfor improving robotic imitation learning generalization. However, generating\nsuch data for complex manipulations is challenging in real-world settings. We\nintroduce HybridGen, an automated framework that integrates Vision-Language\nModel (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first,\nVLM to parse expert demonstrations, decomposing tasks into expert-dependent\n(object-centric pose transformations for precise control) and plannable\nsegments (synthesizing diverse trajectories via path planning); second, pose\ntransformations substantially expand the first-stage data. Crucially, HybridGen\ngenerates a large volume of training data without requiring specific data\nformats, making it broadly applicable to a wide range of imitation learning\nalgorithms, a characteristic which we also demonstrate empirically across\nmultiple algorithms. Evaluations across seven tasks and their variants\ndemonstrate that agents trained with HybridGen achieve substantial performance\nand generalization gains, averaging a 5% improvement over state-of-the-art\nmethods. Notably, in the most challenging task variants, HybridGen achieves\nsignificant improvement, reaching a 59.7% average success rate, significantly\noutperforming Mimicgen's 49.5%. These results demonstrating its effectiveness\nand practicality.",
      "authors": [
        "Wensheng Wang",
        "Ning Tan"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13171v1",
        "http://arxiv.org/pdf/2503.13171v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14536v1",
      "title": "Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models:\n  A Multi modal Framework for Precision Analysis",
      "published": "2025-03-17T13:49:29Z",
      "updated": "2025-03-17T13:49:29Z",
      "summary": "Background This study proposes a Vision-Language Model (VLM) leveraging the\nSIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic\ntuberculosis (TB) screening. By integrating chest X-ray images with clinical\ndata, the model addresses the challenges of manual interpretation, improving\ndiagnostic consistency and accessibility, particularly in resource-constrained\nsettings.\n  Methods The VLM architecture combines a Vision Transformer (ViT) for visual\nencoding and a transformer-based text encoder to process clinical context, such\nas patient histories and treatment records. Cross-modal attention mechanisms\nalign radiographic features with textual information, while the Gemma-3b\ndecoder generates comprehensive diagnostic reports. The model was pre-trained\non 5 million paired medical images and texts and fine-tuned using 100,000\nchronic TB-specific chest X-rays.\n  Results The model demonstrated high precision (94 percent) and recall (94\npercent) for detecting key chronic TB pathologies, including fibrosis,\ncalcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores\nexceeded 0.93, and Intersection over Union (IoU) values were above 0.91,\nvalidating its effectiveness in detecting and localizing TB-related\nabnormalities.\n  Conclusion The VLM offers a robust and scalable solution for automated\nchronic TB diagnosis, integrating radiographic and clinical data to deliver\nactionable and context-aware insights. Future work will address subtle\npathologies and dataset biases to enhance the model's generalizability,\nensuring equitable performance across diverse populations and healthcare\nsettings.",
      "authors": [
        "Praveen Shastry",
        "Sowmya Chowdary Muthulur",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam",
        "Revathi Ezhumalai",
        "Abitha Marimuthu"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 92C55, 68U10, 92C50, 60G35"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14536v1",
        "http://arxiv.org/pdf/2503.14536v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13127v1",
      "title": "An Online Integrated Development Environment for Automated Programming\n  Assessment Systems",
      "published": "2025-03-17T12:50:51Z",
      "updated": "2025-03-17T12:50:51Z",
      "summary": "The increasing demand for programmers has led to a surge in participants in\nprogramming courses, making it increasingly challenging for instructors to\nassess student code manually. As a result, automated programming assessment\nsystems (APASs) have been developed to streamline this process. These APASs\nsupport lecturers by managing and evaluating student programming exercises at\nscale. However, these tools often do not provide feature-rich online editors\ncompared to their traditional integrated development environments (IDEs)\ncounterparts. This absence of key features, such as syntax highlighting and\nautocompletion, can negatively impact the learning experience, as these tools\nare crucial for effective coding practice. To address this gap, this research\ncontributes to the field of programming education by extracting and defining\nrequirements for an online IDE in an educational context and presenting a\nprototypical implementation of an open-source solution for a scalable and\nsecure online IDE. The usability of the new online IDE was assessed using the\nTechnology Acceptance Model (TAM), gathering feedback from 27 first-year\nstudents through a structured survey. In addition to these qualitative\ninsights, quantitative measures such as memory (RAM) usage were evaluated to\ndetermine the efficiency and scalability of the tool under varying usage\nconditions.",
      "authors": [
        "Eduard Frankford",
        "Daniel Crazzolara",
        "Michael Vierhauser",
        "Niklas Meissner",
        "Stephan Krusche",
        "Ruth Breu"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13127v1",
        "http://arxiv.org/pdf/2503.13127v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13119v1",
      "title": "OSLO-IC: On-the-Sphere Learned Omnidirectional Image Compression with\n  Attention Modules and Spatial Context",
      "published": "2025-03-17T12:46:14Z",
      "updated": "2025-03-17T12:46:14Z",
      "summary": "Developing effective 360-degree (spherical) image compression techniques is\ncrucial for technologies like virtual reality and automated driving. This paper\nadvances the state-of-the-art in on-the-sphere learning (OSLO) for\nomnidirectional image compression framework by proposing spherical attention\nmodules, residual blocks, and a spatial autoregressive context model. These\nimprovements achieve a 23.1% bit rate reduction in terms of WS-PSNR BD rate.\nAdditionally, we introduce a spherical transposed convolution operator for\nupsampling, which reduces trainable parameters by a factor of four compared to\nthe pixel shuffling used in the OSLO framework, while maintaining similar\ncompression performance. Therefore, in total, our proposed method offers\nsignificant rate savings with a smaller architecture and can be applied to any\nspherical convolutional application.",
      "authors": [
        "Paul Wawerek-L\u00f3pez",
        "Navid Mahmoudian Bidgoli",
        "Pascal Frossard",
        "Andr\u00e9 Kaup",
        "Thomas Maugey"
      ],
      "categories": [
        "eess.IV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13119v1",
        "http://arxiv.org/pdf/2503.13119v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13090v1",
      "title": "Multi-Platform Teach-and-Repeat Navigation by Visual Place Recognition\n  Based on Deep-Learned Local Features",
      "published": "2025-03-17T11:57:41Z",
      "updated": "2025-03-17T11:57:41Z",
      "summary": "Uniform and variable environments still remain a challenge for stable visual\nlocalization and mapping in mobile robot navigation. One of the possible\napproaches suitable for such environments is appearance-based teach-and-repeat\nnavigation, relying on simplified localization and reactive robot motion\ncontrol - all without a need for standard mapping. This work brings an\ninnovative solution to such a system based on visual place recognition\ntechniques. Here, the major contributions stand in the employment of a new\nvisual place recognition technique, a novel horizontal shift computation\napproach, and a multi-platform system design for applications across various\ntypes of mobile robots. Secondly, a new public dataset for experimental testing\nof appearance-based navigation methods is introduced. Moreover, the work also\nprovides real-world experimental testing and performance comparison of the\nintroduced navigation system against other state-of-the-art methods. The\nresults confirm that the new system outperforms existing methods in several\ntesting scenarios, is capable of operation indoors and outdoors, and exhibits\nrobustness to day and night scene variations.",
      "authors": [
        "V\u00e1clav Truhla\u0159\u00edk",
        "Tom\u00e1\u0161 Pivo\u0148ka",
        "Michal Kasarda",
        "Libor P\u0159eu\u010dil"
      ],
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13090v1",
        "http://arxiv.org/pdf/2503.13090v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13056v1",
      "title": "Deep Hedging of Green PPAs in Electricity Markets",
      "published": "2025-03-17T11:02:23Z",
      "updated": "2025-03-17T11:02:23Z",
      "summary": "In power markets, Green Power Purchase Agreements have become an important\ncontractual tool of the energy transition from fossil fuels to renewable\nsources such as wind or solar radiation. Trading Green PPAs exposes agents to\nprice risks and weather risks. Also, developed electricity markets feature the\nso-called cannibalisation effect : large infeeds induce low prices and vice\nversa. As weather is a non-tradable entity the question arises how to hedge and\nrisk-manage in this highly incom-plete setting. We propose a ''deep hedging''\nframework utilising machine learning methods to construct hedging strategies.\nThe resulting strategies outperform static and dynamic benchmark strategies\nwith respect to different risk measures.",
      "authors": [
        "Richard Biegler-K\u00f6nig",
        "Daniel Oeltz"
      ],
      "categories": [
        "q-fin.CP",
        "cs.LG",
        "q-fin.RM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13056v1",
        "http://arxiv.org/pdf/2503.13056v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13031v1",
      "title": "Halving transcription time: A fast, user-friendly and GDPR-compliant\n  workflow to create AI-assisted transcripts for content analysis",
      "published": "2025-03-17T10:33:39Z",
      "updated": "2025-03-17T10:33:39Z",
      "summary": "In qualitative research, data transcription is often labor-intensive and\ntime-consuming. To expedite this process, a workflow utilizing artificial\nintelligence (AI) was developed. This workflow not only enhances transcription\nspeed but also addresses the issue of AI-generated transcripts often lacking\ncompatibility with standard content analysis software. Within this workflow,\nautomatic speech recognition is employed to create initial transcripts from\naudio recordings, which are then formatted to be compatible with content\nanalysis software such as ATLAS.ti or MAXQDA. Empirical data from a study of 12\ninterviews suggests that this workflow can reduce transcription time by up to\n46.2%. Furthermore, by using widely used standard software, this process is\nsuitable for both students and researchers while also being adaptable to a\nvariety of learning, teaching, and research environments. It is also\nparticularly beneficial for non-native speakers. In addition, the workflow is\nGDPR-compliant and facilitates local, offline transcript generation, which is\ncrucial when dealing with sensitive data.",
      "authors": [
        "Jakob Sponholz",
        "Andreas Weilinghoff",
        "Juliane Schopf"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13031v1",
        "http://arxiv.org/pdf/2503.13031v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12994v1",
      "title": "Conversation-Based Multimodal Abuse Detection Through Text and Graph\n  Embeddings",
      "published": "2025-03-17T09:51:17Z",
      "updated": "2025-03-17T09:51:17Z",
      "summary": "Abusive behavior is common on online social networks, and forces the hosts of\nsuch platforms to find new solutions to address this problem. Various methods\nhave been proposed to automate this task in the past decade. Most of them rely\non the exchanged content, but ignore the structure and dynamics of the\nconversation, which could provide some relevant information. In this article,\nwe propose to use representation learning methods to automatically produce\nembeddings of this textual content and of the conversational graphs depicting\nmessage exchanges. While the latter could be enhanced by including additional\ninformation on top of the raw conversational structure, no method currently\nexists to learn wholegraph representations using simultaneously edge\ndirections, weights, signs, and vertex attributes. We propose two such methods\nto fill this gap in the literature. We experiment with 5 textual and 13 graph\nembedding methods, and apply them to a dataset of online messages annotated for\nabuse detection. Our best results achieve an F -measure of 81.02 using text\nalone and 80.61 using graphs alone. We also combine both modalities of\ninformation (text and graphs) through three fusion strategies, and show that\nthis strongly improves abuse detection performance, increasing the F -measure\nto 87.06. Finally, we identify which specific engineered features are captured\nby the embedding methods under consideration. These features have clear\ninterpretations and help explain what information the representation learning\nmethods deem discriminative.",
      "authors": [
        "No\u00e9 Cecillon",
        "Vincent Labatut",
        "Richard Dufour"
      ],
      "categories": [
        "cs.SI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12994v1",
        "http://arxiv.org/pdf/2503.12994v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12989v1",
      "title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation\n  Classification Using Large Language Models",
      "published": "2025-03-17T09:44:50Z",
      "updated": "2025-03-17T09:44:50Z",
      "summary": "Automatically annotating job data with standardized occupations from\ntaxonomies, known as occupation classification, is crucial for labor market\nanalysis. However, this task is often hindered by data scarcity and the\nchallenges of manual annotations. While large language models (LLMs) hold\npromise due to their extensive world knowledge and in-context learning\ncapabilities, their effectiveness depends on their knowledge of occupational\ntaxonomies, which remains unclear. In this study, we assess the ability of LLMs\nto generate precise taxonomic entities from taxonomy, highlighting their\nlimitations. To address these challenges, we propose a multi-stage framework\nconsisting of inference, retrieval, and reranking stages, which integrates\ntaxonomy-guided reasoning examples to enhance performance by aligning outputs\nwith taxonomic knowledge. Evaluations on a large-scale dataset show significant\nimprovements in classification accuracy. Furthermore, we demonstrate the\nframework's adaptability for multi-label skill classification. Our results\nindicate that the framework outperforms existing LLM-based methods, offering a\npractical and scalable solution for occupation classification and related tasks\nacross LLMs.",
      "authors": [
        "Palakorn Achananuparp",
        "Ee-Peng Lim"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12989v1",
        "http://arxiv.org/pdf/2503.12989v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12978v1",
      "title": "Enhancing Job Salary Prediction with Disentangled Composition Effect\n  Modeling: A Neural Prototyping Approach",
      "published": "2025-03-17T09:36:07Z",
      "updated": "2025-03-17T09:36:07Z",
      "summary": "In the era of the knowledge economy, understanding how job skills influence\nsalary is crucial for promoting recruitment with competitive salary systems and\naligned salary expectations. Despite efforts on salary prediction based on job\npositions and talent demographics, there still lacks methods to effectively\ndiscern the set-structured skills' intricate composition effect on job salary.\nWhile recent advances in neural networks have significantly improved accurate\nset-based quantitative modeling, their lack of explainability hinders obtaining\ninsights into the skills' composition effects. Indeed, model explanation for\nset data is challenging due to the combinatorial nature, rich semantics, and\nunique format. To this end, in this paper, we propose a novel intrinsically\nexplainable set-based neural prototyping approach, namely \\textbf{LGDESetNet},\nfor explainable salary prediction that can reveal disentangled skill sets that\nimpact salary from both local and global perspectives. Specifically, we propose\na skill graph-enhanced disentangled discrete subset selection layer to identify\nmulti-faceted influential input subsets with varied semantics. Furthermore, we\npropose a set-oriented prototype learning method to extract globally\ninfluential prototypical sets. The resulting output is transparently derived\nfrom the semantic interplay between these input subsets and global prototypes.\nExtensive experiments on four real-world datasets demonstrate that our method\nachieves superior performance than state-of-the-art baselines in salary\nprediction while providing explainable insights into salary-influencing\npatterns.",
      "authors": [
        "Yang Ji",
        "Ying Sun",
        "Hengshu Zhu"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12978v1",
        "http://arxiv.org/pdf/2503.12978v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12873v1",
      "title": "SeeAction: Towards Reverse Engineering How-What-Where of HCI Actions\n  from Screencasts for UI Automation",
      "published": "2025-03-17T07:07:38Z",
      "updated": "2025-03-17T07:07:38Z",
      "summary": "UI automation is a useful technique for UI testing, bug reproduction, and\nrobotic process automation. Recording user actions with an application assists\nrapid development of UI automation scripts, but existing recording techniques\nare intrusive, rely on OS or GUI framework accessibility support, or assume\nspecific app implementations. Reverse engineering user actions from screencasts\nis non-intrusive, but a key reverse-engineering step is currently missing -\nrecognizing human-understandable structured user actions ([command] [widget]\n[location]) from action screencasts. To fill the gap, we propose a deep\nlearning-based computer vision model that can recognize 11 commands and 11\nwidgets, and generate location phrases from action screencasts, through joint\nlearning and multi-task learning. We label a large dataset with 7260\nvideo-action pairs, which record user interactions with Word, Zoom, Firefox,\nPhotoshop, and Windows 10 Settings. Through extensive experiments, we confirm\nthe effectiveness and generality of our model, and demonstrate the usefulness\nof a screencast-to-action-script tool built upon our model for bug\nreproduction.",
      "authors": [
        "Dehai Zhao",
        "Zhenchang Xing",
        "Qinghua Lu",
        "Xiwei Xu",
        "Liming Zhu"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12873v1",
        "http://arxiv.org/pdf/2503.12873v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12852v1",
      "title": "ACT360: An Efficient 360-Degree Action Detection and Summarization\n  Framework for Mission-Critical Training and Debriefing",
      "published": "2025-03-17T06:12:36Z",
      "updated": "2025-03-17T06:12:36Z",
      "summary": "Effective training and debriefing are critical in high-stakes,\nmission-critical environments such as disaster response, military simulations,\nand industrial safety, where precision and minimizing errors are paramount. The\ntraditional post-training analysis relies on manually reviewing 2D videos, a\ntime-consuming process that lacks comprehensive situational awareness. To\naddress these limitations, we introduce ACT360, a system that leverages\n360-degree videos and machine learning for automated action detection and\nstructured debriefing. ACT360 integrates 360YOWO, an enhanced You Only Watch\nOnce (YOWO) model with spatial attention and equirectangular-aware convolution\n(EAC) to mitigate panoramic video distortions. To enable deployment in\nresource-constrained environments, we apply quantization and model pruning,\nreducing the model size by 74% while maintaining robust accuracy (mAP drop of\nonly 1.5%, from 0.865 to 0.850) and improving inference speed. We validate our\napproach on a publicly available dataset of 55 labeled 360-degree videos\ncovering seven key operational actions, recorded across various real-world\ntraining sessions and environmental conditions. Additionally, ACT360 integrates\n360AIE (Action Insight Explorer), a web-based interface for automatic action\ndetection, retrieval, and textual summarization using large language models\n(LLMs), significantly enhancing post-incident analysis efficiency. ACT360\nserves as a generalized framework for mission-critical debriefing,\nincorporating EAC, spatial attention, summarization, and model optimization.\nThese innovations apply to any training environment requiring lightweight\naction detection and structured post-exercise analysis.",
      "authors": [
        "Aditi Tiwari",
        "Klara Nahrstedt"
      ],
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12852v1",
        "http://arxiv.org/pdf/2503.12852v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12797v2",
      "title": "DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs\n  for Knowledge-Intensive Visual Grounding",
      "published": "2025-03-17T04:06:34Z",
      "updated": "2025-03-18T05:06:22Z",
      "summary": "Human experts excel at fine-grained visual discrimination by leveraging\ndomain knowledge to refine perceptual features, a capability that remains\nunderdeveloped in current Multimodal Large Language Models (MLLMs). Despite\npossessing vast expert-level knowledge, MLLMs struggle to integrate reasoning\ninto visual perception, often generating direct responses without deeper\nanalysis. To bridge this gap, we introduce knowledge-intensive visual grounding\n(KVG), a novel visual grounding task that requires both fine-grained perception\nand domain-specific knowledge integration. To address the challenges of KVG, we\npropose DeepPerception, an MLLM enhanced with cognitive visual perception\ncapabilities. Our approach consists of (1) an automated data synthesis pipeline\nthat generates high-quality, knowledge-aligned training samples, and (2) a\ntwo-stage training framework combining supervised fine-tuning for cognitive\nreasoning scaffolding and reinforcement learning to optimize\nperception-cognition synergy. To benchmark performance, we introduce KVG-Bench\na comprehensive dataset spanning 10 domains with 1.3K manually curated test\ncases. Experimental results demonstrate that DeepPerception significantly\noutperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on\nKVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over\nbaseline approaches. Our findings highlight the importance of integrating\ncognitive processes into MLLMs for human-like visual perception and open new\ndirections for multimodal reasoning research. The data, codes, and models are\nreleased at https://github.com/thunlp/DeepPerception.",
      "authors": [
        "Xinyu Ma",
        "Ziyang Ding",
        "Zhicong Luo",
        "Chi Chen",
        "Zonghao Guo",
        "Derek F. Wong",
        "Xiaoyi Feng",
        "Maosong Sun"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12797v2",
        "http://arxiv.org/pdf/2503.12797v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12679v1",
      "title": "Discovering uncertainty: Gaussian constitutive neural networks with\n  correlated weights",
      "published": "2025-03-16T22:34:16Z",
      "updated": "2025-03-16T22:34:16Z",
      "summary": "When characterizing materials, it can be important to not only predict their\nmechanical properties, but also to estimate the probability distribution of\nthese properties across a set of samples. Constitutive neural networks allow\nfor the automated discovery of constitutive models that exactly satisfy\nphysical laws given experimental testing data, but are only capable of\npredicting the mean stress response. Stochastic methods treat each weight as a\nrandom variable and are capable of learning their probability distributions.\nBayesian constitutive neural networks combine both methods, but their weights\nlack physical interpretability and we must sample each weight from a\nprobability distribution to train or evaluate the model. Here we introduce a\nmore interpretable network with fewer parameters, simpler training, and the\npotential to discover correlated weights: Gaussian constitutive neural\nnetworks. We demonstrate the performance of our new Gaussian network on biaxial\ntesting data, and discover a sparse and interpretable four-term model with\ncorrelated weights. Importantly, the discovered distributions of material\nparameters across a set of samples can serve as priors to discover better\nconstitutive models for new samples with limited data. We anticipate that\nGaussian constitutive neural networks are a natural first step towards\ngenerative constitutive models informed by physical laws and parameter\nuncertainty.",
      "authors": [
        "Jeremy A. McCulloch",
        "Ellen Kuhl"
      ],
      "categories": [
        "cs.CE",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12679v1",
        "http://arxiv.org/pdf/2503.12679v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12667v1",
      "title": "Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility",
      "published": "2025-03-16T21:55:17Z",
      "updated": "2025-03-16T21:55:17Z",
      "summary": "Despite advances in language modelling, distributional methods that build\nsemantic representations from co-occurrences fail to discriminate between\nplausible and implausible events. In this work, we investigate how plausibility\nprediction can be improved by injecting latent knowledge prompted from large\nlanguage models using parameter-efficient fine-tuning. We train 12 task\nadapters to learn various physical properties and association measures and\nperform adapter fusion to compose latent semantic knowledge from each task on\ntop of pre-trained AlBERT embeddings. We automate auxiliary task data\ngeneration, which enables us to scale our approach and fine-tune our learned\nrepresentations across two plausibility datasets. Our code is available at\nhttps://github.com/Jacob-Chmura/plausibility-vaccine.",
      "authors": [
        "Jacob Chmura",
        "Jonah Dauvet",
        "Sebastian Sabry"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12667v1",
        "http://arxiv.org/pdf/2503.12667v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12611v1",
      "title": "Functional Factor Regression with an Application to Electricity Price\n  Curve Modeling",
      "published": "2025-03-16T18:48:18Z",
      "updated": "2025-03-16T18:48:18Z",
      "summary": "We propose a function-on-function linear regression model for time-dependent\ncurve data that is consistently estimated by imposing factor structures on the\nregressors. An integral operator based on cross-covariances identifies two\ncomponents for each functional regressor: a predictive low-dimensional\ncomponent, along with associated factors that are guaranteed to be correlated\nwith the dependent variable, and an infinite-dimensional component that has no\npredictive power. In order to consistently estimate the correct number of\nfactors for each regressor, we introduce a functional eigenvalue difference\ntest. Our setting allows us to construct a novel central limit theorem for the\nregression parameters in a fully functional model, making it possible to\nconstruct confidence bands and conduct statistical inference. The model is\napplied to forecast electricity price curves in three different energy markets.\nIts prediction accuracy is found to be comparable to popular machine learning\napproaches, while providing statistically valid inference and interpretable\ninsights into the conditional correlation structures of electricity prices.",
      "authors": [
        "Sven Otto",
        "Luis Winter"
      ],
      "categories": [
        "econ.EM",
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12611v1",
        "http://arxiv.org/pdf/2503.12611v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12541v1",
      "title": "Histogram Transporter: Learning Rotation-Equivariant Orientation\n  Histograms for High-Precision Robotic Kitting",
      "published": "2025-03-16T15:21:50Z",
      "updated": "2025-03-16T15:21:50Z",
      "summary": "Robotic kitting is a critical task in industrial automation that requires the\nprecise arrangement of objects into kits to support downstream production\nprocesses. However, when handling complex kitting tasks that involve\nfine-grained orientation alignment, existing approaches often suffer from\nlimited accuracy and computational efficiency. To address these challenges, we\npropose Histogram Transporter, a novel kitting framework that learns\nhigh-precision pick-and-place actions from scratch using only a few\ndemonstrations. First, our method extracts rotation-equivariant orientation\nhistograms (EOHs) from visual observations using an efficient Fourier-based\ndiscretization strategy. These EOHs serve a dual purpose: improving picking\nefficiency by directly modeling action success probabilities over\nhigh-resolution orientations and enhancing placing accuracy by serving as\nlocal, discriminative feature descriptors for object-to-placement matching.\nSecond, we introduce a subgroup alignment strategy in the place model that\ncompresses the full spectrum of EOHs into a compact orientation representation,\nenabling efficient feature matching while preserving accuracy. Finally, we\nexamine the proposed framework on the simulated Hand-Tool Kitting Dataset\n(HTKD), where it outperforms competitive baselines in both success rates and\ncomputational efficiency. Further experiments on five Raven-10 tasks exhibits\nthe remarkable adaptability of our approach, with real-robot trials confirming\nits applicability for real-world deployment.",
      "authors": [
        "Jiadong Zhou",
        "Yadan Zeng",
        "Huixu Dong",
        "I-Ming Chen"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12541v1",
        "http://arxiv.org/pdf/2503.12541v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12515v1",
      "title": "AI-Powered Automated Model Construction for Patient-Specific CFD\n  Simulations of Aortic Flows",
      "published": "2025-03-16T14:18:25Z",
      "updated": "2025-03-16T14:18:25Z",
      "summary": "Image-based modeling is essential for understanding cardiovascular\nhemodynamics and advancing the diagnosis and treatment of cardiovascular\ndiseases. Constructing patient-specific vascular models remains\nlabor-intensive, error-prone, and time-consuming, limiting their clinical\napplications. This study introduces a deep-learning framework that automates\nthe creation of simulation-ready vascular models from medical images. The\nframework integrates a segmentation module for accurate voxel-based vessel\ndelineation with a surface deformation module that performs anatomically\nconsistent and unsupervised surface refinements guided by medical image data.\nBy unifying voxel segmentation and surface deformation into a single cohesive\npipeline, the framework addresses key limitations of existing methods,\nenhancing geometric accuracy and computational efficiency. Evaluated on\npublicly available datasets, the proposed approach demonstrates\nstate-of-the-art performance in segmentation and mesh quality while\nsignificantly reducing manual effort and processing time. This work advances\nthe scalability and reliability of image-based computational modeling,\nfacilitating broader applications in clinical and research settings.",
      "authors": [
        "Pan Du",
        "Delin An",
        "Chaoli Wang",
        "Jian-Xun Wang"
      ],
      "categories": [
        "cs.CV",
        "cs.LG",
        "physics.med-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12515v1",
        "http://arxiv.org/pdf/2503.12515v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12435v1",
      "title": "XAI-Driven Client Selection for Federated Learning in Scalable 6G\n  Network Slicing",
      "published": "2025-03-16T10:14:25Z",
      "updated": "2025-03-16T10:14:25Z",
      "summary": "In recent years, network slicing has embraced artificial intelligence (AI)\nmodels to manage the growing complexity of communication networks. In such a\nsituation, AI-driven zero-touch network automation should present a high degree\nof flexibility and viability, especially when deployed in live production\nnetworks. However, centralized controllers suffer from high data communication\noverhead due to the vast amount of user data, and most network slices are\nreluctant to share private data. In federated learning systems, selecting\ntrustworthy clients to participate in training is critical for ensuring system\nperformance and reliability. The present paper proposes a new approach to\nclient selection by leveraging an XAI method to guarantee scalable and fast\noperation of federated learning based analytic engines that implement\nslice-level resource provisioning at the RAN-Edge in a non-IID scenario.\nAttributions from XAI are used to guide the selection of devices participating\nin training. This approach enhances network trustworthiness for users and\naddresses the black-box nature of neural network models. The simulations\nconducted outperformed the standard approach in terms of both convergence time\nand computational cost, while also demonstrating high scalability.",
      "authors": [
        "Martino Chiarani",
        "Swastika Roy",
        "Christos Verikoukis",
        "Fabrizio Granelli"
      ],
      "categories": [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12435v1",
        "http://arxiv.org/pdf/2503.12435v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12339v1",
      "title": "Augmented Adversarial Trigger Learning",
      "published": "2025-03-16T03:20:52Z",
      "updated": "2025-03-16T03:20:52Z",
      "summary": "Gradient optimization-based adversarial attack methods automate the learning\nof adversarial triggers to generate jailbreak prompts or leak system prompts.\nIn this work, we take a closer look at the optimization objective of\nadversarial trigger learning and propose ATLA: Adversarial Trigger Learning\nwith Augmented objectives. ATLA improves the negative log-likelihood loss used\nby previous studies into a weighted loss formulation that encourages the\nlearned adversarial triggers to optimize more towards response format tokens.\nThis enables ATLA to learn an adversarial trigger from just one query-response\npair and the learned trigger generalizes well to other similar queries. We\nfurther design a variation to augment trigger optimization with an auxiliary\nloss that suppresses evasive responses. We showcase how to use ATLA to learn\nadversarial suffixes jailbreaking LLMs and to extract hidden system prompts.\nEmpirically we demonstrate that ATLA consistently outperforms current\nstate-of-the-art techniques, achieving nearly 100% success in attacking while\nrequiring 80% fewer queries. ATLA learned jailbreak suffixes demonstrate high\ngeneralization to unseen queries and transfer well to new LLMs.",
      "authors": [
        "Zhe Wang",
        "Yanjun Qi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12339v1",
        "http://arxiv.org/pdf/2503.12339v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12293v1",
      "title": "Unified Modeling Language Code Generation from Diagram Images Using\n  Multimodal Large Language Models",
      "published": "2025-03-15T23:20:26Z",
      "updated": "2025-03-15T23:20:26Z",
      "summary": "The Unified Modeling Language is a standardized visual language widely used\nfor modeling and documenting the design of software systems. Although many\ntools generate UML diagrams from UML code, generating executable UML code from\nimage-based UML diagrams remains challenging. This paper proposes a new\napproach to generate UML code using a large multimodal language model\nautomatically. Synthetic UML activity and sequence diagram datasets were\ncreated to train and test the model. We compared standard fine-tuning with LoRA\ntechniques to optimize base models. The experiments measured code generation\naccuracy across different model sizes and training strategies. These results\ndemonstrated that domain-adapted MM-LLMs perform for UML code generation\nautomation, whereby, at the best model, it achieved BLEU and SSIM scores of\n0.779 and 0.942 on sequence diagrams. This will enable the modernization of\nlegacy systems and decrease the manual effort in software development\nworkflows.",
      "authors": [
        "Averi Bates",
        "Ryan Vavricka",
        "Shane Carleton",
        "Ruosi Shao",
        "Chongle Pan"
      ],
      "categories": [
        "cs.SE",
        "cs.LG",
        "D.2.2; D.2.3; I.2.7; I.4.9"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12293v1",
        "http://arxiv.org/pdf/2503.12293v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12267v1",
      "title": "An Efficient Deep Learning-Based Approach to Automating Invoice Document\n  Validation",
      "published": "2025-03-15T21:33:00Z",
      "updated": "2025-03-15T21:33:00Z",
      "summary": "In large organizations, the number of financial transactions can grow\nrapidly, driving the need for fast and accurate multi-criteria invoice\nvalidation. Manual processing remains error-prone and time-consuming, while\ncurrent automated solutions are limited by their inability to support a variety\nof constraints, such as documents that are partially handwritten or\nphotographed with a mobile phone. In this paper, we propose to automate the\nvalidation of machine written invoices using document layout analysis and\nobject detection techniques based on recent deep learning (DL) models. We\nintroduce a novel dataset consisting of manually annotated real-world invoices\nand a multi-criteria validation process. We fine-tune and benchmark the most\nrelevant DL models on our dataset. Experimental results show the effectiveness\nof the proposed pipeline and selected DL models in terms of achieving fast and\naccurate validation of invoices.",
      "authors": [
        "Aziz Amari",
        "Mariem Makni",
        "Wissal Fnaich",
        "Akram Lahmar",
        "Fedi Koubaa",
        "Oumayma Charrad",
        "Mohamed Ali Zormati",
        "Rabaa Youssef Douss"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://dx.doi.org/10.1109/AICCSA63423.2024.10912544",
        "http://arxiv.org/abs/2503.12267v1",
        "http://arxiv.org/pdf/2503.12267v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12215v1",
      "title": "Gun Detection Using Combined Human Pose and Weapon Appearance",
      "published": "2025-03-15T17:57:35Z",
      "updated": "2025-03-15T17:57:35Z",
      "summary": "The increasing frequency of firearm-related incidents has necessitated\nadvancements in security and surveillance systems, particularly in firearm\ndetection within public spaces. Traditional gun detection methods rely on\nmanual inspections and continuous human monitoring of CCTV footage, which are\nlabor-intensive and prone to high false positive and negative rates. To address\nthese limitations, we propose a novel approach that integrates human pose\nestimation with weapon appearance recognition using deep learning techniques.\nUnlike prior studies that focus on either body pose estimation or firearm\ndetection in isolation, our method jointly analyzes posture and weapon presence\nto enhance detection accuracy in real-world, dynamic environments. To train our\nmodel, we curated a diverse dataset comprising images from open-source\nrepositories such as IMFDB and Monash Guns, supplemented with AI-generated and\nmanually collected images from web sources. This dataset ensures robust\ngeneralization and realistic performance evaluation under various surveillance\nconditions. Our research aims to improve the precision and reliability of\nfirearm detection systems, contributing to enhanced public safety and threat\nmitigation in high-risk areas.",
      "authors": [
        "Amulya Reddy Maligireddy",
        "Manohar Reddy Uppula",
        "Nidhi Rastogi",
        "Yaswanth Reddy Parla"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12215v1",
        "http://arxiv.org/pdf/2503.12215v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.14526v1",
      "title": "ReBot: Scaling Robot Learning with Real-to-Sim-to-Real Robotic Video\n  Synthesis",
      "published": "2025-03-15T16:47:25Z",
      "updated": "2025-03-15T16:47:25Z",
      "summary": "Vision-language-action (VLA) models present a promising paradigm by training\npolicies directly on real robot datasets like Open X-Embodiment. However, the\nhigh cost of real-world data collection hinders further data scaling, thereby\nrestricting the generalizability of VLAs. In this paper, we introduce ReBot, a\nnovel real-to-sim-to-real approach for scaling real robot datasets and adapting\nVLA models to target domains, which is the last-mile deployment challenge in\nrobot manipulation. Specifically, ReBot replays real-world robot trajectories\nin simulation to diversify manipulated objects (real-to-sim), and integrates\nthe simulated movements with inpainted real-world background to synthesize\nphysically realistic and temporally consistent robot videos (sim-to-real). Our\napproach has several advantages: 1) it enjoys the benefit of real data to\nminimize the sim-to-real gap; 2) it leverages the scalability of simulation;\nand 3) it can generalize a pretrained VLA to a target domain with fully\nautomated data pipelines. Extensive experiments in both simulation and\nreal-world environments show that ReBot significantly enhances the performance\nand robustness of VLAs. For example, in SimplerEnv with the WidowX robot, ReBot\nimproved the in-domain performance of Octo by 7.2% and OpenVLA by 21.8%, and\nout-of-domain generalization by 19.9% and 9.4%, respectively. For real-world\nevaluation with a Franka robot, ReBot increased the success rates of Octo by\n17% and OpenVLA by 20%. More information can be found at:\nhttps://yuffish.github.io/rebot/",
      "authors": [
        "Yu Fang",
        "Yue Yang",
        "Xinghao Zhu",
        "Kaiyuan Zheng",
        "Gedas Bertasius",
        "Daniel Szafir",
        "Mingyu Ding"
      ],
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.14526v1",
        "http://arxiv.org/pdf/2503.14526v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12143v1",
      "title": "Language Models for Automated Classification of Brain MRI Reports and\n  Growth Chart Generation",
      "published": "2025-03-15T13:59:44Z",
      "updated": "2025-03-15T13:59:44Z",
      "summary": "Clinically acquired brain MRIs and radiology reports are valuable but\nunderutilized resources due to the challenges of manual analysis and data\nheterogeneity. We developed fine-tuned language models (LMs) to classify brain\nMRI reports as normal (reports with limited pathology) or abnormal, fine-tuning\nBERT, BioBERT, ClinicalBERT, and RadBERT on 44,661 reports. We also explored\nthe reasoning capabilities of a leading LM, Gemini 1.5-Pro, for normal report\ncategorization. Automated image processing and modeling generated brain growth\ncharts from LM-classified normal scans, comparing them to human-derived charts.\nFine-tuned LMs achieved high classification performance (F1-Score >97%), with\nunbalanced training mitigating class imbalance. Performance was robust on\nout-of-distribution data, with full text outperforming summary (impression)\nsections. Gemini 1.5-Pro showed a promising categorization performance,\nespecially with clinical inference. LM-derived brain growth charts were nearly\nidentical to human-annotated charts (r = 0.99, p < 2.2e-16). Our LMs offer\nscalable analysis of radiology reports, enabling automated classification of\nbrain MRIs in large datasets. One application is automated generation of brain\ngrowth charts for benchmarking quantitative image features. Further research is\nneeded to address data heterogeneity and optimize LM reasoning.",
      "authors": [
        "Maryam Daniali",
        "Shivaram Karandikar",
        "Dabriel Zimmerman",
        "J. Eric Schmitt",
        "Matthew J. Buczek",
        "Benjamin Jung",
        "Laura Mercedes",
        "Jakob Seidlitz",
        "Vanessa Troiani",
        "Lena Dorfschmidt",
        "Eren Kafadar",
        "Remo Williams",
        "Susan Sotardi",
        "Arastoo Vosough",
        "Scott Haag",
        "Jenna M. Schabdach",
        "Aaron Alexander-Bloch"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12143v1",
        "http://arxiv.org/pdf/2503.12143v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12099v1",
      "title": "Automatic Characterization of Fluxonium Superconducting Qubits\n  Parameters with Deep Transfer Learning",
      "published": "2025-03-15T11:51:16Z",
      "updated": "2025-03-15T11:51:16Z",
      "summary": "Accurate determination of qubit parameters is critical for the successful\nimplementation of quantum information and computation applications. In solid\nstate systems, the parameters of individual qubits vary across the entire\nsystem, requiring time consuming measurements and manual fitting processes for\ncharacterization. Recent developed superconducting qubits, such as fluxonium or\n0-pi qubits, offer improved fidelity operations but exhibit a more complex\nphysical and spectral structure, complicating parameter extraction. In this\nwork, we propose a machine learning (ML)based methodology for the automatic and\naccurate characterization of fluxonium qubit parameters. Our approach utilized\nthe energy spectrum calculated by a model Hamiltonian with various magnetic\nfields, as training data for the ML model. The output consists of the essential\nfluxonium qubit energy parameters, EJ, EC, and EL in Hamiltonian. The ML model\nachieves remarkable accuracy (with an average accuracy 95.6%) as an initial\nguess, enabling the development of an automatic fitting procedure for direct\napplication to realistic experimental data. Moreover, we demonstrate that\nsimilar accuracy can be retrieved even when the input experimental spectrum is\nnoisy or incomplete, highlighting the model robustness. These results suggest\nthat our automated characterization method, based on a transfer learning\napproach, provides a reliable framework for future extensions to other\nsuperconducting qubits or different solid-state systems. Ultimately, we believe\nthis methodology paves the way for the construction of large-scale quantum\nprocessors.",
      "authors": [
        "Huan-Hsuan Kung",
        "Chen-Yu Liu",
        "Qian-Rui Lee",
        "Chiang-Yuan Hu",
        "Yu-Chi Chang",
        "Ching-Yeh Chen",
        "Daw-Wei Wang",
        "Yen-Hsiang Lin"
      ],
      "categories": [
        "quant-ph",
        "cond-mat.supr-con"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12099v1",
        "http://arxiv.org/pdf/2503.12099v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12085v1",
      "title": "Automating the loop in traffic incident management on highway",
      "published": "2025-03-15T11:22:13Z",
      "updated": "2025-03-15T11:22:13Z",
      "summary": "Effective traffic incident management is essential for ensuring safety,\nminimizing congestion, and reducing response times in emergency situations.\nTraditional highway incident management relies heavily on radio room operators,\nwho must make rapid, informed decisions in high-stakes environments. This paper\nproposes an innovative solution to support and enhance these decisions by\nintegrating Large Language Models (LLMs) into a decision-support system for\ntraffic incident management. We introduce two approaches: (1) an LLM +\nOptimization hybrid that leverages both the flexibility of natural language\ninteraction and the robustness of optimization techniques, and (2) a Full LLM\napproach that autonomously generates decisions using only LLM capabilities. We\ntested our solutions using historical event data from Autostrade per l'Italia.\nExperimental results indicate that while both approaches show promise, the LLM\n+ Optimization solution demonstrates superior reliability, making it\nparticularly suited to critical applications where consistency and accuracy are\nparamount. This research highlights the potential for LLMs to transform highway\nincident management by enabling accessible, data-driven decision-making\nsupport.",
      "authors": [
        "Matteo Cercola",
        "Nicola Gatti",
        "Pedro Huertas Leyva",
        "Benedetto Carambia",
        "Simone Formentin"
      ],
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12085v1",
        "http://arxiv.org/pdf/2503.12085v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12066v1",
      "title": "Impact of Data Patterns on Biotype identification Using Machine Learning",
      "published": "2025-03-15T09:44:00Z",
      "updated": "2025-03-15T09:44:00Z",
      "summary": "Background: Patient stratification in brain disorders remains a significant\nchallenge, despite advances in machine learning and multimodal neuroimaging.\nAutomated machine learning algorithms have been widely applied for identifying\npatient subtypes (biotypes), but results have been inconsistent across studies.\nThese inconsistencies are often attributed to algorithmic limitations, yet an\noverlooked factor may be the statistical properties of the input data. This\nstudy investigates the contribution of data patterns on algorithm performance\nby leveraging synthetic brain morphometry data as an exemplar.\n  Methods: Four widely used algorithms-SuStaIn, HYDRA, SmileGAN, and SurrealGAN\nwere evaluated using multiple synthetic pseudo-patient datasets designed to\ninclude varying numbers and sizes of clusters and degrees of complexity of\nmorphometric changes. Ground truth, representing predefined clusters, allowed\nfor the evaluation of performance accuracy across algorithms and datasets.\n  Results: SuStaIn failed to process datasets with more than 17 variables,\nhighlighting computational inefficiencies. HYDRA was able to perform\nindividual-level classification in multiple datasets with no clear pattern\nexplaining failures. SmileGAN and SurrealGAN outperformed other algorithms in\nidentifying variable-based disease patterns, but these patterns were not able\nto provide individual-level classification.\n  Conclusions: Dataset characteristics significantly influence algorithm\nperformance, often more than algorithmic design. The findings emphasize the\nneed for rigorous validation using synthetic data before real-world application\nand highlight the limitations of current clustering approaches in capturing the\nheterogeneity of brain disorders. These insights extend beyond neuroimaging and\nhave implications for machine learning applications in biomedical research.",
      "authors": [
        "Yuetong Yu",
        "Ruiyang Ge",
        "Ilker Hacihaliloglu",
        "Alexander Rauscher",
        "Roger Tam",
        "Sophia Frangou"
      ],
      "categories": [
        "cs.LG",
        "q-bio.NC",
        "q-bio.QM"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12066v1",
        "http://arxiv.org/pdf/2503.12066v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.12053v1",
      "title": "Ferret: An Efficient Online Continual Learning Framework under Varying\n  Memory Constraints",
      "published": "2025-03-15T08:58:38Z",
      "updated": "2025-03-15T08:58:38Z",
      "summary": "In the realm of high-frequency data streams, achieving real-time learning\nwithin varying memory constraints is paramount. This paper presents Ferret, a\ncomprehensive framework designed to enhance online accuracy of Online Continual\nLearning (OCL) algorithms while dynamically adapting to varying memory budgets.\nFerret employs a fine-grained pipeline parallelism strategy combined with an\niterative gradient compensation algorithm, ensuring seamless handling of\nhigh-frequency data with minimal latency, and effectively counteracting the\nchallenge of stale gradients in parallel training. To adapt to varying memory\nbudgets, its automated model partitioning and pipeline planning optimizes\nperformance regardless of memory limitations. Extensive experiments across 20\nbenchmarks and 5 integrated OCL algorithms show Ferret's remarkable efficiency,\nachieving up to 3.7$\\times$ lower memory overhead to reach the same online\naccuracy compared to competing methods. Furthermore, Ferret consistently\noutperforms these methods across diverse memory budgets, underscoring its\nsuperior adaptability. These findings position Ferret as a premier solution for\nefficient and adaptive OCL framework in real-time environments.",
      "authors": [
        "Yuhao Zhou",
        "Yuxin Tian",
        "Jindi Lv",
        "Mingjia Shi",
        "Yuanxi Li",
        "Qing Ye",
        "Shuhao Zhang",
        "Jiancheng Lv"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.12053v1",
        "http://arxiv.org/pdf/2503.12053v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11991v1",
      "title": "Automation and Feature Selection Enhancement with Reinforcement Learning\n  (RL)",
      "published": "2025-03-15T04:30:55Z",
      "updated": "2025-03-15T04:30:55Z",
      "summary": "Effective feature selection, representation and transformation are principal\nsteps in machine learning to improve prediction accuracy, model generalization\nand computational efficiency. Reinforcement learning provides a new perspective\ntowards balanced exploration of optimal feature subset using multi-agent and\nsingle-agent models. Interactive reinforcement learning integrated with\ndecision tree improves feature knowledge, state representation and selection\nefficiency, while diversified teaching strategies improve both selection\nquality and efficiency. The state representation can further be enhanced by\nscanning features sequentially along with the usage of convolutional\nauto-encoder. Monte Carlo-based reinforced feature selection(MCRFS), a\nsingle-agent feature selection method reduces computational burden by\nincorporating early-stopping and reward-level interactive strategies. A\ndual-agent RL framework is also introduced that collectively selects features\nand instances, capturing the interactions between them. This enables the agents\nto navigate through complex data spaces. To outperform the traditional feature\nengineering, cascading reinforced agents are used to iteratively improve the\nfeature space, which is a self-optimizing framework. The blend of reinforcement\nlearning, multi-agent systems, and bandit-based approaches offers exciting\npaths for studying scalable and interpretable machine learning solutions to\nhandle high-dimensional data and challenging predictive tasks.",
      "authors": [
        "Sumana Sanyasipura Nagaraju"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11991v1",
        "http://arxiv.org/pdf/2503.11991v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11989v1",
      "title": "Applications of Large Language Model Reasoning in Feature Generation",
      "published": "2025-03-15T04:18:01Z",
      "updated": "2025-03-15T04:18:01Z",
      "summary": "Large Language Models (LLMs) have revolutionized natural language processing\nthrough their state of art reasoning capabilities. This paper explores the\nconvergence of LLM reasoning techniques and feature generation for machine\nlearning tasks. We examine four key reasoning approaches: Chain of Thought,\nTree of Thoughts, Retrieval-Augmented Generation, and Thought Space\nExploration. Our analysis reveals how these approaches can be used to identify\neffective feature generation rules without having to manually specify search\nspaces. The paper categorizes LLM-based feature generation methods across\nvarious domains including finance, healthcare, and text analytics. LLMs can\nextract key information from clinical notes and radiology reports in\nhealthcare, by enabling more efficient data utilization. In finance, LLMs\nfacilitate text generation, summarization, and entity extraction from complex\ndocuments. We analyze evaluation methodologies for assessing feature quality\nand downstream performance, with particular attention to OCTree's decision tree\nreasoning approach that provides language-based feedback for iterative\nimprovements. Current challenges include hallucination, computational\nefficiency, and domain adaptation. As of March 2025, emerging approaches\ninclude inference-time compute scaling, reinforcement learning, and supervised\nfine-tuning with model distillation. Future directions point toward multimodal\nfeature generation, self-improving systems, and neuro-symbolic approaches. This\npaper provides a detailed overview of an emerging field that promises to\nautomate and enhance feature engineering through language model reasoning.",
      "authors": [
        "Dharani Chandra"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11989v1",
        "http://arxiv.org/pdf/2503.11989v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13528v1",
      "title": "Internet of Things-Based Smart Precision Farming in Soilless\n  Agriculture: Opportunities and Challenges for Global Food Security",
      "published": "2025-03-15T03:40:32Z",
      "updated": "2025-03-15T03:40:32Z",
      "summary": "The rapid growth of the global population and the continuous decline in\ncultivable land pose significant threats to food security. This challenge\nworsens as climate change further reduces the availability of farmland.\nSoilless agriculture, such as hydroponics, aeroponics, and aquaponics, offers a\nsustainable solution by enabling efficient crop cultivation in controlled\nenvironments. The integration of the Internet of Things (IoT) with smart\nprecision farming improves resource efficiency, automates environmental\ncontrol, and ensures stable and high-yield crop production. IoT-enabled smart\nfarming systems utilize real-time monitoring, data-driven decision-making, and\nautomation to optimize water and nutrient usage while minimizing human\nintervention. This paper explores the opportunities and challenges of IoT-based\nsoilless farming, highlighting its role in sustainable agriculture, urban\nfarming, and global food security. These advanced farming methods ensure\ngreater productivity, resource conservation, and year-round cultivation.\nHowever, they also face challenges such as high initial investment,\ntechnological dependency, and energy consumption. Through a comprehensive\nstudy, bibliometric analysis, and comparative analysis, this research\nhighlights current trends and research gaps. It also outlines future directions\nfor researchers, policymakers, and industry stakeholders to drive innovation\nand scalability in IoT-driven soilless agriculture. By emphasizing the benefits\nof vertical farming and Controlled Environment Agriculture (CEA)-enabled\nsoilless techniques, this paper supports informed decision-making to address\nfood security challenges and promote sustainable agricultural innovations.",
      "authors": [
        "Monica Dutta",
        "Deepali Gupta",
        "Sumegh Tharewal",
        "Deepam Goyal",
        "Jasminder Kaur Sandhu",
        "Manjit Kaur",
        "Ahmad Ali Alzubi",
        "Jazem Mutared Alanazi"
      ],
      "categories": [
        "eess.SP",
        "cs.LG"
      ],
      "links": [
        "http://dx.doi.org/10.1109/ACCESS.2025.3540317",
        "http://arxiv.org/abs/2503.13528v1",
        "http://arxiv.org/pdf/2503.13528v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11921v1",
      "title": "RePanda: Pandas-powered Tabular Verification and Reasoning",
      "published": "2025-03-14T23:12:36Z",
      "updated": "2025-03-14T23:12:36Z",
      "summary": "Fact-checking tabular data is essential for ensuring the accuracy of\nstructured information. However, existing methods often rely on black-box\nmodels with opaque reasoning. We introduce RePanda, a structured fact\nverification approach that translates claims into executable pandas queries,\nenabling interpretable and verifiable reasoning.\n  To train RePanda, we construct PanTabFact, a structured dataset derived from\nthe TabFact train set, where claims are paired with executable queries\ngenerated using DeepSeek-Chat and refined through automated error correction.\nFine-tuning DeepSeek-coder-7B-instruct-v1.5 on PanTabFact, RePanda achieves\n84.09% accuracy on the TabFact test set.\n  To evaluate Out-of-Distribution (OOD) generalization, we interpret\nquestion-answer pairs from WikiTableQuestions as factual claims and refer to\nthis dataset as WikiFact. Without additional fine-tuning, RePanda achieves\n84.72% accuracy on WikiFact, significantly outperforming all other baselines\nand demonstrating strong OOD robustness. Notably, these results closely match\nthe zero-shot performance of DeepSeek-Chat (671B), indicating that our\nfine-tuning approach effectively distills structured reasoning from a much\nlarger model into a compact, locally executable 7B model.\n  Beyond fact verification, RePanda extends to tabular question answering by\ngenerating executable queries that retrieve precise answers. To support this,\nwe introduce PanWiki, a dataset mapping WikiTableQuestions to pandas queries.\nFine-tuning on PanWiki, RePanda achieves 75.1% accuracy in direct answer\nretrieval. These results highlight the effectiveness of structured\nexecution-based reasoning for tabular verification and question answering.\n  We have publicly released the dataset on Hugging Face at\ndatasets/AtoosaChegini/PanTabFact.",
      "authors": [
        "Atoosa Malemir Chegini",
        "Keivan Rezaei",
        "Hamid Eghbalzadeh",
        "Soheil Feizi"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11921v1",
        "http://arxiv.org/pdf/2503.11921v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.13522v1",
      "title": "Advanced Deep Learning Methods for Protein Structure Prediction and\n  Design",
      "published": "2025-03-14T21:28:29Z",
      "updated": "2025-03-14T21:28:29Z",
      "summary": "After AlphaFold won the Nobel Prize, protein prediction with deep learning\nonce again became a hot topic. We comprehensively explore advanced deep\nlearning methods applied to protein structure prediction and design. It begins\nby examining recent innovations in prediction architectures, with detailed\ndiscussions on improvements such as diffusion based frameworks and novel\npairwise attention modules. The text analyses key components including\nstructure generation, evaluation metrics, multiple sequence alignment\nprocessing, and network architecture, thereby illustrating the current state of\nthe art in computational protein modelling. Subsequent chapters focus on\npractical applications, presenting case studies that range from individual\nprotein predictions to complex biomolecular interactions. Strategies for\nenhancing prediction accuracy and integrating deep learning techniques with\nexperimental validation are thoroughly explored. The later sections review the\nindustry landscape of protein design, highlighting the transformative role of\nartificial intelligence in biotechnology and discussing emerging market trends\nand future challenges. Supplementary appendices provide essential resources\nsuch as databases and open source tools, making this volume a valuable\nreference for researchers and students.",
      "authors": [
        "Weikun Wu",
        "Tianyang Wang",
        "Yichao Zhang",
        "Ningyuan Deng",
        "Xinyuan Song",
        "Ziqian Bi",
        "Zheyu Yao",
        "Keyu Chen",
        "Ming Li",
        "Qian Niu",
        "Junyu Liu",
        "Benji Peng",
        "Sen Zhang",
        "Ming Liu",
        "Li Zhang",
        "Xuanhe Pan",
        "Jinlang Wang",
        "Pohsun Feng",
        "Yizhu Wen",
        "Lawrence KQ Yan",
        "Hongming Tseng",
        "Yan Zhong",
        "Yunze Wang",
        "Ziyuan Qin",
        "Bowen Jing",
        "Junjie Yang",
        "Jun Zhou",
        "Chia Xin Liang",
        "Junhao Song"
      ],
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.13522v1",
        "http://arxiv.org/pdf/2503.13522v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11841v1",
      "title": "Trust Under Siege: Label Spoofing Attacks against Machine Learning for\n  Android Malware Detection",
      "published": "2025-03-14T20:05:56Z",
      "updated": "2025-03-14T20:05:56Z",
      "summary": "Machine learning (ML) malware detectors rely heavily on crowd-sourced\nAntiVirus (AV) labels, with platforms like VirusTotal serving as a trusted\nsource of malware annotations. But what if attackers could manipulate these\nlabels to classify benign software as malicious? We introduce label spoofing\nattacks, a new threat that contaminates crowd-sourced datasets by embedding\nminimal and undetectable malicious patterns into benign samples. These patterns\ncoerce AV engines into misclassifying legitimate files as harmful, enabling\npoisoning attacks against ML-based malware classifiers trained on those data.\nWe demonstrate this scenario by developing AndroVenom, a methodology for\npolluting realistic data sources, causing consequent poisoning attacks against\nML malware detectors. Experiments show that not only state-of-the-art feature\nextractors are unable to filter such injection, but also various ML models\nexperience Denial of Service already with 1% poisoned samples. Additionally,\nattackers can flip decisions of specific unaltered benign samples by modifying\nonly 0.015% of the training data, threatening their reputation and market share\nand being unable to be stopped by anomaly detectors on training data. We\nconclude our manuscript by raising the alarm on the trustworthiness of the\ntraining process based on AV annotations, requiring further investigation on\nhow to produce proper labels for ML malware detectors.",
      "authors": [
        "Tianwei Lan",
        "Luca Demetrio",
        "Farid Nait-Abdesselam",
        "Yufei Han",
        "Simone Aonzo"
      ],
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11841v1",
        "http://arxiv.org/pdf/2503.11841v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11836v1",
      "title": "Transfer Learning for Automated Feedback Generation on Small Datasets",
      "published": "2025-03-14T19:57:54Z",
      "updated": "2025-03-14T19:57:54Z",
      "summary": "Feedback is a very important part the learning process. However, it is\nchallenging to make this feedback both timely and accurate when relying on\nhuman markers. This is the challenge that Automated Feedback Generation\nattempts to address. In this paper, a technique to train such a system on a\nvery small dataset with very long sequences is presented. Both of these\nattributes make this a very challenging task, however, by using a three stage\ntransfer learning pipeline state-of-the-art results can be achieved with\nqualitatively accurate but unhuman sounding results. The use of both Automated\nEssay Scoring and Automated Feedback Generation systems in the real world is\nalso discussed.",
      "authors": [
        "Oscar Morris"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11836v1",
        "http://arxiv.org/pdf/2503.11836v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11827v1",
      "title": "Bridging the LLM Accessibility Divide? Performance, Fairness, and Cost\n  of Closed versus Open LLMs for Automated Essay Scoring",
      "published": "2025-03-14T19:34:40Z",
      "updated": "2025-03-14T19:34:40Z",
      "summary": "Closed large language models (LLMs) such as GPT-4 have set state-of-the-art\nresults across a number of NLP tasks and have become central to NLP and machine\nlearning (ML)-driven solutions. Closed LLMs' performance and wide adoption has\nsparked considerable debate about their accessibility in terms of availability,\ncost, and transparency. In this study, we perform a rigorous comparative\nanalysis of nine leading LLMs, spanning closed, open, and open-source LLM\necosystems, across text assessment and generation tasks related to automated\nessay scoring. Our findings reveal that for few-shot learning-based assessment\nof human generated essays, open LLMs such as Llama 3 and Qwen2.5 perform\ncomparably to GPT-4 in terms of predictive performance, with no significant\ndifferences in disparate impact scores when considering age- or race-related\nfairness. Moreover, Llama 3 offers a substantial cost advantage, being up to 37\ntimes more cost-efficient than GPT-4. For generative tasks, we find that essays\ngenerated by top open LLMs are comparable to closed LLMs in terms of their\nsemantic composition/embeddings and ML assessed scores. Our findings challenge\nthe dominance of closed LLMs and highlight the democratizing potential of open\nLLMs, suggesting they can effectively bridge accessibility divides while\nmaintaining competitive performance and fairness.",
      "authors": [
        "Kezia Oketch",
        "John P. Lalor",
        "Yi Yang",
        "Ahmed Abbasi"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11827v1",
        "http://arxiv.org/pdf/2503.11827v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11807v1",
      "title": "Mitigating Bad Ground Truth in Supervised Machine Learning based Crop\n  Classification: A Multi-Level Framework with Sentinel-2 Images",
      "published": "2025-03-14T18:50:30Z",
      "updated": "2025-03-14T18:50:30Z",
      "summary": "In agricultural management, precise Ground Truth (GT) data is crucial for\naccurate Machine Learning (ML) based crop classification. Yet, issues like crop\nmislabeling and incorrect land identification are common. We propose a\nmulti-level GT cleaning framework while utilizing multi-temporal Sentinel-2\ndata to address these issues. Specifically, this framework utilizes generating\nembeddings for farmland, clustering similar crop profiles, and identification\nof outliers indicating GT errors. We validated clusters with False Colour\nComposite (FCC) checks and used distance-based metrics to scale and automate\nthis verification process. The importance of cleaning the GT data became\napparent when the models were trained on the clean and unclean data. For\ninstance, when we trained a Random Forest model with the clean GT data, we\nachieved upto 70\\% absolute percentage points higher for the F1 score metric.\nThis approach advances crop classification methodologies, with potential for\napplications towards improving loan underwriting and agricultural\ndecision-making.",
      "authors": [
        "Sanayya A",
        "Amoolya Shetty",
        "Abhijeet Sharma",
        "Venkatesh Ravichandran",
        "Masthan Wali Gosuvarapalli",
        "Sarthak Jain",
        "Priyamvada Nanjundiah",
        "Ujjal Kr Dutta",
        "Divya Sharma"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11807v1",
        "http://arxiv.org/pdf/2503.11807v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11787v1",
      "title": "ECLARE: Efficient cross-planar learning for anisotropic resolution\n  enhancement",
      "published": "2025-03-14T18:24:35Z",
      "updated": "2025-03-14T18:24:35Z",
      "summary": "In clinical imaging, magnetic resonance (MR) image volumes are often acquired\nas stacks of 2D slices, permitting decreased scan times, improved\nsignal-to-noise ratio, and image contrasts unique to 2D MR pulse sequences.\nWhile this is sufficient for clinical evaluation, automated algorithms designed\nfor 3D analysis perform sub-optimally on 2D-acquired scans, especially those\nwith thick slices and gaps between slices. Super-resolution (SR) methods aim to\naddress this problem, but previous methods do not address all of the following:\nslice profile shape estimation, slice gap, domain shift, and non-integer /\narbitrary upsampling factors. In this paper, we propose ECLARE (Efficient\nCross-planar Learning for Anisotropic Resolution Enhancement), a self-SR method\nthat addresses each of these factors. ECLARE estimates the slice profile from\nthe 2D-acquired multi-slice MR volume, trains a network to learn the mapping\nfrom low-resolution to high-resolution in-plane patches from the same volume,\nand performs SR with anti-aliasing. We compared ECLARE to cubic B-spline\ninterpolation, SMORE, and other contemporary SR methods. We used realistic and\nrepresentative simulations so that quantitative performance against a ground\ntruth could be computed, and ECLARE outperformed all other methods in both\nsignal recovery and downstream tasks. On real data for which there is no ground\ntruth, ECLARE demonstrated qualitative superiority over other methods as well.\nImportantly, as ECLARE does not use external training data it cannot suffer\nfrom domain shift between training and testing. Our code is open-source and\navailable at https://www.github.com/sremedios/eclare.",
      "authors": [
        "Samuel W. Remedios",
        "Shuwen Wei",
        "Shuo Han",
        "Jinwei Zhang",
        "Aaron Carass",
        "Kurt G. Schilling",
        "Dzung L. Pham",
        "Jerry L. Prince",
        "Blake E. Dewey"
      ],
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11787v1",
        "http://arxiv.org/pdf/2503.11787v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11638v1",
      "title": "Scaling the Automated Discovery of Quantum Circuits via Reinforcement\n  Learning with Gadgets",
      "published": "2025-03-14T17:55:49Z",
      "updated": "2025-03-14T17:55:49Z",
      "summary": "Reinforcement Learning (RL) has established itself as a powerful tool for\ndesigning quantum circuits, which are essential for processing quantum\ninformation. RL applications have typically focused on circuits of small to\nintermediate complexity, as computation times tend to increase exponentially\nwith growing circuit complexity. This computational explosion severely limits\nthe scalability of RL and casts significant doubt on its broader applicability.\nIn this paper, we propose a principled approach based on the systematic\ndiscovery and introduction of composite gates -- {\\it gadgets}, that enables RL\nscalability, thereby expanding its potential applications. As a case study, we\nexplore the discovery of Clifford encoders for Quantum Error Correction. We\ndemonstrate that incorporating gadgets in the form of composite Clifford gates,\nin addition to standard CNOT and Hadamard gates, significantly enhances the\nefficiency of RL agents. Specifically, the computation speed increases (by one\nor even two orders of magnitude), enabling RL to discover highly complex\nquantum codes without previous knowledge. We illustrate this advancement with\nexamples of QEC code discovery with parameters $ [[n,1,d]] $ for $ d \\leq 7 $\nand $ [[n,k,6]] $ for $ k \\leq 7 $. We note that the most complicated circuits\nof these classes were not previously found. We highlight the advantages and\nlimitations of the gadget-based approach. Our method paves the way for scaling\nthe RL-based automatic discovery of complicated quantum circuits for various\ntasks, which may include designing logical operations between logical qubits or\ndiscovering quantum algorithms.",
      "authors": [
        "Jan Olle",
        "Oleg M. Yevtushenko",
        "Florian Marquardt"
      ],
      "categories": [
        "quant-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11638v1",
        "http://arxiv.org/pdf/2503.11638v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11392v1",
      "title": "Watch and Learn: Leveraging Expert Knowledge and Language for Surgical\n  Video Understanding",
      "published": "2025-03-14T13:36:13Z",
      "updated": "2025-03-14T13:36:13Z",
      "summary": "Automated surgical workflow analysis is crucial for education, research, and\nclinical decision-making, but the lack of annotated datasets hinders the\ndevelopment of accurate and comprehensive workflow analysis solutions. We\nintroduce a novel approach for addressing the sparsity and heterogeneity of\nannotated training data inspired by the human learning procedure of watching\nexperts and understanding their explanations. Our method leverages a\nvideo-language model trained on alignment, denoising, and generative tasks to\nlearn short-term spatio-temporal and multimodal representations. A\ntask-specific temporal model is then used to capture relationships across\nentire videos. To achieve comprehensive video-language understanding in the\nsurgical domain, we introduce a data collection and filtering strategy to\nconstruct a large-scale pretraining dataset from educational YouTube videos. We\nthen utilize parameter-efficient fine-tuning by projecting downstream task\nannotations from publicly available surgical datasets into the language domain.\nExtensive experiments in two surgical domains demonstrate the effectiveness of\nour approach, with performance improvements of up to 7% in phase segmentation\ntasks, 8% in zero-shot phase segmentation, and comparable capabilities to\nfully-supervised models in few-shot settings. Harnessing our model's\ncapabilities for long-range temporal localization and text generation, we\npresent the first comprehensive solution for dense video captioning (DVC) of\nsurgical videos, addressing this task despite the absence of existing DVC\ndatasets in the surgical domain. We introduce a novel approach to surgical\nworkflow understanding that leverages video-language pretraining, large-scale\nvideo pretraining, and optimized fine-tuning. Our method improves performance\nover state-of-the-art techniques and enables new downstream tasks for surgical\nvideo understanding.",
      "authors": [
        "David Gastager",
        "Ghazal Ghazaei",
        "Constantin Patsch"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11392v1",
        "http://arxiv.org/pdf/2503.11392v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11387v1",
      "title": "Hierarchical Information-Guided Spatio-Temporal Mamba for Stock Time\n  Series Forecasting",
      "published": "2025-03-14T13:30:38Z",
      "updated": "2025-03-14T13:30:38Z",
      "summary": "Mamba has demonstrated excellent performance in various time series\nforecasting tasks due to its superior selection mechanism. Nevertheless,\nconventional Mamba-based models encounter significant challenges in accurately\npredicting stock time series, as they fail to adequately capture both the\noverarching market dynamics and the intricate interdependencies among\nindividual stocks. To overcome these constraints, we introduce the Hierarchical\nInformation-Guided Spatio-Temporal Mamba (HIGSTM) framework. HIGSTM introduces\nIndex-Guided Frequency Filtering Decomposition to extract commonality and\nspecificity from time series. The model architecture features a meticulously\ndesigned hierarchical framework that systematically captures both temporal\ndynamic patterns and global static relationships within the stock market.\nFurthermore, we propose an Information-Guided Mamba that integrates macro\ninformations into the sequence selection process, thereby facilitating more\nmarket-conscious decision-making. Comprehensive experimental evaluations\nconducted on the CSI500, CSI800 and CSI1000 datasets demonstrate that HIGSTM\nachieves state-of-the-art performance.",
      "authors": [
        "Wenbo Yan",
        "Shurui Wang",
        "Ying Tan"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11387v1",
        "http://arxiv.org/pdf/2503.11387v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11352v1",
      "title": "Enhancing Hand Palm Motion Gesture Recognition by Eliminating Reference\n  Frame Bias via Frame-Invariant Similarity Measures",
      "published": "2025-03-14T12:40:43Z",
      "updated": "2025-03-14T12:40:43Z",
      "summary": "The ability of robots to recognize human gestures facilitates a natural and\naccessible human-robot collaboration. However, most work in gesture recognition\nremains rooted in reference frame-dependent representations. This poses a\nchallenge when reference frames vary due to different work cell layouts,\nimprecise frame calibrations, or other environmental changes. This paper\ninvestigated the use of invariant trajectory descriptors for robust hand palm\nmotion gesture recognition under reference frame changes. First, a novel\ndataset of recorded Hand Palm Motion (HPM) gestures is introduced. The motion\ngestures in this dataset were specifically designed to be distinguishable\nwithout dependence on specific reference frames or directional cues.\nAfterwards, multiple invariant trajectory descriptor approaches were\nbenchmarked to assess how their performances generalize to this novel HPM\ndataset. After this offline benchmarking, the best scoring approach is\nvalidated for online recognition by developing a real-time Proof of Concept\n(PoC). In this PoC, hand palm motion gestures were used to control the\nreal-time movement of a manipulator arm. The PoC demonstrated a high\nrecognition reliability in real-time operation, achieving an $F_1$-score of\n92.3%. This work demonstrates the effectiveness of the invariant descriptor\napproach as a standalone solution. Moreover, we believe that the invariant\ndescriptor approach can also be utilized within other state-of-the-art pattern\nrecognition and learning systems to improve their robustness against reference\nframe variations.",
      "authors": [
        "Arno Verduyn",
        "Maxim Vochten",
        "Joris De Schutter"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.HC",
        "53Z30, 70B10, 53A55",
        "I.5.m"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11352v1",
        "http://arxiv.org/pdf/2503.11352v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11733v1",
      "title": "LLM Agents for Education: Advances and Applications",
      "published": "2025-03-14T11:53:44Z",
      "updated": "2025-03-14T11:53:44Z",
      "summary": "Large Language Model (LLM) agents have demonstrated remarkable capabilities\nin automating tasks and driving innovation across diverse educational\napplications. In this survey, we provide a systematic review of\nstate-of-the-art research on LLM agents in education, categorizing them into\ntwo broad classes: (1) \\emph{Pedagogical Agents}, which focus on automating\ncomplex pedagogical tasks to support both teachers and students; and (2)\n\\emph{Domain-Specific Educational Agents}, which are tailored for specialized\nfields such as science education, language learning, and professional\ndevelopment. We comprehensively examine the technological advancements\nunderlying these LLM agents, including key datasets, benchmarks, and\nalgorithmic frameworks that drive their effectiveness. Furthermore, we discuss\ncritical challenges such as privacy, bias and fairness concerns, hallucination\nmitigation, and integration with existing educational ecosystems. This survey\naims to provide a comprehensive technological overview of LLM agents for\neducation, fostering further research and collaboration to enhance their impact\nfor the greater good of learners and educators alike.",
      "authors": [
        "Zhendong Chu",
        "Shen Wang",
        "Jian Xie",
        "Tinghui Zhu",
        "Yibo Yan",
        "Jinheng Ye",
        "Aoxiao Zhong",
        "Xuming Hu",
        "Jing Liang",
        "Philip S. Yu",
        "Qingsong Wen"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11733v1",
        "http://arxiv.org/pdf/2503.11733v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11294v1",
      "title": "Latent Space Representation of Electricity Market Curves for Improved\n  Prediction Efficiency",
      "published": "2025-03-14T11:04:46Z",
      "updated": "2025-03-14T11:04:46Z",
      "summary": "This work presents a three-phase ML prediction framework designed to handle a\nhigh dimensionality and multivariate time series character of the electricity\nmarket curves. In the preprocessing phase, we transform the original data to\nachieve a unified structure and mitigate the effect of possible outliers.\nFurther, to address the challenge of high dimensionality, we test three\ndimensionality reduction techniques (PCA, kPCA, UMAP). Finally, we predict\nsupply and demand curves, once represented in a latent space, with a variety of\nmachine learning methods (RF, LSTM, TSMixer). As our results on the MIBEL\ndataset show, a high dimensional structure of the market curves can be best\nhandled by the nonlinear reduction technique UMAP. Regardless of the ML\ntechnique used for prediction, we achieved the lowest values for all considered\nprecision metrics with a UMAP latent space representation in only two or three\ndimensions, even when compared to PCA and kPCA with five or six dimensions.\nFurther, we demonstrate that the most promising machine learning technique to\nhandle the complex structure of the electricity market curves is a novel\nTSMixer architecture. Finally, we fill the gap in the field of electricity\nmarket curves prediction literature: in addition to standard analysis on the\nsupply side, we applied the ML framework and predicted demand curves too. We\ndiscussed the differences in the achieved results for these two types of\ncurves.",
      "authors": [
        "Martin V\u00fdboh",
        "Zuzana Chladn\u00e1",
        "Gabriela Grmanov\u00e1",
        "M\u00e1ria Luck\u00e1"
      ],
      "categories": [
        "cs.LG",
        "I.5.1; I.2.6; I.6.3; J.2; J.4"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11294v1",
        "http://arxiv.org/pdf/2503.11294v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11281v3",
      "title": "AI and Deep Learning for Automated Segmentation and Quantitative\n  Measurement of Spinal Structures in MRI",
      "published": "2025-03-14T10:39:52Z",
      "updated": "2025-03-19T06:18:20Z",
      "summary": "Background: Accurate spinal structure measurement is crucial for assessing\nspine health and diagnosing conditions like spondylosis, disc herniation, and\nstenosis. Manual methods for measuring intervertebral disc height and spinal\ncanal diameter are subjective and time-consuming. Automated solutions are\nneeded to improve accuracy, efficiency, and reproducibility in clinical\npractice.\n  Purpose: This study develops an autonomous AI system for segmenting and\nmeasuring key spinal structures in MRI scans, focusing on intervertebral disc\nheight and spinal canal anteroposterior (AP) diameter in the cervical, lumbar,\nand thoracic regions. The goal is to reduce clinician workload, enhance\ndiagnostic consistency, and improve assessments.\n  Methods: The AI model leverages deep learning architectures, including UNet,\nnnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated\nagainst expert annotations. Performance was evaluated using Dice coefficients\nand segmentation accuracy.\n  Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for\ncervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely\nmeasured spinal parameters like disc height and canal diameter, demonstrating\nrobustness and clinical applicability.\n  Conclusion: The AI system effectively automates MRI-based spinal\nmeasurements, improving accuracy and reducing clinician workload. Its\nconsistent performance across spinal regions supports clinical decision-making,\nparticularly in high-demand settings, enhancing spinal assessments and patient\noutcomes.",
      "authors": [
        "Praveen Shastry",
        "Bhawana Sonawane",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Raghotham Sripadraj",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Kaviya SP",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "92C55, 68T07, 68U10, 62P10, 65D18"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11281v3",
        "http://arxiv.org/pdf/2503.11281v3"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11270v1",
      "title": "Exploring Competitive and Collusive Behaviors in Algorithmic Pricing\n  with Deep Reinforcement Learning",
      "published": "2025-03-14T10:26:56Z",
      "updated": "2025-03-14T10:26:56Z",
      "summary": "Nowadays, a significant share of the business-to-consumer sector is based on\nonline platforms like Amazon and Alibaba and uses AI for pricing strategies.\nThis has sparked debate on whether pricing algorithms may tacitly collude to\nset supra-competitive prices without being explicitly designed to do so. Our\nstudy addresses these concerns by examining the risk of collusion when\nReinforcement Learning (RL) algorithms are used to decide on pricing strategies\nin competitive markets. Prior research in this field focused on Tabular\nQ-learning (TQL) and led to opposing views on whether learning-based algorithms\ncan result in supra-competitive prices. Building on this, our work contributes\nto this ongoing discussion by providing a more nuanced numerical study that\ngoes beyond TQL, additionally capturing off- and on- policy Deep Reinforcement\nLearning (DRL) algorithms, two distinct families of DRL algorithms that\nrecently gained attention for algorithmic pricing. We study multiple Bertrand\noligopoly variants and show that algorithmic collusion depends on the algorithm\nused. In our experiments, we observed that TQL tends to exhibit higher\ncollusion and price dispersion. Moreover, it suffers from instability and\ndisparity, as agents with higher learning rates consistently achieve higher\nprofits, and it lacks robustness in state representation, with pricing dynamics\nvarying significantly based on information access. In contrast, DRL algorithms,\nsuch as PPO and DQN, generally converge to lower prices closer to the Nash\nequilibrium. Additionally, we show that when pre-trained TQL agents interact\nwith DRL agents, the latter quickly outperforms the former, highlighting the\nadvantages of DRL in pricing competition. Lastly, we find that competition\nbetween heterogeneous DRL algorithms, such as PPO and DQN, tends to reduce the\nlikelihood of supra-competitive pricing.",
      "authors": [
        "Shidi Deng",
        "Maximilian Schiffer",
        "Martin Bichler"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11270v1",
        "http://arxiv.org/pdf/2503.11270v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11163v1",
      "title": "A Benchmarking Study of Vision-based Robotic Grasping Algorithms",
      "published": "2025-03-14T08:03:20Z",
      "updated": "2025-03-14T08:03:20Z",
      "summary": "We present a benchmarking study of vision-based robotic grasping algorithms\nwith distinct approaches, and provide a comparative analysis. In particular, we\ncompare two machine-learning-based and two analytical algorithms using an\nexisting benchmarking protocol from the literature and determine the\nalgorithm's strengths and weaknesses under different experimental conditions.\nThese conditions include variations in lighting, background textures, cameras\nwith different noise levels, and grippers. We also run analogous experiments in\nsimulations and with real robots and present the discrepancies. Some\nexperiments are also run in two different laboratories using same protocols to\nfurther analyze the repeatability of our results. We believe that this study,\ncomprising 5040 experiments, provides important insights into the role and\nchallenges of systematic experimentation in robotic manipulation, and guides\nthe development of new algorithms by considering the factors that could impact\nthe performance. The experiment recordings and our benchmarking software are\npublicly available.",
      "authors": [
        "Bharath K Rameshbabu",
        "Sumukh S Balakrishna",
        "Brian Flynn",
        "Vinarak Kapoor",
        "Adam Norton",
        "Holly Yanco",
        "Berk Calli"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "68T99"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11163v1",
        "http://arxiv.org/pdf/2503.11163v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11081v1",
      "title": "MoMa-Kitchen: A 100K+ Benchmark for Affordance-Grounded Last-Mile\n  Navigation in Mobile Manipulation",
      "published": "2025-03-14T04:47:38Z",
      "updated": "2025-03-14T04:47:38Z",
      "summary": "In mobile manipulation, navigation and manipulation are often treated as\nseparate problems, resulting in a significant gap between merely approaching an\nobject and engaging with it effectively. Many navigation approaches primarily\ndefine success by proximity to the target, often overlooking the necessity for\noptimal positioning that facilitates subsequent manipulation. To address this,\nwe introduce MoMa-Kitchen, a benchmark dataset comprising over 100k samples\nthat provide training data for models to learn optimal final navigation\npositions for seamless transition to manipulation. Our dataset includes\naffordance-grounded floor labels collected from diverse kitchen environments,\nin which robotic mobile manipulators of different models attempt to grasp\ntarget objects amidst clutter. Using a fully automated pipeline, we simulate\ndiverse real-world scenarios and generate affordance labels for optimal\nmanipulation positions. Visual data are collected from RGB-D inputs captured by\na first-person view camera mounted on the robotic arm, ensuring consistency in\nviewpoint during data collection. We also develop a lightweight baseline model,\nNavAff, for navigation affordance grounding that demonstrates promising\nperformance on the MoMa-Kitchen benchmark. Our approach enables models to learn\naffordance-based final positioning that accommodates different arm types and\nplatform heights, thereby paving the way for more robust and generalizable\nintegration of navigation and manipulation in embodied AI. Project page:\n\\href{https://momakitchen.github.io/}{https://momakitchen.github.io/}.",
      "authors": [
        "Pingrui Zhang",
        "Xianqiang Gao",
        "Yuhan Wu",
        "Kehui Liu",
        "Dong Wang",
        "Zhigang Wang",
        "Bin Zhao",
        "Yan Ding",
        "Xuelong Li"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11081v1",
        "http://arxiv.org/pdf/2503.11081v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11065v1",
      "title": "Low-cost Real-world Implementation of the Swing-up Pendulum for Deep\n  Reinforcement Learning Experiments",
      "published": "2025-03-14T04:18:36Z",
      "updated": "2025-03-14T04:18:36Z",
      "summary": "Deep reinforcement learning (DRL) has had success in virtual and simulated\ndomains, but due to key differences between simulated and real-world\nenvironments, DRL-trained policies have had limited success in real-world\napplications. To assist researchers to bridge the \\textit{sim-to-real gap}, in\nthis paper, we describe a low-cost physical inverted pendulum apparatus and\nsoftware environment for exploring sim-to-real DRL methods. In particular, the\ndesign of our apparatus enables detailed examination of the delays that arise\nin physical systems when sensing, communicating, learning, inferring and\nactuating. Moreover, we wish to improve access to educational systems, so our\napparatus uses readily available materials and parts to reduce cost and\nlogistical barriers. Our design shows how commercial, off-the-shelf electronics\nand electromechanical and sensor systems, combined with common metal\nextrusions, dowel and 3D printed couplings provide a pathway for affordable\nphysical DRL apparatus. The physical apparatus is complemented with a simulated\nenvironment implemented using a high-fidelity physics engine and OpenAI Gym\ninterface.",
      "authors": [
        "Peter B\u00f6hm",
        "Pauline Pounds",
        "Archie C. Chapman"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11065v1",
        "http://arxiv.org/pdf/2503.11065v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11059v1",
      "title": "Training Directional Locomotion for Quadrupedal Low-Cost Robotic Systems\n  via Deep Reinforcement Learning",
      "published": "2025-03-14T03:53:01Z",
      "updated": "2025-03-14T03:53:01Z",
      "summary": "In this work we present Deep Reinforcement Learning (DRL) training of\ndirectional locomotion for low-cost quadrupedal robots in the real world. In\nparticular, we exploit randomization of heading that the robot must follow to\nfoster exploration of action-state transitions most useful for learning both\nforward locomotion as well as course adjustments. Changing the heading in\nepisode resets to current yaw plus a random value drawn from a normal\ndistribution yields policies able to follow complex trajectories involving\nfrequent turns in both directions as well as long straight-line stretches. By\nrepeatedly changing the heading, this method keeps the robot moving within the\ntraining platform and thus reduces human involvement and need for manual resets\nduring the training. Real world experiments on a custom-built, low-cost\nquadruped demonstrate the efficacy of our method with the robot successfully\nnavigating all validation tests. When trained with other approaches, the robot\nonly succeeds in forward locomotion test and fails when turning is required.",
      "authors": [
        "Peter B\u00f6hm",
        "Archie C. Chapman",
        "Pauline Pounds"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11059v1",
        "http://arxiv.org/pdf/2503.11059v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11046v1",
      "title": "Measuring Similarity in Causal Graphs: A Framework for Semantic and\n  Structural Analysis",
      "published": "2025-03-14T03:29:26Z",
      "updated": "2025-03-14T03:29:26Z",
      "summary": "Causal graphs are commonly used to understand and model complex systems.\nResearchers often construct these graphs from different perspectives, leading\nto significant variations for the same problem. Comparing causal graphs is,\ntherefore, essential for evaluating assumptions, integrating insights, and\nresolving disagreements. The rise of AI tools has further amplified this need,\nas they are increasingly used to generate hypothesized causal graphs by\nsynthesizing information from various sources such as prior research and\ncommunity inputs, providing the potential for automating and scaling causal\nmodeling for complex systems. Similar to humans, these tools also produce\ninconsistent results across platforms, versions, and iterations. Despite its\nimportance, research on causal graph comparison remains scarce. Existing\nmethods often focus solely on structural similarities, assuming identical\nvariable names, and fail to capture nuanced semantic relationships, which is\nessential for causal graph comparison. We address these gaps by investigating\nmethods for comparing causal graphs from both semantic and structural\nperspectives. First, we reviewed over 40 existing metrics and, based on\npredefined criteria, selected nine for evaluation from two threads of machine\nlearning: four semantic similarity metrics and five learning graph kernels. We\ndiscuss the usability of these metrics in simple examples to illustrate their\nstrengths and limitations. We then generated a synthetic dataset of 2,000\ncausal graphs using generative AI based on a reference diagram. Our findings\nreveal that each metric captures a different aspect of similarity, highlighting\nthe need to use multiple metrics.",
      "authors": [
        "Ning-Yuan Georgia Liu",
        "Flower Yang",
        "Mohammad S. Jalali"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 68R10, 62H30",
        "I.2.6; G.2.2; I.5.4; H.2.8"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11046v1",
        "http://arxiv.org/pdf/2503.11046v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11008v2",
      "title": "Comparative Analysis of Advanced AI-based Object Detection Models for\n  Pavement Marking Quality Assessment during Daytime",
      "published": "2025-03-14T02:06:46Z",
      "updated": "2025-03-17T02:29:40Z",
      "summary": "Visual object detection utilizing deep learning plays a vital role in\ncomputer vision and has extensive applications in transportation engineering.\nThis paper focuses on detecting pavement marking quality during daytime using\nthe You Only Look Once (YOLO) model, leveraging its advanced architectural\nfeatures to enhance road safety through precise and real-time assessments.\nUtilizing image data from New Jersey, this study employed three YOLOv8\nvariants: YOLOv8m, YOLOv8n, and YOLOv8x. The models were evaluated based on\ntheir prediction accuracy for classifying pavement markings into good,\nmoderate, and poor visibility categories. The results demonstrated that YOLOv8n\nprovides the best balance between accuracy and computational efficiency,\nachieving the highest mean Average Precision (mAP) for objects with good\nvisibility and demonstrating robust performance across various Intersections\nover Union (IoU) thresholds. This research enhances transportation safety by\noffering an automated and accurate method for evaluating the quality of\npavement markings.",
      "authors": [
        "Gian Antariksa",
        "Rohit Chakraborty",
        "Shriyank Somvanshi",
        "Subasish Das",
        "Mohammad Jalayer",
        "Deep Rameshkumar Patel",
        "David Mills"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11008v2",
        "http://arxiv.org/pdf/2503.11008v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10940v1",
      "title": "Automated Tomato Maturity Estimation Using an Optimized Residual Model\n  with Pruning and Quantization Techniques",
      "published": "2025-03-13T22:56:19Z",
      "updated": "2025-03-13T22:56:19Z",
      "summary": "Tomato maturity plays a pivotal role in optimizing harvest timing and\nensuring product quality, but current methods struggle to achieve high accuracy\nalong computational efficiency simultaneously. Existing deep learning\napproaches, while accurate, are often too computationally demanding for\npractical use in resource-constrained agricultural settings. In contrast,\nsimpler techniques fail to capture the nuanced features needed for precise\nclassification. This study aims to develop a computationally efficient tomato\nclassification model using the ResNet-18 architecture optimized through\ntransfer learning, pruning, and quantization techniques. Our objective is to\naddress the dual challenge of maintaining high accuracy while enabling\nreal-time performance on low-power edge devices. Then, these models were\ndeployed on an edge device to investigate their performance for tomato maturity\nclassification. The quantized model achieved an accuracy of 97.81%, with an\naverage classification time of 0.000975 seconds per image. The pruned and\nauto-tuned model also demonstrated significant improvements in deployment\nmetrics, further highlighting the benefits of optimization techniques. These\nresults underscore the potential for a balanced solution that meets the\naccuracy and efficiency demands of modern agricultural production, paving the\nway for practical, real-world deployment in resource-limited environments.",
      "authors": [
        "Muhammad Waseem",
        "Chung-Hsuan Huang",
        "Muhammad Muzzammil Sajjad",
        "Laraib Haider Naqvi",
        "Yaqoob Majeed",
        "Tanzeel Ur Rehman",
        "Tayyaba Nadeem"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10940v1",
        "http://arxiv.org/pdf/2503.10940v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10937v1",
      "title": "ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with\n  Multi-Modal Large Language Models and General Vision Models",
      "published": "2025-03-13T22:53:24Z",
      "updated": "2025-03-13T22:53:24Z",
      "summary": "Face Recognition Systems (FRS) are increasingly vulnerable to face-morphing\nattacks, prompting the development of Morphing Attack Detection (MAD)\nalgorithms. However, a key challenge in MAD lies in its limited\ngeneralizability to unseen data and its lack of explainability-critical for\npractical application environments such as enrolment stations and automated\nborder control systems. Recognizing that most existing MAD algorithms rely on\nsupervised learning paradigms, this work explores a novel approach to MAD using\nzero-shot learning leveraged on Large Language Models (LLMs). We propose two\ntypes of zero-shot MAD algorithms: one leveraging general vision models and the\nother utilizing multimodal LLMs. For general vision models, we address the MAD\ntask by computing the mean support embedding of an independent support set\nwithout using morphed images. For the LLM-based approach, we employ the\nstate-of-the-art GPT-4 Turbo API with carefully crafted prompts. To evaluate\nthe feasibility of zero-shot MAD and the effectiveness of the proposed methods,\nwe constructed a print-scan morph dataset featuring various unseen morphing\nalgorithms, simulating challenging real-world application scenarios.\nExperimental results demonstrated notable detection accuracy, validating the\napplicability of zero-shot learning for MAD tasks. Additionally, our\ninvestigation into LLM-based MAD revealed that multimodal LLMs, such as\nChatGPT, exhibit remarkable generalizability to untrained MAD tasks.\nFurthermore, they possess a unique ability to provide explanations and\nguidance, which can enhance transparency and usability for end-users in\npractical applications.",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10937v1",
        "http://arxiv.org/pdf/2503.10937v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10918v1",
      "title": "Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for\n  Deep Learning Clusters",
      "published": "2025-03-13T22:13:20Z",
      "updated": "2025-03-13T22:13:20Z",
      "summary": "Scheduling deep learning (DL) models to train on powerful clusters with\naccelerators like GPUs and TPUs, presently falls short, either lacking\nfine-grained heterogeneity awareness or leaving resources substantially\nunder-utilized. To fill this gap, we propose a novel design of a task-level\nheterogeneity-aware scheduler, {\\em Hadar}, based on an optimization framework\nthat can boost resource utilization. {\\em Hadar} leverages the performance\ntraits of DL jobs on a heterogeneous DL cluster, characterizes the task-level\nperformance heterogeneity in the optimization problem, and makes scheduling\ndecisions across both spatial and temporal dimensions. %with the objective to\nreduce the average job completion time of DL jobs. It involves the primal-dual\nframework employing a dual subroutine, to solve the optimization problem and\nguide the scheduling design. Our trace-driven simulation with representative DL\nmodel training workloads demonstrates that {\\em Hadar} accelerates the total\ntime duration by 1.20$\\times$ when compared with its state-of-the-art\nheterogeneity-aware counterpart, Gavel. Further, our {\\em Hadar} scheduler is\nenhanced to {\\em HadarE} by forking each job into multiple copies to let a job\ntrain concurrently on heterogeneous GPUs resided on separate available nodes\n(i.e., machines or servers) for resource utilization enhancement. {\\em HadarE}\nis evaluated extensively on physical DL clusters for comparison with {\\em\nHadar} and Gavel. With substantial enhancement in cluster resource utilization\n(by 1.45$\\times$), {\\em HadarE} exhibits considerable speed-ups in DL model\ntraining, reducing the total time duration by 50\\% (or 80\\%) on an Amazon's AWS\n(or our lab) cluster, while producing trained DL models with consistently\nbetter inference quality than those trained by \\textit{Hadar}.",
      "authors": [
        "Abeda Sultana",
        "Nabin Pakka",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; F.1.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10918v1",
        "http://arxiv.org/pdf/2503.10918v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10894v1",
      "title": "HyperDAS: Towards Automating Mechanistic Interpretability with\n  Hypernetworks",
      "published": "2025-03-13T21:25:38Z",
      "updated": "2025-03-13T21:25:38Z",
      "summary": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.",
      "authors": [
        "Jiuding Sun",
        "Jing Huang",
        "Sidharth Baskaran",
        "Karel D'Oosterlinck",
        "Christopher Potts",
        "Michael Sklar",
        "Atticus Geiger"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10894v1",
        "http://arxiv.org/pdf/2503.10894v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10886v1",
      "title": "Taxonomic Reasoning for Rare Arthropods: Combining Dense Image\n  Captioning and RAG for Interpretable Classification",
      "published": "2025-03-13T21:18:10Z",
      "updated": "2025-03-13T21:18:10Z",
      "summary": "In the context of pressing climate change challenges and the significant\nbiodiversity loss among arthropods, automated taxonomic classification from\norganismal images is a subject of intense research. However, traditional AI\npipelines based on deep neural visual architectures such as CNNs or ViTs face\nlimitations such as degraded performance on the long-tail of classes and the\ninability to reason about their predictions. We integrate image captioning and\nretrieval-augmented generation (RAG) with large language models (LLMs) to\nenhance biodiversity monitoring, showing particular promise for characterizing\nrare and unknown arthropod species. While a naive Vision-Language Model (VLM)\nexcels in classifying images of common species, the RAG model enables\nclassification of rarer taxa by matching explicit textual descriptions of\ntaxonomic features to contextual biodiversity text data from external sources.\nThe RAG model shows promise in reducing overconfidence and enhancing accuracy\nrelative to naive LLMs, suggesting its viability in capturing the nuances of\ntaxonomic hierarchy, particularly at the challenging family and genus levels.\nOur findings highlight the potential for modern vision-language AI pipelines to\nsupport biodiversity conservation initiatives, emphasizing the role of\ncomprehensive data curation and collaboration with citizen science platforms to\nimprove species identification, unknown species characterization and ultimately\ninform conservation strategies.",
      "authors": [
        "Nathaniel Lesperance",
        "Sujeevan Ratnasingham",
        "Graham W. Taylor"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "q-bio.PE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10886v1",
        "http://arxiv.org/pdf/2503.10886v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10798v1",
      "title": "The Atacama Cosmology Telescope: The Development of Machine Learning\n  Tools for Detecting Millimeter Sources in Timestream Pre-processing",
      "published": "2025-03-13T18:50:19Z",
      "updated": "2025-03-13T18:50:19Z",
      "summary": "We present a new machine learning algorithm for classifying short-duration\nfeatures in raw time ordered data (TODs) of cosmic microwave background survey\nobservations. The algorithm, specifically designed for the Atacama Cosmology\nTelescope (ACT), works in conjunction with the previous TOD preprocessing\ntechniques that employ statistical thresholding to indiscriminately remove all\nlarge spikes in the data, whether they are due to noise features, cosmic rays,\nor true astrophysical sources in a process called \"data cuts\". This has the\nundesirable effect of excising real astrophysical sources, including\ntransients, from the data. The machine learning algorithm demonstrated in this\nwork uses the output from these data cuts and is able to differentiate between\nelectronic noise, cosmic rays, and point sources, enabling the removal of\nundesired signals while retaining true astrophysical signals during TOD\npre-processing. We achieve an overall accuracy of 90% in categorizing data\nspikes of different origin and, importantly, 94% for identifying those caused\nby astrophysical sources. Our algorithm also measures the amplitude of any\ndetected source seen more than once and produces a sub-minute to minute light\ncurve, providing information on its short timescale variability. This automated\nalgorithm for source detection and amplitude estimation will be particularly\nuseful for upcoming surveys with large data volumes, such as the Simons\nObservatory.",
      "authors": [
        "Simran K. Nerval",
        "Erika Hornecker",
        "Yilun Guan",
        "Zeling Zhang",
        "Adam Hincks",
        "Emily Biermann",
        "J. Richard Bond",
        "Justin Clancy",
        "Rolando Dunner",
        "Allen Foster",
        "Carlos Hervias-Caimapo",
        "Renee Hlozek",
        "Thomas W. Morris",
        "Sigurd Naess",
        "John Orlowski-Scherer",
        "Cristobal Sifon",
        "Jesse Treu"
      ],
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10798v1",
        "http://arxiv.org/pdf/2503.10798v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10586v2",
      "title": "Unlock the Power of Unlabeled Data in Language Driving Model",
      "published": "2025-03-13T17:36:36Z",
      "updated": "2025-03-15T06:25:33Z",
      "summary": "Recent Vision-based Large Language Models~(VisionLLMs) for autonomous driving\nhave seen rapid advancements. However, such promotion is extremely dependent on\nlarge-scale high-quality annotated data, which is costly and labor-intensive.\nTo address this issue, we propose unlocking the value of abundant yet unlabeled\ndata to improve the language-driving model in a semi-supervised learning\nmanner. Specifically, we first introduce a series of template-based prompts to\nextract scene information, generating questions that create pseudo-answers for\nthe unlabeled data based on a model trained with limited labeled data. Next, we\npropose a Self-Consistency Refinement method to improve the quality of these\npseudo-annotations, which are later used for further training. By utilizing a\npre-trained VisionLLM (e.g., InternVL), we build a strong Language Driving\nModel (LDM) for driving scene question-answering, outperforming previous\nstate-of-the-art methods. Extensive experiments on the DriveLM benchmark show\nthat our approach performs well with just 5% labeled data, achieving\ncompetitive performance against models trained with full datasets. In\nparticular, our LDM achieves 44.85% performance with limited labeled data,\nincreasing to 54.27% when using unlabeled data, while models trained with full\ndatasets reach 60.68% on the DriveLM benchmark.",
      "authors": [
        "Chaoqun Wang",
        "Jie Yang",
        "Xiaobin Hong",
        "Ruimao Zhang"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10586v2",
        "http://arxiv.org/pdf/2503.10586v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10520v1",
      "title": "CountPath: Automating Fragment Counting in Digital Pathology",
      "published": "2025-03-13T16:29:16Z",
      "updated": "2025-03-13T16:29:16Z",
      "summary": "Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.",
      "authors": [
        "Ana Beatriz Vieira",
        "Maria Valente",
        "Diana Montezuma",
        "Tom\u00e9 Albuquerque",
        "Liliana Ribeiro",
        "Domingos Oliveira",
        "Jo\u00e3o Monteiro",
        "Sofia Gon\u00e7alves",
        "Isabel M. Pinto",
        "Jaime S. Cardoso",
        "Arlindo L. Oliveira"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2; I.4"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10520v1",
        "http://arxiv.org/pdf/2503.10520v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10419v2",
      "title": "A nonlinear real time capable motion cueing algorithm based on deep\n  reinforcement learning",
      "published": "2025-03-13T14:39:19Z",
      "updated": "2025-03-19T13:54:58Z",
      "summary": "In motion simulation, motion cueing algorithms are used for the trajectory\nplanning of the motion simulator platform, where workspace limitations prevent\ndirect reproduction of reference trajectories. Strategies such as motion\nwashout, which return the platform to its center, are crucial in these\nsettings. For serial robotic MSPs with highly nonlinear workspaces, it is\nessential to maximize the efficient utilization of the MSPs kinematic and\ndynamic capabilities. Traditional approaches, including classical washout\nfiltering and linear model predictive control, fail to consider\nplatform-specific, nonlinear properties, while nonlinear model predictive\ncontrol, though comprehensive, imposes high computational demands that hinder\nreal-time, pilot-in-the-loop application without further simplification. To\novercome these limitations, we introduce a novel approach using deep\nreinforcement learning for motion cueing, demonstrated here for the first time\nin a 6-degree-of-freedom setting with full consideration of the MSPs kinematic\nnonlinearities. Previous work by the authors successfully demonstrated the\napplication of DRL to a simplified 2-DOF setup, which did not consider\nkinematic or dynamic constraints. This approach has been extended to all 6 DOF\nby incorporating a complete kinematic model of the MSP into the algorithm, a\ncrucial step for enabling its application on a real motion simulator. The\ntraining of the DRL-MCA is based on Proximal Policy Optimization in an\nactor-critic implementation combined with an automated hyperparameter\noptimization. After detailing the necessary training framework and the\nalgorithm itself, we provide a comprehensive validation, demonstrating that the\nDRL MCA achieves competitive performance against established algorithms.\nMoreover, it generates feasible trajectories by respecting all system\nconstraints and meets all real-time requirements with low...",
      "authors": [
        "Hendrik Scheidel",
        "Camilo Gonzalez",
        "Houshyar Asadi",
        "Tobias Bellmann",
        "Andreas Seefried",
        "Shady Mohamed",
        "Saeid Nahavandi"
      ],
      "categories": [
        "eess.SY",
        "cs.RO",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10419v2",
        "http://arxiv.org/pdf/2503.10419v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10404v1",
      "title": "Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in\n  Neural Architecture Search",
      "published": "2025-03-13T14:30:17Z",
      "updated": "2025-03-13T14:30:17Z",
      "summary": "Neural Architecture Search (NAS) has become an essential tool for designing\neffective and efficient neural networks. In this paper, we investigate the\ngeometric properties of neural architecture spaces commonly used in\ndifferentiable NAS methods, specifically NAS-Bench-201 and DARTS. By defining\nflatness metrics such as neighborhoods and loss barriers along paths in\narchitecture space, we reveal locality and flatness characteristics analogous\nto the well-known properties of neural network loss landscapes in weight space.\nIn particular, we find that highly accurate architectures cluster together in\nflat regions, while suboptimal architectures remain isolated, unveiling the\ndetailed geometrical structure of the architecture search landscape. Building\non these insights, we propose Architecture-Aware Minimization (A$^2$M), a novel\nanalytically derived algorithmic framework that explicitly biases, for the\nfirst time, the gradient of differentiable NAS methods towards flat minima in\narchitecture space. A$^2$M consistently improves generalization over\nstate-of-the-art DARTS-based algorithms on benchmark datasets including\nCIFAR-10, CIFAR-100, and ImageNet16-120, across both NAS-Bench-201 and DARTS\nsearch spaces. Notably, A$^2$M is able to increase the test accuracy, on\naverage across different differentiable NAS methods, by +3.60\\% on CIFAR-10,\n+4.60\\% on CIFAR-100, and +3.64\\% on ImageNet16-120, demonstrating its superior\neffectiveness in practice. A$^2$M can be easily integrated into existing\ndifferentiable NAS frameworks, offering a versatile tool for future research\nand applications in automated machine learning. We open-source our code at\nhttps://github.com/AI-Tech-Research-Lab/AsquaredM.",
      "authors": [
        "Matteo Gambella",
        "Fabrizio Pittorino",
        "Manuel Roveri"
      ],
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10404v1",
        "http://arxiv.org/pdf/2503.10404v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10371v1",
      "title": "A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted\n  Features-based Deep Learning Networks for Facial Palsy Detection",
      "published": "2025-03-13T13:48:35Z",
      "updated": "2025-03-13T13:48:35Z",
      "summary": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).",
      "authors": [
        "Heng Yim Nicole Oo",
        "Min Hun Lee",
        "Jeong Hoon Lim"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10371v1",
        "http://arxiv.org/pdf/2503.10371v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10370v1",
      "title": "LUMOS: Language-Conditioned Imitation Learning with World Models",
      "published": "2025-03-13T13:48:24Z",
      "updated": "2025-03-13T13:48:24Z",
      "summary": "We introduce LUMOS, a language-conditioned multi-task imitation learning\nframework for robotics. LUMOS learns skills by practicing them over many\nlong-horizon rollouts in the latent space of a learned world model and\ntransfers these skills zero-shot to a real robot. By learning on-policy in the\nlatent space of the learned world model, our algorithm mitigates policy-induced\ndistribution shift which most offline imitation learning methods suffer from.\nLUMOS learns from unstructured play data with fewer than 1% hindsight language\nannotations but is steerable with language commands at test time. We achieve\nthis coherent long-horizon performance by combining latent planning with both\nimage- and language-based hindsight goal relabeling during training, and by\noptimizing an intrinsic reward defined in the latent space of the world model\nover multiple time steps, effectively reducing covariate shift. In experiments\non the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior\nlearning-based methods with comparable approaches on chained multi-task\nevaluations. To the best of our knowledge, we are the first to learn a\nlanguage-conditioned continuous visuomotor control for a real-world robot\nwithin an offline world model. Videos, dataset and code are available at\nhttp://lumos.cs.uni-freiburg.de.",
      "authors": [
        "Iman Nematollahi",
        "Branton DeMoss",
        "Akshay L Chandra",
        "Nick Hawes",
        "Wolfram Burgard",
        "Ingmar Posner"
      ],
      "categories": [
        "cs.RO",
        "cs.CV",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10370v1",
        "http://arxiv.org/pdf/2503.10370v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10362v1",
      "title": "BioSerenity-E1: a self-supervised EEG model for medical applications",
      "published": "2025-03-13T13:42:46Z",
      "updated": "2025-03-13T13:42:46Z",
      "summary": "Electroencephalography (EEG) serves as an essential diagnostic tool in\nneurology; however, its accurate manual interpretation is a time-intensive\nprocess that demands highly specialized expertise, which remains relatively\nscarce and not consistently accessible. To address these limitations, the\nimplementation of automated pre-screening and analysis systems for EEG data\nholds considerable promise. Advances in self-supervised learning made it\npossible to pre-train complex deep learning architectures on large volumes of\nunlabeled EEG data to learn generalizable representations, that can later be\nused to enhance performance on multiple tasks while needing less downstream\ndata. In the present paper, we introduce BioSerenity-E1, the first of a family\nof self-supervised foundation models for clinical EEG applications that\ncombines spectral tokenization with masked prediction to achieve\nstate-of-the-art performance across relevant diagnostic tasks. The two-phase\nself-supervised pretraining framework initially acquires compressed EEG\nrepresentations via a transformer-based VQ-VAE architecture designed to\nreconstruct log-multitaper spectral projections, then implements extensive (70%\nblock) masked token prediction to force the model to learn complex\nspatiotemporal dependencies in EEG signals. BioSerenity-E1 achieves strong\nperformance across three clinical tasks, either in line or above\nstate-of-the-art methods: seizure detection (AUROC = 0.926, Sensitivity =\n0.909), normal/abnormal classification (AUPRC = 0.970 on proprietary data;\n0.910 on TUH-Abnormal), and multiclass pathology differentiation on unbalanced\ndata (Weighted F1 = 0.730). The utility of BioSerenity-E1 is further confirmed\nin low-data regimes scenarios, showing clear improvements in AUPRC (from +2% to\n17%) when trained on less than 10% of the available data.",
      "authors": [
        "Ruggero G. Bettinardi",
        "Mohamed Rahmouni",
        "Ulysse Gimenez"
      ],
      "categories": [
        "q-bio.QM",
        "cs.LG",
        "eess.SP",
        "q-bio.NC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10362v1",
        "http://arxiv.org/pdf/2503.10362v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10334v1",
      "title": "Enhanced View Planning for Robotic Harvesting: Tackling Occlusions with\n  Imitation Learning",
      "published": "2025-03-13T13:12:52Z",
      "updated": "2025-03-13T13:12:52Z",
      "summary": "In agricultural automation, inherent occlusion presents a major challenge for\nrobotic harvesting. We propose a novel imitation learning-based viewpoint\nplanning approach to actively adjust camera viewpoint and capture unobstructed\nimages of the target crop. Traditional viewpoint planners and existing\nlearning-based methods, depend on manually designed evaluation metrics or\nreward functions, often struggle to generalize to complex, unseen scenarios.\nOur method employs the Action Chunking with Transformer (ACT) algorithm to\nlearn effective camera motion policies from expert demonstrations. This enables\ncontinuous six-degree-of-freedom (6-DoF) viewpoint adjustments that are\nsmoother, more precise and reveal occluded targets. Extensive experiments in\nboth simulated and real-world environments, featuring agricultural scenarios\nand a 6-DoF robot arm equipped with an RGB-D camera, demonstrate our method's\nsuperior success rate and efficiency, especially in complex occlusion\nconditions, as well as its ability to generalize across different crops without\nreprogramming. This study advances robotic harvesting by providing a practical\n\"learn from demonstration\" (LfD) solution to occlusion challenges, ultimately\nenhancing autonomous harvesting performance and productivity.",
      "authors": [
        "Lun Li",
        "Hamidreza Kasaei"
      ],
      "categories": [
        "cs.RO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10334v1",
        "http://arxiv.org/pdf/2503.10334v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10306v1",
      "title": "Test Amplification for REST APIs Using \"Out-of-the-box\" Large Language\n  Models",
      "published": "2025-03-13T12:30:14Z",
      "updated": "2025-03-13T12:30:14Z",
      "summary": "REST APIs are an indispensable building block in today's cloud-native\napplications, so testing them is critically important. However, writing\nautomated tests for such REST APIs is challenging because one needs strong and\nreadable tests that exercise the boundary values of the protocol embedded in\nthe REST API. In this paper, we report our experience with using \"out of the\nbox\" large language models (ChatGPT and GitHub's Copilot) to amplify REST API\ntest suites. We compare the resulting tests based on coverage and\nunderstandability, and we derive a series of guidelines and lessons learned\nconcerning the prompts that result in the strongest test suite.",
      "authors": [
        "Tolgahan Bardakci",
        "Serge Demeyer",
        "Mutlu Beyazit"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10306v1",
        "http://arxiv.org/pdf/2503.10306v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10294v1",
      "title": "Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy\n  for Analysing Wiki Deletion Discussions",
      "published": "2025-03-13T12:07:35Z",
      "updated": "2025-03-13T12:07:35Z",
      "summary": "Automated content moderation for collaborative knowledge hubs like Wikipedia\nor Wikidata is an important yet challenging task due to multiple factors. In\nthis paper, we construct a database of discussions happening around articles\nmarked for deletion in several Wikis and in three languages, which we then use\nto evaluate a range of LMs on different tasks (from predicting the outcome of\nthe discussion to identifying the implicit policy an individual comment might\nbe pointing to). Our results reveal, among others, that discussions leading to\ndeletion are easier to predict, and that, surprisingly, self-produced tags\n(keep, delete or redirect) don't always help guiding the classifiers,\npresumably because of users' hesitation or deliberation within comments.",
      "authors": [
        "Hsuvas Borkakoty",
        "Luis Espinosa-Anke"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10294v1",
        "http://arxiv.org/pdf/2503.10294v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10723v1",
      "title": "RankPO: Preference Optimization for Job-Talent Matching",
      "published": "2025-03-13T10:14:37Z",
      "updated": "2025-03-13T10:14:37Z",
      "summary": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.",
      "authors": [
        "Yafei Zhang",
        "Murray Wang",
        "Yu Wang",
        "Xiaohui Wang"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10723v1",
        "http://arxiv.org/pdf/2503.10723v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10156v2",
      "title": "Automatic quality control in multi-centric fetal brain MRI\n  super-resolution reconstruction",
      "published": "2025-03-13T08:34:40Z",
      "updated": "2025-03-17T10:05:34Z",
      "summary": "Quality control (QC) has long been considered essential to guarantee the\nreliability of neuroimaging studies. It is particularly important for fetal\nbrain MRI, where acquisitions and image processing techniques are less\nstandardized than in adult imaging. In this work, we focus on automated quality\ncontrol of super-resolution reconstruction (SRR) volumes of fetal brain MRI, an\nimportant processing step where multiple stacks of thick 2D slices are\nregistered together and combined to build a single, isotropic and artifact-free\nT2 weighted volume. We propose FetMRQC$_{SR}$, a machine-learning method that\nextracts more than 100 image quality metrics to predict image quality scores\nusing a random forest model. This approach is well suited to a problem that is\nhigh dimensional, with highly heterogeneous data and small datasets. We\nvalidate FetMRQC$_{SR}$ in an out-of-domain (OOD) setting and report high\nperformance (ROC AUC = 0.89), even when faced with data from an unknown site or\nSRR method. We also investigate failure cases and show that they occur in\n$45\\%$ of the images due to ambiguous configurations for which the rating from\nthe expert is arguable. These results are encouraging and illustrate how a non\ndeep learning-based method like FetMRQC$_{SR}$ is well suited to this\nmultifaceted problem. Our tool, along with all the code used to generate, train\nand evaluate the model will be released upon acceptance of the paper.",
      "authors": [
        "Thomas Sanchez",
        "Vladyslav Zalevskyi",
        "Angeline Mihailov",
        "Gerard Mart\u00ed-Juan",
        "Elisenda Eixarch",
        "Andras Jakab",
        "Vincent Dunet",
        "M\u00e9riam Koob",
        "Guillaume Auzias",
        "Meritxell Bach Cuadra"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10156v2",
        "http://arxiv.org/pdf/2503.10156v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10717v1",
      "title": "Deep Learning-Based Automated Workflow for Accurate Segmentation and\n  Measurement of Abdominal Organs in CT Scans",
      "published": "2025-03-13T06:50:44Z",
      "updated": "2025-03-13T06:50:44Z",
      "summary": "Background: Automated analysis of CT scans for abdominal organ measurement is\ncrucial for improving diagnostic efficiency and reducing inter-observer\nvariability. Manual segmentation and measurement of organs such as the kidneys,\nliver, spleen, and prostate are time-consuming and subject to inconsistency,\nunderscoring the need for automated approaches.\n  Purpose: The purpose of this study is to develop and validate an automated\nworkflow for the segmentation and measurement of abdominal organs in CT scans\nusing advanced deep learning models, in order to improve accuracy, reliability,\nand efficiency in clinical evaluations.\n  Methods: The proposed workflow combines nnU-Net, U-Net++ for organ\nsegmentation, followed by a 3D RCNN model for measuring organ volumes and\ndimensions. The models were trained and evaluated on CT datasets with metrics\nsuch as precision, recall, and Mean Squared Error (MSE) to assess performance.\nSegmentation quality was verified for its adaptability to variations in patient\nanatomy and scanner settings.\n  Results: The developed workflow achieved high precision and recall values,\nexceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were\nlow, indicating a high level of consistency between predicted and ground truth\nmeasurements. The segmentation and measurement pipeline demonstrated robust\nperformance, providing accurate delineation and quantification of the kidneys,\nliver, spleen, and prostate.\n  Conclusion: The proposed approach offers an automated, efficient, and\nreliable solution for abdominal organ measurement in CT scans. By significantly\nreducing manual intervention, this workflow enhances measurement accuracy and\nconsistency, with potential for widespread clinical implementation. Future work\nwill focus on expanding the approach to other organs and addressing complex\npathological cases.",
      "authors": [
        "Praveen Shastry",
        "Ashok Sharma",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T99"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10717v1",
        "http://arxiv.org/pdf/2503.10717v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10049v1",
      "title": "Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based\n  Planner and Graph-based Policy",
      "published": "2025-03-13T05:02:49Z",
      "updated": "2025-03-13T05:02:49Z",
      "summary": "Multi-agent systems (MAS) have shown great potential in executing complex\ntasks, but coordination and safety remain significant challenges. Multi-Agent\nReinforcement Learning (MARL) offers a promising framework for agent\ncollaboration, but it faces difficulties in handling complex tasks and\ndesigning reward functions. The introduction of Large Language Models (LLMs)\nhas brought stronger reasoning and cognitive abilities to MAS, but existing\nLLM-based systems struggle to respond quickly and accurately in dynamic\nenvironments. To address these challenges, we propose LLM-based Graph\nCollaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and\nMARL. This framework decomposes complex tasks into executable subtasks and\nachieves efficient collaboration among multiple agents through graph-based\ncoordination. Specifically, LGC-MARL consists of two main components: an LLM\nplanner and a graph-based collaboration meta policy. The LLM planner transforms\ncomplex task instructions into a series of executable subtasks, evaluates the\nrationality of these subtasks using a critic model, and generates an action\ndependency graph. The graph-based collaboration meta policy facilitates\ncommunication and collaboration among agents based on the action dependency\ngraph, and adapts to new task environments through meta-learning. Experimental\nresults on the AI2-THOR simulation platform demonstrate the superior\nperformance and scalability of LGC-MARL in completing various complex tasks.",
      "authors": [
        "Ziqi Jia",
        "Junjie Li",
        "Xiaoyang Qu",
        "Jianzong Wang"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10049v1",
        "http://arxiv.org/pdf/2503.10049v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10040v1",
      "title": "Rapid analysis of point-contact Andreev reflection spectra via machine\n  learning with adaptive data augmentation",
      "published": "2025-03-13T04:45:38Z",
      "updated": "2025-03-13T04:45:38Z",
      "summary": "Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.",
      "authors": [
        "Dongik Lee",
        "Valentin Stanev",
        "Xiaohang Zhang",
        "Mijeong Kang",
        "Ichiro Takeuchi",
        "Seunghun Lee"
      ],
      "categories": [
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10040v1",
        "http://arxiv.org/pdf/2503.10040v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09988v1",
      "title": "Label Unbalance in High-frequency Trading",
      "published": "2025-03-13T02:55:06Z",
      "updated": "2025-03-13T02:55:06Z",
      "summary": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
      "authors": [
        "Zijian Zhao",
        "Xuming Chen",
        "Jiayu Wen",
        "Mingwen Liu",
        "Xiaoteng Ma"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09988v1",
        "http://arxiv.org/pdf/2503.09988v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09905v1",
      "title": "Quantization for OpenAI's Whisper Models: A Comparative Analysis",
      "published": "2025-03-12T23:50:35Z",
      "updated": "2025-03-12T23:50:35Z",
      "summary": "Automated speech recognition (ASR) models have gained prominence for\napplications such as captioning, speech translation, and live transcription.\nThis paper studies Whisper and two model variants: one optimized for live\nspeech streaming and another for offline transcription. Notably, these models\nhave been found to generate hallucinated content, reducing transcription\nreliability. Furthermore, larger model variants exhibit increased latency and\npose challenges for deployment on resource-constrained devices. This study\nanalyzes the similarities and differences between three Whisper models,\nqualitatively examining their distinct capabilities. Next, this study\nquantifies the impact of model quantization on latency and evaluates its\nviability for edge deployment. Using the open source LibriSpeech dataset, this\npaper evaluates the word error rate (WER) along with latency analysis of\nwhispercpp using 3 quantization methods (INT4, INT5, INT8). Results show that\nquantization reduces latency by 19\\% and model size by 45\\%, while preserving\ntranscription accuracy. These findings provide insights into the optimal use\ncases of different Whisper models and edge device deployment possibilities. All\ncode, datasets, and implementation details are available in a public GitHub\nrepository: https://github.com/allisonandreyev/WhisperQuantization.git",
      "authors": [
        "Allison Andreyev"
      ],
      "categories": [
        "cs.SD",
        "cs.CL",
        "cs.LG",
        "eess.AS",
        "68T50, 68T10",
        "I.2.7; I.5.4; H.5.1"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09905v1",
        "http://arxiv.org/pdf/2503.09905v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09885v1",
      "title": "QuickDraw: Fast Visualization, Analysis and Active Learning for Medical\n  Image Segmentation",
      "published": "2025-03-12T22:53:27Z",
      "updated": "2025-03-12T22:53:27Z",
      "summary": "Analyzing CT scans, MRIs and X-rays is pivotal in diagnosing and treating\ndiseases. However, detecting and identifying abnormalities from such medical\nimages is a time-intensive process that requires expert analysis and is prone\nto interobserver variability. To mitigate such issues, machine learning-based\nmodels have been introduced to automate and significantly reduce the cost of\nimage segmentation. Despite significant advances in medical image analysis in\nrecent years, many of the latest models are never applied in clinical settings\nbecause state-of-the-art models do not easily interface with existing medical\nimage viewers. To address these limitations, we propose QuickDraw, an\nopen-source framework for medical image visualization and analysis that allows\nusers to upload DICOM images and run off-the-shelf models to generate 3D\nsegmentation masks. In addition, our tool allows users to edit, export, and\nevaluate segmentation masks to iteratively improve state-of-the-art models\nthrough active learning. In this paper, we detail the design of our tool and\npresent survey results that highlight the usability of our software. Notably,\nwe find that QuickDraw reduces the time to manually segment a CT scan from four\nhours to six minutes and reduces machine learning-assisted segmentation time by\n10\\% compared to prior work. Our code and documentation are available at\nhttps://github.com/qd-seg/quickdraw",
      "authors": [
        "Daniel Syomichev",
        "Padmini Gopinath",
        "Guang-Lin Wei",
        "Eric Chang",
        "Ian Gordon",
        "Amanuel Seifu",
        "Rahul Pemmaraju",
        "Neehar Peri",
        "James Purtilo"
      ],
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09885v1",
        "http://arxiv.org/pdf/2503.09885v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09871v1",
      "title": "LuciBot: Automated Robot Policy Learning from Generated Videos",
      "published": "2025-03-12T22:07:36Z",
      "updated": "2025-03-12T22:07:36Z",
      "summary": "Automatically generating training supervision for embodied tasks is crucial,\nas manual designing is tedious and not scalable. While prior works use large\nlanguage models (LLMs) or vision-language models (VLMs) to generate rewards,\nthese approaches are largely limited to simple tasks with well-defined rewards,\nsuch as pick-and-place. This limitation arises because LLMs struggle to\ninterpret complex scenes compressed into text or code due to their restricted\ninput modality, while VLM-based rewards, though better at visual perception,\nremain limited by their less expressive output modality. To address these\nchallenges, we leverage the imagination capability of general-purpose video\ngeneration models. Given an initial simulation frame and a textual task\ndescription, the video generation model produces a video demonstrating task\ncompletion with correct semantics. We then extract rich supervisory signals\nfrom the generated video, including 6D object pose sequences, 2D segmentations,\nand estimated depth, to facilitate task learning in simulation. Our approach\nsignificantly improves supervision quality for complex embodied tasks, enabling\nlarge-scale training in simulators.",
      "authors": [
        "Xiaowen Qiu",
        "Yian Wang",
        "Jiting Cai",
        "Zhehuan Chen",
        "Chunru Lin",
        "Tsun-Hsuan Wang",
        "Chuang Gan"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09871v1",
        "http://arxiv.org/pdf/2503.09871v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09865v2",
      "title": "Identification and Classification of Human Performance related\n  Challenges during Remote Driving",
      "published": "2025-03-12T21:50:16Z",
      "updated": "2025-03-18T13:05:01Z",
      "summary": "Remote driving of vehicles is gaining in importance in the transportation\nsector, especially when Automated Driving Systems (ADSs) reach the limits of\ntheir system boundaries. This study investigates the challenges faced by human\nRemote Drivers (RDs) during remote driving, particularly focusing on the\nidentification and classification of human performance-related challenges\nthrough a comprehensive analysis of real-world remote driving data Las Vegas.\nFor this purpose, a total of 183 RD performance-related Safety Driver (SD)\ninterventions were analyzed and classified using an introduced severity\nclassification. As it is essential to prevent the need for SD interventions,\nthis study identified and analyzed harsh driving events to detect an increased\nlikelihood of interventions by the SD. In addition, the results of the\nsubjective RD questionnaire are used to evaluate whether the objective metrics\nfrom SD interventions and harsh driving events can also be confirmed by the RDs\nand whether additional challenges can be uncovered. The analysis reveals\nlearning curves, showing a significant decrease in SD interventions as RD\nexperience increases. Early phases of remote driving experience, especially\nbelow 200 km of experience, showed the highest frequency of safety-related\nevents, including braking late for traffic signs and responding impatiently to\nother traffic participants. Over time, RDs follow defined rules for improving\ntheir control, with experience leading to less harsh braking, acceleration, and\nsteering maneuvers. The study contributes to understanding the requirements of\nRDS, emphasizing the importance of targeted training to address human\nperformance limitations. It further highlights the need for system improvements\nto address challenges like latency and the limited haptic feedback replaced by\nvisual feedback, which affect the RDs' perception and vehicle control.",
      "authors": [
        "Ole Hans",
        "J\u00fcrgen Adamy"
      ],
      "categories": [
        "eess.SY",
        "cs.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09865v2",
        "http://arxiv.org/pdf/2503.09865v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09839v1",
      "title": "The E-Rule: A Novel Composite Indicator for Predicting Economic\n  Recessions",
      "published": "2025-03-12T21:00:12Z",
      "updated": "2025-03-12T21:00:12Z",
      "summary": "This study develops the E-Rule, a novel composite recession indicator that\nintegrates financial market and labor market signals to improve the precision\nof recession forecasting. Combining the yield curve and the Sahm rule, the\nE-Rule provides a holistic and early-warning measure of economic downturns.\nUsing historical data from 1976 onward, we empirically evaluate the E-Rule's\npredictive power relative to traditional indicators. The analysis employs\nmachine learning techniques, including logistic regression, support vector\nmachines, gradient boosting, and random forests, to assess predictive accuracy.\nOur findings demonstrate that the E-Rule offers a superior lead time in\nforecasting recessions and improves stability over existing methods.",
      "authors": [
        "Esmaeil Ebadi"
      ],
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09839v1",
        "http://arxiv.org/pdf/2503.09839v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09829v2",
      "title": "SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey",
      "published": "2025-03-12T20:47:40Z",
      "updated": "2025-03-18T06:26:34Z",
      "summary": "Recent advances in deep learning and Transformers have driven major\nbreakthroughs in robotics by employing techniques such as imitation learning,\nreinforcement learning, and LLM-based multimodal perception and\ndecision-making. However, conventional deep learning and Transformer models\noften struggle to process data with inherent symmetries and invariances,\ntypically relying on large datasets or extensive data augmentation. Equivariant\nneural networks overcome these limitations by explicitly integrating symmetry\nand invariance into their architectures, leading to improved efficiency and\ngeneralization. This tutorial survey reviews a wide range of equivariant deep\nlearning and control methods for robotics, from classic to state-of-the-art,\nwith a focus on SE(3)-equivariant models that leverage the natural 3D\nrotational and translational symmetries in visual robotic manipulation and\ncontrol design. Using unified mathematical notation, we begin by reviewing key\nconcepts from group theory, along with matrix Lie groups and Lie algebras. We\nthen introduce foundational group-equivariant neural network design and show\nhow the group-equivariance can be obtained through their structure. Next, we\ndiscuss the applications of SE(3)-equivariant neural networks in robotics in\nterms of imitation learning and reinforcement learning. The SE(3)-equivariant\ncontrol design is also reviewed from the perspective of geometric control.\nFinally, we highlight the challenges and future directions of equivariant\nmethods in developing more robust, sample-efficient, and multi-modal real-world\nrobotic systems.",
      "authors": [
        "Joohwan Seo",
        "Soochul Yoo",
        "Junwoo Chang",
        "Hyunseok An",
        "Hyunwoo Ryu",
        "Soomi Lee",
        "Arvind Kruthiventy",
        "Jongeun Choi",
        "Roberto Horowitz"
      ],
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09829v2",
        "http://arxiv.org/pdf/2503.09829v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09807v1",
      "title": "How good are deep learning methods for automated road safety analysis\n  using video data? An experimental study",
      "published": "2025-03-12T20:17:50Z",
      "updated": "2025-03-12T20:17:50Z",
      "summary": "Image-based multi-object detection (MOD) and multi-object tracking (MOT) are\nadvancing at a fast pace. A variety of 2D and 3D MOD and MOT methods have been\ndeveloped for monocular and stereo cameras. Road safety analysis can benefit\nfrom those advancements. As crashes are rare events, surrogate measures of\nsafety (SMoS) have been developed for safety analyses. (Semi-)Automated safety\nanalysis methods extract road user trajectories to compute safety indicators,\nfor example, Time-to-Collision (TTC) and Post-encroachment Time (PET). Inspired\nby the success of deep learning in MOD and MOT, we investigate three MOT\nmethods, including one based on a stereo-camera, using the annotated KITTI\ntraffic video dataset. Two post-processing steps, IDsplit and SS, are developed\nto improve the tracking results and investigate the factors influencing the\nTTC. The experimental results show that, despite some advantages in terms of\nthe numbers of interactions or similarity to the TTC distributions, all the\ntested methods systematically over-estimate the number of interactions and\nunder-estimate the TTC: they report more interactions and more severe\ninteractions, making the road user interactions appear less safe than they are.\nFurther efforts will be directed towards testing more methods and more data, in\nparticular from roadside sensors, to verify the results and improve the\nperformance.",
      "authors": [
        "Qingwu Liu",
        "Nicolas Saunier",
        "Guillaume-Alexandre Bilodeau"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09807v1",
        "http://arxiv.org/pdf/2503.09807v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09793v1",
      "title": "Integrated Experiment and Simulation Co-Design: A Key Infrastructure for\n  Predictive Mesoscale Materials Modeling",
      "published": "2025-03-12T19:55:34Z",
      "updated": "2025-03-12T19:55:34Z",
      "summary": "The design of structural & functional materials for specialized applications\nis being fueled by rapid advancements in materials synthesis, characterization,\nmanufacturing, with sophisticated computational materials modeling frameworks\nthat span a wide spectrum of length & time scales in the mesoscale between\natomistic & continuum approaches. This is leading towards a systems-based\ndesign methodology that will replace traditional empirical approaches,\nembracing the principles of the Materials Genome Initiative. However, several\ngaps remain in this framework as it relates to advanced structural\nmaterials:(1) limited availability & access to high-fidelity experimental &\ncomputational datasets, (2) lack of co-design of experiments & simulation aimed\nat computational model validation,(3) lack of on-demand access to verified and\nvalidated codes for simulation and for experimental analyses, & (4) limited\nopportunities for workforce training and educational outreach. These\nshortcomings stifle major innovations in structural materials design. This\npaper describes plans for a community-driven research initiative that addresses\ncurrent gaps based on best-practice recommendations of leaders in mesoscale\nmodeling, experimentation & cyberinfrastructure obtained at an NSF-sponsored\nworkshop dedicated to this topic. The proposal is to create a hub for Mesoscale\nExperimentation and Simulation co-Operation (hMESO)-that will (I) provide\ncuration and sharing of models, data, & codes, (II) foster co-design of\nexperiments for model validation with systematic uncertainty quantification, &\n(III) provide a platform for education & workforce development. It will engage\nexperimental & computational experts in mesoscale mechanics and plasticity,\nalong with mathematicians and computer scientists with expertise in algorithms,\ndata science, machine learning, & large-scale cyberinfrastructure initiatives.",
      "authors": [
        "Shailendra P. Joshi",
        "Ashley Bucsek",
        "Darren C. Pagan",
        "Samantha Daly",
        "Suraj Ravindran",
        "Jaime Marian",
        "Miguel A. Bessa",
        "Surya R. Kalidindi",
        "Nikhil C. Admal",
        "Celia Reina",
        "Somnath Ghosh",
        "Jorge Vinals",
        "Ellad B. Tadmor"
      ],
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09793v1",
        "http://arxiv.org/pdf/2503.09793v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11711v1",
      "title": "Privacy-Preserved Automated Scoring using Federated Learning for\n  Educational Research",
      "published": "2025-03-12T19:06:25Z",
      "updated": "2025-03-12T19:06:25Z",
      "summary": "Data privacy remains a critical concern in educational research,\nnecessitating Institutional Review Board (IRB) certification and stringent data\nhandling protocols to ensure compliance with ethical standards. Traditional\napproaches rely on anonymization and controlled data-sharing mechanisms to\nfacilitate research while mitigating privacy risks. However, these methods\nstill involve direct access to raw student data, posing potential\nvulnerabilities and being time-consuming. This study proposes a federated\nlearning (FL) framework for automatic scoring in educational assessments,\neliminating the need to share raw data. Our approach leverages client-side\nmodel training, where student responses are processed locally on edge devices,\nand only optimized model parameters are shared with a central aggregation\nserver. To effectively aggregate heterogeneous model updates, we introduce an\nadaptive weighted averaging strategy, which dynamically adjusts weight\ncontributions based on client-specific learning characteristics. This method\nensures robust model convergence while preserving privacy. We evaluate our\nframework using assessment data from nine middle schools, comparing the\naccuracy of federated learning-based scoring models with traditionally trained\ncentralized models. A statistical significance test (paired t-test, $t(8) =\n2.29, p = 0.051$) confirms that the accuracy difference between the two\napproaches is not statistically significant, demonstrating that federated\nlearning achieves comparable performance while safeguarding student data.\nFurthermore, our method significantly reduces data collection, processing, and\ndeployment overhead, accelerating the adoption of AI-driven educational\nassessments in a privacy-compliant manner.",
      "authors": [
        "Ehsan Latif",
        "Xiaoming Zhai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11711v1",
        "http://arxiv.org/pdf/2503.11711v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11710v1",
      "title": "ConjointNet: Enhancing Conjoint Analysis for Preference Prediction with\n  Representation Learning",
      "published": "2025-03-12T19:01:59Z",
      "updated": "2025-03-12T19:01:59Z",
      "summary": "Understanding consumer preferences is essential to product design and\npredicting market response to these new products. Choice-based conjoint\nanalysis is widely used to model user preferences using their choices in\nsurveys. However, traditional conjoint estimation techniques assume simple\nlinear models. This assumption may lead to limited predictability and\ninaccurate estimation of product attribute contributions, especially on data\nthat has underlying non-linear relationships. In this work, we employ\nrepresentation learning to efficiently alleviate this issue. We propose\nConjointNet, which is composed of two novel neural architectures, to predict\nuser preferences. We demonstrate that the proposed ConjointNet models\noutperform traditional conjoint estimate techniques on two preference datasets\nby over 5%, and offer insights into non-linear feature interactions.",
      "authors": [
        "Yanxia Zhang",
        "Francine Chen",
        "Shabnam Hakimi",
        "Totte Harinen",
        "Alex Filipowicz",
        "Yan-Ying Chen",
        "Rumen Iliev",
        "Nikos Arechiga",
        "Kalani Murakami",
        "Kent Lyons",
        "Charlene Wu",
        "Matt Klenk"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11710v1",
        "http://arxiv.org/pdf/2503.11710v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09730v1",
      "title": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem\n  Proving",
      "published": "2025-03-12T18:20:47Z",
      "updated": "2025-03-12T18:20:47Z",
      "summary": "The most promising recent methods for AI reasoning require applying variants\nof reinforcement learning (RL) either on rolled out trajectories from the\nmodel, even for the step-wise rewards, or large quantities of human annotated\ntrajectory data. The reliance on the rolled-out trajectory renders the compute\ncost and time prohibitively high. In particular, the correctness of a reasoning\ntrajectory can typically only be judged at its completion, leading to sparse\nrewards in RL or requiring expensive synthetic data generation in expert\niteration-like methods. In this work, we focus on the Automatic Theorem Proving\n(ATP) task and propose a novel verifier-in-the-loop design, which unlike\nexisting approaches that leverage feedback on the entire reasoning trajectory,\nemploys an automated verifier to give intermediate feedback at each step of the\nreasoning process. Using Lean as the verifier, we empirically show that the\nstep-by-step local verification produces a global improvement in the model's\nreasoning accuracy and efficiency.",
      "authors": [
        "Sara Rajaee",
        "Kumar Pratik",
        "Gabriele Cesa",
        "Arash Behboodi"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09730v1",
        "http://arxiv.org/pdf/2503.09730v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.10298v2",
      "title": "Proceedings of the ISCA/ITG Workshop on Diversity in Large Speech and\n  Language Models",
      "published": "2025-03-12T17:58:57Z",
      "updated": "2025-03-14T06:24:05Z",
      "summary": "Machine learning techniques have conquered many different tasks in speech and\nnatural language processing, such as speech recognition, information\nextraction, text and speech generation, and human machine interaction using\nnatural language or speech (chatbots). Modern techniques typically rely on\nlarge models for representing general knowledge of one or several languages\n(Large Language Models, LLMs), or for representing speech and general audio\ncharacteristics. These models have been trained with large amounts of speech\nand language data, typically including web content. When humans interact with\nsuch technologies, the effectiveness of the interaction will be influenced by\nhow far humans make use of the same type of language the models have been\ntrained on or, in other words, if the models are able to generalize to the\nlanguage used by humans when interacting with the technology. This may lead to\nsome gradual forms of adaptation in human speech and language production, and\nusers who do not adapt may be excluded from efficient use of such technologies.\nOn top of this, as commercial model development follows market needs,\nunder-represented languages and dialects/sociolects may decrease in terms of\npriorities. Furthermore, for many lesser spoken languages the necessary data is\nnot available, which will worsen a digital divide in speech and language\ntechnology usage. The workshop sets out to discuss this problem based on\nscientific contributions from the perspective of computer science and\nlinguistics (including computational linguistics and NLP).",
      "authors": [
        "Sebastian M\u00f6ller",
        "Pia Knoeferle",
        "Britta Schulte",
        "Nils Feldhus"
      ],
      "categories": [
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2503.10298v2",
        "http://arxiv.org/pdf/2503.10298v2"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09669v1",
      "title": "Silent Branding Attack: Trigger-free Data Poisoning Attack on\n  Text-to-Image Diffusion Models",
      "published": "2025-03-12T17:21:57Z",
      "updated": "2025-03-12T17:21:57Z",
      "summary": "Text-to-image diffusion models have achieved remarkable success in generating\nhigh-quality contents from text prompts. However, their reliance on publicly\navailable data and the growing trend of data sharing for fine-tuning make these\nmodels particularly vulnerable to data poisoning attacks. In this work, we\nintroduce the Silent Branding Attack, a novel data poisoning method that\nmanipulates text-to-image diffusion models to generate images containing\nspecific brand logos or symbols without any text triggers. We find that when\ncertain visual patterns are repeatedly in the training data, the model learns\nto reproduce them naturally in its outputs, even without prompt mentions.\nLeveraging this, we develop an automated data poisoning algorithm that\nunobtrusively injects logos into original images, ensuring they blend naturally\nand remain undetected. Models trained on this poisoned dataset generate images\ncontaining logos without degrading image quality or text alignment. We\nexperimentally validate our silent branding attack across two realistic\nsettings on large-scale high-quality image datasets and style personalization\ndatasets, achieving high success rates even without a specific text trigger.\nHuman evaluation and quantitative metrics including logo detection show that\nour method can stealthily embed logos.",
      "authors": [
        "Sangwon Jang",
        "June Suk Choi",
        "Jaehyeong Jo",
        "Kimin Lee",
        "Sung Ju Hwang"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09669v1",
        "http://arxiv.org/pdf/2503.09669v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09409v1",
      "title": "AI-based Framework for Robust Model-Based Connector Mating in Robotic\n  Wire Harness Installation",
      "published": "2025-03-12T13:59:26Z",
      "updated": "2025-03-12T13:59:26Z",
      "summary": "Despite the widespread adoption of industrial robots in automotive assembly,\nwire harness installation remains a largely manual process, as it requires\nprecise and flexible manipulation. To address this challenge, we design a novel\nAI-based framework that automates cable connector mating by integrating force\ncontrol with deep visuotactile learning. Our system optimizes\nsearch-and-insertion strategies using first-order optimization over a\nmultimodal transformer architecture trained on visual, tactile, and\nproprioceptive data. Additionally, we design a novel automated data collection\nand optimization pipeline that minimizes the need for machine learning\nexpertise. The framework optimizes robot programs that run natively on standard\nindustrial controllers, permitting human experts to audit and certify them.\nExperimental validations on a center console assembly task demonstrate\nsignificant improvements in cycle times and robustness compared to conventional\nrobot programming approaches. Videos are available under\nhttps://claudius-kienle.github.io/AppMuTT.",
      "authors": [
        "Claudius Kienle",
        "Benjamin Alt",
        "Finn Schneider",
        "Tobias Pertlwieser",
        "Rainer J\u00e4kel",
        "Rania Rayyes"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "68T40",
        "I.2; J.2"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09409v1",
        "http://arxiv.org/pdf/2503.09409v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09304v1",
      "title": "Priority-Aware Preemptive Scheduling for Mixed-Priority Workloads in MoE\n  Inference",
      "published": "2025-03-12T11:56:01Z",
      "updated": "2025-03-12T11:56:01Z",
      "summary": "Large Language Models have revolutionized natural language processing, yet\nserving them efficiently in data centers remains challenging due to mixed\nworkloads comprising latency-sensitive (LS) and best-effort (BE) jobs. Existing\ninference systems employ iteration-level first-come-first-served scheduling,\ncausing head-of-line blocking when BE jobs delay LS jobs. We introduce QLLM, a\nnovel inference system designed for Mixture of Experts (MoE) models, featuring\na fine-grained, priority-aware preemptive scheduler. QLLM enables expert-level\npreemption, deferring BE job execution while minimizing LS time-to-first-token\n(TTFT). Our approach removes iteration-level scheduling constraints, enabling\nthe scheduler to preempt jobs at any layer based on priority. Evaluations on an\nNvidia A100 GPU show that QLLM significantly improves performance. It reduces\nLS TTFT by an average of $65.5\\times$ and meets the SLO at up to $7$\nrequests/sec, whereas the baseline fails to do so under the tested workload.\nAdditionally, it cuts LS turnaround time by up to $12.8\\times$ without\nimpacting throughput. QLLM is modular, extensible, and seamlessly integrates\nwith Hugging Face MoE models.",
      "authors": [
        "Mohammad Siavashi",
        "Faezeh Keshmiri Dindarloo",
        "Dejan Kostic",
        "Marco Chiesa"
      ],
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3721146.3721956",
        "http://arxiv.org/abs/2503.09304v1",
        "http://arxiv.org/pdf/2503.09304v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09655v1",
      "title": "A Deep Reinforcement Learning Approach to Automated Stock Trading, using\n  xLSTM Networks",
      "published": "2025-03-12T10:56:03Z",
      "updated": "2025-03-12T10:56:03Z",
      "summary": "Traditional Long Short-Term Memory (LSTM) networks are effective for handling\nsequential data but have limitations such as gradient vanishing and difficulty\nin capturing long-term dependencies, which can impact their performance in\ndynamic and risky environments like stock trading. To address these\nlimitations, this study explores the usage of the newly introduced Extended\nLong Short Term Memory (xLSTM) network in combination with a deep reinforcement\nlearning (DRL) approach for automated stock trading. Our proposed method\nutilizes xLSTM networks in both actor and critic components, enabling effective\nhandling of time series data and dynamic market environments. Proximal Policy\nOptimization (PPO), with its ability to balance exploration and exploitation,\nis employed to optimize the trading strategy. Experiments were conducted using\nfinancial data from major tech companies over a comprehensive timeline,\ndemonstrating that the xLSTM-based model outperforms LSTM-based methods in key\ntrading evaluation metrics, including cumulative return, average profitability\nper trade, maximum earning rate, maximum pullback, and Sharpe ratio. These\nfindings mark the potential of xLSTM for enhancing DRL-based stock trading\nsystems.",
      "authors": [
        "Faezeh Sarlakifar",
        "Mohammadreza Mohammadzadeh Asl",
        "Sajjad Rezvani Khaledi",
        "Armin Salimi-Badr"
      ],
      "categories": [
        "cs.CE",
        "cs.LG",
        "q-fin.TR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09655v1",
        "http://arxiv.org/pdf/2503.09655v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09244v1",
      "title": "How To Make Your Cell Tracker Say \"I dunno!\"",
      "published": "2025-03-12T10:39:14Z",
      "updated": "2025-03-12T10:39:14Z",
      "summary": "Cell tracking is a key computational task in live-cell microscopy, but fully\nautomated analysis of high-throughput imaging requires reliable and, thus,\nuncertainty-aware data analysis tools, as the amount of data recorded within a\nsingle experiment exceeds what humans are able to overlook. We here propose and\nbenchmark various methods to reason about and quantify uncertainty in linear\nassignment-based cell tracking algorithms. Our methods take inspiration from\nstatistics and machine learning, leveraging two perspectives on the cell\ntracking problem explored throughout this work: Considering it as a Bayesian\ninference problem and as a classification problem. Our methods admit a\nframework-like character in that they equip any frame-to-frame tracking method\nwith uncertainty quantification. We demonstrate this by applying it to various\nexisting tracking algorithms including the recently presented Transformer-based\ntrackers. We demonstrate empirically that our methods yield useful and\nwell-calibrated tracking uncertainties.",
      "authors": [
        "Richard D. Paul",
        "Johannes Seiffarth",
        "David R\u00fcgamer",
        "Hanno Scharr",
        "Katharina N\u00f6h"
      ],
      "categories": [
        "cs.CV",
        "q-bio.QM",
        "stat.AP"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09244v1",
        "http://arxiv.org/pdf/2503.09244v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.11704v1",
      "title": "Unlimited Practice Opportunities: Automated Generation of Comprehensive,\n  Personalized Programming Tasks",
      "published": "2025-03-12T10:35:25Z",
      "updated": "2025-03-12T10:35:25Z",
      "summary": "Generative artificial intelligence (GenAI) offers new possibilities for\ngenerating personalized programming exercises, addressing the need for\nindividual practice. However, the task quality along with the student\nperspective on such generated tasks remains largely unexplored. Therefore, this\npaper introduces and evaluates a new feature of the so-called Tutor Kai for\ngenerating comprehensive programming tasks, including problem descriptions,\ncode skeletons, unit tests, and model solutions. The presented system allows\nstudents to freely choose programming concepts and contextual themes for their\ntasks. To evaluate the system, we conducted a two-phase mixed-methods study\ncomprising (1) an expert rating of 200 automatically generated programming\ntasks w.r.t. task quality, and (2) a study with 26 computer science students\nwho solved and rated the personalized programming tasks. Results show that\nexperts classified 89.5% of the generated tasks as functional and 92.5% as\nsolvable. However, the system's rate for implementing all requested programming\nconcepts decreased from 94% for single-concept tasks to 40% for tasks\naddressing three concepts. The student evaluation further revealed high\nsatisfaction with the personalization. Students also reported perceived\nbenefits for learning. The results imply that the new feature has the potential\nto offer students individual tasks aligned with their context and need for\nexercise. Tool developers, educators, and, above all, students can benefit from\nthese insights and the system itself.",
      "authors": [
        "Sven Jacobs",
        "Henning Peters",
        "Steffen Jaschke",
        "Natalie Kiesler"
      ],
      "categories": [
        "cs.SE",
        "cs.CY",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2503.11704v1",
        "http://arxiv.org/pdf/2503.11704v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09192v1",
      "title": "Differential Privacy Personalized Federated Learning Based on\n  Dynamically Sparsified Client Updates",
      "published": "2025-03-12T09:34:05Z",
      "updated": "2025-03-12T09:34:05Z",
      "summary": "Personalized federated learning is extensively utilized in scenarios\ncharacterized by data heterogeneity, facilitating more efficient and automated\nlocal training on data-owning terminals. This includes the automated selection\nof high-performance model parameters for upload, thereby enhancing the overall\ntraining process. However, it entails significant risks of privacy leakage.\nExisting studies have attempted to mitigate these risks by utilizing\ndifferential privacy. Nevertheless, these studies present two major\nlimitations: (1) The integration of differential privacy into personalized\nfederated learning lacks sufficient personalization, leading to the\nintroduction of excessive noise into the model. (2) It fails to adequately\ncontrol the spatial scope of model update information, resulting in a\nsuboptimal balance between data privacy and model effectiveness in differential\nprivacy federated learning. In this paper, we propose a differentially private\npersonalized federated learning approach that employs dynamically sparsified\nclient updates through reparameterization and adaptive norm(DP-pFedDSU).\nReparameterization training effectively selects personalized client update\ninformation, thereby reducing the quantity of updates. This approach minimizes\nthe introduction of noise to the greatest extent possible. Additionally,\ndynamic adaptive norm refers to controlling the norm space of model updates\nduring the training process, mitigating the negative impact of clipping on the\nupdate information. These strategies substantially enhance the effective\nintegration of differential privacy and personalized federated learning.\nExperimental results on EMNIST, CIFAR-10, and CIFAR-100 demonstrate that our\nproposed scheme achieves superior performance and is well-suited for more\ncomplex personalized federated learning scenarios.",
      "authors": [
        "Chuanyin Wang",
        "Yifei Zhang",
        "Neng Gao",
        "Qiang Luo"
      ],
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09192v1",
        "http://arxiv.org/pdf/2503.09192v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09068v1",
      "title": "Probing Network Decisions: Capturing Uncertainties and Unveiling\n  Vulnerabilities Without Label Information",
      "published": "2025-03-12T05:05:58Z",
      "updated": "2025-03-12T05:05:58Z",
      "summary": "To improve trust and transparency, it is crucial to be able to interpret the\ndecisions of Deep Neural classifiers (DNNs). Instance-level examinations, such\nas attribution techniques, are commonly employed to interpret the model\ndecisions. However, when interpreting misclassified decisions, human\nintervention may be required. Analyzing the attribu tions across each class\nwithin one instance can be particularly labor intensive and influenced by the\nbias of the human interpreter. In this paper, we present a novel framework to\nuncover the weakness of the classifier via counterfactual examples. A prober is\nintroduced to learn the correctness of the classifier's decision in terms of\nbinary code-hit or miss. It enables the creation of the counterfactual example\nconcerning the prober's decision. We test the performance of our prober's\nmisclassification detection and verify its effectiveness on the image\nclassification benchmark datasets. Furthermore, by generating counterfactuals\nthat penetrate the prober, we demonstrate that our framework effectively\nidentifies vulnerabilities in the target classifier without relying on label\ninformation on the MNIST dataset.",
      "authors": [
        "Youngju Joung",
        "Sehyun Lee",
        "Jaesik Choi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "links": [
        "http://dx.doi.org/10.1007/978-981-97-8702-9_21",
        "http://arxiv.org/abs/2503.09068v1",
        "http://arxiv.org/pdf/2503.09068v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2503.09050v1",
      "title": "Mono2D: A Trainable Monogenic Layer for Robust Knee Cartilage\n  Segmentation on Out-of-Distribution 2D Ultrasound Data",
      "published": "2025-03-12T04:27:45Z",
      "updated": "2025-03-12T04:27:45Z",
      "summary": "Automated knee cartilage segmentation using point-of-care ultrasound devices\nand deep-learning networks has the potential to enhance the management of knee\nosteoarthritis. However, segmentation algorithms often struggle with domain\nshifts caused by variations in ultrasound devices and acquisition parameters,\nlimiting their generalizability. In this paper, we propose Mono2D, a monogenic\nlayer that extracts multi-scale, contrast- and intensity-invariant local phase\nfeatures using trainable bandpass quadrature filters. This layer mitigates\ndomain shifts, improving generalization to out-of-distribution domains. Mono2D\nis integrated before the first layer of a segmentation network, and its\nparameters jointly trained alongside the network's parameters. We evaluated\nMono2D on a multi-domain 2D ultrasound knee cartilage dataset for single-source\ndomain generalization (SSDG). Our results demonstrate that Mono2D outperforms\nother SSDG methods in terms of Dice score and mean average surface distance. To\nfurther assess its generalizability, we evaluate Mono2D on a multi-site\nprostate MRI dataset, where it continues to outperform other SSDG methods,\nhighlighting its potential to improve domain generalization in medical imaging.\nNevertheless, further evaluation on diverse datasets is still necessary to\nassess its clinical utility.",
      "authors": [
        "Alvin Kimbowa",
        "Arjun Parmar",
        "Maziar Badii",
        "David Liu",
        "Matthew Harkey",
        "Ilker Hacihaliloglu"
      ],
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2503.09050v1",
        "http://arxiv.org/pdf/2503.09050v1"
      ],
      "primary_search_term": "machine learning",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}