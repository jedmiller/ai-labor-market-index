{
  "query": "all:artificial intelligence AND (labor market OR employment OR jobs OR workforce OR automation)",
  "date_collected": "2025-05-03T02:54:18.116913",
  "target_period": "2025-04",
  "papers": [
    {
      "id": "http://arxiv.org/abs/2505.00222v1",
      "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
      "published": "2025-04-30T23:55:44Z",
      "updated": "2025-04-30T23:55:44Z",
      "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.",
      "authors": [
        "Peter Yichen Chen",
        "Pingchuan Ma",
        "Niklas Hagemann",
        "John Romanishin",
        "Wei Wang",
        "Daniela Rus",
        "Wojciech Matusik"
      ],
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "physics.comp-ph"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00222v1",
        "http://arxiv.org/pdf/2505.00222v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00174v1",
      "title": "Real-World Gaps in AI Governance Research",
      "published": "2025-04-30T20:44:42Z",
      "updated": "2025-04-30T20:44:42Z",
      "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.",
      "authors": [
        "Ilan Strauss",
        "Isobel Moure",
        "Tim O'Reilly",
        "Sruly Rosenblat"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.35650/AIDP.4112.d.2025",
        "http://arxiv.org/abs/2505.00174v1",
        "http://arxiv.org/pdf/2505.00174v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21798v1",
      "title": "SWE-smith: Scaling Data for Software Engineering Agents",
      "published": "2025-04-30T16:56:06Z",
      "updated": "2025-04-30T16:56:06Z",
      "summary": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.",
      "authors": [
        "John Yang",
        "Kilian Leret",
        "Carlos E. Jimenez",
        "Alexander Wettig",
        "Kabir Khandpur",
        "Yanzhe Zhang",
        "Binyuan Hui",
        "Ofir Press",
        "Ludwig Schmidt",
        "Diyi Yang"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21798v1",
        "http://arxiv.org/pdf/2504.21798v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21694v1",
      "title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries\n  and Validation",
      "published": "2025-04-30T14:34:56Z",
      "updated": "2025-04-30T14:34:56Z",
      "summary": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.",
      "authors": [
        "Tom Westermann",
        "Malte Ramonat",
        "Johannes Hujer",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21694v1",
        "http://arxiv.org/pdf/2504.21694v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21589v1",
      "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for\n  Automated Subject Indexing",
      "published": "2025-04-30T12:47:09Z",
      "updated": "2025-04-30T12:47:09Z",
      "summary": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.",
      "authors": [
        "Lisa Kluge",
        "Maximilian K\u00e4hler"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "I.2.7"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21589v1",
        "http://arxiv.org/pdf/2504.21589v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21574v1",
      "title": "Generative AI in Financial Institution: A Global Survey of\n  Opportunities, Threats, and Regulation",
      "published": "2025-04-30T12:25:30Z",
      "updated": "2025-04-30T12:25:30Z",
      "summary": "Generative Artificial Intelligence (GenAI) is rapidly reshaping the global\nfinancial landscape, offering unprecedented opportunities to enhance customer\nengagement, automate complex workflows, and extract actionable insights from\nvast financial data. This survey provides an overview of GenAI adoption across\nthe financial ecosystem, examining how banks, insurers, asset managers, and\nfintech startups worldwide are integrating large language models and other\ngenerative tools into their operations. From AI-powered virtual assistants and\npersonalized financial advisory to fraud detection and compliance automation,\nGenAI is driving innovation across functions. However, this transformation\ncomes with significant cybersecurity and ethical risks. We discuss emerging\nthreats such as AI-generated phishing, deepfake-enabled fraud, and adversarial\nattacks on AI systems, as well as concerns around bias, opacity, and data\nmisuse. The evolving global regulatory landscape is explored in depth,\nincluding initiatives by major financial regulators and international efforts\nto develop risk-based AI governance. Finally, we propose best practices for\nsecure and responsible adoption - including explainability techniques,\nadversarial testing, auditability, and human oversight. Drawing from academic\nliterature, industry case studies, and policy frameworks, this chapter offers a\nperspective on how the financial sector can harness GenAI's transformative\npotential while navigating the complex risks it introduces.",
      "authors": [
        "Bikash Saha",
        "Nanda Rani",
        "Sandeep Kumar Shukla"
      ],
      "categories": [
        "cs.CR",
        "cs.CE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21574v1",
        "http://arxiv.org/pdf/2504.21574v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2505.00054v1",
      "title": "Algorithmic Addiction by Design: Big Tech's Leverage of Dark Patterns to\n  Maintain Market Dominance and its Challenge for Content Moderation",
      "published": "2025-04-30T10:43:18Z",
      "updated": "2025-04-30T10:43:18Z",
      "summary": "Today's largest technology corporations, especially ones with consumer-facing\nproducts such as social media platforms, use a variety of unethical and often\noutright illegal tactics to maintain their dominance. One tactic that has risen\nto the level of the public consciousness is the concept of addictive design,\nevidenced by the fact that excessive social media use has become a salient\nproblem, particularly in the mental and social development of adolescents and\nyoung adults. As tech companies have developed more and more sophisticated\nartificial intelligence (AI) models to power their algorithmic recommender\nsystems, they will become more successful at their goal of ensuring addiction\nto their platforms. This paper explores how online platforms intentionally\ncultivate addictive user behaviors and the broad societal implications,\nincluding on the health and well-being of children and adolescents. It presents\nthe usage of addictive design - including the usage of dark patterns,\npersuasive design elements, and recommender algorithms - as a tool leveraged by\ntechnology corporations to maintain their dominance. Lastly, it describes the\nchallenge of content moderation to address the problem and gives an overview of\nsolutions at the policy level to counteract addictive design.",
      "authors": [
        "Michelle Nie"
      ],
      "categories": [
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2505.00054v1",
        "http://arxiv.org/pdf/2505.00054v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21400v1",
      "title": "Who Gets the Callback? Generative AI and Gender Bias",
      "published": "2025-04-30T07:55:52Z",
      "updated": "2025-04-30T07:55:52Z",
      "summary": "Generative artificial intelligence (AI), particularly large language models\n(LLMs), is being rapidly deployed in recruitment and for candidate\nshortlisting. We audit several mid-sized open-source LLMs for gender bias using\na dataset of 332,044 real-world online job postings. For each posting, we\nprompt the model to recommend whether an equally qualified male or female\ncandidate should receive an interview callback. We find that most models tend\nto favor men, especially for higher-wage roles. Mapping job descriptions to the\nStandard Occupational Classification system, we find lower callback rates for\nwomen in male-dominated occupations and higher rates in female-associated ones,\nindicating occupational segregation. A comprehensive analysis of linguistic\nfeatures in job ads reveals strong alignment of model recommendations with\ntraditional gender stereotypes. To examine the role of recruiter identity, we\nsteer model behavior by infusing Big Five personality traits and simulating the\nperspectives of historical figures. We find that less agreeable personas reduce\nstereotyping, consistent with an agreeableness bias in LLMs. Our findings\nhighlight how AI-driven hiring may perpetuate biases in the labor market and\nhave implications for fairness and diversity within firms.",
      "authors": [
        "Sugat Chaturvedi",
        "Rochana Chaturvedi"
      ],
      "categories": [
        "econ.GN",
        "cs.CL",
        "q-fin.EC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21400v1",
        "http://arxiv.org/pdf/2504.21400v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21211v1",
      "title": "A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in\n  Online Marketplaces",
      "published": "2025-04-29T22:34:42Z",
      "updated": "2025-04-29T22:34:42Z",
      "summary": "Wildlife trafficking remains a critical global issue, significantly impacting\nbiodiversity, ecological stability, and public health. Despite efforts to\ncombat this illicit trade, the rise of e-commerce platforms has made it easier\nto sell wildlife products, putting new pressure on wild populations of\nendangered and threatened species. The use of these platforms also opens a new\nopportunity: as criminals sell wildlife products online, they leave digital\ntraces of their activity that can provide insights into trafficking activities\nas well as how they can be disrupted. The challenge lies in finding these\ntraces. Online marketplaces publish ads for a plethora of products, and\nidentifying ads for wildlife-related products is like finding a needle in a\nhaystack. Learning classifiers can automate ad identification, but creating\nthem requires costly, time-consuming data labeling that hinders support for\ndiverse ads and research questions. This paper addresses a critical challenge\nin the data science pipeline for wildlife trafficking analytics: generating\nquality labeled data for classifiers that select relevant data. While large\nlanguage models (LLMs) can directly label advertisements, doing so at scale is\nprohibitively expensive. We propose a cost-effective strategy that leverages\nLLMs to generate pseudo labels for a small sample of the data and uses these\nlabels to create specialized classification models. Our novel method\nautomatically gathers diverse and representative samples to be labeled while\nminimizing the labeling costs. Our experimental evaluation shows that our\nclassifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We\npresent real use cases that demonstrate the effectiveness of our approach in\nenabling analyses of different aspects of wildlife trafficking.",
      "authors": [
        "Juliana Barbosa",
        "Ulhas Gondhali",
        "Gohar Petrossian",
        "Kinshuk Sharma",
        "Sunandan Chakraborty",
        "Jennifer Jacquet",
        "Juliana Freire"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3725256",
        "http://arxiv.org/abs/2504.21211v1",
        "http://arxiv.org/pdf/2504.21211v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21202v1",
      "title": "Automatic Legal Writing Evaluation of LLMs",
      "published": "2025-04-29T22:16:39Z",
      "updated": "2025-04-29T22:16:39Z",
      "summary": "Despite the recent advances in Large Language Models, benchmarks for\nevaluating legal writing remain scarce due to the inherent complexity of\nassessing open-ended responses in this domain. One of the key challenges in\nevaluating language models on domain-specific tasks is finding test datasets\nthat are public, frequently updated, and contain comprehensive evaluation\nguidelines. The Brazilian Bar Examination meets these requirements. We\nintroduce oab-bench, a benchmark comprising 105 questions across seven areas of\nlaw from recent editions of the exam. The benchmark includes comprehensive\nevaluation guidelines and reference materials used by human examiners to ensure\nconsistent grading. We evaluate the performance of four LLMs on oab-bench,\nfinding that Claude-3.5 Sonnet achieves the best results with an average score\nof 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can\nserve as reliable automated judges for evaluating legal writing. Our\nexperiments show that frontier models like OpenAI's o1 achieve a strong\ncorrelation with human scores when evaluating approved exams, suggesting their\npotential as reliable automated evaluators despite the inherently subjective\nnature of legal writing assessment. The source code and the benchmark --\ncontaining questions, evaluation guidelines, model-generated responses, and\ntheir respective automated evaluations -- are publicly available.",
      "authors": [
        "Ramon Pires",
        "Roseval Malaquias Junior",
        "Rodrigo Nogueira"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21202v1",
        "http://arxiv.org/pdf/2504.21202v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21194v1",
      "title": "Geolocating Earth Imagery from ISS: Integrating Machine Learning with\n  Astronaut Photography for Enhanced Geographic Mapping",
      "published": "2025-04-29T22:00:02Z",
      "updated": "2025-04-29T22:00:02Z",
      "summary": "This paper presents a novel approach to geolocating images captured from the\nInternational Space Station (ISS) using advanced machine learning algorithms.\nDespite having precise ISS coordinates, the specific Earth locations depicted\nin astronaut-taken photographs often remain unidentified. Our research\naddresses this gap by employing three distinct image processing pipelines: a\nNeural Network based approach, a SIFT based method, and GPT-4 model. Each\npipeline is tailored to process high-resolution ISS imagery, identifying both\nnatural and man-made geographical features. Through extensive evaluation on a\ndiverse dataset of over 140 ISS images, our methods demonstrate significant\npromise in automated geolocation with varied levels of success. The NN approach\nshowed a high success rate in accurately matching geographical features, while\nthe SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided\nenriched geographical descriptions alongside location predictions. This\nresearch contributes to the fields of remote sensing and Earth observation by\nenhancing the accuracy and efficiency of geolocating space-based imagery,\nthereby aiding environmental monitoring and global mapping efforts.",
      "authors": [
        "Vedika Srivastava",
        "Hemant Kumar Singh",
        "Jaisal Singh"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21194v1",
        "http://arxiv.org/pdf/2504.21194v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21190v1",
      "title": "TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse\n  Mixture-of-Experts",
      "published": "2025-04-29T21:46:43Z",
      "updated": "2025-04-29T21:46:43Z",
      "summary": "We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA\nMoE), a novel computational framework integrating Parameter-Efficient\nFine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in\nlarge model deployments. Unlike traditional MoE approaches, which face\nsubstantial computational overhead as expert counts grow, TT-LoRA MoE\ndecomposes training into two distinct, optimized stages. First, we\nindependently train lightweight, tensorized low-rank adapters (TT-LoRA\nexperts), each specialized for specific tasks. Subsequently, these expert\nadapters remain frozen, eliminating inter-task interference and catastrophic\nforgetting in multi-task setting. A sparse MoE router, trained separately,\ndynamically leverages base model representations to select exactly one\nspecialized adapter per input at inference time, automating expert selection\nwithout explicit task specification. Comprehensive experiments confirm our\narchitecture retains the memory efficiency of low-rank adapters, seamlessly\nscales to large expert pools, and achieves robust task-level optimization. This\nstructured decoupling significantly enhances computational efficiency and\nflexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion\nparameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling\npractical and scalable multi-task inference deployments.",
      "authors": [
        "Pradip Kunwar",
        "Minh N. Vu",
        "Maanak Gupta",
        "Mahmoud Abdelsalam",
        "Manish Bhattarai"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21190v1",
        "http://arxiv.org/pdf/2504.21190v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21184v1",
      "title": "AffectEval: A Modular and Customizable Framework for Affective Computing",
      "published": "2025-04-29T21:40:49Z",
      "updated": "2025-04-29T21:40:49Z",
      "summary": "The field of affective computing focuses on recognizing, interpreting, and\nresponding to human emotions, and has broad applications across education,\nchild development, and human health and wellness. However, developing affective\ncomputing pipelines remains labor-intensive due to the lack of software\nframeworks that support multimodal, multi-domain emotion recognition\napplications. This often results in redundant effort when building pipelines\nfor different applications. While recent frameworks attempt to address these\nchallenges, they remain limited in reducing manual effort and ensuring\ncross-domain generalizability. We introduce AffectEval, a modular and\ncustomizable framework to facilitate the development of affective computing\npipelines while reducing the manual effort and duplicate work involved in\ndeveloping such pipelines. We validate AffectEval by replicating prior\naffective computing experiments, and we demonstrate that our framework reduces\nprogramming effort by up to 90%, as measured by the reduction in raw lines of\ncode.",
      "authors": [
        "Emily Zhou",
        "Khushboo Khatri",
        "Yixue Zhao",
        "Bhaskar Krishnamachari"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21184v1",
        "http://arxiv.org/pdf/2504.21184v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21166v1",
      "title": "Dance Style Recognition Using Laban Movement Analysis",
      "published": "2025-04-29T20:35:01Z",
      "updated": "2025-04-29T20:35:01Z",
      "summary": "The growing interest in automated movement analysis has presented new\nchallenges in recognition of complex human activities including dance. This\nstudy focuses on dance style recognition using features extracted using Laban\nMovement Analysis. Previous studies for dance style recognition often focus on\ncross-frame movement analysis, which limits the ability to capture temporal\ncontext and dynamic transitions between movements. This gap highlights the need\nfor a method that can add temporal context to LMA features. For this, we\nintroduce a novel pipeline which combines 3D pose estimation, 3D human mesh\nreconstruction, and floor aware body modeling to effectively extract LMA\nfeatures. To address the temporal limitation, we propose a sliding window\napproach that captures movement evolution across time in features. These\nfeatures are then used to train various machine learning methods for\nclassification, and their explainability explainable AI methods to evaluate the\ncontribution of each feature to classification performance. Our proposed method\nachieves a highest classification accuracy of 99.18\\% which shows that the\naddition of temporal context significantly improves dance style recognition\nperformance.",
      "authors": [
        "Muhammad Turab",
        "Philippe Colantoni",
        "Damien Muselet",
        "Alain Tremeau"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21166v1",
        "http://arxiv.org/pdf/2504.21166v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20970v1",
      "title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep\n  Features",
      "published": "2025-04-29T17:39:16Z",
      "updated": "2025-04-29T17:39:16Z",
      "summary": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.",
      "authors": [
        "Mete Erdogan",
        "Sebnem Demirtas"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20970v1",
        "http://arxiv.org/pdf/2504.20970v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20910v1",
      "title": "When Testing AI Tests Us: Safeguarding Mental Health on the Digital\n  Frontlines",
      "published": "2025-04-29T16:27:20Z",
      "updated": "2025-04-29T16:27:20Z",
      "summary": "Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.",
      "authors": [
        "Sachin R. Pendse",
        "Darren Gergle",
        "Rachel Kornfield",
        "Jonah Meyerhoff",
        "David Mohr",
        "Jina Suh",
        "Annie Wescott",
        "Casey Williams",
        "Jessica Schleider"
      ],
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20910v1",
        "http://arxiv.org/pdf/2504.20910v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.21569v1",
      "title": "A Systematic Literature Review of Parameter-Efficient Fine-Tuning for\n  Large Code Models",
      "published": "2025-04-29T16:19:25Z",
      "updated": "2025-04-29T16:19:25Z",
      "summary": "The rise of Artificial Intelligence (AI)-and particularly Large Language\nModels (LLMs) for code-has reshaped Software Engineering (SE) by enabling the\nautomation of tasks such as code generation, bug detection, and repair.\nHowever, these models require significant computational resources for training\nand fine-tuning, posing challenges for real-world adoption in\nresource-constrained environments. To address this, the research community has\nincreasingly turned to Parameter-Efficient Fine-Tuning (PEFT)-a class of\ntechniques that enables the adaptation of large models by updating only a small\nsubset of parameters, rather than the entire model. In this Systematic\nLiterature Review (SLR), we examine the growing application of PEFT\ntechniques-across a wide range of software engineering tasks. We analyze how\nthese methods are used to optimize various deep learning (DL) architectures,\nfocusing on their impact on both performance and efficiency. Our study\nsynthesizes findings from 27 peer-reviewed papers, identifying patterns in\nconfiguration strategies and adaptation trade-offs. The outcome of this review\nis a comprehensive taxonomy that categorizes PEFT usage by task type,\ndistinguishing between generative (e.g., Code Summarization) and non-generative\n(e.g., Code Clone Detection) scenarios. Our findings aim to inform future\nresearch and guide the practical deployment of PEFT in sustainable, AI-powered\nsoftware development. Our artifacts are publicly available at\nhttps://github.com/alvi75/SLR-PEFT",
      "authors": [
        "Md Zahidul Haque",
        "Saima Afrin",
        "Antonio Mastropaolo"
      ],
      "categories": [
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.21569v1",
        "http://arxiv.org/pdf/2504.21569v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20898v1",
      "title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report\n  Generation with Multi-Agent RAG and Concept Bottleneck Models",
      "published": "2025-04-29T16:14:55Z",
      "updated": "2025-04-29T16:14:55Z",
      "summary": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.",
      "authors": [
        "Hasan Md Tusfiqur Alam",
        "Devansh Srivastav",
        "Abdulrahman Mohamed Selim",
        "Md Abdul Kadir",
        "Md Moktadiurl Hoque Shuvo",
        "Daniel Sonntag"
      ],
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "links": [
        "http://dx.doi.org/10.1145/3731406.3731970",
        "http://arxiv.org/abs/2504.20898v1",
        "http://arxiv.org/pdf/2504.20898v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20776v1",
      "title": "ECOSoundSet: a finely annotated dataset for the automated acoustic\n  identification of Orthoptera and Cicadidae in North, Central and temperate\n  Western Europe",
      "published": "2025-04-29T13:53:33Z",
      "updated": "2025-04-29T13:53:33Z",
      "summary": "Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.",
      "authors": [
        "David Funosas",
        "Elodie Massol",
        "Yves Bas",
        "Svenja Schmidt",
        "Dominik Arend",
        "Alexander Gebhard",
        "Luc Barbaro",
        "Sebastian K\u00f6nig",
        "Rafael Carbonell Font",
        "David Sannier",
        "Fernand Deroussen",
        "J\u00e9r\u00f4me Sueur",
        "Christian Roesti",
        "Tomi Trilar",
        "Wolfgang Forstmeier",
        "Lucas Roger",
        "Elo\u00efsa Matheu",
        "Piotr Guzik",
        "Julien Barataud",
        "Laurent Pelozuelo",
        "St\u00e9phane Puissant",
        "Sandra Mueller",
        "Bj\u00f6rn Schuller",
        "Jose M. Montoya",
        "Andreas Triantafyllopoulos",
        "Maxime Cauchoix"
      ],
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20776v1",
        "http://arxiv.org/pdf/2504.20776v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20726v1",
      "title": "Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization",
      "published": "2025-04-29T13:08:27Z",
      "updated": "2025-04-29T13:08:27Z",
      "summary": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.",
      "authors": [
        "Hattan Althebeiti",
        "Mohammed Alkinoon",
        "Manar Mohaisen",
        "Saeed Salem",
        "DaeHun Nyang",
        "David Mohaisen"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20726v1",
        "http://arxiv.org/pdf/2504.20726v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20612v1",
      "title": "The Hidden Risks of LLM-Generated Web Application Code: A\n  Security-Centric Evaluation of Code Generation Capabilities in Large Language\n  Models",
      "published": "2025-04-29T10:23:11Z",
      "updated": "2025-04-29T10:23:11Z",
      "summary": "The rapid advancement of Large Language Models (LLMs) has enhanced software\ndevelopment processes, minimizing the time and effort required for coding and\nenhancing developer productivity. However, despite their potential benefits,\ncode generated by LLMs has been shown to generate insecure code in controlled\nenvironments, raising critical concerns about their reliability and security in\nreal-world applications. This paper uses predefined security parameters to\nevaluate the security compliance of LLM-generated code across multiple models,\nsuch as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals\ncritical vulnerabilities in authentication mechanisms, session management,\ninput validation and HTTP security headers. Although some models implement\nsecurity measures to a limited extent, none fully align with industry best\npractices, highlighting the associated risks in automated software development.\nOur findings underscore that human expertise is crucial to ensure secure\nsoftware deployment or review of LLM-generated code. Also, there is a need for\nrobust security assessment frameworks to enhance the reliability of\nLLM-generated code in real-world applications.",
      "authors": [
        "Swaroop Dora",
        "Deven Lunkad",
        "Naziya Aslam",
        "S. Venkatesan",
        "Sandeep Kumar Shukla"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20612v1",
        "http://arxiv.org/pdf/2504.20612v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20471v1",
      "title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams",
      "published": "2025-04-29T07:13:28Z",
      "updated": "2025-04-29T07:13:28Z",
      "summary": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.",
      "authors": [
        "Baining Chen",
        "Yiming Zhang",
        "Yuqiao Han",
        "Ruyue Zhang",
        "Ruihuan Du",
        "Zhishuo Zhou",
        "Zhengdan Zhu",
        "Xun Liu",
        "Jiecheng Guo"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20471v1",
        "http://arxiv.org/pdf/2504.20471v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20462v2",
      "title": "TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with\n  Multi-Modality Observation Data",
      "published": "2025-04-29T06:50:48Z",
      "updated": "2025-04-30T10:20:10Z",
      "summary": "With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.",
      "authors": [
        "Qi Wang",
        "Xiao Zhang",
        "Mingyi Li",
        "Yuan Yuan",
        "Mengbai Xiao",
        "Fuzhen Zhuang",
        "Dongxiao Yu"
      ],
      "categories": [
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20462v2",
        "http://arxiv.org/pdf/2504.20462v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20447v1",
      "title": "APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech",
      "published": "2025-04-29T05:45:09Z",
      "updated": "2025-04-29T05:45:09Z",
      "summary": "Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.",
      "authors": [
        "Zhicheng Lian",
        "Lizhi Wang",
        "Hua Huang"
      ],
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20447v1",
        "http://arxiv.org/pdf/2504.20447v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20434v1",
      "title": "ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative\n  Refinement",
      "published": "2025-04-29T05:15:52Z",
      "updated": "2025-04-29T05:15:52Z",
      "summary": "In supercomputing, efficient and optimized code generation is essential to\nleverage high-performance systems effectively. We propose Agentic\nRetrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate,\nrobust, and efficient code generation, completion, and translation. ARCS\nintegrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT)\nreasoning to systematically break down and iteratively refine complex\nprogramming tasks. An agent-based RAG mechanism retrieves relevant code\nsnippets, while real-time execution feedback drives the synthesis of candidate\nsolutions. This process is formalized as a state-action search tree\noptimization, balancing code correctness with editing efficiency. Evaluations\non the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly\noutperforms traditional prompting methods in translation and generation\nquality. By enabling scalable and precise code synthesis, ARCS offers\ntransformative potential for automating and optimizing code development in\nsupercomputing applications, enhancing computational resource utilization.",
      "authors": [
        "Manish Bhattarai",
        "Miguel Cordova",
        "Javier Santos",
        "Dan O'Malley"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20434v1",
        "http://arxiv.org/pdf/2504.20434v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20419v1",
      "title": "Plant Disease Detection through Multimodal Large Language Models and\n  Convolutional Neural Networks",
      "published": "2025-04-29T04:31:58Z",
      "updated": "2025-04-29T04:31:58Z",
      "summary": "Automation in agriculture plays a vital role in addressing challenges related\nto crop monitoring and disease management, particularly through early detection\nsystems. This study investigates the effectiveness of combining multimodal\nLarge Language Models (LLMs), specifically GPT-4o, with Convolutional Neural\nNetworks (CNNs) for automated plant disease classification using leaf imagery.\nLeveraging the PlantVillage dataset, we systematically evaluate model\nperformance across zero-shot, few-shot, and progressive fine-tuning scenarios.\nA comparative analysis between GPT-4o and the widely used ResNet-50 model was\nconducted across three resolutions (100, 150, and 256 pixels) and two plant\nspecies (apple and corn). Results indicate that fine-tuned GPT-4o models\nachieved slightly better performance compared to the performance of ResNet-50,\nachieving up to 98.12% classification accuracy on apple leaf images, compared\nto 96.88% achieved by ResNet-50, with improved generalization and near-zero\ntraining loss. However, zero-shot performance of GPT-4o was significantly\nlower, underscoring the need for minimal training. Additional evaluations on\ncross-resolution and cross-plant generalization revealed the models'\nadaptability and limitations when applied to new domains. The findings\nhighlight the promise of integrating multimodal LLMs into automated disease\ndetection pipelines, enhancing the scalability and intelligence of precision\nagriculture systems while reducing the dependence on large, labeled datasets\nand high-resolution sensor infrastructure. Large Language Models, Vision\nLanguage Models, LLMs and CNNs, Disease Detection with Vision Language Models,\nVLMs",
      "authors": [
        "Konstantinos I. Roumeliotis",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Nikolaos D. Tselikas",
        "Dimitrios K. Nasiopoulos"
      ],
      "categories": [
        "cs.CV"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20419v1",
        "http://arxiv.org/pdf/2504.20419v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20406v1",
      "title": "Skill Discovery for Software Scripting Automation via Offline\n  Simulations with LLMs",
      "published": "2025-04-29T04:03:37Z",
      "updated": "2025-04-29T04:03:37Z",
      "summary": "Scripting interfaces enable users to automate tasks and customize software\nworkflows, but creating scripts traditionally requires programming expertise\nand familiarity with specific APIs, posing barriers for many users. While Large\nLanguage Models (LLMs) can generate code from natural language queries, runtime\ncode generation is severely limited due to unverified code, security risks,\nlonger response times, and higher computational costs. To bridge the gap, we\npropose an offline simulation framework to curate a software-specific skillset,\na collection of verified scripts, by exploiting LLMs and publicly available\nscripting guides. Our framework comprises two components: (1) task creation,\nusing top-down functionality guidance and bottom-up API synergy exploration to\ngenerate helpful tasks; and (2) skill generation with trials, refining and\nvalidating scripts based on execution feedback. To efficiently navigate the\nextensive API landscape, we introduce a Graph Neural Network (GNN)-based link\nprediction model to capture API synergy, enabling the generation of skills\ninvolving underutilized APIs and expanding the skillset's diversity.\nExperiments with Adobe Illustrator demonstrate that our framework significantly\nimproves automation success rates, reduces response time, and saves runtime\ntoken costs compared to traditional runtime code generation. This is the first\nattempt to use software scripting interfaces as a testbed for LLM-based\nsystems, highlighting the advantages of leveraging execution feedback in a\ncontrolled environment and offering valuable insights into aligning AI\ncapabilities with user needs in specialized software domains.",
      "authors": [
        "Paiheng Xu",
        "Gang Wu",
        "Xiang Chen",
        "Tong Yu",
        "Chang Xiao",
        "Franck Dernoncourt",
        "Tianyi Zhou",
        "Wei Ai",
        "Viswanathan Swaminathan"
      ],
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20406v1",
        "http://arxiv.org/pdf/2504.20406v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20368v1",
      "title": "AKIBoards: A Structure-Following Multiagent System for Predicting Acute\n  Kidney Injury",
      "published": "2025-04-29T02:12:48Z",
      "updated": "2025-04-29T02:12:48Z",
      "summary": "Diagnostic reasoning entails a physician's local (mental) model based on an\nassumed or known shared perspective (global model) to explain patient\nobservations with evidence assigned towards a clinical assessment. But in\nseveral (complex) medical situations, multiple experts work together as a team\nto optimize health evaluation and decision-making by leveraging different\nperspectives. Such consensus-driven reasoning reflects individual knowledge\ncontributing toward a broader perspective on the patient. In this light, we\nintroduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework\nautomating the learning of these global models and their incorporation as prior\nbeliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof\nof concept with a prosocial MAS application for predicting acute kidney\ninjuries (AKIs). In this case, we found that incorporating a global structure\nenabled multiple agents to achieve better performance (average precision, AP)\nin predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT,\nAP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs.\nbaseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180)\nfor balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents\nwith higher recall scores reported lower confidence levels in the initial round\non true positive and false negative cases. But after explicit interactions,\ntheir confidence in their decisions increased (suggesting reinforced belief).\nIn contrast, the SF-FT agent with the lowest recall decreased its confidence in\ntrue positive and false negative cases (suggesting a new belief). This approach\nsuggests that learning and leveraging global structures in MAS is necessary\nprior to achieving competitive classification and diagnostic reasoning\nperformance.",
      "authors": [
        "David Gordon",
        "Panayiotis Petousis",
        "Susanne B. Nicholas",
        "Alex A. T. Bui"
      ],
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20368v1",
        "http://arxiv.org/pdf/2504.20368v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20357v1",
      "title": "Automated Unit Test Case Generation: A Systematic Literature Review",
      "published": "2025-04-29T01:50:06Z",
      "updated": "2025-04-29T01:50:06Z",
      "summary": "Software is omnipresent within all factors of society. It is thus important\nto ensure that software are well tested to mitigate bad user experiences as\nwell as the potential for severe financial and human losses. Software testing\nis however expensive and absorbs valuable time and resources. As a result, the\nfield of automated software testing has grown of interest to researchers in\npast decades. In our review of present and past research papers, we have\nidentified an information gap in the areas of improvement for the Genetic\nAlgorithm and Particle Swarm Optimisation. A gap in knowledge in the current\nchallenges that face automated testing has also been identified. We therefore\npresent this systematic literature review in an effort to consolidate existing\nknowledge in regards to the evolutionary approaches as well as their\nimprovements and resulting limitations. These improvements include hybrid\nalgorithm combinations as well as interoperability with mutation testing and\nneural networks. We will also explore the main test criterion that are used in\nthese algorithms alongside the challenges currently faced in the field related\nto readability, mocking and more.",
      "authors": [
        "Jason Wang",
        "Basem Suleiman",
        "Muhammad Johan Alibasa"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20357v1",
        "http://arxiv.org/pdf/2504.20357v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20323v1",
      "title": "Labeling Case Similarity based on Co-Citation of Legal Articles in\n  Judgment Documents with Empirical Dispute-Based Evaluation",
      "published": "2025-04-29T00:26:37Z",
      "updated": "2025-04-29T00:26:37Z",
      "summary": "This report addresses the challenge of limited labeled datasets for\ndeveloping legal recommender systems, particularly in specialized domains like\nlabor disputes. We propose a new approach leveraging the co-citation of legal\narticles within cases to establish similarity and enable algorithmic\nannotation. This method draws a parallel to the concept of case co-citation,\nutilizing cited precedents as indicators of shared legal issues. To evaluate\nthe labeled results, we employ a system that recommends similar cases based on\nplaintiffs' accusations, defendants' rebuttals, and points of disputes. The\nevaluation demonstrates that the recommender, with finetuned text embedding\nmodels and a reasonable BiLSTM module can recommend labor cases whose\nsimilarity was measured by the co-citation of the legal articles. This research\ncontributes to the development of automated annotation techniques for legal\ndocuments, particularly in areas with limited access to comprehensive legal\ndatabases.",
      "authors": [
        "Chao-Lin Liu",
        "Po-Hsien Wu",
        "Yi-Ting Yu"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20323v1",
        "http://arxiv.org/pdf/2504.20323v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20213v1",
      "title": "Can Large Language Models Learn Formal Logic? A Data-Driven Training and\n  Evaluation Framework",
      "published": "2025-04-28T19:25:29Z",
      "updated": "2025-04-28T19:25:29Z",
      "summary": "This paper investigates the logical reasoning capabilities of large language\nmodels (LLMs). For a precisely defined yet tractable formulation, we choose the\nconceptually simple but technically complex task of constructing proofs in\nBoolean logic. A trained LLM receives as input a set of assumptions and a goal,\nand produces as output a proof that formally derives the goal from the\nassumptions. Incorrect proofs are caught by an automated proof checker. A\ncritical obstacle for training is the scarcity of real-world proofs. We propose\nan efficient, randomized procedure for synthesizing valid proofs and introduce\nTemplate Transformation, a data augmentation technique that enhances the\nmodel's ability to handle complex logical expressions. The central evaluation\nquestion is whether an LLM has indeed learned to reason. We propose tests to\nmeasure the reasoning ability of a black-box LLM. By these measures,\nexperiments demonstrate strong reasoning capabilities for assertions with short\nproofs, which decline with proof complexity. Notably, template transformation\nimproves accuracy even for smaller models, suggesting its effectiveness across\nmodel scales.",
      "authors": [
        "Yuan Xia",
        "Akanksha Atrey",
        "Fadoua Khmaissia",
        "Kedar S. Namjoshi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20213v1",
        "http://arxiv.org/pdf/2504.20213v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20183v1",
      "title": "BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of\n  iterative optimisation heuristics",
      "published": "2025-04-28T18:34:09Z",
      "updated": "2025-04-28T18:34:09Z",
      "summary": "The application of Large Language Models (LLMs) for Automated Algorithm\nDiscovery (AAD), particularly for optimisation heuristics, is an emerging field\nof research. This emergence necessitates robust, standardised benchmarking\npractices to rigorously evaluate the capabilities and limitations of LLM-driven\nAAD methods and the resulting generated algorithms, especially given the\nopacity of their design process and known issues with existing benchmarks. To\naddress this need, we introduce BLADE (Benchmark suite for LLM-driven Automated\nDesign and Evolution), a modular and extensible framework specifically designed\nfor benchmarking LLM-driven AAD methods in a continuous black-box optimisation\ncontext. BLADE integrates collections of benchmark problems (including MA-BBOB\nand SBOX-COST among others) with instance generators and textual descriptions\naimed at capability-focused testing, such as generalisation, specialisation and\ninformation exploitation. It offers flexible experimental setup options,\nstandardised logging for reproducibility and fair comparison, incorporates\nmethods for analysing the AAD process (e.g., Code Evolution Graphs and various\nvisualisation approaches) and facilitates comparison against human-designed\nbaselines through integration with established tools like IOHanalyser and\nIOHexplainer. BLADE provides an `out-of-the-box' solution to systematically\nevaluate LLM-driven AAD approaches. The framework is demonstrated through two\ndistinct use cases exploring mutation prompt strategies and function\nspecialisation.",
      "authors": [
        "Niki van Stein",
        "Anna V. Kononova",
        "Haoran Yin",
        "Thomas B\u00e4ck"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20183v1",
        "http://arxiv.org/pdf/2504.20183v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20010v1",
      "title": "Towards Automated Scoping of AI for Social Good Projects",
      "published": "2025-04-28T17:29:51Z",
      "updated": "2025-04-28T17:29:51Z",
      "summary": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.",
      "authors": [
        "Jacob Emmerson",
        "Rayid Ghani",
        "Zheyuan Ryan Shi"
      ],
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20010v1",
        "http://arxiv.org/pdf/2504.20010v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19990v1",
      "title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and\n  Directions",
      "published": "2025-04-28T17:06:30Z",
      "updated": "2025-04-28T17:06:30Z",
      "summary": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.",
      "authors": [
        "Salem Lahlou"
      ],
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19990v1",
        "http://arxiv.org/pdf/2504.19990v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19933v1",
      "title": "Automated decision-making for dynamic task assignment at scale",
      "published": "2025-04-28T16:08:35Z",
      "updated": "2025-04-28T16:08:35Z",
      "summary": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.",
      "authors": [
        "Riccardo Lo Bianco",
        "Willem van Jaarsveld",
        "Jeroen Middelhuis",
        "Luca Begnardi",
        "Remco Dijkman"
      ],
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19933v1",
        "http://arxiv.org/pdf/2504.19933v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19848v1",
      "title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric\n  Study",
      "published": "2025-04-28T14:45:48Z",
      "updated": "2025-04-28T14:45:48Z",
      "summary": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.",
      "authors": [
        "Simona Casini",
        "Pietro Ducange",
        "Francesco Marcelloni",
        "Lorenzo Pollini"
      ],
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19848v1",
        "http://arxiv.org/pdf/2504.19848v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19838v1",
      "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and\n  Prospects",
      "published": "2025-04-28T14:39:25Z",
      "updated": "2025-04-28T14:39:25Z",
      "summary": "With the rapid rise of large language models (LLMs), phone automation has\nundergone transformative changes. This paper systematically reviews LLM-driven\nphone GUI agents, highlighting their evolution from script-based automation to\nintelligent, adaptive systems. We first contextualize key challenges, (i)\nlimited generality, (ii) high maintenance overhead, and (iii) weak intent\ncomprehension, and show how LLMs address these issues through advanced language\nunderstanding, multimodal perception, and robust decision-making. We then\npropose a taxonomy covering fundamental agent frameworks (single-agent,\nmulti-agent, plan-then-act), modeling approaches (prompt engineering,\ntraining-based), and essential datasets and benchmarks. Furthermore, we detail\ntask-specific architectures, supervised fine-tuning, and reinforcement learning\nstrategies that bridge user intent and GUI operations. Finally, we discuss open\nchallenges such as dataset diversity, on-device deployment efficiency,\nuser-centric adaptation, and security concerns, offering forward-looking\ninsights into this rapidly evolving field. By providing a structured overview\nand identifying pressing research gaps, this paper serves as a definitive\nreference for researchers and practitioners seeking to harness LLMs in\ndesigning scalable, user-friendly phone GUI agents.",
      "authors": [
        "Guangyi Liu",
        "Pengxiang Zhao",
        "Liang Liu",
        "Yaxuan Guo",
        "Han Xiao",
        "Weifeng Lin",
        "Yuxiang Chai",
        "Yue Han",
        "Shuai Ren",
        "Hao Wang",
        "Xiaoyu Liang",
        "Wenhao Wang",
        "Tianze Wu",
        "Linghao Li",
        "Hao Wang",
        "Guanjing Xiong",
        "Yong Liu",
        "Hongsheng Li"
      ],
      "categories": [
        "cs.HC"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19838v1",
        "http://arxiv.org/pdf/2504.19838v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19818v1",
      "title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated\n  Plant Phenotyping",
      "published": "2025-04-28T14:20:30Z",
      "updated": "2025-04-28T14:20:30Z",
      "summary": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.",
      "authors": [
        "Feng Chen",
        "Ilias Stogiannidis",
        "Andrew Wood",
        "Danilo Bueno",
        "Dominic Williams",
        "Fraser Macfarlane",
        "Bruce Grieve",
        "Darren Wells",
        "Jonathan A. Atkinson",
        "Malcolm J. Hawkesford",
        "Stephen A. Rolfe",
        "Tracy Lawson",
        "Tony Pridmore",
        "Mario Valerio Giuffrida",
        "Sotirios A. Tsaftaris"
      ],
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19818v1",
        "http://arxiv.org/pdf/2504.19818v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19678v1",
      "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review",
      "published": "2025-04-28T11:08:22Z",
      "updated": "2025-04-28T11:08:22Z",
      "summary": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.",
      "authors": [
        "Mohamed Amine Ferrag",
        "Norbert Tihanyi",
        "Merouane Debbah"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19678v1",
        "http://arxiv.org/pdf/2504.19678v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19674v1",
      "title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation",
      "published": "2025-04-28T11:01:08Z",
      "updated": "2025-04-28T11:01:08Z",
      "summary": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.",
      "authors": [
        "Madhur Jindal",
        "Hari Shrawgi",
        "Parag Agrawal",
        "Sandipan Dandapat"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19674v1",
        "http://arxiv.org/pdf/2504.19674v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19667v1",
      "title": "A Tripartite Perspective on GraphRAG",
      "published": "2025-04-28T10:43:35Z",
      "updated": "2025-04-28T10:43:35Z",
      "summary": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.",
      "authors": [
        "Michael Banf",
        "Johannes Kuhn"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19667v1",
        "http://arxiv.org/pdf/2504.19667v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19636v2",
      "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm\n  Search",
      "published": "2025-04-28T09:52:41Z",
      "updated": "2025-05-01T08:33:32Z",
      "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.",
      "authors": [
        "Fei Liu",
        "Qingfu Zhang",
        "Xialiang Tong",
        "Kun Mao",
        "Mingxuan Yuan"
      ],
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19636v2",
        "http://arxiv.org/pdf/2504.19636v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20119v2",
      "title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and\n  Datasets",
      "published": "2025-04-28T08:22:19Z",
      "updated": "2025-05-01T13:03:37Z",
      "summary": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.",
      "authors": [
        "Lorenz Brehme",
        "Thomas Str\u00f6hle",
        "Ruth Breu"
      ],
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20119v2",
        "http://arxiv.org/pdf/2504.20119v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20117v1",
      "title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification\n  of Research Methodologies",
      "published": "2025-04-28T07:18:45Z",
      "updated": "2025-04-28T07:18:45Z",
      "summary": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.",
      "authors": [
        "Shubham Gandhi",
        "Dhruv Shah",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Gautam Shroff"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20117v1",
        "http://arxiv.org/pdf/2504.20117v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20115v1",
      "title": "AutoP2C: An LLM-Based Agent Framework for Code Repository Generation\n  from Multimodal Content in Academic Papers",
      "published": "2025-04-28T05:47:37Z",
      "updated": "2025-04-28T05:47:37Z",
      "summary": "Machine Learning (ML) research is spread through academic papers featuring\nrich multimodal content, including text, diagrams, and tabular results.\nHowever, translating these multimodal elements into executable code remains a\nchallenging and time-consuming process that requires substantial ML expertise.\nWe introduce ``Paper-to-Code'' (P2C), a novel task that transforms the\nmultimodal content of scientific publications into fully executable code\nrepositories, which extends beyond the existing formulation of code generation\nthat merely converts textual descriptions into isolated code snippets. To\nautomate the P2C process, we propose AutoP2C, a multi-agent framework based on\nlarge language models that processes both textual and visual content from\nresearch papers to generate complete code repositories. Specifically, AutoP2C\ncontains four stages: (1) repository blueprint extraction from established\ncodebases, (2) multimodal content parsing that integrates information from\ntext, equations, and figures, (3) hierarchical task decomposition for\nstructured code generation, and (4) iterative feedback-driven debugging to\nensure functionality and performance. Evaluation on a benchmark of eight\nresearch papers demonstrates the effectiveness of AutoP2C, which can\nsuccessfully generate executable code repositories for all eight papers, while\nOpenAI-o1 or DeepSeek-R1 can only produce runnable code for one paper. The code\nis available at https://github.com/shoushouyu/Automated-Paper-to-Code.",
      "authors": [
        "Zijie Lin",
        "Yiqing Shen",
        "Qilin Cai",
        "He Sun",
        "Jinrui Zhou",
        "Mingjun Xiao"
      ],
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20115v1",
        "http://arxiv.org/pdf/2504.20115v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19480v1",
      "title": "An Automated Reinforcement Learning Reward Design Framework with Large\n  Language Model for Cooperative Platoon Coordination",
      "published": "2025-04-28T04:41:15Z",
      "updated": "2025-04-28T04:41:15Z",
      "summary": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.",
      "authors": [
        "Dixiao Wei",
        "Peng Yi",
        "Jinlong Lei",
        "Yiguang Hong",
        "Yuchuan Du"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19480v1",
        "http://arxiv.org/pdf/2504.19480v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19443v1",
      "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal\n  Learning and Symmetry-Aware Loss Functions",
      "published": "2025-04-28T03:10:24Z",
      "updated": "2025-04-28T03:10:24Z",
      "summary": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.",
      "authors": [
        "Yejin Jeong",
        "Donghun Lee"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19443v1",
        "http://arxiv.org/pdf/2504.19443v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.20113v1",
      "title": "Transforming Evidence Synthesis: A Systematic Review of the Evolution of\n  Automated Meta-Analysis in the Age of AI",
      "published": "2025-04-28T00:40:17Z",
      "updated": "2025-04-28T00:40:17Z",
      "summary": "Exponential growth in scientific literature has heightened the demand for\nefficient evidence-based synthesis, driving the rise of the field of Automated\nMeta-analysis (AMA) powered by natural language processing and machine\nlearning. This PRISMA systematic review introduces a structured framework for\nassessing the current state of AMA, based on screening 978 papers from 2006 to\n2024, and analyzing 54 studies across diverse domains. Findings reveal a\npredominant focus on automating data processing (57%), such as extraction and\nstatistical modeling, while only 17% address advanced synthesis stages. Just\none study (2%) explored preliminary full-process automation, highlighting a\ncritical gap that limits AMA's capacity for comprehensive synthesis. Despite\nrecent breakthroughs in large language models (LLMs) and advanced AI, their\nintegration into statistical modeling and higher-order synthesis, such as\nheterogeneity assessment and bias evaluation, remains underdeveloped. This has\nconstrained AMA's potential for fully autonomous meta-analysis. From our\ndataset spanning medical (67%) and non-medical (33%) applications, we found\nthat AMA has exhibited distinct implementation patterns and varying degrees of\neffectiveness in actually improving efficiency, scalability, and\nreproducibility. While automation has enhanced specific meta-analytic tasks,\nachieving seamless, end-to-end automation remains an open challenge. As AI\nsystems advance in reasoning and contextual understanding, addressing these\ngaps is now imperative. Future efforts must focus on bridging automation across\nall meta-analysis stages, refining interpretability, and ensuring\nmethodological robustness to fully realize AMA's potential for scalable,\ndomain-agnostic synthesis.",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.20113v1",
        "http://arxiv.org/pdf/2504.20113v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19323v2",
      "title": "NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture\n  for Neuro-Symbolic AI",
      "published": "2025-04-27T18:28:43Z",
      "updated": "2025-04-29T14:56:56Z",
      "summary": "Neuro-Symbolic AI (NSAI) is an emerging paradigm that integrates neural\nnetworks with symbolic reasoning to enhance the transparency, reasoning\ncapabilities, and data efficiency of AI systems. Recent NSAI systems have\ngained traction due to their exceptional performance in reasoning tasks and\nhuman-AI collaborative scenarios. Despite these algorithmic advancements,\nexecuting NSAI tasks on existing hardware (e.g., CPUs, GPUs, TPUs) remains\nchallenging, due to their heterogeneous computing kernels, high memory\nintensity, and unique memory access patterns. Moreover, current NSAI algorithms\nexhibit significant variation in operation types and scales, making them\nincompatible with existing ML accelerators. These challenges highlight the need\nfor a versatile and flexible acceleration framework tailored to NSAI workloads.\nIn this paper, we propose NSFlow, an FPGA-based acceleration framework designed\nto achieve high efficiency, scalability, and versatility across NSAI systems.\nNSFlow features a design architecture generator that identifies workload data\ndependencies and creates optimized dataflow architectures, as well as a\nreconfigurable array with flexible compute units, re-organizable memory, and\nmixed-precision capabilities. Evaluating across NSAI workloads, NSFlow achieves\n31x speedup over Jetson TX2, more than 2x over GPU, 8x speedup over TPU-like\nsystolic array, and more than 3x over Xilinx DPU. NSFlow also demonstrates\nenhanced scalability, with only 4x runtime increase when symbolic workloads\nscale by 150x. To the best of our knowledge, NSFlow is the first framework to\nenable real-time generalizable NSAI algorithms acceleration, demonstrating a\npromising solution for next-generation cognitive systems.",
      "authors": [
        "Hanchen Yang",
        "Zishen Wan",
        "Ritik Raj",
        "Joongun Park",
        "Ziwei Li",
        "Ananda Samajdar",
        "Arijit Raychowdhury",
        "Tushar Krishna"
      ],
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19323v2",
        "http://arxiv.org/pdf/2504.19323v2"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2504.19284v1",
      "title": "Ethical Challenges of Using Artificial Intelligence in Judiciary",
      "published": "2025-04-27T15:51:56Z",
      "updated": "2025-04-27T15:51:56Z",
      "summary": "Artificial intelligence (AI) has emerged as a ubiquitous concept in numerous\ndomains, including the legal system. AI has the potential to revolutionize the\nfunctioning of the judiciary and the dispensation of justice. Incorporating AI\ninto the legal system offers the prospect of enhancing decision-making for\njudges, lawyers, and legal professionals, while concurrently providing the\npublic with more streamlined, efficient, and cost-effective services. The\nintegration of AI into the legal landscape offers manifold benefits,\nencompassing tasks such as document review, legal research, contract analysis,\ncase prediction, and decision-making. By automating laborious and error-prone\nprocedures, AI has the capacity to alleviate the burden associated with these\narduous tasks. Consequently, courts around the world have begun embracing AI\ntechnology as a means to enhance the administration of justice. However,\nalongside its potential advantages, the use of AI in the judiciary poses a\nrange of ethical challenges. These ethical quandaries must be duly addressed to\nensure the responsible and equitable deployment of AI systems. This article\ndelineates the principal ethical challenges entailed in employing AI within the\njudiciary and provides recommendations to effectively address these issues.",
      "authors": [
        "Angel Mary John",
        "Aiswarya M. U.",
        "Jerrin Thomas Panachakel"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": [
        "http://arxiv.org/abs/2504.19284v1",
        "http://arxiv.org/pdf/2504.19284v1"
      ],
      "primary_search_term": "artificial intelligence",
      "secondary_search_terms": [
        "labor market",
        "employment",
        "jobs",
        "workforce",
        "automation"
      ]
    }
  ]
}